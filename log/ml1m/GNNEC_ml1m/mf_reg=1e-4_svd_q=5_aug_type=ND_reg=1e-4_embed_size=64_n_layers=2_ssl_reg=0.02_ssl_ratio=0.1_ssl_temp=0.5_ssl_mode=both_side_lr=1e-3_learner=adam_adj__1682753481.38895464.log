2023-04-29 15:31:21.389: my pid: 32706
2023-04-29 15:31:21.389: model: model.general_recommender.GNNEC_ml1m
2023-04-29 15:31:21.389: Dataset statistics:
Name: ml1m
The number of users: 6040
The number of items: 3706
The number of ratings: 1000209
Average actions of users: 165.60
Average actions of items: 269.89
The sparsity of the dataset: 95.531637%

The number of training: 902826
The number of validation: 0
The number of testing: 97383
2023-04-29 15:31:21.389: NeuRec:[NeuRec]:
recommender=GNNEC_ml1m
dataset=ml1m
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC_ml1m:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=100
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC_ml1m
dataset=ml1m
epochs=100
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
mf_reg=1e-4
svd_q=5
2023-04-29 15:31:27.087: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-04-29 15:32:28.613: [iter 1 : loss : 0.9417 = 0.6831 + 0.2586 + 0.0000, time: 61.524163]
2023-04-29 15:32:29.015: epoch 1:	0.09412146  	0.15075016  	0.16199093  
2023-04-29 15:32:29.015: Find a better model.
2023-04-29 15:33:33.089: [iter 2 : loss : 0.6527 = 0.3526 + 0.2995 + 0.0006, time: 64.037760]
2023-04-29 15:33:33.533: epoch 2:	0.09904655  	0.15413888  	0.16569519  
2023-04-29 15:33:33.534: Find a better model.
2023-04-29 15:34:38.326: [iter 3 : loss : 0.5535 = 0.2582 + 0.2942 + 0.0010, time: 64.765758]
2023-04-29 15:34:38.753: epoch 3:	0.11516373  	0.18219653  	0.19354820  
2023-04-29 15:34:38.753: Find a better model.
2023-04-29 15:35:43.245: [iter 4 : loss : 0.5186 = 0.2285 + 0.2888 + 0.0013, time: 64.452956]
2023-04-29 15:35:43.712: epoch 4:	0.12437719  	0.19828883  	0.20909956  
2023-04-29 15:35:43.718: Find a better model.
2023-04-29 15:36:48.157: [iter 5 : loss : 0.4980 = 0.2107 + 0.2857 + 0.0015, time: 64.403288]
2023-04-29 15:36:48.555: epoch 5:	0.13080938  	0.20980591  	0.21980546  
2023-04-29 15:36:48.556: Find a better model.
2023-04-29 15:37:53.467: [iter 6 : loss : 0.4835 = 0.1981 + 0.2837 + 0.0018, time: 64.888327]
2023-04-29 15:37:53.907: epoch 6:	0.13503131  	0.21639270  	0.22672978  
2023-04-29 15:37:53.913: Find a better model.
2023-04-29 15:38:58.334: [iter 7 : loss : 0.4742 = 0.1903 + 0.2820 + 0.0020, time: 64.388702]
2023-04-29 15:38:58.758: epoch 7:	0.13892196  	0.22458716  	0.23336244  
2023-04-29 15:38:58.758: Find a better model.
2023-04-29 15:40:03.034: [iter 8 : loss : 0.4651 = 0.1823 + 0.2806 + 0.0021, time: 64.241258]
2023-04-29 15:40:03.499: epoch 8:	0.14147195  	0.22905664  	0.23819686  
2023-04-29 15:40:03.499: Find a better model.
2023-04-29 15:41:07.969: [iter 9 : loss : 0.4571 = 0.1754 + 0.2794 + 0.0023, time: 64.434770]
2023-04-29 15:41:08.416: epoch 9:	0.14421199  	0.23398526  	0.24327600  
2023-04-29 15:41:08.417: Find a better model.
2023-04-29 15:42:11.194: [iter 10 : loss : 0.4506 = 0.1698 + 0.2784 + 0.0025, time: 62.736987]
2023-04-29 15:42:11.624: epoch 10:	0.14625658  	0.23857082  	0.24713317  
2023-04-29 15:42:11.624: Find a better model.
2023-04-29 15:43:16.179: [iter 11 : loss : 0.4447 = 0.1646 + 0.2775 + 0.0026, time: 64.509755]
2023-04-29 15:43:16.613: epoch 11:	0.14821830  	0.24165219  	0.25075930  
2023-04-29 15:43:16.613: Find a better model.
2023-04-29 15:44:21.133: [iter 12 : loss : 0.4397 = 0.1603 + 0.2767 + 0.0028, time: 64.494875]
2023-04-29 15:44:21.559: epoch 12:	0.14984916  	0.24394679  	0.25303590  
2023-04-29 15:44:21.559: Find a better model.
2023-04-29 15:45:24.436: [iter 13 : loss : 0.4351 = 0.1562 + 0.2759 + 0.0029, time: 62.839268]
2023-04-29 15:45:24.842: epoch 13:	0.15116544  	0.24709313  	0.25583595  
2023-04-29 15:45:24.843: Find a better model.
2023-04-29 15:46:28.866: [iter 14 : loss : 0.4300 = 0.1516 + 0.2752 + 0.0031, time: 63.993366]
2023-04-29 15:46:29.279: epoch 14:	0.15262234  	0.24960749  	0.25857264  
2023-04-29 15:46:29.279: Find a better model.
2023-04-29 15:47:33.766: [iter 15 : loss : 0.4268 = 0.1490 + 0.2746 + 0.0032, time: 64.457140]
2023-04-29 15:47:34.174: epoch 15:	0.15356600  	0.25099105  	0.26034784  
2023-04-29 15:47:34.175: Find a better model.
2023-04-29 15:48:38.864: [iter 16 : loss : 0.4224 = 0.1450 + 0.2740 + 0.0033, time: 64.656001]
2023-04-29 15:48:39.280: epoch 16:	0.15453447  	0.25298202  	0.26211837  
2023-04-29 15:48:39.280: Find a better model.
2023-04-29 15:49:44.184: [iter 17 : loss : 0.4194 = 0.1425 + 0.2735 + 0.0035, time: 64.874101]
2023-04-29 15:49:44.610: epoch 17:	0.15537070  	0.25407770  	0.26348418  
2023-04-29 15:49:44.610: Find a better model.
2023-04-29 15:50:49.496: [iter 18 : loss : 0.4161 = 0.1395 + 0.2730 + 0.0036, time: 64.853309]
2023-04-29 15:50:49.923: epoch 18:	0.15619847  	0.25542936  	0.26541251  
2023-04-29 15:50:49.923: Find a better model.
2023-04-29 15:51:52.551: [iter 19 : loss : 0.4134 = 0.1372 + 0.2725 + 0.0037, time: 62.589022]
2023-04-29 15:51:52.967: epoch 19:	0.15718368  	0.25724036  	0.26703048  
2023-04-29 15:51:52.967: Find a better model.
2023-04-29 15:52:57.564: [iter 20 : loss : 0.4103 = 0.1344 + 0.2721 + 0.0039, time: 64.564084]
2023-04-29 15:52:57.975: epoch 20:	0.15804462  	0.25899476  	0.26820511  
2023-04-29 15:52:57.975: Find a better model.
2023-04-29 15:54:02.227: [iter 21 : loss : 0.4078 = 0.1322 + 0.2717 + 0.0040, time: 64.207101]
2023-04-29 15:54:02.609: epoch 21:	0.15891388  	0.26068413  	0.26963520  
2023-04-29 15:54:02.610: Find a better model.
2023-04-29 15:55:07.627: [iter 22 : loss : 0.4052 = 0.1298 + 0.2713 + 0.0041, time: 64.986499]
2023-04-29 15:55:08.031: epoch 22:	0.15996526  	0.26280227  	0.27091813  
2023-04-29 15:55:08.031: Find a better model.
2023-04-29 15:56:04.951: [iter 23 : loss : 0.4019 = 0.1267 + 0.2710 + 0.0043, time: 56.884965]
2023-04-29 15:56:05.396: epoch 23:	0.16032946  	0.26380292  	0.27202937  
2023-04-29 15:56:05.396: Find a better model.
2023-04-29 15:57:00.245: [iter 24 : loss : 0.4006 = 0.1255 + 0.2706 + 0.0044, time: 54.823572]
2023-04-29 15:57:00.669: epoch 24:	0.16122334  	0.26640284  	0.27372569  
2023-04-29 15:57:00.675: Find a better model.
2023-04-29 15:57:55.437: [iter 25 : loss : 0.3994 = 0.1246 + 0.2703 + 0.0045, time: 54.723570]
2023-04-29 15:57:55.858: epoch 25:	0.16153803  	0.26705921  	0.27406123  
2023-04-29 15:57:55.858: Find a better model.
2023-04-29 15:58:50.211: [iter 26 : loss : 0.3961 = 0.1215 + 0.2699 + 0.0046, time: 54.317869]
2023-04-29 15:58:50.632: epoch 26:	0.16200152  	0.26787078  	0.27554625  
2023-04-29 15:58:50.632: Find a better model.
2023-04-29 15:59:46.261: [iter 27 : loss : 0.3943 = 0.1198 + 0.2697 + 0.0047, time: 55.574455]
2023-04-29 15:59:46.647: epoch 27:	0.16248158  	0.26891154  	0.27631620  
2023-04-29 15:59:46.647: Find a better model.
2023-04-29 16:00:43.563: [iter 28 : loss : 0.3924 = 0.1181 + 0.2694 + 0.0049, time: 56.877059]
2023-04-29 16:00:43.973: epoch 28:	0.16293682  	0.26957291  	0.27750856  
2023-04-29 16:00:43.973: Find a better model.
2023-04-29 16:01:48.153: [iter 29 : loss : 0.3908 = 0.1167 + 0.2692 + 0.0050, time: 64.147092]
2023-04-29 16:01:48.592: epoch 29:	0.16316032  	0.26971242  	0.27736771  
2023-04-29 16:01:48.598: Find a better model.
2023-04-29 16:02:49.928: [iter 30 : loss : 0.3883 = 0.1142 + 0.2689 + 0.0051, time: 61.292294]
2023-04-29 16:02:50.379: epoch 30:	0.16366540  	0.27119631  	0.27864075  
2023-04-29 16:02:50.379: Find a better model.
2023-04-29 16:03:54.910: [iter 31 : loss : 0.3871 = 0.1131 + 0.2687 + 0.0052, time: 64.496663]
2023-04-29 16:03:55.356: epoch 31:	0.16399647  	0.27154222  	0.27848491  
2023-04-29 16:03:55.356: Find a better model.
2023-04-29 16:04:59.738: [iter 32 : loss : 0.3857 = 0.1118 + 0.2686 + 0.0053, time: 64.347532]
2023-04-29 16:05:00.125: epoch 32:	0.16407102  	0.27199471  	0.27878803  
2023-04-29 16:05:00.125: Find a better model.
2023-04-29 16:06:04.449: [iter 33 : loss : 0.3844 = 0.1108 + 0.2682 + 0.0054, time: 64.276349]
2023-04-29 16:06:04.889: epoch 33:	0.16489042  	0.27273238  	0.27940717  
2023-04-29 16:06:04.889: Find a better model.
2023-04-29 16:07:09.152: [iter 34 : loss : 0.3827 = 0.1092 + 0.2681 + 0.0055, time: 64.223731]
2023-04-29 16:07:09.605: epoch 34:	0.16523004  	0.27361292  	0.27985874  
2023-04-29 16:07:09.605: Find a better model.
2023-04-29 16:08:14.202: [iter 35 : loss : 0.3811 = 0.1076 + 0.2679 + 0.0056, time: 64.569935]
2023-04-29 16:08:14.591: epoch 35:	0.16503955  	0.27356225  	0.28027800  
2023-04-29 16:09:12.684: [iter 36 : loss : 0.3805 = 0.1071 + 0.2677 + 0.0057, time: 58.060927]
2023-04-29 16:09:13.072: epoch 36:	0.16530454  	0.27357605  	0.28056666  
2023-04-29 16:10:17.594: [iter 37 : loss : 0.3796 = 0.1063 + 0.2675 + 0.0058, time: 64.491850]
2023-04-29 16:10:18.043: epoch 37:	0.16559418  	0.27444431  	0.28103936  
2023-04-29 16:10:18.049: Find a better model.
2023-04-29 16:11:22.061: [iter 38 : loss : 0.3786 = 0.1054 + 0.2674 + 0.0059, time: 63.976746]
2023-04-29 16:11:22.462: epoch 38:	0.16614883  	0.27483088  	0.28158084  
2023-04-29 16:11:22.462: Find a better model.
2023-04-29 16:12:27.034: [iter 39 : loss : 0.3767 = 0.1035 + 0.2672 + 0.0060, time: 64.534489]
2023-04-29 16:12:27.468: epoch 39:	0.16618201  	0.27500346  	0.28162730  
2023-04-29 16:12:27.468: Find a better model.
2023-04-29 16:13:29.760: [iter 40 : loss : 0.3752 = 0.1022 + 0.2670 + 0.0061, time: 62.263497]
2023-04-29 16:13:30.183: epoch 40:	0.16631465  	0.27507311  	0.28162527  
2023-04-29 16:13:30.183: Find a better model.
2023-04-29 16:14:34.005: [iter 41 : loss : 0.3746 = 0.1015 + 0.2669 + 0.0062, time: 63.777531]
2023-04-29 16:14:34.426: epoch 41:	0.16666219  	0.27641106  	0.28223062  
2023-04-29 16:14:34.426: Find a better model.
2023-04-29 16:15:36.111: [iter 42 : loss : 0.3732 = 0.1003 + 0.2667 + 0.0063, time: 61.654626]
2023-04-29 16:15:36.541: epoch 42:	0.16681950  	0.27654222  	0.28234968  
2023-04-29 16:15:36.542: Find a better model.
2023-04-29 16:16:40.731: [iter 43 : loss : 0.3720 = 0.0991 + 0.2665 + 0.0064, time: 64.152861]
2023-04-29 16:16:41.166: epoch 43:	0.16724168  	0.27728373  	0.28272510  
2023-04-29 16:16:41.166: Find a better model.
2023-04-29 16:17:45.210: [iter 44 : loss : 0.3709 = 0.0979 + 0.2664 + 0.0065, time: 64.021149]
2023-04-29 16:17:45.628: epoch 44:	0.16730785  	0.27724990  	0.28325689  
2023-04-29 16:18:49.687: [iter 45 : loss : 0.3707 = 0.0978 + 0.2664 + 0.0066, time: 64.022480]
2023-04-29 16:18:50.100: epoch 45:	0.16738240  	0.27771673  	0.28332546  
2023-04-29 16:18:50.100: Find a better model.
2023-04-29 16:19:54.503: [iter 46 : loss : 0.3692 = 0.0963 + 0.2661 + 0.0067, time: 64.379222]
2023-04-29 16:19:54.965: epoch 46:	0.16763905  	0.27828923  	0.28394473  
2023-04-29 16:19:54.965: Find a better model.
2023-04-29 16:20:59.225: [iter 47 : loss : 0.3683 = 0.0955 + 0.2661 + 0.0068, time: 64.236531]
2023-04-29 16:20:59.635: epoch 47:	0.16787912  	0.27844715  	0.28420478  
2023-04-29 16:20:59.635: Find a better model.
2023-04-29 16:22:04.155: [iter 48 : loss : 0.3671 = 0.0942 + 0.2660 + 0.0069, time: 64.475330]
2023-04-29 16:22:04.573: epoch 48:	0.16794525  	0.27872780  	0.28459084  
2023-04-29 16:22:04.573: Find a better model.
2023-04-29 16:23:04.738: [iter 49 : loss : 0.3673 = 0.0946 + 0.2658 + 0.0070, time: 60.117472]
2023-04-29 16:23:05.163: epoch 49:	0.16826814  	0.27912793  	0.28499034  
2023-04-29 16:23:05.163: Find a better model.
2023-04-29 16:24:09.961: [iter 50 : loss : 0.3656 = 0.0928 + 0.2657 + 0.0070, time: 64.763041]
2023-04-29 16:24:10.380: epoch 50:	0.16864890  	0.27964967  	0.28547284  
2023-04-29 16:24:10.380: Find a better model.
2023-04-29 16:25:14.803: [iter 51 : loss : 0.3647 = 0.0920 + 0.2656 + 0.0071, time: 64.388105]
2023-04-29 16:25:15.210: epoch 51:	0.16894680  	0.27967778  	0.28558055  
2023-04-29 16:25:15.210: Find a better model.
2023-04-29 16:26:17.468: [iter 52 : loss : 0.3643 = 0.0917 + 0.2654 + 0.0072, time: 62.225345]
2023-04-29 16:26:17.876: epoch 52:	0.16902965  	0.27975884  	0.28579977  
2023-04-29 16:26:17.876: Find a better model.
2023-04-29 16:27:21.860: [iter 53 : loss : 0.3634 = 0.0908 + 0.2653 + 0.0073, time: 63.956425]
2023-04-29 16:27:22.279: epoch 53:	0.16912900  	0.27957982  	0.28527457  
2023-04-29 16:28:26.994: [iter 54 : loss : 0.3624 = 0.0898 + 0.2653 + 0.0074, time: 64.667383]
2023-04-29 16:28:27.381: epoch 54:	0.16917032  	0.27945614  	0.28571194  
2023-04-29 16:29:31.547: [iter 55 : loss : 0.3622 = 0.0895 + 0.2652 + 0.0075, time: 64.132538]
2023-04-29 16:29:31.938: epoch 55:	0.16926964  	0.28084984  	0.28579345  
2023-04-29 16:29:31.938: Find a better model.
2023-04-29 16:30:36.349: [iter 56 : loss : 0.3604 = 0.0878 + 0.2650 + 0.0076, time: 64.379493]
2023-04-29 16:30:36.789: epoch 56:	0.16917849  	0.27996382  	0.28535107  
2023-04-29 16:31:41.162: [iter 57 : loss : 0.3601 = 0.0875 + 0.2650 + 0.0076, time: 64.334179]
2023-04-29 16:31:41.626: epoch 57:	0.16928622  	0.27984387  	0.28535572  
2023-04-29 16:32:46.502: [iter 58 : loss : 0.3594 = 0.0868 + 0.2649 + 0.0077, time: 64.840508]
2023-04-29 16:32:46.934: epoch 58:	0.16940215  	0.27941722  	0.28540963  
2023-04-29 16:33:52.274: [iter 59 : loss : 0.3590 = 0.0864 + 0.2648 + 0.0078, time: 65.303841]
2023-04-29 16:33:52.717: epoch 59:	0.16944364  	0.28009456  	0.28540263  
2023-04-29 16:34:57.739: [iter 60 : loss : 0.3582 = 0.0857 + 0.2646 + 0.0079, time: 64.984474]
2023-04-29 16:34:58.157: epoch 60:	0.16945171  	0.28035322  	0.28561109  
2023-04-29 16:36:03.458: [iter 61 : loss : 0.3579 = 0.0853 + 0.2646 + 0.0080, time: 65.258783]
2023-04-29 16:36:03.871: epoch 61:	0.16948491  	0.27984330  	0.28545514  
2023-04-29 16:37:05.456: [iter 62 : loss : 0.3572 = 0.0847 + 0.2645 + 0.0080, time: 61.542480]
2023-04-29 16:37:05.880: epoch 62:	0.16971664  	0.27995905  	0.28581637  
2023-04-29 16:38:11.174: [iter 63 : loss : 0.3569 = 0.0843 + 0.2645 + 0.0081, time: 65.252772]
2023-04-29 16:38:11.567: epoch 63:	0.16985759  	0.27998483  	0.28574300  
2023-04-29 16:39:15.140: [iter 64 : loss : 0.3561 = 0.0836 + 0.2643 + 0.0082, time: 63.539214]
2023-04-29 16:39:15.568: epoch 64:	0.16997325  	0.28006873  	0.28547928  
2023-04-29 16:40:21.055: [iter 65 : loss : 0.3556 = 0.0831 + 0.2643 + 0.0083, time: 65.446713]
2023-04-29 16:40:21.464: epoch 65:	0.17041193  	0.28073257  	0.28577846  
2023-04-29 16:40:21.464: Early stopping is trigger at epoch: 65
2023-04-29 16:40:21.464: best_result@epoch 55:

2023-04-29 16:40:21.464: 		0.1693      	0.2808      	0.2858      

2023-09-01 15:59:00.021: my pid: 25994
2023-09-01 15:59:00.022: model: model.general_recommender.GNNEC
2023-09-01 15:59:00.022: Dataset statistics:
Name: ml1m
The number of users: 6040
The number of items: 3706
The number of ratings: 1000209
Average actions of users: 165.60
Average actions of items: 269.89
The sparsity of the dataset: 95.531637%

The number of training: 902826
The number of validation: 0
The number of testing: 97383
2023-09-01 15:59:00.022: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=ml1m
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=ml1m
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=5
mf_reg=0.02
svd_q=5
2023-09-01 15:59:04.740: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 15:59:32.581: [iter 1 : loss : 1.2464 = 0.5836 + 0.3317 + 0.0001 + 0.3310, time: 27.840606]
2023-09-01 15:59:32.808: epoch 1:	0.08106711  	0.12523471  	0.12873119  
2023-09-01 15:59:32.808: Find a better model.
2023-09-01 15:59:59.963: [iter 2 : loss : 1.0970 = 0.4454 + 0.3261 + 0.0003 + 0.3251, time: 27.112527]
2023-09-01 16:00:00.192: epoch 2:	0.08818610  	0.13449804  	0.13907389  
2023-09-01 16:00:00.192: Find a better model.
2023-09-01 16:00:27.480: [iter 3 : loss : 1.0415 = 0.3939 + 0.3241 + 0.0005 + 0.3231, time: 27.233895]
2023-09-01 16:00:27.711: epoch 3:	0.09491600  	0.14297110  	0.15075041  
2023-09-01 16:00:27.711: Find a better model.
2023-09-01 16:00:54.693: [iter 4 : loss : 1.0067 = 0.3619 + 0.3227 + 0.0007 + 0.3214, time: 26.930865]
2023-09-01 16:00:54.919: epoch 4:	0.10061114  	0.15147935  	0.16195793  
2023-09-01 16:00:54.919: Find a better model.
2023-09-01 16:01:21.794: [iter 5 : loss : 0.9822 = 0.3400 + 0.3213 + 0.0009 + 0.3200, time: 26.826352]
2023-09-01 16:01:22.024: epoch 5:	0.10470864  	0.15779102  	0.16793802  
2023-09-01 16:01:22.024: Find a better model.
2023-09-01 16:01:49.147: [iter 6 : loss : 0.9643 = 0.3244 + 0.3201 + 0.0010 + 0.3189, time: 27.083361]
2023-09-01 16:01:49.374: epoch 6:	0.10812747  	0.16370004  	0.17417181  
2023-09-01 16:01:49.374: Find a better model.
2023-09-01 16:02:16.555: [iter 7 : loss : 0.9523 = 0.3138 + 0.3194 + 0.0012 + 0.3180, time: 27.131840]
2023-09-01 16:02:16.780: epoch 7:	0.11148822  	0.16948843  	0.17954955  
2023-09-01 16:02:16.780: Find a better model.
2023-09-01 16:02:43.735: [iter 8 : loss : 0.9397 = 0.3024 + 0.3188 + 0.0013 + 0.3172, time: 26.909964]
2023-09-01 16:02:43.961: epoch 8:	0.11463384  	0.17355143  	0.18344854  
2023-09-01 16:02:43.961: Find a better model.
2023-09-01 16:03:11.244: [iter 9 : loss : 0.9281 = 0.2922 + 0.3181 + 0.0014 + 0.3164, time: 27.231921]
2023-09-01 16:03:11.469: epoch 9:	0.11782928  	0.17883089  	0.18858683  
2023-09-01 16:03:11.469: Find a better model.
2023-09-01 16:03:38.564: [iter 10 : loss : 0.9176 = 0.2832 + 0.3172 + 0.0016 + 0.3157, time: 27.054556]
2023-09-01 16:03:38.792: epoch 10:	0.12137235  	0.18466188  	0.19396603  
2023-09-01 16:03:38.792: Find a better model.
2023-09-01 16:04:05.727: [iter 11 : loss : 0.9082 = 0.2748 + 0.3167 + 0.0017 + 0.3149, time: 26.889385]
2023-09-01 16:04:05.953: epoch 11:	0.12440210  	0.19032480  	0.19964153  
2023-09-01 16:04:05.953: Find a better model.
2023-09-01 16:04:32.748: [iter 12 : loss : 0.8996 = 0.2674 + 0.3162 + 0.0018 + 0.3143, time: 26.756929]
2023-09-01 16:04:32.976: epoch 12:	0.12763885  	0.19675578  	0.20507570  
2023-09-01 16:04:32.976: Find a better model.
2023-09-01 16:04:59.755: [iter 13 : loss : 0.8919 = 0.2612 + 0.3151 + 0.0019 + 0.3136, time: 26.739697]
2023-09-01 16:04:59.981: epoch 13:	0.13061889  	0.20290169  	0.21082897  
2023-09-01 16:04:59.981: Find a better model.
2023-09-01 16:05:27.217: [iter 14 : loss : 0.8848 = 0.2553 + 0.3144 + 0.0021 + 0.3130, time: 27.187675]
2023-09-01 16:05:27.447: epoch 14:	0.13338384  	0.20666848  	0.21506989  
2023-09-01 16:05:27.447: Find a better model.
2023-09-01 16:05:54.301: [iter 15 : loss : 0.8790 = 0.2507 + 0.3138 + 0.0022 + 0.3124, time: 26.802698]
2023-09-01 16:05:54.526: epoch 15:	0.13573496  	0.21194680  	0.21962065  
2023-09-01 16:05:54.526: Find a better model.
2023-09-01 16:06:21.432: [iter 16 : loss : 0.8733 = 0.2455 + 0.3136 + 0.0023 + 0.3118, time: 26.864102]
2023-09-01 16:06:21.659: epoch 16:	0.13770509  	0.21592136  	0.22389124  
2023-09-01 16:06:21.659: Find a better model.
2023-09-01 16:06:48.602: [iter 17 : loss : 0.8678 = 0.2413 + 0.3128 + 0.0024 + 0.3113, time: 26.891741]
2023-09-01 16:06:48.827: epoch 17:	0.13970020  	0.21975142  	0.22769068  
2023-09-01 16:06:48.827: Find a better model.
2023-09-01 16:07:15.584: [iter 18 : loss : 0.8635 = 0.2373 + 0.3128 + 0.0025 + 0.3108, time: 26.714415]
2023-09-01 16:07:15.808: epoch 18:	0.14132288  	0.22306018  	0.23098336  
2023-09-01 16:07:15.808: Find a better model.
2023-09-01 16:07:42.598: [iter 19 : loss : 0.8582 = 0.2333 + 0.3120 + 0.0026 + 0.3103, time: 26.749294]
2023-09-01 16:07:42.825: epoch 19:	0.14314391  	0.22599813  	0.23419245  
2023-09-01 16:07:42.825: Find a better model.
2023-09-01 16:08:09.950: [iter 20 : loss : 0.8533 = 0.2292 + 0.3115 + 0.0028 + 0.3098, time: 27.089455]
2023-09-01 16:08:10.179: epoch 20:	0.14491537  	0.22879897  	0.23773901  
2023-09-01 16:08:10.179: Find a better model.
2023-09-01 16:08:37.177: [iter 21 : loss : 0.8495 = 0.2263 + 0.3110 + 0.0029 + 0.3093, time: 26.959318]
2023-09-01 16:08:37.403: epoch 21:	0.14623158  	0.23156971  	0.23990417  
2023-09-01 16:08:37.403: Find a better model.
2023-09-01 16:09:04.468: [iter 22 : loss : 0.8439 = 0.2214 + 0.3107 + 0.0030 + 0.3089, time: 27.022283]
2023-09-01 16:09:04.695: epoch 22:	0.14736566  	0.23395012  	0.24170551  
2023-09-01 16:09:04.695: Find a better model.
2023-09-01 16:09:31.625: [iter 23 : loss : 0.8394 = 0.2178 + 0.3100 + 0.0031 + 0.3084, time: 26.880427]
2023-09-01 16:09:31.852: epoch 23:	0.14845841  	0.23620266  	0.24462728  
2023-09-01 16:09:31.852: Find a better model.
2023-09-01 16:09:58.782: [iter 24 : loss : 0.8361 = 0.2152 + 0.3097 + 0.0032 + 0.3079, time: 26.890125]
2023-09-01 16:09:59.011: epoch 24:	0.14962557  	0.23771237  	0.24649514  
2023-09-01 16:09:59.011: Find a better model.
2023-09-01 16:10:25.681: [iter 25 : loss : 0.8336 = 0.2135 + 0.3093 + 0.0033 + 0.3075, time: 26.619737]
2023-09-01 16:10:25.910: epoch 25:	0.15059419  	0.24005552  	0.24878892  
2023-09-01 16:10:25.911: Find a better model.
2023-09-01 16:10:53.169: [iter 26 : loss : 0.8298 = 0.2098 + 0.3095 + 0.0034 + 0.3071, time: 27.213953]
2023-09-01 16:10:53.397: epoch 26:	0.15213390  	0.24281719  	0.25171959  
2023-09-01 16:10:53.397: Find a better model.
2023-09-01 16:11:20.633: [iter 27 : loss : 0.8253 = 0.2064 + 0.3087 + 0.0035 + 0.3067, time: 27.180713]
2023-09-01 16:11:20.862: epoch 27:	0.15251482  	0.24429785  	0.25305957  
2023-09-01 16:11:20.863: Find a better model.
2023-09-01 16:11:48.053: [iter 28 : loss : 0.8216 = 0.2032 + 0.3085 + 0.0036 + 0.3063, time: 27.141536]
2023-09-01 16:11:48.283: epoch 28:	0.15350799  	0.24627756  	0.25490895  
2023-09-01 16:11:48.283: Find a better model.
2023-09-01 16:12:15.368: [iter 29 : loss : 0.8184 = 0.2012 + 0.3077 + 0.0037 + 0.3059, time: 27.036833]
2023-09-01 16:12:15.597: epoch 29:	0.15447667  	0.24850085  	0.25690436  
2023-09-01 16:12:15.598: Find a better model.
2023-09-01 16:12:42.781: [iter 30 : loss : 0.8150 = 0.1983 + 0.3074 + 0.0038 + 0.3055, time: 27.136260]
2023-09-01 16:12:43.012: epoch 30:	0.15540391  	0.25016883  	0.25872838  
2023-09-01 16:12:43.013: Find a better model.
2023-09-01 16:13:10.206: [iter 31 : loss : 0.8119 = 0.1963 + 0.3066 + 0.0039 + 0.3051, time: 27.145157]
2023-09-01 16:13:10.432: epoch 31:	0.15627311  	0.25235656  	0.26060903  
2023-09-01 16:13:10.432: Find a better model.
2023-09-01 16:13:37.591: [iter 32 : loss : 0.8089 = 0.1935 + 0.3066 + 0.0040 + 0.3047, time: 27.114629]
2023-09-01 16:13:37.820: epoch 32:	0.15638904  	0.25270107  	0.26162940  
2023-09-01 16:13:37.820: Find a better model.
2023-09-01 16:14:04.986: [iter 33 : loss : 0.8068 = 0.1923 + 0.3060 + 0.0041 + 0.3043, time: 27.126667]
2023-09-01 16:14:05.213: epoch 33:	0.15724158  	0.25454676  	0.26307756  
2023-09-01 16:14:05.213: Find a better model.
2023-09-01 16:14:32.528: [iter 34 : loss : 0.8034 = 0.1899 + 0.3053 + 0.0042 + 0.3040, time: 27.271532]
2023-09-01 16:14:32.755: epoch 34:	0.15787080  	0.25604880  	0.26467517  
2023-09-01 16:14:32.756: Find a better model.
2023-09-01 16:14:59.849: [iter 35 : loss : 0.8013 = 0.1881 + 0.3053 + 0.0043 + 0.3036, time: 27.052211]
2023-09-01 16:15:00.075: epoch 35:	0.15808591  	0.25596583  	0.26514134  
2023-09-01 16:15:27.307: [iter 36 : loss : 0.7991 = 0.1866 + 0.3048 + 0.0044 + 0.3033, time: 27.182981]
2023-09-01 16:15:27.534: epoch 36:	0.15877302  	0.25705022  	0.26632085  
2023-09-01 16:15:27.535: Find a better model.
2023-09-01 16:15:54.669: [iter 37 : loss : 0.7967 = 0.1850 + 0.3042 + 0.0045 + 0.3029, time: 27.087001]
2023-09-01 16:15:54.899: epoch 37:	0.15920344  	0.25812575  	0.26758140  
2023-09-01 16:15:54.899: Find a better model.
2023-09-01 16:16:22.057: [iter 38 : loss : 0.7949 = 0.1835 + 0.3042 + 0.0046 + 0.3026, time: 27.113136]
2023-09-01 16:16:22.285: epoch 38:	0.15956777  	0.25945726  	0.26842645  
2023-09-01 16:16:22.286: Find a better model.
2023-09-01 16:16:49.387: [iter 39 : loss : 0.7920 = 0.1815 + 0.3035 + 0.0047 + 0.3023, time: 27.053304]
2023-09-01 16:16:49.613: epoch 39:	0.15973325  	0.26080960  	0.26914525  
2023-09-01 16:16:49.613: Find a better model.
2023-09-01 16:17:16.812: [iter 40 : loss : 0.7917 = 0.1807 + 0.3042 + 0.0048 + 0.3020, time: 27.152200]
2023-09-01 16:17:17.042: epoch 40:	0.16051149  	0.26258105  	0.27036098  
2023-09-01 16:17:17.042: Find a better model.
2023-09-01 16:17:44.217: [iter 41 : loss : 0.7876 = 0.1780 + 0.3031 + 0.0049 + 0.3016, time: 27.123800]
2023-09-01 16:17:44.449: epoch 41:	0.16131440  	0.26401043  	0.27179560  
2023-09-01 16:17:44.449: Find a better model.
2023-09-01 16:18:11.333: [iter 42 : loss : 0.7850 = 0.1758 + 0.3029 + 0.0050 + 0.3013, time: 26.829829]
2023-09-01 16:18:11.559: epoch 42:	0.16152978  	0.26447004  	0.27233499  
2023-09-01 16:18:11.559: Find a better model.
2023-09-01 16:18:38.481: [iter 43 : loss : 0.7830 = 0.1746 + 0.3023 + 0.0051 + 0.3010, time: 26.875247]
2023-09-01 16:18:38.704: epoch 43:	0.16200164  	0.26603764  	0.27351156  
2023-09-01 16:18:38.704: Find a better model.
2023-09-01 16:19:05.716: [iter 44 : loss : 0.7812 = 0.1728 + 0.3026 + 0.0052 + 0.3007, time: 26.961493]
2023-09-01 16:19:05.942: epoch 44:	0.16268875  	0.26770958  	0.27480829  
2023-09-01 16:19:05.942: Find a better model.
2023-09-01 16:19:32.877: [iter 45 : loss : 0.7809 = 0.1729 + 0.3023 + 0.0053 + 0.3004, time: 26.886989]
2023-09-01 16:19:33.101: epoch 45:	0.16289574  	0.26749179  	0.27539024  
2023-09-01 16:20:00.331: [iter 46 : loss : 0.7776 = 0.1707 + 0.3015 + 0.0054 + 0.3001, time: 27.174703]
2023-09-01 16:20:00.561: epoch 46:	0.16325983  	0.26884279  	0.27650985  
2023-09-01 16:20:00.562: Find a better model.
2023-09-01 16:20:27.808: [iter 47 : loss : 0.7760 = 0.1694 + 0.3013 + 0.0055 + 0.2998, time: 27.207350]
2023-09-01 16:20:28.037: epoch 47:	0.16344213  	0.26985416  	0.27701154  
2023-09-01 16:20:28.037: Find a better model.
2023-09-01 16:20:55.044: [iter 48 : loss : 0.7744 = 0.1680 + 0.3013 + 0.0056 + 0.2995, time: 26.953539]
2023-09-01 16:20:55.267: epoch 48:	0.16393872  	0.27052447  	0.27783984  
2023-09-01 16:20:55.267: Find a better model.
2023-09-01 16:21:22.168: [iter 49 : loss : 0.7741 = 0.1675 + 0.3017 + 0.0056 + 0.2992, time: 26.869010]
2023-09-01 16:21:22.394: epoch 49:	0.16426140  	0.27166119  	0.27852574  
2023-09-01 16:21:22.394: Find a better model.
2023-09-01 16:21:49.318: [iter 50 : loss : 0.7705 = 0.1653 + 0.3005 + 0.0057 + 0.2990, time: 26.886262]
2023-09-01 16:21:49.545: epoch 50:	0.16440214  	0.27191442  	0.27944660  
2023-09-01 16:21:49.545: Find a better model.
2023-09-01 16:22:16.861: [iter 51 : loss : 0.7696 = 0.1644 + 0.3008 + 0.0058 + 0.2986, time: 27.269365]
2023-09-01 16:22:17.089: epoch 51:	0.16489896  	0.27218682  	0.28022572  
2023-09-01 16:22:17.089: Find a better model.
2023-09-01 16:22:44.235: [iter 52 : loss : 0.7686 = 0.1640 + 0.3003 + 0.0059 + 0.2984, time: 27.097728]
2023-09-01 16:22:44.462: epoch 52:	0.16547009  	0.27429762  	0.28094453  
2023-09-01 16:22:44.462: Find a better model.
2023-09-01 16:23:11.657: [iter 53 : loss : 0.7660 = 0.1622 + 0.2997 + 0.0060 + 0.2981, time: 27.155037]
2023-09-01 16:23:11.886: epoch 53:	0.16561905  	0.27468845  	0.28107375  
2023-09-01 16:23:11.886: Find a better model.
2023-09-01 16:23:39.021: [iter 54 : loss : 0.7646 = 0.1614 + 0.2992 + 0.0061 + 0.2979, time: 27.079561]
2023-09-01 16:23:39.247: epoch 54:	0.16602483  	0.27482730  	0.28182796  
2023-09-01 16:23:39.247: Find a better model.
2023-09-01 16:24:06.427: [iter 55 : loss : 0.7631 = 0.1599 + 0.2995 + 0.0062 + 0.2976, time: 27.135417]
2023-09-01 16:24:06.654: epoch 55:	0.16603298  	0.27430591  	0.28171241  
2023-09-01 16:24:33.676: [iter 56 : loss : 0.7611 = 0.1585 + 0.2990 + 0.0063 + 0.2973, time: 26.979162]
2023-09-01 16:24:33.904: epoch 56:	0.16596682  	0.27424675  	0.28175807  
2023-09-01 16:25:01.185: [iter 57 : loss : 0.7604 = 0.1582 + 0.2988 + 0.0064 + 0.2971, time: 27.240196]
2023-09-01 16:25:01.411: epoch 57:	0.16623163  	0.27540949  	0.28253251  
2023-09-01 16:25:01.411: Find a better model.
2023-09-01 16:25:28.544: [iter 58 : loss : 0.7594 = 0.1571 + 0.2990 + 0.0065 + 0.2968, time: 27.084318]
2023-09-01 16:25:28.769: epoch 58:	0.16675322  	0.27612188  	0.28296894  
2023-09-01 16:25:28.770: Find a better model.
2023-09-01 16:25:56.099: [iter 59 : loss : 0.7578 = 0.1564 + 0.2983 + 0.0065 + 0.2965, time: 27.282665]
2023-09-01 16:25:56.327: epoch 59:	0.16648827  	0.27522326  	0.28307876  
2023-09-01 16:26:23.505: [iter 60 : loss : 0.7560 = 0.1550 + 0.2981 + 0.0066 + 0.2963, time: 27.130149]
2023-09-01 16:26:23.735: epoch 60:	0.16687742  	0.27602950  	0.28338709  
2023-09-01 16:26:51.005: [iter 61 : loss : 0.7546 = 0.1542 + 0.2976 + 0.0067 + 0.2960, time: 27.229445]
2023-09-01 16:26:51.234: epoch 61:	0.16728306  	0.27727842  	0.28453240  
2023-09-01 16:26:51.234: Find a better model.
2023-09-01 16:27:18.240: [iter 62 : loss : 0.7539 = 0.1533 + 0.2979 + 0.0068 + 0.2958, time: 26.968505]
2023-09-01 16:27:18.468: epoch 62:	0.16748165  	0.27807966  	0.28482160  
2023-09-01 16:27:18.469: Find a better model.
2023-09-01 16:27:45.799: [iter 63 : loss : 0.7531 = 0.1529 + 0.2978 + 0.0069 + 0.2955, time: 27.285860]
2023-09-01 16:27:46.029: epoch 63:	0.16785415  	0.27925447  	0.28576559  
2023-09-01 16:27:46.029: Find a better model.
2023-09-01 16:28:13.112: [iter 64 : loss : 0.7501 = 0.1511 + 0.2968 + 0.0070 + 0.2953, time: 27.042876]
2023-09-01 16:28:13.340: epoch 64:	0.16747335  	0.27757883  	0.28496873  
2023-09-01 16:28:40.745: [iter 65 : loss : 0.7491 = 0.1506 + 0.2964 + 0.0071 + 0.2950, time: 27.357860]
2023-09-01 16:28:40.976: epoch 65:	0.16801143  	0.27868402  	0.28597304  
2023-09-01 16:29:07.820: [iter 66 : loss : 0.7478 = 0.1496 + 0.2962 + 0.0072 + 0.2948, time: 26.802195]
2023-09-01 16:29:08.048: epoch 66:	0.16862407  	0.27997747  	0.28671509  
2023-09-01 16:29:08.048: Find a better model.
2023-09-01 16:29:35.263: [iter 67 : loss : 0.7478 = 0.1490 + 0.2970 + 0.0073 + 0.2945, time: 27.168513]
2023-09-01 16:29:35.489: epoch 67:	0.16849978  	0.27951682  	0.28691703  
2023-09-01 16:30:02.365: [iter 68 : loss : 0.7457 = 0.1480 + 0.2961 + 0.0073 + 0.2943, time: 26.836078]
2023-09-01 16:30:02.591: epoch 68:	0.16843365  	0.27898669  	0.28639010  
2023-09-01 16:30:29.849: [iter 69 : loss : 0.7438 = 0.1465 + 0.2958 + 0.0074 + 0.2940, time: 27.224873]
2023-09-01 16:30:30.071: epoch 69:	0.16874829  	0.27975777  	0.28676525  
2023-09-01 16:30:56.840: [iter 70 : loss : 0.7444 = 0.1473 + 0.2958 + 0.0075 + 0.2938, time: 26.728677]
2023-09-01 16:30:57.069: epoch 70:	0.16910410  	0.27979749  	0.28686887  
2023-09-01 16:31:24.134: [iter 71 : loss : 0.7428 = 0.1461 + 0.2955 + 0.0076 + 0.2936, time: 27.025877]
2023-09-01 16:31:24.359: epoch 71:	0.16903795  	0.27967411  	0.28724334  
2023-09-01 16:31:51.520: [iter 72 : loss : 0.7418 = 0.1449 + 0.2959 + 0.0077 + 0.2934, time: 27.112443]
2023-09-01 16:31:51.749: epoch 72:	0.16952623  	0.28020847  	0.28776100  
2023-09-01 16:31:51.749: Find a better model.
2023-09-01 16:32:19.033: [iter 73 : loss : 0.7412 = 0.1452 + 0.2951 + 0.0078 + 0.2931, time: 27.243630]
2023-09-01 16:32:19.263: epoch 73:	0.16934413  	0.28044429  	0.28795776  
2023-09-01 16:32:19.263: Find a better model.
2023-09-01 16:32:46.527: [iter 74 : loss : 0.7391 = 0.1437 + 0.2946 + 0.0078 + 0.2929, time: 27.220314]
2023-09-01 16:32:46.756: epoch 74:	0.16953453  	0.28014448  	0.28782701  
2023-09-01 16:33:13.834: [iter 75 : loss : 0.7386 = 0.1434 + 0.2945 + 0.0079 + 0.2927, time: 27.035357]
2023-09-01 16:33:14.065: epoch 75:	0.16975819  	0.28072071  	0.28832382  
2023-09-01 16:33:14.065: Find a better model.
2023-09-01 16:33:41.261: [iter 76 : loss : 0.7376 = 0.1427 + 0.2944 + 0.0080 + 0.2925, time: 27.160653]
2023-09-01 16:33:41.486: epoch 76:	0.16989885  	0.28141537  	0.28898141  
2023-09-01 16:33:41.486: Find a better model.
2023-09-01 16:34:08.703: [iter 77 : loss : 0.7361 = 0.1421 + 0.2936 + 0.0081 + 0.2922, time: 27.175824]
2023-09-01 16:34:08.927: epoch 77:	0.16998999  	0.28081575  	0.28907073  
2023-09-01 16:34:36.108: [iter 78 : loss : 0.7363 = 0.1420 + 0.2941 + 0.0082 + 0.2920, time: 27.142415]
2023-09-01 16:34:36.337: epoch 78:	0.16965051  	0.28010800  	0.28876230  
2023-09-01 16:35:03.176: [iter 79 : loss : 0.7340 = 0.1405 + 0.2933 + 0.0083 + 0.2918, time: 26.794302]
2023-09-01 16:35:03.403: epoch 79:	0.16963392  	0.28029004  	0.28872326  
2023-09-01 16:35:30.451: [iter 80 : loss : 0.7333 = 0.1402 + 0.2932 + 0.0084 + 0.2916, time: 27.003322]
2023-09-01 16:35:30.677: epoch 80:	0.16986571  	0.28064364  	0.28880501  
2023-09-01 16:35:57.969: [iter 81 : loss : 0.7319 = 0.1389 + 0.2932 + 0.0084 + 0.2914, time: 27.241863]
2023-09-01 16:35:58.199: epoch 81:	0.17022157  	0.28051776  	0.28914917  
2023-09-01 16:36:25.270: [iter 82 : loss : 0.7304 = 0.1380 + 0.2927 + 0.0085 + 0.2911, time: 27.017107]
2023-09-01 16:36:25.498: epoch 82:	0.17029621  	0.28114855  	0.28918561  
2023-09-01 16:36:52.709: [iter 83 : loss : 0.7303 = 0.1380 + 0.2928 + 0.0086 + 0.2909, time: 27.169321]
2023-09-01 16:36:52.941: epoch 83:	0.17051959  	0.28138050  	0.28959271  
2023-09-01 16:37:19.974: [iter 84 : loss : 0.7286 = 0.1369 + 0.2923 + 0.0087 + 0.2907, time: 26.992455]
2023-09-01 16:37:20.202: epoch 84:	0.17051128  	0.28186592  	0.28961167  
2023-09-01 16:37:20.202: Find a better model.
2023-09-01 16:37:47.148: [iter 85 : loss : 0.7284 = 0.1368 + 0.2924 + 0.0088 + 0.2905, time: 26.897027]
2023-09-01 16:37:47.378: epoch 85:	0.17067708  	0.28187171  	0.28987288  
2023-09-01 16:37:47.378: Find a better model.
2023-09-01 16:38:14.703: [iter 86 : loss : 0.7284 = 0.1365 + 0.2927 + 0.0088 + 0.2903, time: 27.280571]
2023-09-01 16:38:14.934: epoch 86:	0.17043689  	0.28124925  	0.28970724  
2023-09-01 16:38:41.818: [iter 87 : loss : 0.7272 = 0.1362 + 0.2920 + 0.0089 + 0.2901, time: 26.838783]
2023-09-01 16:38:42.047: epoch 87:	0.17051958  	0.28097746  	0.28959760  
2023-09-01 16:39:09.432: [iter 88 : loss : 0.7257 = 0.1353 + 0.2915 + 0.0090 + 0.2899, time: 27.345474]
2023-09-01 16:39:09.660: epoch 88:	0.17066038  	0.28190514  	0.28966367  
2023-09-01 16:39:09.661: Find a better model.
2023-09-01 16:39:36.812: [iter 89 : loss : 0.7256 = 0.1353 + 0.2915 + 0.0091 + 0.2897, time: 27.107511]
2023-09-01 16:39:37.044: epoch 89:	0.17033748  	0.28117350  	0.28959972  
2023-09-01 16:40:03.989: [iter 90 : loss : 0.7243 = 0.1340 + 0.2917 + 0.0092 + 0.2895, time: 26.894689]
2023-09-01 16:40:04.217: epoch 90:	0.17046183  	0.28109914  	0.28939506  
2023-09-01 16:40:31.272: [iter 91 : loss : 0.7236 = 0.1337 + 0.2914 + 0.0093 + 0.2893, time: 27.018347]
2023-09-01 16:40:31.498: epoch 91:	0.17017199  	0.28064746  	0.28882957  
2023-09-01 16:40:58.351: [iter 92 : loss : 0.7233 = 0.1339 + 0.2910 + 0.0093 + 0.2891, time: 26.799335]
2023-09-01 16:40:58.581: epoch 92:	0.17044534  	0.28050947  	0.28920272  
2023-09-01 16:41:25.422: [iter 93 : loss : 0.7219 = 0.1331 + 0.2906 + 0.0094 + 0.2889, time: 26.802379]
2023-09-01 16:41:25.650: epoch 93:	0.17042053  	0.28067568  	0.28917450  
2023-09-01 16:41:52.672: [iter 94 : loss : 0.7217 = 0.1328 + 0.2907 + 0.0095 + 0.2887, time: 26.984200]
2023-09-01 16:41:52.900: epoch 94:	0.17053643  	0.28049228  	0.28877544  
2023-09-01 16:42:20.070: [iter 95 : loss : 0.7206 = 0.1321 + 0.2904 + 0.0096 + 0.2885, time: 27.121216]
2023-09-01 16:42:20.302: epoch 95:	0.17060272  	0.28053162  	0.28867289  
2023-09-01 16:42:47.393: [iter 96 : loss : 0.7198 = 0.1319 + 0.2899 + 0.0097 + 0.2883, time: 27.039348]
2023-09-01 16:42:47.622: epoch 96:	0.17037086  	0.28017262  	0.28859341  
2023-09-01 16:43:14.392: [iter 97 : loss : 0.7194 = 0.1313 + 0.2903 + 0.0097 + 0.2881, time: 26.725571]
2023-09-01 16:43:14.618: epoch 97:	0.17055300  	0.28015965  	0.28846940  
2023-09-01 16:43:41.957: [iter 98 : loss : 0.7184 = 0.1307 + 0.2900 + 0.0098 + 0.2879, time: 27.297699]
2023-09-01 16:43:42.186: epoch 98:	0.17028807  	0.27885610  	0.28770292  
2023-09-01 16:43:42.186: Early stopping is trigger at epoch: 98
2023-09-01 16:43:42.186: best_result@epoch 88:

2023-09-01 16:43:42.186: 		0.1707      	0.2819      	0.2897      

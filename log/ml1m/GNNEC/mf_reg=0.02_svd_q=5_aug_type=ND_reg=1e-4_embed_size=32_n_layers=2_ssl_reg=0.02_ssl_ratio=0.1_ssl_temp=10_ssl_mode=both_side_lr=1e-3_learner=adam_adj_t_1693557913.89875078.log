2023-09-01 16:45:13.899: my pid: 24423
2023-09-01 16:45:13.899: model: model.general_recommender.GNNEC
2023-09-01 16:45:13.899: Dataset statistics:
Name: ml1m
The number of users: 6040
The number of items: 3706
The number of ratings: 1000209
Average actions of users: 165.60
Average actions of items: 269.89
The sparsity of the dataset: 95.531637%

The number of training: 902826
The number of validation: 0
The number of testing: 97383
2023-09-01 16:45:13.899: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=ml1m
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=10
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=ml1m
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=10
mf_reg=0.02
svd_q=5
2023-09-01 16:45:18.524: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 16:45:46.164: [iter 1 : loss : 1.2535 = 0.5834 + 0.3352 + 0.0001 + 0.3348, time: 27.639010]
2023-09-01 16:45:46.389: epoch 1:	0.07842651  	0.12275344  	0.12528519  
2023-09-01 16:45:46.389: Find a better model.
2023-09-01 16:46:13.245: [iter 2 : loss : 1.1165 = 0.4514 + 0.3327 + 0.0003 + 0.3322, time: 26.808278]
2023-09-01 16:46:13.473: epoch 2:	0.08232535  	0.12575448  	0.13019963  
2023-09-01 16:46:13.474: Find a better model.
2023-09-01 16:46:40.425: [iter 3 : loss : 1.0682 = 0.4043 + 0.3320 + 0.0005 + 0.3315, time: 26.905431]
2023-09-01 16:46:40.643: epoch 3:	0.08821923  	0.13226242  	0.13837650  
2023-09-01 16:46:40.643: Find a better model.
2023-09-01 16:47:07.121: [iter 4 : loss : 1.0333 = 0.3705 + 0.3315 + 0.0007 + 0.3307, time: 26.435957]
2023-09-01 16:47:07.343: epoch 4:	0.09396402  	0.14060208  	0.14877945  
2023-09-01 16:47:07.344: Find a better model.
2023-09-01 16:47:33.888: [iter 5 : loss : 1.0073 = 0.3458 + 0.3307 + 0.0008 + 0.3299, time: 26.511276]
2023-09-01 16:47:34.112: epoch 5:	0.09970064  	0.14902426  	0.15809786  
2023-09-01 16:47:34.112: Find a better model.
2023-09-01 16:48:00.647: [iter 6 : loss : 0.9889 = 0.3286 + 0.3299 + 0.0010 + 0.3293, time: 26.491183]
2023-09-01 16:48:00.870: epoch 6:	0.10444380  	0.15649949  	0.16706507  
2023-09-01 16:48:00.870: Find a better model.
2023-09-01 16:48:27.472: [iter 7 : loss : 0.9768 = 0.3173 + 0.3296 + 0.0011 + 0.3289, time: 26.566303]
2023-09-01 16:48:27.694: epoch 7:	0.10755612  	0.16285713  	0.17352070  
2023-09-01 16:48:27.694: Find a better model.
2023-09-01 16:48:54.274: [iter 8 : loss : 0.9647 = 0.3058 + 0.3293 + 0.0013 + 0.3284, time: 26.547311]
2023-09-01 16:48:54.493: epoch 8:	0.11102464  	0.16864704  	0.17887032  
2023-09-01 16:48:54.494: Find a better model.
2023-09-01 16:49:21.176: [iter 9 : loss : 0.9537 = 0.2953 + 0.3289 + 0.0014 + 0.3280, time: 26.651717]
2023-09-01 16:49:21.397: epoch 9:	0.11444359  	0.17394641  	0.18402798  
2023-09-01 16:49:21.397: Find a better model.
2023-09-01 16:49:47.975: [iter 10 : loss : 0.9440 = 0.2863 + 0.3285 + 0.0015 + 0.3277, time: 26.546282]
2023-09-01 16:49:48.201: epoch 10:	0.11723327  	0.17859085  	0.18879312  
2023-09-01 16:49:48.201: Find a better model.
2023-09-01 16:50:15.461: [iter 11 : loss : 0.9352 = 0.2780 + 0.3283 + 0.0017 + 0.3273, time: 27.214298]
2023-09-01 16:50:15.686: epoch 11:	0.12073485  	0.18453102  	0.19426894  
2023-09-01 16:50:15.686: Find a better model.
2023-09-01 16:50:42.744: [iter 12 : loss : 0.9275 = 0.2707 + 0.3280 + 0.0018 + 0.3270, time: 27.025420]
2023-09-01 16:50:42.974: epoch 12:	0.12416199  	0.19113159  	0.19991584  
2023-09-01 16:50:42.974: Find a better model.
2023-09-01 16:51:09.950: [iter 13 : loss : 0.9208 = 0.2646 + 0.3275 + 0.0019 + 0.3267, time: 26.928219]
2023-09-01 16:51:10.182: epoch 13:	0.12745668  	0.19748861  	0.20566149  
2023-09-01 16:51:10.182: Find a better model.
2023-09-01 16:51:37.305: [iter 14 : loss : 0.9143 = 0.2587 + 0.3272 + 0.0020 + 0.3264, time: 27.079597]
2023-09-01 16:51:37.533: epoch 14:	0.13002302  	0.20196460  	0.21016723  
2023-09-01 16:51:37.533: Find a better model.
2023-09-01 16:52:04.649: [iter 15 : loss : 0.9092 = 0.2541 + 0.3268 + 0.0021 + 0.3261, time: 27.068962]
2023-09-01 16:52:04.876: epoch 15:	0.13229127  	0.20579445  	0.21456295  
2023-09-01 16:52:04.876: Find a better model.
2023-09-01 16:52:31.699: [iter 16 : loss : 0.9039 = 0.2490 + 0.3268 + 0.0023 + 0.3259, time: 26.786517]
2023-09-01 16:52:31.932: epoch 16:	0.13410416  	0.20947151  	0.21856587  
2023-09-01 16:52:31.932: Find a better model.
2023-09-01 16:52:59.024: [iter 17 : loss : 0.8993 = 0.2449 + 0.3264 + 0.0024 + 0.3257, time: 27.049667]
2023-09-01 16:52:59.255: epoch 17:	0.13619031  	0.21370122  	0.22249730  
2023-09-01 16:52:59.255: Find a better model.
2023-09-01 16:53:26.300: [iter 18 : loss : 0.8953 = 0.2410 + 0.3265 + 0.0025 + 0.3254, time: 26.997842]
2023-09-01 16:53:26.527: epoch 18:	0.13779618  	0.21679814  	0.22566193  
2023-09-01 16:53:26.527: Find a better model.
2023-09-01 16:53:53.449: [iter 19 : loss : 0.8910 = 0.2372 + 0.3261 + 0.0026 + 0.3252, time: 26.873235]
2023-09-01 16:53:53.681: epoch 19:	0.13948484  	0.21982975  	0.22903846  
2023-09-01 16:53:53.681: Find a better model.
2023-09-01 16:54:20.622: [iter 20 : loss : 0.8866 = 0.2331 + 0.3258 + 0.0027 + 0.3250, time: 26.901373]
2023-09-01 16:54:20.849: epoch 20:	0.14133096  	0.22333597  	0.23262517  
2023-09-01 16:54:20.850: Find a better model.
2023-09-01 16:54:47.960: [iter 21 : loss : 0.8835 = 0.2303 + 0.3256 + 0.0028 + 0.3248, time: 27.064185]
2023-09-01 16:54:48.184: epoch 21:	0.14268035  	0.22621696  	0.23508316  
2023-09-01 16:54:48.184: Find a better model.
2023-09-01 16:55:15.377: [iter 22 : loss : 0.8787 = 0.2258 + 0.3255 + 0.0029 + 0.3246, time: 27.148987]
2023-09-01 16:55:15.606: epoch 22:	0.14346679  	0.22682253  	0.23666342  
2023-09-01 16:55:15.606: Find a better model.
2023-09-01 16:55:42.752: [iter 23 : loss : 0.8748 = 0.2222 + 0.3252 + 0.0030 + 0.3244, time: 27.102665]
2023-09-01 16:55:42.982: epoch 23:	0.14500649  	0.23017861  	0.23927300  
2023-09-01 16:55:42.982: Find a better model.
2023-09-01 16:56:10.041: [iter 24 : loss : 0.8720 = 0.2197 + 0.3251 + 0.0031 + 0.3242, time: 27.012017]
2023-09-01 16:56:10.268: epoch 24:	0.14580940  	0.23181464  	0.24119240  
2023-09-01 16:56:10.268: Find a better model.
2023-09-01 16:56:37.145: [iter 25 : loss : 0.8701 = 0.2180 + 0.3249 + 0.0032 + 0.3240, time: 26.836098]
2023-09-01 16:56:37.373: epoch 25:	0.14700146  	0.23396926  	0.24346903  
2023-09-01 16:56:37.373: Find a better model.
2023-09-01 16:57:04.491: [iter 26 : loss : 0.8664 = 0.2144 + 0.3250 + 0.0033 + 0.3238, time: 27.080033]
2023-09-01 16:57:04.712: epoch 26:	0.14861570  	0.23719032  	0.24668418  
2023-09-01 16:57:04.712: Find a better model.
2023-09-01 16:57:31.767: [iter 27 : loss : 0.8626 = 0.2110 + 0.3246 + 0.0034 + 0.3236, time: 27.017996]
2023-09-01 16:57:31.995: epoch 27:	0.14917023  	0.23817019  	0.24811393  
2023-09-01 16:57:31.995: Find a better model.
2023-09-01 16:57:59.066: [iter 28 : loss : 0.8593 = 0.2078 + 0.3246 + 0.0035 + 0.3234, time: 27.028786]
2023-09-01 16:57:59.294: epoch 28:	0.14997332  	0.23986331  	0.24954800  
2023-09-01 16:57:59.294: Find a better model.
2023-09-01 16:58:26.221: [iter 29 : loss : 0.8567 = 0.2057 + 0.3242 + 0.0036 + 0.3233, time: 26.881325]
2023-09-01 16:58:26.442: epoch 29:	0.15084256  	0.24190165  	0.25151700  
2023-09-01 16:58:26.442: Find a better model.
2023-09-01 16:58:53.427: [iter 30 : loss : 0.8536 = 0.2028 + 0.3240 + 0.0037 + 0.3231, time: 26.949552]
2023-09-01 16:58:53.655: epoch 30:	0.15180285  	0.24396496  	0.25356913  
2023-09-01 16:58:53.655: Find a better model.
2023-09-01 16:59:20.653: [iter 31 : loss : 0.8510 = 0.2007 + 0.3237 + 0.0038 + 0.3229, time: 26.958027]
2023-09-01 16:59:20.886: epoch 31:	0.15300319  	0.24581760  	0.25553849  
2023-09-01 16:59:20.886: Find a better model.
2023-09-01 16:59:47.945: [iter 32 : loss : 0.8483 = 0.1980 + 0.3237 + 0.0038 + 0.3227, time: 27.013382]
2023-09-01 16:59:48.172: epoch 32:	0.15364899  	0.24759667  	0.25680217  
2023-09-01 16:59:48.172: Find a better model.
2023-09-01 17:00:15.124: [iter 33 : loss : 0.8466 = 0.1967 + 0.3234 + 0.0039 + 0.3226, time: 26.910791]
2023-09-01 17:00:15.357: epoch 33:	0.15479119  	0.24977641  	0.25865734  
2023-09-01 17:00:15.357: Find a better model.
2023-09-01 17:00:42.469: [iter 34 : loss : 0.8438 = 0.1942 + 0.3231 + 0.0040 + 0.3224, time: 27.070268]
2023-09-01 17:00:42.696: epoch 34:	0.15527956  	0.25052032  	0.25992495  
2023-09-01 17:00:42.696: Find a better model.
2023-09-01 17:01:09.846: [iter 35 : loss : 0.8419 = 0.1924 + 0.3231 + 0.0041 + 0.3223, time: 27.105963]
2023-09-01 17:01:10.076: epoch 35:	0.15552789  	0.25080681  	0.26057410  
2023-09-01 17:01:10.076: Find a better model.
2023-09-01 17:01:37.267: [iter 36 : loss : 0.8400 = 0.1908 + 0.3229 + 0.0042 + 0.3221, time: 27.143762]
2023-09-01 17:01:37.495: epoch 36:	0.15595016  	0.25194225  	0.26170954  
2023-09-01 17:01:37.496: Find a better model.
2023-09-01 17:02:04.626: [iter 37 : loss : 0.8381 = 0.1892 + 0.3226 + 0.0043 + 0.3220, time: 27.080751]
2023-09-01 17:02:04.859: epoch 37:	0.15662907  	0.25345686  	0.26310492  
2023-09-01 17:02:04.859: Find a better model.
2023-09-01 17:02:31.944: [iter 38 : loss : 0.8364 = 0.1876 + 0.3226 + 0.0044 + 0.3218, time: 27.038022]
2023-09-01 17:02:32.170: epoch 38:	0.15725812  	0.25463820  	0.26400161  
2023-09-01 17:02:32.170: Find a better model.
2023-09-01 17:02:59.121: [iter 39 : loss : 0.8340 = 0.1855 + 0.3223 + 0.0045 + 0.3217, time: 26.906795]
2023-09-01 17:02:59.348: epoch 39:	0.15720856  	0.25490060  	0.26473361  
2023-09-01 17:02:59.348: Find a better model.
2023-09-01 17:03:26.429: [iter 40 : loss : 0.8333 = 0.1845 + 0.3226 + 0.0046 + 0.3215, time: 27.035720]
2023-09-01 17:03:26.660: epoch 40:	0.15817714  	0.25731120  	0.26615500  
2023-09-01 17:03:26.660: Find a better model.
2023-09-01 17:03:53.679: [iter 41 : loss : 0.8300 = 0.1818 + 0.3221 + 0.0046 + 0.3214, time: 26.970404]
2023-09-01 17:03:53.911: epoch 41:	0.15898000  	0.25932929  	0.26791432  
2023-09-01 17:03:53.911: Find a better model.
2023-09-01 17:04:20.939: [iter 42 : loss : 0.8277 = 0.1797 + 0.3220 + 0.0047 + 0.3213, time: 26.985729]
2023-09-01 17:04:21.170: epoch 42:	0.15927806  	0.25939217  	0.26853353  
2023-09-01 17:04:21.170: Find a better model.
2023-09-01 17:04:48.263: [iter 43 : loss : 0.8261 = 0.1784 + 0.3218 + 0.0048 + 0.3211, time: 27.054169]
2023-09-01 17:04:48.497: epoch 43:	0.15955959  	0.26018861  	0.26971018  
2023-09-01 17:04:48.497: Find a better model.
2023-09-01 17:05:15.489: [iter 44 : loss : 0.8244 = 0.1766 + 0.3219 + 0.0049 + 0.3210, time: 26.952260]
2023-09-01 17:05:15.714: epoch 44:	0.16027150  	0.26189336  	0.27120146  
2023-09-01 17:05:15.714: Find a better model.
2023-09-01 17:05:42.854: [iter 45 : loss : 0.8242 = 0.1766 + 0.3218 + 0.0050 + 0.3208, time: 27.089558]
2023-09-01 17:05:43.084: epoch 45:	0.16083443  	0.26265755  	0.27250016  
2023-09-01 17:05:43.084: Find a better model.
2023-09-01 17:06:10.329: [iter 46 : loss : 0.8215 = 0.1743 + 0.3214 + 0.0051 + 0.3207, time: 27.196497]
2023-09-01 17:06:10.557: epoch 46:	0.16083442  	0.26333395  	0.27273664  
2023-09-01 17:06:10.557: Find a better model.
2023-09-01 17:06:37.810: [iter 47 : loss : 0.8202 = 0.1731 + 0.3214 + 0.0052 + 0.3206, time: 27.219689]
2023-09-01 17:06:38.038: epoch 47:	0.16124837  	0.26474273  	0.27341455  
2023-09-01 17:06:38.038: Find a better model.
2023-09-01 17:07:04.796: [iter 48 : loss : 0.8187 = 0.1717 + 0.3214 + 0.0052 + 0.3205, time: 26.709120]
2023-09-01 17:07:05.022: epoch 48:	0.16155463  	0.26499861  	0.27372289  
2023-09-01 17:07:05.023: Find a better model.
2023-09-01 17:07:31.913: [iter 49 : loss : 0.8183 = 0.1710 + 0.3216 + 0.0053 + 0.3204, time: 26.856208]
2023-09-01 17:07:32.141: epoch 49:	0.16158764  	0.26606929  	0.27443942  
2023-09-01 17:07:32.141: Find a better model.
2023-09-01 17:07:59.096: [iter 50 : loss : 0.8155 = 0.1689 + 0.3210 + 0.0054 + 0.3202, time: 26.914080]
2023-09-01 17:07:59.324: epoch 50:	0.16210091  	0.26756412  	0.27577567  
2023-09-01 17:07:59.324: Find a better model.
2023-09-01 17:08:26.309: [iter 51 : loss : 0.8146 = 0.1679 + 0.3211 + 0.0055 + 0.3201, time: 26.947436]
2023-09-01 17:08:26.537: epoch 51:	0.16268872  	0.26781023  	0.27624890  
2023-09-01 17:08:26.537: Find a better model.
2023-09-01 17:08:53.514: [iter 52 : loss : 0.8140 = 0.1675 + 0.3209 + 0.0056 + 0.3200, time: 26.930627]
2023-09-01 17:08:53.741: epoch 52:	0.16367385  	0.26939827  	0.27783656  
2023-09-01 17:08:53.741: Find a better model.
2023-09-01 17:09:20.806: [iter 53 : loss : 0.8119 = 0.1657 + 0.3207 + 0.0056 + 0.3199, time: 27.027593]
2023-09-01 17:09:21.036: epoch 53:	0.16407105  	0.27031466  	0.27818584  
2023-09-01 17:09:21.036: Find a better model.
2023-09-01 17:09:48.117: [iter 54 : loss : 0.8107 = 0.1648 + 0.3204 + 0.0057 + 0.3198, time: 27.034642]
2023-09-01 17:09:48.346: epoch 54:	0.16444358  	0.27117866  	0.27894479  
2023-09-01 17:09:48.346: Find a better model.
2023-09-01 17:10:15.474: [iter 55 : loss : 0.8092 = 0.1632 + 0.3206 + 0.0058 + 0.3196, time: 27.086915]
2023-09-01 17:10:15.703: epoch 55:	0.16448483  	0.27176359  	0.27914989  
2023-09-01 17:10:15.703: Find a better model.
2023-09-01 17:10:42.873: [iter 56 : loss : 0.8075 = 0.1618 + 0.3204 + 0.0059 + 0.3195, time: 27.125854]
2023-09-01 17:10:43.100: epoch 56:	0.16482432  	0.27204159  	0.27975297  
2023-09-01 17:10:43.101: Find a better model.
2023-09-01 17:11:10.504: [iter 57 : loss : 0.8070 = 0.1613 + 0.3203 + 0.0060 + 0.3194, time: 27.359843]
2023-09-01 17:11:10.733: epoch 57:	0.16480780  	0.27259761  	0.28013393  
2023-09-01 17:11:10.733: Find a better model.
2023-09-01 17:11:37.857: [iter 58 : loss : 0.8060 = 0.1603 + 0.3204 + 0.0060 + 0.3193, time: 27.068570]
2023-09-01 17:11:38.088: epoch 58:	0.16509759  	0.27339640  	0.28079328  
2023-09-01 17:11:38.088: Find a better model.
2023-09-01 17:12:05.377: [iter 59 : loss : 0.8048 = 0.1594 + 0.3201 + 0.0061 + 0.3192, time: 27.238966]
2023-09-01 17:12:05.607: epoch 59:	0.16558604  	0.27421948  	0.28137481  
2023-09-01 17:12:05.607: Find a better model.
2023-09-01 17:12:32.766: [iter 60 : loss : 0.8034 = 0.1581 + 0.3200 + 0.0062 + 0.3191, time: 27.110770]
2023-09-01 17:12:32.996: epoch 60:	0.16557778  	0.27388871  	0.28141704  
2023-09-01 17:13:00.283: [iter 61 : loss : 0.8022 = 0.1572 + 0.3198 + 0.0063 + 0.3190, time: 27.244236]
2023-09-01 17:13:00.516: epoch 61:	0.16551977  	0.27424195  	0.28215501  
2023-09-01 17:13:00.516: Find a better model.
2023-09-01 17:13:27.592: [iter 62 : loss : 0.8015 = 0.1564 + 0.3199 + 0.0064 + 0.3189, time: 27.038041]
2023-09-01 17:13:27.820: epoch 62:	0.16649657  	0.27622262  	0.28320596  
2023-09-01 17:13:27.820: Find a better model.
2023-09-01 17:13:54.687: [iter 63 : loss : 0.8008 = 0.1557 + 0.3199 + 0.0064 + 0.3188, time: 26.821090]
2023-09-01 17:13:54.916: epoch 63:	0.16644691  	0.27588937  	0.28337997  
2023-09-01 17:14:22.051: [iter 64 : loss : 0.7987 = 0.1541 + 0.3194 + 0.0065 + 0.3187, time: 27.092607]
2023-09-01 17:14:22.281: epoch 64:	0.16669513  	0.27642432  	0.28353158  
2023-09-01 17:14:22.281: Find a better model.
2023-09-01 17:14:49.404: [iter 65 : loss : 0.7978 = 0.1534 + 0.3192 + 0.0066 + 0.3186, time: 27.081759]
2023-09-01 17:14:49.631: epoch 65:	0.16661249  	0.27659094  	0.28408337  
2023-09-01 17:14:49.631: Find a better model.
2023-09-01 17:15:16.566: [iter 66 : loss : 0.7967 = 0.1524 + 0.3192 + 0.0067 + 0.3185, time: 26.897543]
2023-09-01 17:15:16.792: epoch 66:	0.16715062  	0.27720377  	0.28442648  
2023-09-01 17:15:16.792: Find a better model.
2023-09-01 17:15:43.972: [iter 67 : loss : 0.7963 = 0.1517 + 0.3196 + 0.0067 + 0.3184, time: 27.132859]
2023-09-01 17:15:44.197: epoch 67:	0.16725829  	0.27739325  	0.28487328  
2023-09-01 17:15:44.197: Find a better model.
2023-09-01 17:16:11.222: [iter 68 : loss : 0.7947 = 0.1505 + 0.3191 + 0.0068 + 0.3183, time: 26.984207]
2023-09-01 17:16:11.451: epoch 68:	0.16717540  	0.27723357  	0.28471372  
2023-09-01 17:16:38.656: [iter 69 : loss : 0.7931 = 0.1491 + 0.3190 + 0.0069 + 0.3181, time: 27.161171]
2023-09-01 17:16:38.883: epoch 69:	0.16752300  	0.27682862  	0.28430474  
2023-09-01 17:17:05.923: [iter 70 : loss : 0.7934 = 0.1494 + 0.3190 + 0.0070 + 0.3180, time: 26.984124]
2023-09-01 17:17:06.150: epoch 70:	0.16798672  	0.27880636  	0.28529379  
2023-09-01 17:17:06.151: Find a better model.
2023-09-01 17:17:33.177: [iter 71 : loss : 0.7925 = 0.1486 + 0.3189 + 0.0070 + 0.3180, time: 26.982063]
2023-09-01 17:17:33.408: epoch 71:	0.16817719  	0.27893201  	0.28554651  
2023-09-01 17:17:33.408: Find a better model.
2023-09-01 17:18:00.538: [iter 72 : loss : 0.7913 = 0.1472 + 0.3191 + 0.0071 + 0.3179, time: 27.084899]
2023-09-01 17:18:00.766: epoch 72:	0.16843364  	0.27993113  	0.28607130  
2023-09-01 17:18:00.766: Find a better model.
2023-09-01 17:18:27.679: [iter 73 : loss : 0.7909 = 0.1472 + 0.3187 + 0.0072 + 0.3178, time: 26.868081]
2023-09-01 17:18:27.907: epoch 73:	0.16863242  	0.27999109  	0.28654093  
2023-09-01 17:18:27.908: Find a better model.
2023-09-01 17:18:54.984: [iter 74 : loss : 0.7893 = 0.1459 + 0.3185 + 0.0073 + 0.3177, time: 27.022738]
2023-09-01 17:18:55.213: epoch 74:	0.16864876  	0.27981657  	0.28682861  
2023-09-01 17:19:22.229: [iter 75 : loss : 0.7887 = 0.1454 + 0.3185 + 0.0073 + 0.3176, time: 26.975784]
2023-09-01 17:19:22.456: epoch 75:	0.16918695  	0.28078866  	0.28759471  
2023-09-01 17:19:22.456: Find a better model.
2023-09-01 17:19:49.563: [iter 76 : loss : 0.7879 = 0.1446 + 0.3184 + 0.0074 + 0.3175, time: 27.065395]
2023-09-01 17:19:49.796: epoch 76:	0.16925308  	0.28130567  	0.28803512  
2023-09-01 17:19:49.796: Find a better model.
2023-09-01 17:20:16.910: [iter 77 : loss : 0.7868 = 0.1439 + 0.3180 + 0.0075 + 0.3174, time: 27.063930]
2023-09-01 17:20:17.137: epoch 77:	0.16955931  	0.28141397  	0.28852746  
2023-09-01 17:20:17.137: Find a better model.
2023-09-01 17:20:44.227: [iter 78 : loss : 0.7868 = 0.1436 + 0.3183 + 0.0075 + 0.3173, time: 27.047193]
2023-09-01 17:20:44.454: epoch 78:	0.16958432  	0.28136268  	0.28871542  
2023-09-01 17:21:11.755: [iter 79 : loss : 0.7849 = 0.1421 + 0.3179 + 0.0076 + 0.3172, time: 27.250641]
2023-09-01 17:21:11.983: epoch 79:	0.16958418  	0.28156006  	0.28889522  
2023-09-01 17:21:11.983: Find a better model.
2023-09-01 17:21:39.246: [iter 80 : loss : 0.7844 = 0.1417 + 0.3179 + 0.0077 + 0.3171, time: 27.223315]
2023-09-01 17:21:39.472: epoch 80:	0.16967528  	0.28152874  	0.28903222  
2023-09-01 17:22:06.541: [iter 81 : loss : 0.7831 = 0.1405 + 0.3179 + 0.0078 + 0.3170, time: 27.023418]
2023-09-01 17:22:06.765: epoch 81:	0.16989884  	0.28156489  	0.28921258  
2023-09-01 17:22:06.765: Find a better model.
2023-09-01 17:22:33.917: [iter 82 : loss : 0.7819 = 0.1395 + 0.3177 + 0.0078 + 0.3169, time: 27.114727]
2023-09-01 17:22:34.145: epoch 82:	0.17024647  	0.28222415  	0.28958642  
2023-09-01 17:22:34.145: Find a better model.
2023-09-01 17:23:01.220: [iter 83 : loss : 0.7817 = 0.1393 + 0.3177 + 0.0079 + 0.3168, time: 27.027962]
2023-09-01 17:23:01.450: epoch 83:	0.17047821  	0.28341982  	0.29050463  
2023-09-01 17:23:01.450: Find a better model.
2023-09-01 17:23:28.612: [iter 84 : loss : 0.7804 = 0.1382 + 0.3175 + 0.0080 + 0.3167, time: 27.113317]
2023-09-01 17:23:28.840: epoch 84:	0.17028770  	0.28318140  	0.28990158  
2023-09-01 17:23:55.940: [iter 85 : loss : 0.7802 = 0.1380 + 0.3176 + 0.0081 + 0.3166, time: 27.046886]
2023-09-01 17:23:56.167: epoch 85:	0.17056087  	0.28346640  	0.29029706  
2023-09-01 17:23:56.167: Find a better model.
2023-09-01 17:24:23.169: [iter 86 : loss : 0.7801 = 0.1377 + 0.3177 + 0.0081 + 0.3166, time: 26.964275]
2023-09-01 17:24:23.395: epoch 86:	0.17056097  	0.28306094  	0.29028958  
2023-09-01 17:24:50.460: [iter 87 : loss : 0.7793 = 0.1373 + 0.3174 + 0.0082 + 0.3165, time: 27.013652]
2023-09-01 17:24:50.688: epoch 87:	0.17060226  	0.28321865  	0.28999883  
2023-09-01 17:25:17.990: [iter 88 : loss : 0.7780 = 0.1361 + 0.3172 + 0.0083 + 0.3164, time: 27.257595]
2023-09-01 17:25:18.219: epoch 88:	0.17068510  	0.28292191  	0.29031864  
2023-09-01 17:25:45.217: [iter 89 : loss : 0.7779 = 0.1361 + 0.3172 + 0.0083 + 0.3163, time: 26.945419]
2023-09-01 17:25:45.447: epoch 89:	0.17046990  	0.28235161  	0.29035339  
2023-09-01 17:26:11.644: [iter 90 : loss : 0.7768 = 0.1349 + 0.3173 + 0.0084 + 0.3162, time: 26.153456]
2023-09-01 17:26:11.868: epoch 90:	0.17077619  	0.28312731  	0.29052624  
2023-09-01 17:26:38.680: [iter 91 : loss : 0.7762 = 0.1344 + 0.3171 + 0.0085 + 0.3161, time: 26.770029]
2023-09-01 17:26:38.907: epoch 91:	0.17065212  	0.28263673  	0.29030138  
2023-09-01 17:27:05.669: [iter 92 : loss : 0.7761 = 0.1345 + 0.3170 + 0.0085 + 0.3161, time: 26.718173]
2023-09-01 17:27:05.891: epoch 92:	0.17087559  	0.28306633  	0.29028627  
2023-09-01 17:27:32.001: [iter 93 : loss : 0.7751 = 0.1338 + 0.3168 + 0.0086 + 0.3160, time: 26.079700]
2023-09-01 17:27:32.227: epoch 93:	0.17098320  	0.28319880  	0.29085875  
2023-09-01 17:27:59.212: [iter 94 : loss : 0.7747 = 0.1333 + 0.3169 + 0.0087 + 0.3159, time: 26.940455]
2023-09-01 17:27:59.439: epoch 94:	0.17135568  	0.28397679  	0.29122946  
2023-09-01 17:27:59.440: Find a better model.
2023-09-01 17:28:25.697: [iter 95 : loss : 0.7738 = 0.1325 + 0.3167 + 0.0087 + 0.3158, time: 26.210266]
2023-09-01 17:28:25.923: epoch 95:	0.17167045  	0.28359422  	0.29107207  
2023-09-01 17:28:53.105: [iter 96 : loss : 0.7731 = 0.1321 + 0.3165 + 0.0088 + 0.3157, time: 27.145319]
2023-09-01 17:28:53.334: epoch 96:	0.17176972  	0.28395715  	0.29143590  
2023-09-01 17:29:20.179: [iter 97 : loss : 0.7729 = 0.1317 + 0.3167 + 0.0089 + 0.3156, time: 26.802659]
2023-09-01 17:29:20.412: epoch 97:	0.17150475  	0.28273818  	0.29121095  
2023-09-01 17:29:47.355: [iter 98 : loss : 0.7719 = 0.1308 + 0.3166 + 0.0089 + 0.3156, time: 26.907675]
2023-09-01 17:29:47.583: epoch 98:	0.17133923  	0.28221086  	0.29046923  
2023-09-01 17:30:13.883: [iter 99 : loss : 0.7696 = 0.1288 + 0.3163 + 0.0090 + 0.3155, time: 26.254721]
2023-09-01 17:30:14.109: epoch 99:	0.17119838  	0.28247559  	0.29036278  
2023-09-01 17:30:41.231: [iter 100 : loss : 0.7710 = 0.1304 + 0.3162 + 0.0091 + 0.3154, time: 27.068879]
2023-09-01 17:30:41.461: epoch 100:	0.17142184  	0.28213146  	0.29062188  
2023-09-01 17:31:07.743: [iter 101 : loss : 0.7704 = 0.1298 + 0.3162 + 0.0091 + 0.3153, time: 26.244698]
2023-09-01 17:31:07.974: epoch 101:	0.17150454  	0.28207710  	0.29056230  
2023-09-01 17:31:35.160: [iter 102 : loss : 0.7707 = 0.1300 + 0.3162 + 0.0092 + 0.3152, time: 27.141174]
2023-09-01 17:31:35.389: epoch 102:	0.17185222  	0.28259954  	0.29088217  
2023-09-01 17:32:02.407: [iter 103 : loss : 0.7690 = 0.1286 + 0.3160 + 0.0093 + 0.3152, time: 26.963811]
2023-09-01 17:32:02.634: epoch 103:	0.17169523  	0.28267989  	0.29085040  
2023-09-01 17:32:29.646: [iter 104 : loss : 0.7690 = 0.1286 + 0.3160 + 0.0093 + 0.3151, time: 26.967692]
2023-09-01 17:32:29.872: epoch 104:	0.17158742  	0.28266707  	0.29073858  
2023-09-01 17:32:29.872: Early stopping is trigger at epoch: 104
2023-09-01 17:32:29.872: best_result@epoch 94:

2023-09-01 17:32:29.872: 		0.1714      	0.2840      	0.2912      

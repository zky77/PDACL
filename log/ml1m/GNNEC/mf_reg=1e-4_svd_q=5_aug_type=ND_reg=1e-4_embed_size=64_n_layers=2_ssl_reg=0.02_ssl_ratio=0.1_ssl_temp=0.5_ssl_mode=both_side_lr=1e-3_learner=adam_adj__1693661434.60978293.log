2023-09-02 21:30:34.610: my pid: 18664
2023-09-02 21:30:34.610: model: model.general_recommender.GNNEC
2023-09-02 21:30:34.610: Dataset statistics:
Name: ml1m
The number of users: 6040
The number of items: 3706
The number of ratings: 1000209
Average actions of users: 165.60
Average actions of items: 269.89
The sparsity of the dataset: 95.531637%

The number of training: 902826
The number of validation: 0
The number of testing: 97383
2023-09-02 21:30:34.610: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=ml1m
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=ml1m
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
mf_reg=1e-4
svd_q=5
2023-09-02 21:30:38.815: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-02 21:31:11.181: [iter 1 : loss : 0.8109 = 0.5524 + 0.2570 + 0.0002 + 0.0013, time: 32.365289]
2023-09-02 21:31:11.413: epoch 1:	0.09216779  	0.14097013  	0.14824064  
2023-09-02 21:31:11.413: Find a better model.
2023-09-02 21:31:43.271: [iter 2 : loss : 0.5916 = 0.4003 + 0.1898 + 0.0006 + 0.0009, time: 31.814557]
2023-09-02 21:31:43.506: epoch 2:	0.10661257  	0.16322683  	0.17738411  
2023-09-02 21:31:43.506: Find a better model.
2023-09-02 21:32:15.391: [iter 3 : loss : 0.5057 = 0.3495 + 0.1546 + 0.0009 + 0.0008, time: 31.831673]
2023-09-02 21:32:15.624: epoch 3:	0.11572655  	0.17936628  	0.19337989  
2023-09-02 21:32:15.624: Find a better model.
2023-09-02 21:32:46.788: [iter 4 : loss : 0.4535 = 0.3217 + 0.1299 + 0.0012 + 0.0006, time: 31.120323]
2023-09-02 21:32:47.015: epoch 4:	0.12306088  	0.19146821  	0.20333363  
2023-09-02 21:32:47.015: Find a better model.
2023-09-02 21:33:18.700: [iter 5 : loss : 0.4121 = 0.3019 + 0.1082 + 0.0015 + 0.0005, time: 31.651588]
2023-09-02 21:33:18.934: epoch 5:	0.12956755  	0.20123340  	0.21385188  
2023-09-02 21:33:18.934: Find a better model.
2023-09-02 21:33:50.738: [iter 6 : loss : 0.3748 = 0.2848 + 0.0877 + 0.0018 + 0.0004, time: 31.754745]
2023-09-02 21:33:50.971: epoch 6:	0.13609061  	0.21359123  	0.22558860  
2023-09-02 21:33:50.971: Find a better model.
2023-09-02 21:34:22.771: [iter 7 : loss : 0.3466 = 0.2736 + 0.0706 + 0.0021 + 0.0004, time: 31.757606]
2023-09-02 21:34:23.007: epoch 7:	0.14060234  	0.22077930  	0.23048747  
2023-09-02 21:34:23.007: Find a better model.
2023-09-02 21:34:53.874: [iter 8 : loss : 0.3191 = 0.2615 + 0.0549 + 0.0024 + 0.0003, time: 30.831110]
2023-09-02 21:34:54.102: epoch 8:	0.14427803  	0.22782755  	0.23600759  
2023-09-02 21:34:54.102: Find a better model.
2023-09-02 21:35:25.647: [iter 9 : loss : 0.2941 = 0.2519 + 0.0393 + 0.0026 + 0.0002, time: 31.507056]
2023-09-02 21:35:25.875: epoch 9:	0.14715873  	0.23336031  	0.24211922  
2023-09-02 21:35:25.875: Find a better model.
2023-09-02 21:35:57.356: [iter 10 : loss : 0.2708 = 0.2434 + 0.0243 + 0.0029 + 0.0001, time: 31.442218]
2023-09-02 21:35:57.585: epoch 10:	0.15038736  	0.23866288  	0.24826789  
2023-09-02 21:35:57.585: Find a better model.
2023-09-02 21:36:29.149: [iter 11 : loss : 0.2511 = 0.2367 + 0.0110 + 0.0032 + 0.0001, time: 31.513924]
2023-09-02 21:36:29.375: epoch 11:	0.15258121  	0.24326968  	0.25312018  
2023-09-02 21:36:29.375: Find a better model.
2023-09-02 21:37:00.642: [iter 12 : loss : 0.2329 = 0.2307 + -0.0014 + 0.0035 + 0.0000, time: 31.234041]
2023-09-02 21:37:00.866: epoch 12:	0.15471698  	0.24775775  	0.25743991  
2023-09-02 21:37:00.866: Find a better model.
2023-09-02 21:37:32.233: [iter 13 : loss : 0.2129 = 0.2250 + -0.0159 + 0.0038 + -0.0001, time: 31.323193]
2023-09-02 21:37:32.459: epoch 13:	0.15656294  	0.25140929  	0.26090923  
2023-09-02 21:37:32.459: Find a better model.
2023-09-02 21:38:04.352: [iter 14 : loss : 0.1953 = 0.2195 + -0.0282 + 0.0041 + -0.0001, time: 31.851929]
2023-09-02 21:38:04.582: epoch 14:	0.15865731  	0.25601035  	0.26527730  
2023-09-02 21:38:04.582: Find a better model.
2023-09-02 21:38:36.208: [iter 15 : loss : 0.1800 = 0.2158 + -0.0401 + 0.0044 + -0.0002, time: 31.590602]
2023-09-02 21:38:36.434: epoch 15:	0.16040398  	0.26032847  	0.26917720  
2023-09-02 21:38:36.434: Find a better model.
2023-09-02 21:39:07.920: [iter 16 : loss : 0.1662 = 0.2119 + -0.0501 + 0.0047 + -0.0002, time: 31.450220]
2023-09-02 21:39:08.135: epoch 16:	0.16129795  	0.26249558  	0.27121654  
2023-09-02 21:39:08.136: Find a better model.
2023-09-02 21:39:39.650: [iter 17 : loss : 0.1505 = 0.2072 + -0.0614 + 0.0050 + -0.0003, time: 31.484688]
2023-09-02 21:39:39.877: epoch 17:	0.16252314  	0.26585612  	0.27330589  
2023-09-02 21:39:39.877: Find a better model.
2023-09-02 21:40:11.472: [iter 18 : loss : 0.1390 = 0.2039 + -0.0699 + 0.0053 + -0.0003, time: 31.560233]
2023-09-02 21:40:11.702: epoch 18:	0.16296184  	0.26753530  	0.27516979  
2023-09-02 21:40:11.703: Find a better model.
2023-09-02 21:40:43.096: [iter 19 : loss : 0.1245 = 0.2003 + -0.0811 + 0.0056 + -0.0004, time: 31.353634]
2023-09-02 21:40:43.323: epoch 19:	0.16406280  	0.26971945  	0.27760896  
2023-09-02 21:40:43.323: Find a better model.
2023-09-02 21:41:14.668: [iter 20 : loss : 0.1118 = 0.1975 + -0.0912 + 0.0059 + -0.0004, time: 31.309778]
2023-09-02 21:41:14.896: epoch 20:	0.16449341  	0.27084908  	0.27836460  
2023-09-02 21:41:14.896: Find a better model.
2023-09-02 21:41:46.229: [iter 21 : loss : 0.0999 = 0.1952 + -0.1011 + 0.0062 + -0.0005, time: 31.290836]
2023-09-02 21:41:46.456: epoch 21:	0.16536264  	0.27211830  	0.27974167  
2023-09-02 21:41:46.456: Find a better model.
2023-09-02 21:42:17.705: [iter 22 : loss : 0.0864 = 0.1904 + -0.1100 + 0.0065 + -0.0005, time: 31.215475]
2023-09-02 21:42:17.932: epoch 22:	0.16604154  	0.27358630  	0.28039178  
2023-09-02 21:42:17.932: Find a better model.
2023-09-02 21:42:49.297: [iter 23 : loss : 0.0734 = 0.1868 + -0.1196 + 0.0069 + -0.0006, time: 31.332200]
2023-09-02 21:42:49.524: epoch 23:	0.16614923  	0.27455941  	0.28122249  
2023-09-02 21:42:49.524: Find a better model.
2023-09-02 21:43:20.719: [iter 24 : loss : 0.0636 = 0.1854 + -0.1284 + 0.0072 + -0.0006, time: 31.155956]
2023-09-02 21:43:20.953: epoch 24:	0.16674526  	0.27524018  	0.28250107  
2023-09-02 21:43:20.953: Find a better model.
2023-09-02 21:43:52.402: [iter 25 : loss : 0.0548 = 0.1845 + -0.1366 + 0.0075 + -0.0006, time: 31.413242]
2023-09-02 21:43:52.628: epoch 25:	0.16696052  	0.27565759  	0.28310370  
2023-09-02 21:43:52.629: Find a better model.
2023-09-02 21:44:24.110: [iter 26 : loss : 0.0443 = 0.1811 + -0.1439 + 0.0078 + -0.0007, time: 31.446299]
2023-09-02 21:44:24.338: epoch 26:	0.16734132  	0.27627775  	0.28339171  
2023-09-02 21:44:24.338: Find a better model.
2023-09-02 21:44:55.980: [iter 27 : loss : 0.0327 = 0.1790 + -0.1537 + 0.0081 + -0.0007, time: 31.597472]
2023-09-02 21:44:56.206: epoch 27:	0.16737442  	0.27607223  	0.28331387  
2023-09-02 21:45:27.799: [iter 28 : loss : 0.0229 = 0.1758 + -0.1606 + 0.0084 + -0.0008, time: 31.559593]
2023-09-02 21:45:28.026: epoch 28:	0.16765587  	0.27757040  	0.28385344  
2023-09-02 21:45:28.026: Find a better model.
2023-09-02 21:45:59.599: [iter 29 : loss : 0.0122 = 0.1743 + -0.1701 + 0.0088 + -0.0008, time: 31.539003]
2023-09-02 21:45:59.827: epoch 29:	0.16794555  	0.27771488  	0.28400370  
2023-09-02 21:45:59.827: Find a better model.
2023-09-02 21:46:31.282: [iter 30 : loss : 0.0027 = 0.1721 + -0.1776 + 0.0091 + -0.0009, time: 31.406949]
2023-09-02 21:46:31.506: epoch 30:	0.16785458  	0.27741686  	0.28451687  
2023-09-02 21:47:02.773: [iter 31 : loss : -0.0079 = 0.1705 + -0.1869 + 0.0094 + -0.0009, time: 31.235277]
2023-09-02 21:47:03.003: epoch 31:	0.16835943  	0.27814046  	0.28545654  
2023-09-02 21:47:03.003: Find a better model.
2023-09-02 21:47:34.478: [iter 32 : loss : -0.0156 = 0.1682 + -0.1926 + 0.0097 + -0.0009, time: 31.432050]
2023-09-02 21:47:34.705: epoch 32:	0.16854163  	0.27856404  	0.28618303  
2023-09-02 21:47:34.705: Find a better model.
2023-09-02 21:48:06.002: [iter 33 : loss : -0.0236 = 0.1683 + -0.2009 + 0.0100 + -0.0010, time: 31.254498]
2023-09-02 21:48:06.228: epoch 33:	0.16871537  	0.27844992  	0.28637335  
2023-09-02 21:48:38.155: [iter 34 : loss : -0.0351 = 0.1648 + -0.2093 + 0.0103 + -0.0010, time: 31.887582]
2023-09-02 21:48:38.389: epoch 34:	0.16878982  	0.27855214  	0.28640839  
2023-09-02 21:49:10.143: [iter 35 : loss : -0.0418 = 0.1639 + -0.2153 + 0.0107 + -0.0010, time: 31.708935]
2023-09-02 21:49:10.391: epoch 35:	0.16867384  	0.27837676  	0.28627720  
2023-09-02 21:49:42.331: [iter 36 : loss : -0.0479 = 0.1642 + -0.2220 + 0.0110 + -0.0011, time: 31.906205]
2023-09-02 21:49:42.564: epoch 36:	0.16821840  	0.27757850  	0.28543878  
2023-09-02 21:50:14.255: [iter 37 : loss : -0.0569 = 0.1628 + -0.2298 + 0.0113 + -0.0011, time: 31.653512]
2023-09-02 21:50:14.492: epoch 37:	0.16816886  	0.27779850  	0.28559589  
2023-09-02 21:50:46.646: [iter 38 : loss : -0.0636 = 0.1613 + -0.2354 + 0.0116 + -0.0011, time: 32.118329]
2023-09-02 21:50:46.883: epoch 38:	0.16831785  	0.27854213  	0.28604779  
2023-09-02 21:51:18.843: [iter 39 : loss : -0.0709 = 0.1610 + -0.2427 + 0.0119 + -0.0012, time: 31.918953]
2023-09-02 21:51:19.079: epoch 39:	0.16801159  	0.27711242  	0.28540096  
2023-09-02 21:51:50.704: [iter 40 : loss : -0.0746 = 0.1609 + -0.2465 + 0.0122 + -0.0012, time: 31.572757]
2023-09-02 21:51:50.936: epoch 40:	0.16807774  	0.27731368  	0.28560519  
2023-09-02 21:52:22.506: [iter 41 : loss : -0.0843 = 0.1585 + -0.2542 + 0.0125 + -0.0012, time: 31.528587]
2023-09-02 21:52:22.736: epoch 41:	0.16761421  	0.27620164  	0.28500488  
2023-09-02 21:52:54.103: [iter 42 : loss : -0.0918 = 0.1571 + -0.2605 + 0.0129 + -0.0013, time: 31.324515]
2023-09-02 21:52:54.333: epoch 42:	0.16724996  	0.27567491  	0.28458691  
2023-09-02 21:52:54.333: Early stopping is trigger at epoch: 42
2023-09-02 21:52:54.334: best_result@epoch 32:

2023-09-02 21:52:54.334: 		0.1685      	0.2786      	0.2862      

2023-09-01 13:45:45.463: my pid: 30535
2023-09-01 13:45:45.463: model: model.general_recommender.GNNEC
2023-09-01 13:45:45.463: Dataset statistics:
Name: ml1m
The number of users: 6040
The number of items: 3706
The number of ratings: 1000209
Average actions of users: 165.60
Average actions of items: 269.89
The sparsity of the dataset: 95.531637%

The number of training: 902826
The number of validation: 0
The number of testing: 97383
2023-09-01 13:45:45.463: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=ml1m
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=ml1m
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
mf_reg=0.02
svd_q=5
2023-09-01 13:45:51.154: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 13:46:23.253: [iter 1 : loss : 1.2163 = 0.5924 + 0.3114 + 0.0001 + 0.3123, time: 32.097142]
2023-09-01 13:46:23.536: epoch 1:	0.09523064  	0.14664580  	0.15752429  
2023-09-01 13:46:23.536: Find a better model.
2023-09-01 13:46:56.762: [iter 2 : loss : 1.0044 = 0.4344 + 0.2835 + 0.0005 + 0.2860, time: 33.196095]
2023-09-01 13:46:57.044: epoch 2:	0.10936105  	0.17310385  	0.18414533  
2023-09-01 13:46:57.044: Find a better model.
2023-09-01 13:47:30.512: [iter 3 : loss : 0.9236 = 0.3808 + 0.2694 + 0.0007 + 0.2727, time: 33.433476]
2023-09-01 13:47:30.796: epoch 3:	0.11758120  	0.18650840  	0.19717857  
2023-09-01 13:47:30.796: Find a better model.
2023-09-01 13:48:03.984: [iter 4 : loss : 0.8766 = 0.3520 + 0.2601 + 0.0009 + 0.2636, time: 33.162047]
2023-09-01 13:48:04.244: epoch 4:	0.12388067  	0.19761217  	0.20721084  
2023-09-01 13:48:04.245: Find a better model.
2023-09-01 13:48:37.533: [iter 5 : loss : 0.8397 = 0.3307 + 0.2521 + 0.0011 + 0.2557, time: 33.261576]
2023-09-01 13:48:37.814: epoch 5:	0.13029633  	0.20823696  	0.21790349  
2023-09-01 13:48:37.814: Find a better model.
2023-09-01 13:49:09.320: [iter 6 : loss : 0.8069 = 0.3125 + 0.2446 + 0.0013 + 0.2485, time: 31.470546]
2023-09-01 13:49:09.604: epoch 6:	0.13523841  	0.21753368  	0.22715941  
2023-09-01 13:49:09.604: Find a better model.
2023-09-01 13:49:42.632: [iter 7 : loss : 0.7802 = 0.2994 + 0.2377 + 0.0015 + 0.2416, time: 33.003297]
2023-09-01 13:49:42.923: epoch 7:	0.14015542  	0.22532053  	0.23450123  
2023-09-01 13:49:42.924: Find a better model.
2023-09-01 13:50:16.149: [iter 8 : loss : 0.7542 = 0.2860 + 0.2315 + 0.0017 + 0.2350, time: 33.200364]
2023-09-01 13:50:16.432: epoch 8:	0.14422019  	0.23161532  	0.24084596  
2023-09-01 13:50:16.432: Find a better model.
2023-09-01 13:50:49.495: [iter 9 : loss : 0.7307 = 0.2748 + 0.2252 + 0.0019 + 0.2287, time: 33.031631]
2023-09-01 13:50:49.778: epoch 9:	0.14734082  	0.23643805  	0.24607675  
2023-09-01 13:50:49.778: Find a better model.
2023-09-01 13:51:22.892: [iter 10 : loss : 0.7093 = 0.2653 + 0.2192 + 0.0021 + 0.2227, time: 33.082338]
2023-09-01 13:51:23.175: epoch 10:	0.14988229  	0.24110785  	0.25086120  
2023-09-01 13:51:23.175: Find a better model.
2023-09-01 13:51:55.596: [iter 11 : loss : 0.6910 = 0.2578 + 0.2139 + 0.0023 + 0.2170, time: 32.395170]
2023-09-01 13:51:55.854: epoch 11:	0.15152149  	0.24496788  	0.25439939  
2023-09-01 13:51:55.854: Find a better model.
2023-09-01 13:52:28.900: [iter 12 : loss : 0.6739 = 0.2510 + 0.2088 + 0.0025 + 0.2117, time: 33.002056]
2023-09-01 13:52:29.184: epoch 12:	0.15361576  	0.24903286  	0.25781509  
2023-09-01 13:52:29.184: Find a better model.
2023-09-01 13:53:02.444: [iter 13 : loss : 0.6580 = 0.2453 + 0.2033 + 0.0027 + 0.2066, time: 33.230022]
2023-09-01 13:53:02.731: epoch 13:	0.15465043  	0.25118750  	0.26005670  
2023-09-01 13:53:02.731: Find a better model.
2023-09-01 13:53:35.282: [iter 14 : loss : 0.6429 = 0.2397 + 0.1985 + 0.0029 + 0.2018, time: 32.524359]
2023-09-01 13:53:35.569: epoch 14:	0.15581763  	0.25434244  	0.26236448  
2023-09-01 13:53:35.569: Find a better model.
2023-09-01 13:54:08.464: [iter 15 : loss : 0.6299 = 0.2357 + 0.1939 + 0.0031 + 0.1973, time: 32.872457]
2023-09-01 13:54:08.753: epoch 15:	0.15668686  	0.25611195  	0.26457295  
2023-09-01 13:54:08.754: Find a better model.
2023-09-01 13:54:41.907: [iter 16 : loss : 0.6174 = 0.2315 + 0.1897 + 0.0033 + 0.1929, time: 33.127630]
2023-09-01 13:54:42.094: epoch 16:	0.15728302  	0.25708789  	0.26611167  
2023-09-01 13:54:42.094: Find a better model.
2023-09-01 13:55:15.439: [iter 17 : loss : 0.6051 = 0.2272 + 0.1856 + 0.0035 + 0.1888, time: 33.318761]
2023-09-01 13:55:15.697: epoch 17:	0.15825976  	0.25924888  	0.26725438  
2023-09-01 13:55:15.697: Find a better model.
2023-09-01 13:55:48.138: [iter 18 : loss : 0.5947 = 0.2241 + 0.1821 + 0.0037 + 0.1848, time: 32.413236]
2023-09-01 13:55:48.422: epoch 18:	0.15878135  	0.26022366  	0.26862350  
2023-09-01 13:55:48.423: Find a better model.
2023-09-01 13:56:20.283: [iter 19 : loss : 0.5832 = 0.2204 + 0.1780 + 0.0038 + 0.1809, time: 31.833915]
2023-09-01 13:56:20.468: epoch 19:	0.15947674  	0.26170212  	0.26975578  
2023-09-01 13:56:20.468: Find a better model.
2023-09-01 13:56:53.789: [iter 20 : loss : 0.5729 = 0.2175 + 0.1742 + 0.0040 + 0.1772, time: 33.297057]
2023-09-01 13:56:54.071: epoch 20:	0.15954310  	0.26123685  	0.26964840  
2023-09-01 13:57:27.262: [iter 21 : loss : 0.5640 = 0.2157 + 0.1705 + 0.0042 + 0.1736, time: 33.158084]
2023-09-01 13:57:27.544: epoch 21:	0.15970042  	0.26118237  	0.26987979  
2023-09-01 13:57:59.531: [iter 22 : loss : 0.5534 = 0.2115 + 0.1673 + 0.0044 + 0.1703, time: 31.961359]
2023-09-01 13:57:59.821: epoch 22:	0.16000666  	0.26200521  	0.27039999  
2023-09-01 13:57:59.821: Find a better model.
2023-09-01 13:58:33.024: [iter 23 : loss : 0.5437 = 0.2084 + 0.1639 + 0.0046 + 0.1669, time: 33.176098]
2023-09-01 13:58:33.275: epoch 23:	0.16008119  	0.26187578  	0.26996905  
2023-09-01 13:59:06.428: [iter 24 : loss : 0.5361 = 0.2070 + 0.1607 + 0.0047 + 0.1637, time: 33.126152]
2023-09-01 13:59:06.748: epoch 24:	0.16010602  	0.26234686  	0.26988494  
2023-09-01 13:59:06.749: Find a better model.
2023-09-01 13:59:39.698: [iter 25 : loss : 0.5298 = 0.2063 + 0.1578 + 0.0049 + 0.1608, time: 32.923596]
2023-09-01 13:59:39.986: epoch 25:	0.15996526  	0.26189175  	0.26921579  
2023-09-01 14:00:12.960: [iter 26 : loss : 0.5213 = 0.2033 + 0.1551 + 0.0051 + 0.1578, time: 32.943468]
2023-09-01 14:00:13.250: epoch 26:	0.16019699  	0.26102421  	0.26920283  
2023-09-01 14:00:44.766: [iter 27 : loss : 0.5136 = 0.2017 + 0.1517 + 0.0053 + 0.1549, time: 31.489629]
2023-09-01 14:00:44.992: epoch 27:	0.15961754  	0.26109275  	0.26865748  
2023-09-01 14:01:17.720: [iter 28 : loss : 0.5058 = 0.1988 + 0.1495 + 0.0054 + 0.1521, time: 32.702757]
2023-09-01 14:01:18.008: epoch 28:	0.15961753  	0.26114330  	0.26850942  
2023-09-01 14:01:51.222: [iter 29 : loss : 0.5001 = 0.1988 + 0.1463 + 0.0056 + 0.1494, time: 33.183876]
2023-09-01 14:01:51.471: epoch 29:	0.15989062  	0.26148206  	0.26843175  
2023-09-01 14:02:24.355: [iter 30 : loss : 0.4925 = 0.1962 + 0.1437 + 0.0058 + 0.1469, time: 32.858434]
2023-09-01 14:02:24.636: epoch 30:	0.15951817  	0.26050738  	0.26749697  
2023-09-01 14:02:57.876: [iter 31 : loss : 0.4864 = 0.1953 + 0.1408 + 0.0059 + 0.1444, time: 33.210716]
2023-09-01 14:02:58.166: epoch 31:	0.15912910  	0.25983933  	0.26693189  
2023-09-01 14:03:30.751: [iter 32 : loss : 0.4806 = 0.1935 + 0.1389 + 0.0061 + 0.1421, time: 32.556984]
2023-09-01 14:03:30.975: epoch 32:	0.15864065  	0.25897521  	0.26609427  
2023-09-01 14:04:03.867: [iter 33 : loss : 0.4751 = 0.1929 + 0.1363 + 0.0062 + 0.1397, time: 32.867357]
2023-09-01 14:04:04.161: epoch 33:	0.15857443  	0.25856987  	0.26533705  
2023-09-01 14:04:37.555: [iter 34 : loss : 0.4689 = 0.1915 + 0.1336 + 0.0064 + 0.1374, time: 33.359423]
2023-09-01 14:04:37.841: epoch 34:	0.15792030  	0.25682089  	0.26387882  
2023-09-01 14:04:37.841: Early stopping is trigger at epoch: 34
2023-09-01 14:04:37.841: best_result@epoch 24:

2023-09-01 14:04:37.841: 		0.1601      	0.2623      	0.2699      

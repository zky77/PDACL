2023-09-01 15:17:04.513: my pid: 30960
2023-09-01 15:17:04.513: model: model.general_recommender.GNNEC
2023-09-01 15:17:04.513: Dataset statistics:
Name: ml1m
The number of users: 6040
The number of items: 3706
The number of ratings: 1000209
Average actions of users: 165.60
Average actions of items: 269.89
The sparsity of the dataset: 95.531637%

The number of training: 902826
The number of validation: 0
The number of testing: 97383
2023-09-01 15:17:04.513: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=ml1m
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=1
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=ml1m
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=1
mf_reg=0.02
svd_q=5
2023-09-01 15:17:09.320: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 15:17:36.931: [iter 1 : loss : 1.1864 = 0.5832 + 0.3020 + 0.0001 + 0.3010, time: 27.609560]
2023-09-01 15:17:37.153: epoch 1:	0.08853379  	0.13154574  	0.14141169  
2023-09-01 15:17:37.153: Find a better model.
2023-09-01 15:18:04.194: [iter 2 : loss : 0.9713 = 0.4355 + 0.2684 + 0.0004 + 0.2670, time: 26.997538]
2023-09-01 15:18:04.428: epoch 2:	0.09988256  	0.14881530  	0.16205505  
2023-09-01 15:18:04.428: Find a better model.
2023-09-01 15:18:31.702: [iter 3 : loss : 0.8845 = 0.3821 + 0.2517 + 0.0007 + 0.2500, time: 27.228683]
2023-09-01 15:18:31.929: epoch 3:	0.10650490  	0.16105364  	0.17458692  
2023-09-01 15:18:31.930: Find a better model.
2023-09-01 15:18:59.017: [iter 4 : loss : 0.8353 = 0.3557 + 0.2405 + 0.0009 + 0.2382, time: 27.042196]
2023-09-01 15:18:59.251: epoch 4:	0.11132275  	0.16938862  	0.18253070  
2023-09-01 15:18:59.251: Find a better model.
2023-09-01 15:19:26.455: [iter 5 : loss : 0.7991 = 0.3379 + 0.2312 + 0.0011 + 0.2289, time: 27.156852]
2023-09-01 15:19:26.687: epoch 5:	0.11524651  	0.17513838  	0.18792640  
2023-09-01 15:19:26.687: Find a better model.
2023-09-01 15:19:53.899: [iter 6 : loss : 0.7686 = 0.3230 + 0.2233 + 0.0013 + 0.2210, time: 27.152256]
2023-09-01 15:19:54.131: epoch 6:	0.11981595  	0.18165979  	0.19478254  
2023-09-01 15:19:54.131: Find a better model.
2023-09-01 15:20:21.500: [iter 7 : loss : 0.7451 = 0.3132 + 0.2164 + 0.0015 + 0.2141, time: 27.328203]
2023-09-01 15:20:21.728: epoch 7:	0.12358247  	0.18780279  	0.20019074  
2023-09-01 15:20:21.728: Find a better model.
2023-09-01 15:20:48.737: [iter 8 : loss : 0.7214 = 0.3017 + 0.2106 + 0.0016 + 0.2075, time: 26.965727]
2023-09-01 15:20:48.965: epoch 8:	0.12748143  	0.19429410  	0.20530725  
2023-09-01 15:20:48.965: Find a better model.
2023-09-01 15:21:16.223: [iter 9 : loss : 0.7002 = 0.2927 + 0.2044 + 0.0018 + 0.2013, time: 27.216935]
2023-09-01 15:21:16.454: epoch 9:	0.13029604  	0.19919738  	0.20982774  
2023-09-01 15:21:16.454: Find a better model.
2023-09-01 15:21:43.552: [iter 10 : loss : 0.6808 = 0.2846 + 0.1988 + 0.0020 + 0.1954, time: 27.059529]
2023-09-01 15:21:43.782: epoch 10:	0.13359079  	0.20566083  	0.21549717  
2023-09-01 15:21:43.782: Find a better model.
2023-09-01 15:22:10.963: [iter 11 : loss : 0.6634 = 0.2779 + 0.1936 + 0.0022 + 0.1897, time: 27.138940]
2023-09-01 15:22:11.190: epoch 11:	0.13570179  	0.20951474  	0.21947321  
2023-09-01 15:22:11.190: Find a better model.
2023-09-01 15:22:38.369: [iter 12 : loss : 0.6463 = 0.2716 + 0.1881 + 0.0024 + 0.1842, time: 27.132662]
2023-09-01 15:22:38.600: epoch 12:	0.13830116  	0.21398510  	0.22356473  
2023-09-01 15:22:38.600: Find a better model.
2023-09-01 15:23:05.546: [iter 13 : loss : 0.6300 = 0.2661 + 0.1823 + 0.0025 + 0.1791, time: 26.899462]
2023-09-01 15:23:05.774: epoch 13:	0.14038736  	0.21834707  	0.22765110  
2023-09-01 15:23:05.774: Find a better model.
2023-09-01 15:23:32.850: [iter 14 : loss : 0.6150 = 0.2612 + 0.1771 + 0.0027 + 0.1739, time: 27.026232]
2023-09-01 15:23:33.081: epoch 14:	0.14273827  	0.22273012  	0.23160711  
2023-09-01 15:23:33.081: Find a better model.
2023-09-01 15:24:00.060: [iter 15 : loss : 0.6019 = 0.2578 + 0.1722 + 0.0029 + 0.1691, time: 26.938542]
2023-09-01 15:24:00.291: epoch 15:	0.14493199  	0.22707938  	0.23579350  
2023-09-01 15:24:00.291: Find a better model.
2023-09-01 15:24:27.414: [iter 16 : loss : 0.5891 = 0.2536 + 0.1680 + 0.0031 + 0.1644, time: 27.077331]
2023-09-01 15:24:27.639: epoch 16:	0.14653799  	0.22931758  	0.23841916  
2023-09-01 15:24:27.640: Find a better model.
2023-09-01 15:24:54.849: [iter 17 : loss : 0.5761 = 0.2498 + 0.1632 + 0.0033 + 0.1598, time: 27.164465]
2023-09-01 15:24:55.077: epoch 17:	0.14798655  	0.23286304  	0.24116270  
2023-09-01 15:24:55.077: Find a better model.
2023-09-01 15:25:22.466: [iter 18 : loss : 0.5647 = 0.2463 + 0.1595 + 0.0035 + 0.1554, time: 27.340008]
2023-09-01 15:25:22.706: epoch 18:	0.14889710  	0.23493816  	0.24319500  
2023-09-01 15:25:22.707: Find a better model.
2023-09-01 15:25:49.760: [iter 19 : loss : 0.5533 = 0.2434 + 0.1551 + 0.0037 + 0.1511, time: 27.007728]
2023-09-01 15:25:49.993: epoch 19:	0.15042861  	0.23846833  	0.24673097  
2023-09-01 15:25:49.993: Find a better model.
2023-09-01 15:26:17.045: [iter 20 : loss : 0.5421 = 0.2407 + 0.1507 + 0.0038 + 0.1469, time: 27.011029]
2023-09-01 15:26:17.273: epoch 20:	0.15177795  	0.24082430  	0.24887408  
2023-09-01 15:26:17.273: Find a better model.
2023-09-01 15:26:44.429: [iter 21 : loss : 0.5312 = 0.2387 + 0.1459 + 0.0040 + 0.1426, time: 27.112281]
2023-09-01 15:26:44.659: epoch 21:	0.15256445  	0.24259517  	0.25020683  
2023-09-01 15:26:44.659: Find a better model.
2023-09-01 15:27:11.989: [iter 22 : loss : 0.5184 = 0.2340 + 0.1416 + 0.0042 + 0.1386, time: 27.290075]
2023-09-01 15:27:12.217: epoch 22:	0.15350819  	0.24451031  	0.25180596  
2023-09-01 15:27:12.217: Find a better model.
2023-09-01 15:27:39.501: [iter 23 : loss : 0.5088 = 0.2318 + 0.1380 + 0.0044 + 0.1346, time: 27.242391]
2023-09-01 15:27:39.730: epoch 23:	0.15445185  	0.24670477  	0.25392580  
2023-09-01 15:27:39.730: Find a better model.
2023-09-01 15:28:06.304: [iter 24 : loss : 0.4993 = 0.2299 + 0.1342 + 0.0046 + 0.1306, time: 26.542957]
2023-09-01 15:28:06.528: epoch 24:	0.15518862  	0.24806623  	0.25541261  
2023-09-01 15:28:06.528: Find a better model.
2023-09-01 15:28:33.404: [iter 25 : loss : 0.4924 = 0.2300 + 0.1307 + 0.0048 + 0.1269, time: 26.839999]
2023-09-01 15:28:33.635: epoch 25:	0.15598330  	0.25012150  	0.25737712  
2023-09-01 15:28:33.636: Find a better model.
2023-09-01 15:29:00.915: [iter 26 : loss : 0.4830 = 0.2277 + 0.1272 + 0.0050 + 0.1232, time: 27.237715]
2023-09-01 15:29:01.143: epoch 26:	0.15691879  	0.25219911  	0.25903046  
2023-09-01 15:29:01.144: Find a better model.
2023-09-01 15:29:28.129: [iter 27 : loss : 0.4724 = 0.2252 + 0.1225 + 0.0052 + 0.1195, time: 26.933398]
2023-09-01 15:29:28.357: epoch 27:	0.15759754  	0.25377846  	0.26009244  
2023-09-01 15:29:28.357: Find a better model.
2023-09-01 15:29:55.499: [iter 28 : loss : 0.4641 = 0.2226 + 0.1204 + 0.0054 + 0.1157, time: 27.104789]
2023-09-01 15:29:55.727: epoch 28:	0.15812741  	0.25530505  	0.26130792  
2023-09-01 15:29:55.728: Find a better model.
2023-09-01 15:30:22.565: [iter 29 : loss : 0.4557 = 0.2221 + 0.1159 + 0.0056 + 0.1121, time: 26.788857]
2023-09-01 15:30:22.795: epoch 29:	0.15892214  	0.25678140  	0.26304257  
2023-09-01 15:30:22.795: Find a better model.
2023-09-01 15:30:50.004: [iter 30 : loss : 0.4479 = 0.2207 + 0.1128 + 0.0057 + 0.1087, time: 27.157682]
2023-09-01 15:30:50.238: epoch 30:	0.15965053  	0.25886419  	0.26472098  
2023-09-01 15:30:50.238: Find a better model.
2023-09-01 15:31:17.210: [iter 31 : loss : 0.4384 = 0.2194 + 0.1078 + 0.0059 + 0.1053, time: 26.923574]
2023-09-01 15:31:17.438: epoch 31:	0.15970860  	0.25916821  	0.26552510  
2023-09-01 15:31:17.439: Find a better model.
2023-09-01 15:31:44.367: [iter 32 : loss : 0.4306 = 0.2168 + 0.1058 + 0.0061 + 0.1019, time: 26.887422]
2023-09-01 15:31:44.595: epoch 32:	0.16016372  	0.26062617  	0.26680732  
2023-09-01 15:31:44.595: Find a better model.
2023-09-01 15:32:11.414: [iter 33 : loss : 0.4240 = 0.2177 + 0.1015 + 0.0063 + 0.0985, time: 26.782170]
2023-09-01 15:32:11.642: epoch 33:	0.16052800  	0.26185039  	0.26794687  
2023-09-01 15:32:11.643: Find a better model.
2023-09-01 15:32:38.734: [iter 34 : loss : 0.4151 = 0.2158 + 0.0975 + 0.0065 + 0.0952, time: 27.055579]
2023-09-01 15:32:38.963: epoch 34:	0.16114055  	0.26312265  	0.26907530  
2023-09-01 15:32:38.963: Find a better model.
2023-09-01 15:33:06.187: [iter 35 : loss : 0.4085 = 0.2149 + 0.0949 + 0.0067 + 0.0919, time: 27.183662]
2023-09-01 15:33:06.416: epoch 35:	0.16156274  	0.26410359  	0.27000907  
2023-09-01 15:33:06.416: Find a better model.
2023-09-01 15:33:33.709: [iter 36 : loss : 0.4033 = 0.2156 + 0.0919 + 0.0069 + 0.0889, time: 27.252081]
2023-09-01 15:33:33.938: epoch 36:	0.16181938  	0.26460949  	0.27050203  
2023-09-01 15:33:33.939: Find a better model.
2023-09-01 15:34:00.852: [iter 37 : loss : 0.3950 = 0.2144 + 0.0877 + 0.0071 + 0.0858, time: 26.865074]
2023-09-01 15:34:01.078: epoch 37:	0.16192700  	0.26483905  	0.27111369  
2023-09-01 15:34:01.078: Find a better model.
2023-09-01 15:34:28.354: [iter 38 : loss : 0.3886 = 0.2132 + 0.0853 + 0.0073 + 0.0827, time: 27.236399]
2023-09-01 15:34:28.587: epoch 38:	0.16237409  	0.26520795  	0.27182639  
2023-09-01 15:34:28.587: Find a better model.
2023-09-01 15:34:55.792: [iter 39 : loss : 0.3816 = 0.2128 + 0.0817 + 0.0075 + 0.0797, time: 27.166088]
2023-09-01 15:34:56.022: epoch 39:	0.16239062  	0.26568329  	0.27235648  
2023-09-01 15:34:56.022: Find a better model.
2023-09-01 15:35:23.168: [iter 40 : loss : 0.3789 = 0.2140 + 0.0803 + 0.0077 + 0.0768, time: 27.095655]
2023-09-01 15:35:23.397: epoch 40:	0.16294523  	0.26679543  	0.27321124  
2023-09-01 15:35:23.397: Find a better model.
2023-09-01 15:35:50.349: [iter 41 : loss : 0.3704 = 0.2121 + 0.0766 + 0.0079 + 0.0738, time: 26.914289]
2023-09-01 15:35:50.579: epoch 41:	0.16313562  	0.26785064  	0.27409902  
2023-09-01 15:35:50.579: Find a better model.
2023-09-01 15:36:17.531: [iter 42 : loss : 0.3627 = 0.2100 + 0.0737 + 0.0081 + 0.0710, time: 26.916271]
2023-09-01 15:36:17.761: epoch 42:	0.16301151  	0.26752117  	0.27425408  
2023-09-01 15:36:44.749: [iter 43 : loss : 0.3566 = 0.2103 + 0.0700 + 0.0083 + 0.0679, time: 26.949923]
2023-09-01 15:36:44.977: epoch 43:	0.16339229  	0.26838726  	0.27490148  
2023-09-01 15:36:44.977: Find a better model.
2023-09-01 15:37:11.744: [iter 44 : loss : 0.3511 = 0.2088 + 0.0687 + 0.0085 + 0.0651, time: 26.725744]
2023-09-01 15:37:11.974: epoch 44:	0.16373989  	0.26915488  	0.27547795  
2023-09-01 15:37:11.974: Find a better model.
2023-09-01 15:37:38.777: [iter 45 : loss : 0.3487 = 0.2115 + 0.0661 + 0.0087 + 0.0624, time: 26.760102]
2023-09-01 15:37:39.004: epoch 45:	0.16373160  	0.26953122  	0.27593371  
2023-09-01 15:37:39.004: Find a better model.
2023-09-01 15:38:06.195: [iter 46 : loss : 0.3410 = 0.2107 + 0.0619 + 0.0089 + 0.0595, time: 27.158092]
2023-09-01 15:38:06.422: epoch 46:	0.16385582  	0.26982528  	0.27611816  
2023-09-01 15:38:06.422: Find a better model.
2023-09-01 15:38:33.313: [iter 47 : loss : 0.3350 = 0.2095 + 0.0596 + 0.0091 + 0.0569, time: 26.849500]
2023-09-01 15:38:33.543: epoch 47:	0.16404629  	0.27069664  	0.27683592  
2023-09-01 15:38:33.543: Find a better model.
2023-09-01 15:39:00.552: [iter 48 : loss : 0.3300 = 0.2092 + 0.0573 + 0.0093 + 0.0541, time: 26.971081]
2023-09-01 15:39:00.777: epoch 48:	0.16398020  	0.27051306  	0.27674052  
2023-09-01 15:39:27.544: [iter 49 : loss : 0.3266 = 0.2092 + 0.0563 + 0.0095 + 0.0516, time: 26.731904]
2023-09-01 15:39:27.768: epoch 49:	0.16394700  	0.27125725  	0.27698398  
2023-09-01 15:39:27.768: Find a better model.
2023-09-01 15:39:54.637: [iter 50 : loss : 0.3182 = 0.2081 + 0.0515 + 0.0097 + 0.0489, time: 26.833683]
2023-09-01 15:39:54.864: epoch 50:	0.16422845  	0.27148205  	0.27742592  
2023-09-01 15:39:54.864: Find a better model.
2023-09-01 15:40:21.671: [iter 51 : loss : 0.3146 = 0.2083 + 0.0503 + 0.0099 + 0.0461, time: 26.761058]
2023-09-01 15:40:21.895: epoch 51:	0.16440225  	0.27173874  	0.27777731  
2023-09-01 15:40:21.895: Find a better model.
2023-09-01 15:40:48.390: [iter 52 : loss : 0.3105 = 0.2094 + 0.0472 + 0.0101 + 0.0437, time: 26.453654]
2023-09-01 15:40:48.619: epoch 52:	0.16472508  	0.27201566  	0.27810299  
2023-09-01 15:40:48.619: Find a better model.
2023-09-01 15:41:15.406: [iter 53 : loss : 0.3036 = 0.2084 + 0.0438 + 0.0103 + 0.0411, time: 26.752248]
2023-09-01 15:41:15.631: epoch 53:	0.16458437  	0.27190650  	0.27801245  
2023-09-01 15:41:42.445: [iter 54 : loss : 0.2993 = 0.2094 + 0.0408 + 0.0105 + 0.0387, time: 26.777122]
2023-09-01 15:41:42.671: epoch 54:	0.16477466  	0.27192762  	0.27851877  
2023-09-01 15:42:09.414: [iter 55 : loss : 0.2939 = 0.2079 + 0.0392 + 0.0107 + 0.0361, time: 26.703303]
2023-09-01 15:42:09.640: epoch 55:	0.16465878  	0.27172440  	0.27843276  
2023-09-01 15:42:36.389: [iter 56 : loss : 0.2886 = 0.2078 + 0.0362 + 0.0109 + 0.0337, time: 26.713098]
2023-09-01 15:42:36.614: epoch 56:	0.16481616  	0.27219808  	0.27878526  
2023-09-01 15:42:36.615: Find a better model.
2023-09-01 15:43:03.409: [iter 57 : loss : 0.2866 = 0.2103 + 0.0339 + 0.0111 + 0.0312, time: 26.757104]
2023-09-01 15:43:03.635: epoch 57:	0.16498163  	0.27197239  	0.27891362  
2023-09-01 15:43:30.725: [iter 58 : loss : 0.2823 = 0.2092 + 0.0329 + 0.0113 + 0.0289, time: 27.053911]
2023-09-01 15:43:30.952: epoch 58:	0.16508922  	0.27277741  	0.27924517  
2023-09-01 15:43:30.952: Find a better model.
2023-09-01 15:43:57.759: [iter 59 : loss : 0.2772 = 0.2097 + 0.0295 + 0.0115 + 0.0266, time: 26.755932]
2023-09-01 15:43:57.981: epoch 59:	0.16510592  	0.27272406  	0.27913329  
2023-09-01 15:44:24.456: [iter 60 : loss : 0.2713 = 0.2083 + 0.0272 + 0.0117 + 0.0241, time: 26.442416]
2023-09-01 15:44:24.681: epoch 60:	0.16512257  	0.27281135  	0.27929944  
2023-09-01 15:44:24.681: Find a better model.
2023-09-01 15:44:51.378: [iter 61 : loss : 0.2672 = 0.2093 + 0.0242 + 0.0119 + 0.0219, time: 26.657547]
2023-09-01 15:44:51.601: epoch 61:	0.16534606  	0.27311131  	0.27962744  
2023-09-01 15:44:51.602: Find a better model.
2023-09-01 15:45:18.048: [iter 62 : loss : 0.2632 = 0.2085 + 0.0231 + 0.0120 + 0.0196, time: 26.408569]
2023-09-01 15:45:18.271: epoch 62:	0.16535431  	0.27326053  	0.27990454  
2023-09-01 15:45:18.271: Find a better model.
2023-09-01 15:45:44.736: [iter 63 : loss : 0.2611 = 0.2103 + 0.0212 + 0.0122 + 0.0173, time: 26.432522]
2023-09-01 15:45:44.963: epoch 63:	0.16512257  	0.27291647  	0.27949452  
2023-09-01 15:46:11.533: [iter 64 : loss : 0.2522 = 0.2078 + 0.0170 + 0.0124 + 0.0150, time: 26.537580]
2023-09-01 15:46:11.764: epoch 64:	0.16531298  	0.27351984  	0.27967089  
2023-09-01 15:46:11.764: Find a better model.
2023-09-01 15:46:38.800: [iter 65 : loss : 0.2491 = 0.2092 + 0.0144 + 0.0126 + 0.0128, time: 27.001290]
2023-09-01 15:46:39.018: epoch 65:	0.16523832  	0.27336368  	0.27978066  
2023-09-01 15:47:05.683: [iter 66 : loss : 0.2460 = 0.2098 + 0.0128 + 0.0128 + 0.0105, time: 26.634220]
2023-09-01 15:47:05.908: epoch 66:	0.16509765  	0.27308953  	0.27960810  
2023-09-01 15:47:32.717: [iter 67 : loss : 0.2425 = 0.2093 + 0.0120 + 0.0130 + 0.0082, time: 26.776001]
2023-09-01 15:47:32.939: epoch 67:	0.16486593  	0.27281934  	0.27976704  
2023-09-01 15:47:59.461: [iter 68 : loss : 0.2397 = 0.2113 + 0.0089 + 0.0132 + 0.0063, time: 26.489760]
2023-09-01 15:47:59.688: epoch 68:	0.16498177  	0.27257892  	0.28000969  
2023-09-01 15:48:26.774: [iter 69 : loss : 0.2323 = 0.2080 + 0.0069 + 0.0134 + 0.0040, time: 27.032802]
2023-09-01 15:48:27.006: epoch 69:	0.16499826  	0.27276516  	0.28004482  
2023-09-01 15:48:53.702: [iter 70 : loss : 0.2330 = 0.2130 + 0.0047 + 0.0136 + 0.0017, time: 26.661916]
2023-09-01 15:48:53.926: epoch 70:	0.16508111  	0.27279937  	0.28015074  
2023-09-01 15:49:20.870: [iter 71 : loss : 0.2273 = 0.2110 + 0.0027 + 0.0138 + -0.0002, time: 26.908105]
2023-09-01 15:49:21.096: epoch 71:	0.16496524  	0.27265134  	0.27998060  
2023-09-01 15:49:47.854: [iter 72 : loss : 0.2255 = 0.2120 + 0.0016 + 0.0140 + -0.0022, time: 26.713226]
2023-09-01 15:49:48.082: epoch 72:	0.16494046  	0.27248004  	0.28011554  
2023-09-01 15:50:14.736: [iter 73 : loss : 0.2230 = 0.2137 + -0.0006 + 0.0142 + -0.0043, time: 26.621205]
2023-09-01 15:50:14.962: epoch 73:	0.16485764  	0.27234411  	0.28006935  
2023-09-01 15:50:42.117: [iter 74 : loss : 0.2162 = 0.2120 + -0.0038 + 0.0144 + -0.0063, time: 27.119914]
2023-09-01 15:50:42.345: epoch 74:	0.16446854  	0.27165890  	0.27970889  
2023-09-01 15:50:42.345: Early stopping is trigger at epoch: 74
2023-09-01 15:50:42.345: best_result@epoch 64:

2023-09-01 15:50:42.345: 		0.1653      	0.2735      	0.2797      

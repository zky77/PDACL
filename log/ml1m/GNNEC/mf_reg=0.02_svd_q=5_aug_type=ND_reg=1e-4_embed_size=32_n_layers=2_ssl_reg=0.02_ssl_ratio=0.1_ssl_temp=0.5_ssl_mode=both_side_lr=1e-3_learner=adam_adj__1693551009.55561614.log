2023-09-01 14:50:09.556: my pid: 12131
2023-09-01 14:50:09.556: model: model.general_recommender.GNNEC
2023-09-01 14:50:09.556: Dataset statistics:
Name: ml1m
The number of users: 6040
The number of items: 3706
The number of ratings: 1000209
Average actions of users: 165.60
Average actions of items: 269.89
The sparsity of the dataset: 95.531637%

The number of training: 902826
The number of validation: 0
The number of testing: 97383
2023-09-01 14:50:09.556: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=ml1m
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=ml1m
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
mf_reg=0.02
svd_q=5
2023-09-01 14:50:14.242: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 14:50:41.606: [iter 1 : loss : 1.1210 = 0.5874 + 0.2668 + 0.0001 + 0.2667, time: 27.363342]
2023-09-01 14:50:41.833: epoch 1:	0.09346750  	0.13927785  	0.15210548  
2023-09-01 14:50:41.833: Find a better model.
2023-09-01 14:51:08.771: [iter 2 : loss : 0.8195 = 0.4300 + 0.1953 + 0.0005 + 0.1937, time: 26.892358]
2023-09-01 14:51:09.001: epoch 2:	0.10744040  	0.16468219  	0.17783682  
2023-09-01 14:51:09.001: Find a better model.
2023-09-01 14:51:35.829: [iter 3 : loss : 0.6892 = 0.3789 + 0.1556 + 0.0008 + 0.1539, time: 26.764821]
2023-09-01 14:51:36.058: epoch 3:	0.11345831  	0.17530943  	0.18888487  
2023-09-01 14:51:36.058: Find a better model.
2023-09-01 14:52:02.866: [iter 4 : loss : 0.6095 = 0.3555 + 0.1276 + 0.0011 + 0.1253, time: 26.761368]
2023-09-01 14:52:03.094: epoch 4:	0.11969995  	0.18500419  	0.19918340  
2023-09-01 14:52:03.094: Find a better model.
2023-09-01 14:52:29.923: [iter 5 : loss : 0.5461 = 0.3392 + 0.1040 + 0.0014 + 0.1016, time: 26.793021]
2023-09-01 14:52:30.150: epoch 5:	0.12609902  	0.19586535  	0.20896299  
2023-09-01 14:52:30.151: Find a better model.
2023-09-01 14:52:56.966: [iter 6 : loss : 0.4915 = 0.3256 + 0.0831 + 0.0017 + 0.0811, time: 26.775749]
2023-09-01 14:52:57.194: epoch 6:	0.13070172  	0.20398988  	0.21739572  
2023-09-01 14:52:57.194: Find a better model.
2023-09-01 14:53:24.177: [iter 7 : loss : 0.4478 = 0.3183 + 0.0647 + 0.0019 + 0.0628, time: 26.941884]
2023-09-01 14:53:24.404: epoch 7:	0.13484095  	0.21115912  	0.22311929  
2023-09-01 14:53:24.404: Find a better model.
2023-09-01 14:53:51.127: [iter 8 : loss : 0.4050 = 0.3086 + 0.0484 + 0.0022 + 0.0457, time: 26.683900]
2023-09-01 14:53:51.351: epoch 8:	0.13859098  	0.21813886  	0.22935680  
2023-09-01 14:53:51.351: Find a better model.
2023-09-01 14:54:18.226: [iter 9 : loss : 0.3655 = 0.3011 + 0.0322 + 0.0025 + 0.0298, time: 26.839629]
2023-09-01 14:54:18.453: epoch 9:	0.14109932  	0.22257262  	0.23360150  
2023-09-01 14:54:18.453: Find a better model.
2023-09-01 14:54:45.185: [iter 10 : loss : 0.3288 = 0.2945 + 0.0170 + 0.0028 + 0.0145, time: 26.696942]
2023-09-01 14:54:45.412: epoch 10:	0.14354964  	0.22796796  	0.23850870  
2023-09-01 14:54:45.412: Find a better model.
2023-09-01 14:55:12.640: [iter 11 : loss : 0.2953 = 0.2893 + 0.0029 + 0.0031 + -0.0000, time: 27.184964]
2023-09-01 14:55:12.864: epoch 11:	0.14595853  	0.23204732  	0.24261576  
2023-09-01 14:55:12.864: Find a better model.
2023-09-01 14:55:39.850: [iter 12 : loss : 0.2632 = 0.2844 + -0.0108 + 0.0034 + -0.0138, time: 26.944394]
2023-09-01 14:55:40.080: epoch 12:	0.14798658  	0.23539869  	0.24592340  
2023-09-01 14:55:40.080: Find a better model.
2023-09-01 14:56:06.819: [iter 13 : loss : 0.2318 = 0.2800 + -0.0248 + 0.0037 + -0.0270, time: 26.702696]
2023-09-01 14:56:07.050: epoch 13:	0.14974150  	0.23852912  	0.24934399  
2023-09-01 14:56:07.050: Find a better model.
2023-09-01 14:56:33.681: [iter 14 : loss : 0.2034 = 0.2770 + -0.0377 + 0.0040 + -0.0399, time: 26.593761]
2023-09-01 14:56:33.905: epoch 14:	0.15143856  	0.24208374  	0.25286427  
2023-09-01 14:56:33.905: Find a better model.
2023-09-01 14:57:00.450: [iter 15 : loss : 0.1768 = 0.2747 + -0.0502 + 0.0043 + -0.0520, time: 26.511336]
2023-09-01 14:57:00.676: epoch 15:	0.15287893  	0.24479282  	0.25584841  
2023-09-01 14:57:00.676: Find a better model.
2023-09-01 14:57:27.151: [iter 16 : loss : 0.1517 = 0.2724 + -0.0616 + 0.0046 + -0.0637, time: 26.430973]
2023-09-01 14:57:27.375: epoch 16:	0.15380628  	0.24678883  	0.25759244  
2023-09-01 14:57:27.375: Find a better model.
2023-09-01 14:57:54.086: [iter 17 : loss : 0.1268 = 0.2698 + -0.0729 + 0.0049 + -0.0749, time: 26.675478]
2023-09-01 14:57:54.313: epoch 17:	0.15513070  	0.24926661  	0.25960425  
2023-09-01 14:57:54.313: Find a better model.
2023-09-01 14:58:21.099: [iter 18 : loss : 0.1045 = 0.2678 + -0.0828 + 0.0052 + -0.0857, time: 26.743943]
2023-09-01 14:58:21.324: epoch 18:	0.15575995  	0.25027704  	0.26108539  
2023-09-01 14:58:21.324: Find a better model.
2023-09-01 14:58:47.957: [iter 19 : loss : 0.0818 = 0.2661 + -0.0936 + 0.0055 + -0.0963, time: 26.590910]
2023-09-01 14:58:48.180: epoch 19:	0.15642223  	0.25258517  	0.26261961  
2023-09-01 14:58:48.181: Find a better model.
2023-09-01 14:59:14.945: [iter 20 : loss : 0.0604 = 0.2651 + -0.1041 + 0.0058 + -0.1065, time: 26.722727]
2023-09-01 14:59:15.174: epoch 20:	0.15743223  	0.25510305  	0.26444045  
2023-09-01 14:59:15.174: Find a better model.
2023-09-01 14:59:41.928: [iter 21 : loss : 0.0400 = 0.2649 + -0.1144 + 0.0061 + -0.1166, time: 26.721525]
2023-09-01 14:59:42.151: epoch 21:	0.15773846  	0.25588992  	0.26538149  
2023-09-01 14:59:42.151: Find a better model.
2023-09-01 15:00:08.881: [iter 22 : loss : 0.0180 = 0.2612 + -0.1237 + 0.0065 + -0.1260, time: 26.696274]
2023-09-01 15:00:09.106: epoch 22:	0.15853307  	0.25770190  	0.26652393  
2023-09-01 15:00:09.106: Find a better model.
2023-09-01 15:00:36.122: [iter 23 : loss : -0.0021 = 0.2597 + -0.1331 + 0.0068 + -0.1355, time: 26.974617]
2023-09-01 15:00:36.352: epoch 23:	0.15922837  	0.25873497  	0.26779130  
2023-09-01 15:00:36.352: Find a better model.
2023-09-01 15:01:03.511: [iter 24 : loss : -0.0201 = 0.2596 + -0.1420 + 0.0071 + -0.1447, time: 27.123858]
2023-09-01 15:01:03.736: epoch 24:	0.15960911  	0.25951889  	0.26842397  
2023-09-01 15:01:03.736: Find a better model.
2023-09-01 15:01:30.323: [iter 25 : loss : -0.0353 = 0.2610 + -0.1504 + 0.0074 + -0.1534, time: 26.551018]
2023-09-01 15:01:30.551: epoch 25:	0.15985742  	0.26011387  	0.26898122  
2023-09-01 15:01:30.551: Find a better model.
2023-09-01 15:01:57.404: [iter 26 : loss : -0.0524 = 0.2600 + -0.1581 + 0.0077 + -0.1620, time: 26.818096]
2023-09-01 15:01:57.632: epoch 26:	0.16013893  	0.26075709  	0.26953104  
2023-09-01 15:01:57.633: Find a better model.
2023-09-01 15:02:24.566: [iter 27 : loss : -0.0705 = 0.2592 + -0.1675 + 0.0080 + -0.1702, time: 26.900302]
2023-09-01 15:02:24.788: epoch 27:	0.16020514  	0.26142421  	0.26987356  
2023-09-01 15:02:24.788: Find a better model.
2023-09-01 15:02:51.734: [iter 28 : loss : -0.0873 = 0.2576 + -0.1745 + 0.0083 + -0.1788, time: 26.912210]
2023-09-01 15:02:51.970: epoch 28:	0.16025482  	0.26161805  	0.26991531  
2023-09-01 15:02:51.970: Find a better model.
2023-09-01 15:03:18.673: [iter 29 : loss : -0.1034 = 0.2584 + -0.1836 + 0.0087 + -0.1868, time: 26.664159]
2023-09-01 15:03:18.896: epoch 29:	0.16055280  	0.26236287  	0.27017152  
2023-09-01 15:03:18.896: Find a better model.
2023-09-01 15:03:45.837: [iter 30 : loss : -0.1180 = 0.2584 + -0.1909 + 0.0090 + -0.1944, time: 26.906679]
2023-09-01 15:03:46.062: epoch 30:	0.16097505  	0.26286319  	0.27076802  
2023-09-01 15:03:46.062: Find a better model.
2023-09-01 15:04:12.727: [iter 31 : loss : -0.1341 = 0.2583 + -0.1997 + 0.0093 + -0.2020, time: 26.631379]
2023-09-01 15:04:12.952: epoch 31:	0.16100000  	0.26293936  	0.27101785  
2023-09-01 15:04:12.952: Find a better model.
2023-09-01 15:04:39.837: [iter 32 : loss : -0.1489 = 0.2563 + -0.2055 + 0.0096 + -0.2093, time: 26.851919]
2023-09-01 15:04:40.060: epoch 32:	0.16081783  	0.26273727  	0.27102137  
2023-09-01 15:05:06.920: [iter 33 : loss : -0.1611 = 0.2592 + -0.2135 + 0.0099 + -0.2167, time: 26.827523]
2023-09-01 15:05:07.151: epoch 33:	0.16089228  	0.26321679  	0.27109313  
2023-09-01 15:05:07.151: Find a better model.
2023-09-01 15:05:34.064: [iter 34 : loss : -0.1769 = 0.2581 + -0.2215 + 0.0102 + -0.2237, time: 26.879759]
2023-09-01 15:05:34.291: epoch 34:	0.16133936  	0.26376539  	0.27151412  
2023-09-01 15:05:34.291: Find a better model.
2023-09-01 15:06:01.190: [iter 35 : loss : -0.1891 = 0.2587 + -0.2275 + 0.0105 + -0.2308, time: 26.863227]
2023-09-01 15:06:01.418: epoch 35:	0.16097516  	0.26337409  	0.27128717  
2023-09-01 15:06:28.352: [iter 36 : loss : -0.1992 = 0.2613 + -0.2340 + 0.0108 + -0.2373, time: 26.899783]
2023-09-01 15:06:28.584: epoch 36:	0.16124834  	0.26394495  	0.27144483  
2023-09-01 15:06:28.584: Find a better model.
2023-09-01 15:06:54.503: [iter 37 : loss : -0.2127 = 0.2615 + -0.2414 + 0.0111 + -0.2439, time: 25.883328]
2023-09-01 15:06:54.731: epoch 37:	0.16136423  	0.26434523  	0.27183414  
2023-09-01 15:06:54.731: Find a better model.
2023-09-01 15:07:21.822: [iter 38 : loss : -0.2246 = 0.2611 + -0.2469 + 0.0114 + -0.2502, time: 27.055304]
2023-09-01 15:07:22.051: epoch 38:	0.16108274  	0.26373604  	0.27163836  
2023-09-01 15:07:49.525: [iter 39 : loss : -0.2369 = 0.2620 + -0.2540 + 0.0117 + -0.2566, time: 27.434435]
2023-09-01 15:07:49.767: epoch 39:	0.16126485  	0.26431727  	0.27180612  
2023-09-01 15:08:16.900: [iter 40 : loss : -0.2434 = 0.2651 + -0.2580 + 0.0120 + -0.2625, time: 27.080186]
2023-09-01 15:08:17.133: epoch 40:	0.16130626  	0.26380679  	0.27175862  
2023-09-01 15:08:44.037: [iter 41 : loss : -0.2568 = 0.2647 + -0.2651 + 0.0123 + -0.2687, time: 26.866530]
2023-09-01 15:08:44.272: epoch 41:	0.16127324  	0.26398399  	0.27171692  
2023-09-01 15:09:11.037: [iter 42 : loss : -0.2703 = 0.2627 + -0.2710 + 0.0126 + -0.2745, time: 26.732086]
2023-09-01 15:09:11.262: epoch 42:	0.16139734  	0.26371196  	0.27155912  
2023-09-01 15:09:38.365: [iter 43 : loss : -0.2801 = 0.2649 + -0.2774 + 0.0129 + -0.2805, time: 27.067538]
2023-09-01 15:09:38.595: epoch 43:	0.16099998  	0.26314136  	0.27119797  
2023-09-01 15:10:05.688: [iter 44 : loss : -0.2896 = 0.2647 + -0.2813 + 0.0132 + -0.2862, time: 27.057194]
2023-09-01 15:10:05.920: epoch 44:	0.16106611  	0.26330808  	0.27111238  
2023-09-01 15:10:32.775: [iter 45 : loss : -0.2957 = 0.2689 + -0.2865 + 0.0135 + -0.2916, time: 26.813614]
2023-09-01 15:10:33.004: epoch 45:	0.16108271  	0.26355755  	0.27129301  
2023-09-01 15:11:00.159: [iter 46 : loss : -0.3070 = 0.2700 + -0.2936 + 0.0138 + -0.2972, time: 27.117631]
2023-09-01 15:11:00.390: epoch 46:	0.16086757  	0.26331353  	0.27106923  
2023-09-01 15:11:27.651: [iter 47 : loss : -0.3175 = 0.2690 + -0.2981 + 0.0141 + -0.3024, time: 27.219533]
2023-09-01 15:11:27.884: epoch 47:	0.16038731  	0.26228580  	0.27026120  
2023-09-01 15:11:27.884: Early stopping is trigger at epoch: 47
2023-09-01 15:11:27.884: best_result@epoch 37:

2023-09-01 15:11:27.884: 		0.1614      	0.2643      	0.2718      

2023-09-01 13:00:03.624: my pid: 4556
2023-09-01 13:00:03.624: model: model.general_recommender.GNNEC
2023-09-01 13:00:03.624: Dataset statistics:
Name: ml1m
The number of users: 6040
The number of items: 3706
The number of ratings: 1000209
Average actions of users: 165.60
Average actions of items: 269.89
The sparsity of the dataset: 95.531637%

The number of training: 902826
The number of validation: 0
The number of testing: 97383
2023-09-01 13:00:03.624: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=ml1m
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.0002
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=ml1m
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
mf_reg=0.0002
svd_q=5
2023-09-01 13:00:08.413: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 13:00:54.944: [iter 1 : loss : 0.9087 = 0.5926 + 0.3129 + 0.0001 + 0.0031, time: 46.531322]
2023-09-01 13:00:55.231: epoch 1:	0.09486652  	0.14540841  	0.15736642  
2023-09-01 13:00:55.231: Find a better model.
2023-09-01 13:01:41.316: [iter 2 : loss : 0.7254 = 0.4337 + 0.2884 + 0.0004 + 0.0029, time: 46.054176]
2023-09-01 13:01:41.605: epoch 2:	0.10650493  	0.16610208  	0.17825608  
2023-09-01 13:01:41.605: Find a better model.
2023-09-01 13:02:28.729: [iter 3 : loss : 0.6625 = 0.3814 + 0.2777 + 0.0006 + 0.0028, time: 47.075939]
2023-09-01 13:02:29.015: epoch 3:	0.11203460  	0.17419478  	0.18737021  
2023-09-01 13:02:29.015: Find a better model.
2023-09-01 13:03:15.823: [iter 4 : loss : 0.6282 = 0.3533 + 0.2714 + 0.0008 + 0.0027, time: 46.776635]
2023-09-01 13:03:16.105: epoch 4:	0.11735747  	0.18252060  	0.19545883  
2023-09-01 13:03:16.105: Find a better model.
2023-09-01 13:04:02.258: [iter 5 : loss : 0.6020 = 0.3325 + 0.2660 + 0.0009 + 0.0026, time: 46.125604]
2023-09-01 13:04:02.539: epoch 5:	0.12307768  	0.19022967  	0.20357932  
2023-09-01 13:04:02.539: Find a better model.
2023-09-01 13:04:48.655: [iter 6 : loss : 0.5795 = 0.3151 + 0.2608 + 0.0011 + 0.0026, time: 46.077590]
2023-09-01 13:04:48.950: epoch 6:	0.12862398  	0.19983944  	0.21252356  
2023-09-01 13:04:48.950: Find a better model.
2023-09-01 13:05:35.361: [iter 7 : loss : 0.5635 = 0.3033 + 0.2564 + 0.0012 + 0.0026, time: 46.379791]
2023-09-01 13:05:35.640: epoch 7:	0.13240714  	0.20623159  	0.21631998  
2023-09-01 13:05:35.641: Find a better model.
2023-09-01 13:06:21.690: [iter 8 : loss : 0.5476 = 0.2910 + 0.2528 + 0.0014 + 0.0025, time: 46.022849]
2023-09-01 13:06:21.975: epoch 8:	0.13585907  	0.21285518  	0.22135149  
2023-09-01 13:06:21.975: Find a better model.
2023-09-01 13:07:08.319: [iter 9 : loss : 0.5332 = 0.2806 + 0.2487 + 0.0015 + 0.0025, time: 46.314484]
2023-09-01 13:07:08.600: epoch 9:	0.13905455  	0.21876068  	0.22701766  
2023-09-01 13:07:08.600: Find a better model.
2023-09-01 13:07:55.070: [iter 10 : loss : 0.5201 = 0.2715 + 0.2445 + 0.0016 + 0.0024, time: 46.438004]
2023-09-01 13:07:55.347: epoch 10:	0.14141381  	0.22355841  	0.23250039  
2023-09-01 13:07:55.347: Find a better model.
2023-09-01 13:08:41.542: [iter 11 : loss : 0.5089 = 0.2636 + 0.2411 + 0.0018 + 0.0024, time: 46.164077]
2023-09-01 13:08:41.827: epoch 11:	0.14451826  	0.22916722  	0.23766404  
2023-09-01 13:08:41.827: Find a better model.
2023-09-01 13:09:28.000: [iter 12 : loss : 0.4986 = 0.2564 + 0.2379 + 0.0019 + 0.0024, time: 46.141898]
2023-09-01 13:09:28.286: epoch 12:	0.14749822  	0.23425873  	0.24293165  
2023-09-01 13:09:28.286: Find a better model.
2023-09-01 13:10:14.244: [iter 13 : loss : 0.4876 = 0.2501 + 0.2332 + 0.0020 + 0.0023, time: 45.928097]
2023-09-01 13:10:14.531: epoch 13:	0.14929458  	0.23857532  	0.24756484  
2023-09-01 13:10:14.531: Find a better model.
2023-09-01 13:11:00.967: [iter 14 : loss : 0.4779 = 0.2439 + 0.2295 + 0.0022 + 0.0023, time: 46.412038]
2023-09-01 13:11:01.271: epoch 14:	0.15152961  	0.24251299  	0.25200781  
2023-09-01 13:11:01.272: Find a better model.
2023-09-01 13:11:47.752: [iter 15 : loss : 0.4697 = 0.2392 + 0.2259 + 0.0023 + 0.0022, time: 46.450524]
2023-09-01 13:11:48.052: epoch 15:	0.15321839  	0.24558289  	0.25515550  
2023-09-01 13:11:48.052: Find a better model.
2023-09-01 13:12:34.471: [iter 16 : loss : 0.4624 = 0.2343 + 0.2234 + 0.0024 + 0.0022, time: 46.389778]
2023-09-01 13:12:34.755: epoch 16:	0.15452640  	0.24839424  	0.25833163  
2023-09-01 13:12:34.755: Find a better model.
2023-09-01 13:13:21.113: [iter 17 : loss : 0.4540 = 0.2295 + 0.2197 + 0.0026 + 0.0022, time: 46.333421]
2023-09-01 13:13:21.396: epoch 17:	0.15581787  	0.25125396  	0.26095620  
2023-09-01 13:13:21.396: Find a better model.
2023-09-01 13:14:07.398: [iter 18 : loss : 0.4485 = 0.2257 + 0.2179 + 0.0027 + 0.0021, time: 45.971134]
2023-09-01 13:14:07.681: epoch 18:	0.15715073  	0.25339422  	0.26367489  
2023-09-01 13:14:07.681: Find a better model.
2023-09-01 13:14:54.020: [iter 19 : loss : 0.4404 = 0.2215 + 0.2140 + 0.0028 + 0.0021, time: 46.312095]
2023-09-01 13:14:54.307: epoch 19:	0.15829310  	0.25587025  	0.26605591  
2023-09-01 13:14:54.307: Find a better model.
2023-09-01 13:15:40.373: [iter 20 : loss : 0.4336 = 0.2177 + 0.2109 + 0.0030 + 0.0021, time: 46.037596]
2023-09-01 13:15:40.656: epoch 20:	0.15916219  	0.25803846  	0.26726192  
2023-09-01 13:15:40.656: Find a better model.
2023-09-01 13:16:26.877: [iter 21 : loss : 0.4280 = 0.2151 + 0.2078 + 0.0031 + 0.0021, time: 46.193699]
2023-09-01 13:16:27.160: epoch 21:	0.16006449  	0.26017621  	0.26886901  
2023-09-01 13:16:27.161: Find a better model.
2023-09-01 13:17:13.580: [iter 22 : loss : 0.4211 = 0.2103 + 0.2055 + 0.0032 + 0.0020, time: 46.390232]
2023-09-01 13:17:13.864: epoch 22:	0.16088426  	0.26281288  	0.27015331  
2023-09-01 13:17:13.864: Find a better model.
2023-09-01 13:18:00.492: [iter 23 : loss : 0.4144 = 0.2069 + 0.2022 + 0.0033 + 0.0020, time: 46.597031]
2023-09-01 13:18:00.777: epoch 23:	0.16121514  	0.26381937  	0.27103522  
2023-09-01 13:18:00.778: Find a better model.
2023-09-01 13:18:47.003: [iter 24 : loss : 0.4099 = 0.2048 + 0.1997 + 0.0035 + 0.0020, time: 46.197654]
2023-09-01 13:18:47.290: epoch 24:	0.16215053  	0.26545072  	0.27236459  
2023-09-01 13:18:47.290: Find a better model.
2023-09-01 13:19:33.274: [iter 25 : loss : 0.4059 = 0.2032 + 0.1972 + 0.0036 + 0.0020, time: 45.951208]
2023-09-01 13:19:33.557: epoch 25:	0.16276316  	0.26756451  	0.27433228  
2023-09-01 13:19:33.557: Find a better model.
2023-09-01 13:20:19.943: [iter 26 : loss : 0.4015 = 0.1998 + 0.1960 + 0.0037 + 0.0019, time: 46.355107]
2023-09-01 13:20:20.227: epoch 26:	0.16349159  	0.26832113  	0.27487773  
2023-09-01 13:20:20.227: Find a better model.
2023-09-01 13:21:06.731: [iter 27 : loss : 0.3952 = 0.1971 + 0.1923 + 0.0038 + 0.0019, time: 46.471630]
2023-09-01 13:21:07.015: epoch 27:	0.16352463  	0.26912463  	0.27548543  
2023-09-01 13:21:07.015: Find a better model.
2023-09-01 13:21:53.168: [iter 28 : loss : 0.3907 = 0.1940 + 0.1908 + 0.0040 + 0.0019, time: 46.128248]
2023-09-01 13:21:53.457: epoch 28:	0.16375650  	0.26967043  	0.27599776  
2023-09-01 13:21:53.457: Find a better model.
2023-09-01 13:22:39.794: [iter 29 : loss : 0.3857 = 0.1925 + 0.1873 + 0.0041 + 0.0019, time: 46.312035]
2023-09-01 13:22:40.080: epoch 29:	0.16418688  	0.27095714  	0.27691031  
2023-09-01 13:22:40.080: Find a better model.
2023-09-01 13:23:26.666: [iter 30 : loss : 0.3812 = 0.1900 + 0.1852 + 0.0042 + 0.0018, time: 46.555052]
2023-09-01 13:23:26.947: epoch 30:	0.16461749  	0.27266404  	0.27852601  
2023-09-01 13:23:26.947: Find a better model.
2023-09-01 13:24:13.315: [iter 31 : loss : 0.3759 = 0.1880 + 0.1817 + 0.0043 + 0.0018, time: 46.339666]
2023-09-01 13:24:13.598: epoch 31:	0.16459277  	0.27287042  	0.27879810  
2023-09-01 13:24:13.599: Find a better model.
2023-09-01 13:25:00.245: [iter 32 : loss : 0.3724 = 0.1854 + 0.1808 + 0.0044 + 0.0018, time: 46.619228]
2023-09-01 13:25:00.532: epoch 32:	0.16512240  	0.27388582  	0.27940384  
2023-09-01 13:25:00.533: Find a better model.
2023-09-01 13:25:46.762: [iter 33 : loss : 0.3686 = 0.1844 + 0.1779 + 0.0045 + 0.0018, time: 46.201254]
2023-09-01 13:25:47.052: epoch 33:	0.16527982  	0.27385679  	0.27989414  
2023-09-01 13:26:33.535: [iter 34 : loss : 0.3633 = 0.1820 + 0.1749 + 0.0047 + 0.0017, time: 46.453533]
2023-09-01 13:26:33.816: epoch 34:	0.16533779  	0.27367708  	0.28003743  
2023-09-01 13:27:20.109: [iter 35 : loss : 0.3605 = 0.1803 + 0.1737 + 0.0048 + 0.0017, time: 46.252187]
2023-09-01 13:27:20.395: epoch 35:	0.16533771  	0.27362058  	0.27953720  
2023-09-01 13:28:06.870: [iter 36 : loss : 0.3577 = 0.1795 + 0.1716 + 0.0049 + 0.0017, time: 46.443347]
2023-09-01 13:28:07.146: epoch 36:	0.16549499  	0.27456242  	0.27979770  
2023-09-01 13:28:07.146: Find a better model.
2023-09-01 13:28:52.927: [iter 37 : loss : 0.3535 = 0.1781 + 0.1687 + 0.0050 + 0.0017, time: 45.751889]
2023-09-01 13:28:53.208: epoch 37:	0.16538733  	0.27463406  	0.27996638  
2023-09-01 13:28:53.208: Find a better model.
2023-09-01 13:29:39.803: [iter 38 : loss : 0.3508 = 0.1764 + 0.1676 + 0.0051 + 0.0017, time: 46.573320]
2023-09-01 13:29:40.089: epoch 38:	0.16602482  	0.27580440  	0.28077689  
2023-09-01 13:29:40.089: Find a better model.
2023-09-01 13:30:26.715: [iter 39 : loss : 0.3471 = 0.1751 + 0.1651 + 0.0052 + 0.0016, time: 46.596698]
2023-09-01 13:30:26.991: epoch 39:	0.16556120  	0.27445138  	0.28028101  
2023-09-01 13:31:13.691: [iter 40 : loss : 0.3473 = 0.1748 + 0.1655 + 0.0053 + 0.0016, time: 46.665573]
2023-09-01 13:31:13.972: epoch 40:	0.16569361  	0.27471319  	0.28071621  
2023-09-01 13:32:00.612: [iter 41 : loss : 0.3415 = 0.1724 + 0.1621 + 0.0055 + 0.0016, time: 46.610503]
2023-09-01 13:32:00.902: epoch 41:	0.16575991  	0.27471396  	0.28075567  
2023-09-01 13:32:47.568: [iter 42 : loss : 0.3378 = 0.1704 + 0.1603 + 0.0056 + 0.0016, time: 46.639551]
2023-09-01 13:32:47.853: epoch 42:	0.16563566  	0.27485996  	0.28067735  
2023-09-01 13:33:34.237: [iter 43 : loss : 0.3346 = 0.1694 + 0.1580 + 0.0057 + 0.0016, time: 46.348679]
2023-09-01 13:33:34.517: epoch 43:	0.16565244  	0.27445853  	0.28029391  
2023-09-01 13:34:20.434: [iter 44 : loss : 0.3330 = 0.1679 + 0.1577 + 0.0058 + 0.0016, time: 45.885224]
2023-09-01 13:34:20.717: epoch 44:	0.16602492  	0.27499461  	0.28054303  
2023-09-01 13:35:07.036: [iter 45 : loss : 0.3318 = 0.1682 + 0.1562 + 0.0059 + 0.0015, time: 46.291548]
2023-09-01 13:35:07.317: epoch 45:	0.16570197  	0.27431366  	0.28015035  
2023-09-01 13:35:53.569: [iter 46 : loss : 0.3275 = 0.1667 + 0.1533 + 0.0060 + 0.0015, time: 46.213715]
2023-09-01 13:35:53.860: epoch 46:	0.16566078  	0.27361667  	0.27974963  
2023-09-01 13:36:39.685: [iter 47 : loss : 0.3254 = 0.1659 + 0.1520 + 0.0061 + 0.0015, time: 45.789282]
2023-09-01 13:36:39.974: epoch 47:	0.16546209  	0.27303547  	0.27929971  
2023-09-01 13:37:26.317: [iter 48 : loss : 0.3230 = 0.1643 + 0.1510 + 0.0062 + 0.0015, time: 46.312130]
2023-09-01 13:37:26.600: epoch 48:	0.16541229  	0.27341521  	0.27896217  
2023-09-01 13:37:26.600: Early stopping is trigger at epoch: 48
2023-09-01 13:37:26.600: best_result@epoch 38:

2023-09-01 13:37:26.600: 		0.1660      	0.2758      	0.2808      

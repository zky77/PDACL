2023-09-03 09:32:00.413: my pid: 18168
2023-09-03 09:32:00.413: model: model.general_recommender.GNNEC
2023-09-03 09:32:00.413: Dataset statistics:
Name: yelp
The number of users: 7750
The number of items: 28918
The number of ratings: 750318
Average actions of users: 96.82
Average actions of items: 25.95
The sparsity of the dataset: 99.665208%

The number of training: 678579
The number of validation: 0
The number of testing: 71739
2023-09-03 09:32:00.413: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=yelp
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.8
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=yelp
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.8
mf_reg=1e-4
svd_q=5
2023-09-03 09:32:04.945: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-03 09:32:31.777: [iter 1 : loss : 0.9642 = 0.6226 + 0.3399 + 0.0001 + 0.0017, time: 26.831400]
2023-09-03 09:32:32.493: epoch 1:	0.02536181  	0.05458159  	0.04623510  
2023-09-03 09:32:32.493: Find a better model.
2023-09-03 09:32:58.337: [iter 2 : loss : 0.8438 = 0.5399 + 0.3022 + 0.0002 + 0.0015, time: 25.816236]
2023-09-03 09:32:59.043: epoch 2:	0.02565859  	0.05555076  	0.04682442  
2023-09-03 09:32:59.043: Find a better model.
2023-09-03 09:33:24.752: [iter 3 : loss : 0.8000 = 0.5087 + 0.2896 + 0.0003 + 0.0014, time: 25.681335]
2023-09-03 09:33:25.415: epoch 3:	0.02618766  	0.05678695  	0.04708557  
2023-09-03 09:33:25.415: Find a better model.
2023-09-03 09:33:51.225: [iter 4 : loss : 0.7641 = 0.4813 + 0.2810 + 0.0004 + 0.0014, time: 25.782067]
2023-09-03 09:33:51.895: epoch 4:	0.02681348  	0.05792312  	0.04802226  
2023-09-03 09:33:51.895: Find a better model.
2023-09-03 09:34:17.931: [iter 5 : loss : 0.7381 = 0.4623 + 0.2740 + 0.0005 + 0.0014, time: 26.006597]
2023-09-03 09:34:18.578: epoch 5:	0.02666509  	0.05779466  	0.04842005  
2023-09-03 09:34:44.702: [iter 6 : loss : 0.7156 = 0.4454 + 0.2683 + 0.0006 + 0.0013, time: 26.098155]
2023-09-03 09:34:45.395: epoch 6:	0.02743284  	0.05914764  	0.04909514  
2023-09-03 09:34:45.395: Find a better model.
2023-09-03 09:35:11.280: [iter 7 : loss : 0.6927 = 0.4278 + 0.2630 + 0.0007 + 0.0013, time: 25.850441]
2023-09-03 09:35:11.952: epoch 7:	0.02787158  	0.06000424  	0.04975755  
2023-09-03 09:35:11.952: Find a better model.
2023-09-03 09:35:38.064: [iter 8 : loss : 0.6730 = 0.4132 + 0.2578 + 0.0008 + 0.0013, time: 26.088263]
2023-09-03 09:35:38.785: epoch 8:	0.02806515  	0.06017810  	0.04981131  
2023-09-03 09:35:38.785: Find a better model.
2023-09-03 09:36:04.868: [iter 9 : loss : 0.6562 = 0.4008 + 0.2533 + 0.0009 + 0.0013, time: 26.052775]
2023-09-03 09:36:05.539: epoch 9:	0.02824579  	0.06052135  	0.05023219  
2023-09-03 09:36:05.540: Find a better model.
2023-09-03 09:36:31.452: [iter 10 : loss : 0.6414 = 0.3903 + 0.2489 + 0.0010 + 0.0012, time: 25.885743]
2023-09-03 09:36:32.131: epoch 10:	0.02867808  	0.06159795  	0.05088548  
2023-09-03 09:36:32.131: Find a better model.
2023-09-03 09:36:58.008: [iter 11 : loss : 0.6257 = 0.3785 + 0.2449 + 0.0011 + 0.0012, time: 25.856975]
2023-09-03 09:36:58.715: epoch 11:	0.02931035  	0.06303186  	0.05206754  
2023-09-03 09:36:58.715: Find a better model.
2023-09-03 09:37:24.714: [iter 12 : loss : 0.6108 = 0.3675 + 0.2409 + 0.0012 + 0.0012, time: 25.978014]
2023-09-03 09:37:25.382: epoch 12:	0.03004584  	0.06479218  	0.05356466  
2023-09-03 09:37:25.382: Find a better model.
2023-09-03 09:37:51.436: [iter 13 : loss : 0.5978 = 0.3584 + 0.2369 + 0.0013 + 0.0012, time: 26.028430]
2023-09-03 09:37:52.135: epoch 13:	0.03068459  	0.06649002  	0.05450101  
2023-09-03 09:37:52.136: Find a better model.
2023-09-03 09:38:17.930: [iter 14 : loss : 0.5802 = 0.3453 + 0.2324 + 0.0015 + 0.0011, time: 25.769028]
2023-09-03 09:38:18.605: epoch 14:	0.03113618  	0.06770766  	0.05535283  
2023-09-03 09:38:18.605: Find a better model.
2023-09-03 09:38:44.560: [iter 15 : loss : 0.5697 = 0.3388 + 0.2282 + 0.0016 + 0.0011, time: 25.930275]
2023-09-03 09:38:45.213: epoch 15:	0.03122653  	0.06745207  	0.05563391  
2023-09-03 09:39:11.168: [iter 16 : loss : 0.5597 = 0.3322 + 0.2247 + 0.0017 + 0.0011, time: 25.925236]
2023-09-03 09:39:11.833: epoch 16:	0.03139429  	0.06765383  	0.05612639  
2023-09-03 09:39:37.931: [iter 17 : loss : 0.5465 = 0.3230 + 0.2206 + 0.0018 + 0.0011, time: 26.068018]
2023-09-03 09:39:38.664: epoch 17:	0.03182657  	0.06866994  	0.05664694  
2023-09-03 09:39:38.664: Find a better model.
2023-09-03 09:40:04.716: [iter 18 : loss : 0.5379 = 0.3180 + 0.2168 + 0.0020 + 0.0011, time: 26.027272]
2023-09-03 09:40:05.396: epoch 18:	0.03248466  	0.07058163  	0.05791814  
2023-09-03 09:40:05.396: Find a better model.
2023-09-03 09:40:31.313: [iter 19 : loss : 0.5264 = 0.3102 + 0.2131 + 0.0021 + 0.0011, time: 25.891746]
2023-09-03 09:40:31.974: epoch 19:	0.03315560  	0.07166911  	0.05916777  
2023-09-03 09:40:31.974: Find a better model.
2023-09-03 09:40:57.691: [iter 20 : loss : 0.5170 = 0.3037 + 0.2101 + 0.0022 + 0.0010, time: 25.695695]
2023-09-03 09:40:58.366: epoch 20:	0.03367167  	0.07297759  	0.06003548  
2023-09-03 09:40:58.366: Find a better model.
2023-09-03 09:41:24.045: [iter 21 : loss : 0.5052 = 0.2962 + 0.2057 + 0.0024 + 0.0010, time: 25.654046]
2023-09-03 09:41:24.761: epoch 21:	0.03408453  	0.07399634  	0.06061894  
2023-09-03 09:41:24.761: Find a better model.
2023-09-03 09:41:50.985: [iter 22 : loss : 0.4979 = 0.2916 + 0.2027 + 0.0025 + 0.0010, time: 26.199185]
2023-09-03 09:41:51.698: epoch 22:	0.03435548  	0.07502376  	0.06116530  
2023-09-03 09:41:51.698: Find a better model.
2023-09-03 09:42:17.776: [iter 23 : loss : 0.4876 = 0.2845 + 0.1995 + 0.0026 + 0.0010, time: 26.047819]
2023-09-03 09:42:18.425: epoch 23:	0.03469739  	0.07530985  	0.06195372  
2023-09-03 09:42:18.425: Find a better model.
2023-09-03 09:42:44.143: [iter 24 : loss : 0.4814 = 0.2813 + 0.1964 + 0.0028 + 0.0010, time: 25.691238]
2023-09-03 09:42:44.822: epoch 24:	0.03507153  	0.07625633  	0.06297259  
2023-09-03 09:42:44.822: Find a better model.
2023-09-03 09:43:10.869: [iter 25 : loss : 0.4731 = 0.2758 + 0.1935 + 0.0029 + 0.0010, time: 26.022994]
2023-09-03 09:43:11.558: epoch 25:	0.03547795  	0.07703785  	0.06348990  
2023-09-03 09:43:11.558: Find a better model.
2023-09-03 09:43:37.483: [iter 26 : loss : 0.4664 = 0.2726 + 0.1898 + 0.0031 + 0.0009, time: 25.897286]
2023-09-03 09:43:38.159: epoch 26:	0.03581343  	0.07753780  	0.06432696  
2023-09-03 09:43:38.159: Find a better model.
2023-09-03 09:44:03.994: [iter 27 : loss : 0.4585 = 0.2674 + 0.1870 + 0.0032 + 0.0009, time: 25.808676]
2023-09-03 09:44:04.670: epoch 27:	0.03620046  	0.07857061  	0.06524550  
2023-09-03 09:44:04.670: Find a better model.
2023-09-03 09:44:30.728: [iter 28 : loss : 0.4518 = 0.2635 + 0.1841 + 0.0033 + 0.0009, time: 26.027313]
2023-09-03 09:44:31.429: epoch 28:	0.03675526  	0.07980239  	0.06658962  
2023-09-03 09:44:31.429: Find a better model.
2023-09-03 09:44:57.159: [iter 29 : loss : 0.4461 = 0.2606 + 0.1811 + 0.0035 + 0.0009, time: 25.703274]
2023-09-03 09:44:57.839: epoch 29:	0.03699393  	0.07978971  	0.06693012  
2023-09-03 09:45:23.638: [iter 30 : loss : 0.4381 = 0.2551 + 0.1785 + 0.0036 + 0.0009, time: 25.771310]
2023-09-03 09:45:24.360: epoch 30:	0.03712295  	0.08026260  	0.06729922  
2023-09-03 09:45:24.361: Find a better model.
2023-09-03 09:45:50.466: [iter 31 : loss : 0.4315 = 0.2514 + 0.1754 + 0.0038 + 0.0009, time: 26.067291]
2023-09-03 09:45:51.133: epoch 31:	0.03747777  	0.08106835  	0.06809468  
2023-09-03 09:45:51.133: Find a better model.
2023-09-03 09:46:17.145: [iter 32 : loss : 0.4239 = 0.2466 + 0.1725 + 0.0039 + 0.0009, time: 25.980028]
2023-09-03 09:46:17.855: epoch 32:	0.03772936  	0.08157766  	0.06831463  
2023-09-03 09:46:17.855: Find a better model.
2023-09-03 09:46:43.747: [iter 33 : loss : 0.4191 = 0.2444 + 0.1698 + 0.0040 + 0.0008, time: 25.862458]
2023-09-03 09:46:44.435: epoch 33:	0.03787128  	0.08196192  	0.06887671  
2023-09-03 09:46:44.436: Find a better model.
2023-09-03 09:47:10.322: [iter 34 : loss : 0.4143 = 0.2423 + 0.1670 + 0.0042 + 0.0008, time: 25.865801]
2023-09-03 09:47:10.950: epoch 34:	0.03828413  	0.08296013  	0.06983415  
2023-09-03 09:47:10.950: Find a better model.
2023-09-03 09:47:36.733: [iter 35 : loss : 0.4082 = 0.2383 + 0.1648 + 0.0043 + 0.0008, time: 25.759352]
2023-09-03 09:47:37.403: epoch 35:	0.03886470  	0.08428723  	0.07037757  
2023-09-03 09:47:37.403: Find a better model.
2023-09-03 09:48:03.375: [iter 36 : loss : 0.4038 = 0.2370 + 0.1616 + 0.0045 + 0.0008, time: 25.950936]
2023-09-03 09:48:04.104: epoch 36:	0.03886469  	0.08409955  	0.07044505  
2023-09-03 09:48:30.404: [iter 37 : loss : 0.3964 = 0.2316 + 0.1594 + 0.0046 + 0.0008, time: 26.278421]
2023-09-03 09:48:31.126: epoch 37:	0.03898086  	0.08473348  	0.07103010  
2023-09-03 09:48:31.127: Find a better model.
2023-09-03 09:48:57.058: [iter 38 : loss : 0.3921 = 0.2291 + 0.1575 + 0.0048 + 0.0008, time: 25.898287]
2023-09-03 09:48:57.743: epoch 38:	0.03938080  	0.08559707  	0.07177927  
2023-09-03 09:48:57.743: Find a better model.
2023-09-03 09:49:23.571: [iter 39 : loss : 0.3879 = 0.2275 + 0.1547 + 0.0049 + 0.0008, time: 25.803100]
2023-09-03 09:49:24.261: epoch 39:	0.03974843  	0.08635250  	0.07246161  
2023-09-03 09:49:24.261: Find a better model.
2023-09-03 09:49:50.092: [iter 40 : loss : 0.3812 = 0.2235 + 0.1519 + 0.0050 + 0.0008, time: 25.803600]
2023-09-03 09:49:50.760: epoch 40:	0.03995495  	0.08675990  	0.07262413  
2023-09-03 09:49:50.760: Find a better model.
2023-09-03 09:50:16.780: [iter 41 : loss : 0.3755 = 0.2200 + 0.1496 + 0.0052 + 0.0007, time: 25.991631]
2023-09-03 09:50:17.469: epoch 41:	0.03985814  	0.08643717  	0.07262634  
2023-09-03 09:50:43.421: [iter 42 : loss : 0.3716 = 0.2182 + 0.1474 + 0.0053 + 0.0007, time: 25.930177]
2023-09-03 09:50:44.094: epoch 42:	0.03999364  	0.08659684  	0.07310741  
2023-09-03 09:51:10.101: [iter 43 : loss : 0.3666 = 0.2155 + 0.1449 + 0.0055 + 0.0007, time: 25.985952]
2023-09-03 09:51:10.761: epoch 43:	0.04000009  	0.08677220  	0.07319092  
2023-09-03 09:51:10.761: Find a better model.
2023-09-03 09:51:36.631: [iter 44 : loss : 0.3624 = 0.2139 + 0.1422 + 0.0056 + 0.0007, time: 25.843769]
2023-09-03 09:51:37.382: epoch 44:	0.04039361  	0.08769336  	0.07375345  
2023-09-03 09:51:37.382: Find a better model.
2023-09-03 09:52:03.355: [iter 45 : loss : 0.3580 = 0.2113 + 0.1403 + 0.0058 + 0.0007, time: 25.949867]
2023-09-03 09:52:04.028: epoch 45:	0.04018718  	0.08719250  	0.07343431  
2023-09-03 09:52:29.735: [iter 46 : loss : 0.3546 = 0.2100 + 0.1380 + 0.0059 + 0.0007, time: 25.685735]
2023-09-03 09:52:30.438: epoch 46:	0.04048394  	0.08806911  	0.07401806  
2023-09-03 09:52:30.438: Find a better model.
2023-09-03 09:52:56.591: [iter 47 : loss : 0.3494 = 0.2072 + 0.1354 + 0.0061 + 0.0007, time: 26.128233]
2023-09-03 09:52:57.261: epoch 47:	0.04104514  	0.08929030  	0.07456895  
2023-09-03 09:52:57.261: Find a better model.
2023-09-03 09:53:23.086: [iter 48 : loss : 0.3454 = 0.2051 + 0.1334 + 0.0062 + 0.0007, time: 25.803795]
2023-09-03 09:53:23.764: epoch 48:	0.04075485  	0.08854467  	0.07447766  
2023-09-03 09:53:49.485: [iter 49 : loss : 0.3422 = 0.2041 + 0.1311 + 0.0064 + 0.0007, time: 25.698734]
2023-09-03 09:53:50.196: epoch 49:	0.04087740  	0.08891818  	0.07476471  
2023-09-03 09:54:16.066: [iter 50 : loss : 0.3378 = 0.2017 + 0.1289 + 0.0065 + 0.0006, time: 25.841311]
2023-09-03 09:54:16.773: epoch 50:	0.04103867  	0.08943588  	0.07539502  
2023-09-03 09:54:16.774: Find a better model.
2023-09-03 09:54:42.568: [iter 51 : loss : 0.3343 = 0.2003 + 0.1268 + 0.0066 + 0.0006, time: 25.768152]
2023-09-03 09:54:43.269: epoch 51:	0.04111607  	0.08906347  	0.07530040  
2023-09-03 09:55:09.098: [iter 52 : loss : 0.3303 = 0.1982 + 0.1247 + 0.0068 + 0.0006, time: 25.803540]
2023-09-03 09:55:09.791: epoch 52:	0.04143857  	0.08995637  	0.07600289  
2023-09-03 09:55:09.791: Find a better model.
2023-09-03 09:55:35.632: [iter 53 : loss : 0.3273 = 0.1972 + 0.1226 + 0.0069 + 0.0006, time: 25.808414]
2023-09-03 09:55:36.340: epoch 53:	0.04137414  	0.08952697  	0.07578357  
2023-09-03 09:56:02.177: [iter 54 : loss : 0.3226 = 0.1937 + 0.1212 + 0.0071 + 0.0006, time: 25.814605]
2023-09-03 09:56:02.882: epoch 54:	0.04130963  	0.08942717  	0.07565709  
2023-09-03 09:56:28.690: [iter 55 : loss : 0.3190 = 0.1927 + 0.1185 + 0.0072 + 0.0006, time: 25.783780]
2023-09-03 09:56:29.377: epoch 55:	0.04139993  	0.08938169  	0.07542643  
2023-09-03 09:56:55.250: [iter 56 : loss : 0.3148 = 0.1905 + 0.1163 + 0.0074 + 0.0006, time: 25.847655]
2023-09-03 09:56:55.957: epoch 56:	0.04169020  	0.09033135  	0.07604057  
2023-09-03 09:56:55.957: Find a better model.
2023-09-03 09:57:21.883: [iter 57 : loss : 0.3116 = 0.1891 + 0.1144 + 0.0075 + 0.0006, time: 25.889354]
2023-09-03 09:57:22.569: epoch 57:	0.04178692  	0.09066707  	0.07625952  
2023-09-03 09:57:22.569: Find a better model.
2023-09-03 09:57:48.504: [iter 58 : loss : 0.3117 = 0.1906 + 0.1129 + 0.0077 + 0.0006, time: 25.909328]
2023-09-03 09:57:49.202: epoch 58:	0.04196112  	0.09122253  	0.07648643  
2023-09-03 09:57:49.202: Find a better model.
2023-09-03 09:58:15.260: [iter 59 : loss : 0.3062 = 0.1879 + 0.1100 + 0.0078 + 0.0006, time: 26.033975]
2023-09-03 09:58:15.928: epoch 59:	0.04201921  	0.09153535  	0.07663628  
2023-09-03 09:58:15.928: Find a better model.
2023-09-03 09:58:41.927: [iter 60 : loss : 0.3026 = 0.1853 + 0.1088 + 0.0080 + 0.0005, time: 25.978584]
2023-09-03 09:58:42.627: epoch 60:	0.04236757  	0.09219103  	0.07708449  
2023-09-03 09:58:42.627: Find a better model.
2023-09-03 09:59:08.569: [iter 61 : loss : 0.2989 = 0.1839 + 0.1064 + 0.0081 + 0.0005, time: 25.921468]
2023-09-03 09:59:09.308: epoch 61:	0.04241918  	0.09230810  	0.07714942  
2023-09-03 09:59:09.308: Find a better model.
2023-09-03 09:59:35.186: [iter 62 : loss : 0.2953 = 0.1822 + 0.1044 + 0.0083 + 0.0005, time: 25.856514]
2023-09-03 09:59:35.871: epoch 62:	0.04249008  	0.09258476  	0.07742779  
2023-09-03 09:59:35.872: Find a better model.
2023-09-03 10:00:01.807: [iter 63 : loss : 0.2915 = 0.1802 + 0.1024 + 0.0084 + 0.0005, time: 25.908388]
2023-09-03 10:00:02.470: epoch 63:	0.04259977  	0.09289724  	0.07758221  
2023-09-03 10:00:02.470: Find a better model.
2023-09-03 10:00:28.446: [iter 64 : loss : 0.2876 = 0.1779 + 0.1007 + 0.0086 + 0.0005, time: 25.950624]
2023-09-03 10:00:29.110: epoch 64:	0.04298685  	0.09391306  	0.07813410  
2023-09-03 10:00:29.110: Find a better model.
2023-09-03 10:00:54.958: [iter 65 : loss : 0.2875 = 0.1793 + 0.0989 + 0.0087 + 0.0005, time: 25.825940]
2023-09-03 10:00:55.682: epoch 65:	0.04276754  	0.09326109  	0.07816035  
2023-09-03 10:01:21.916: [iter 66 : loss : 0.2827 = 0.1767 + 0.0967 + 0.0089 + 0.0005, time: 26.207234]
2023-09-03 10:01:22.578: epoch 66:	0.04281916  	0.09318826  	0.07797478  
2023-09-03 10:01:48.606: [iter 67 : loss : 0.2797 = 0.1753 + 0.0949 + 0.0090 + 0.0005, time: 26.004746]
2023-09-03 10:01:49.301: epoch 67:	0.04267081  	0.09308401  	0.07765166  
2023-09-03 10:02:15.156: [iter 68 : loss : 0.2776 = 0.1747 + 0.0932 + 0.0092 + 0.0005, time: 25.829271]
2023-09-03 10:02:15.819: epoch 68:	0.04276759  	0.09352169  	0.07792185  
2023-09-03 10:02:41.641: [iter 69 : loss : 0.2753 = 0.1741 + 0.0914 + 0.0093 + 0.0005, time: 25.792551]
2023-09-03 10:02:42.305: epoch 69:	0.04292883  	0.09368352  	0.07780582  
2023-09-03 10:03:08.316: [iter 70 : loss : 0.2730 = 0.1731 + 0.0899 + 0.0095 + 0.0004, time: 25.987294]
2023-09-03 10:03:09.016: epoch 70:	0.04318687  	0.09388918  	0.07830241  
2023-09-03 10:03:35.078: [iter 71 : loss : 0.2691 = 0.1711 + 0.0879 + 0.0096 + 0.0004, time: 26.021583]
2023-09-03 10:03:35.741: epoch 71:	0.04328366  	0.09454322  	0.07866060  
2023-09-03 10:03:35.741: Find a better model.
2023-09-03 10:04:01.827: [iter 72 : loss : 0.2660 = 0.1704 + 0.0854 + 0.0098 + 0.0004, time: 26.057254]
2023-09-03 10:04:02.497: epoch 72:	0.04320621  	0.09389218  	0.07839639  
2023-09-03 10:04:28.431: [iter 73 : loss : 0.2624 = 0.1676 + 0.0845 + 0.0099 + 0.0004, time: 25.907262]
2023-09-03 10:04:29.124: epoch 73:	0.04321915  	0.09398402  	0.07827370  
2023-09-03 10:04:55.223: [iter 74 : loss : 0.2586 = 0.1663 + 0.0818 + 0.0101 + 0.0004, time: 26.071111]
2023-09-03 10:04:55.898: epoch 74:	0.04329653  	0.09434171  	0.07832418  
2023-09-03 10:05:21.801: [iter 75 : loss : 0.2557 = 0.1651 + 0.0799 + 0.0102 + 0.0004, time: 25.875361]
2023-09-03 10:05:22.506: epoch 75:	0.04343845  	0.09450947  	0.07839201  
2023-09-03 10:05:48.425: [iter 76 : loss : 0.2553 = 0.1658 + 0.0787 + 0.0104 + 0.0004, time: 25.896193]
2023-09-03 10:05:49.084: epoch 76:	0.04337393  	0.09430429  	0.07839525  
2023-09-03 10:06:15.202: [iter 77 : loss : 0.2514 = 0.1634 + 0.0770 + 0.0105 + 0.0004, time: 26.091597]
2023-09-03 10:06:15.885: epoch 77:	0.04359974  	0.09499892  	0.07882602  
2023-09-03 10:06:15.886: Find a better model.
2023-09-03 10:06:41.936: [iter 78 : loss : 0.2513 = 0.1650 + 0.0753 + 0.0107 + 0.0004, time: 26.019475]
2023-09-03 10:06:42.600: epoch 78:	0.04370300  	0.09523214  	0.07897270  
2023-09-03 10:06:42.600: Find a better model.
2023-09-03 10:07:08.677: [iter 79 : loss : 0.2478 = 0.1632 + 0.0734 + 0.0108 + 0.0004, time: 26.050913]
2023-09-03 10:07:09.367: epoch 79:	0.04370944  	0.09523504  	0.07909821  
2023-09-03 10:07:09.367: Find a better model.
2023-09-03 10:07:35.338: [iter 80 : loss : 0.2453 = 0.1622 + 0.0718 + 0.0110 + 0.0004, time: 25.943765]
2023-09-03 10:07:36.022: epoch 80:	0.04380623  	0.09535429  	0.07943629  
2023-09-03 10:07:36.022: Find a better model.
2023-09-03 10:08:02.099: [iter 81 : loss : 0.2408 = 0.1600 + 0.0693 + 0.0112 + 0.0004, time: 26.046035]
2023-09-03 10:08:02.737: epoch 81:	0.04393525  	0.09581935  	0.07947081  
2023-09-03 10:08:02.737: Find a better model.
2023-09-03 10:08:28.654: [iter 82 : loss : 0.2391 = 0.1595 + 0.0680 + 0.0113 + 0.0003, time: 25.894547]
2023-09-03 10:08:29.355: epoch 82:	0.04399326  	0.09575853  	0.07947860  
2023-09-03 10:08:55.329: [iter 83 : loss : 0.2362 = 0.1583 + 0.0662 + 0.0115 + 0.0003, time: 25.947739]
2023-09-03 10:08:56.011: epoch 83:	0.04417393  	0.09644078  	0.07995800  
2023-09-03 10:08:56.011: Find a better model.
2023-09-03 10:09:22.149: [iter 84 : loss : 0.2345 = 0.1575 + 0.0651 + 0.0116 + 0.0003, time: 26.101052]
2023-09-03 10:09:22.819: epoch 84:	0.04423196  	0.09629158  	0.07995948  
2023-09-03 10:09:48.829: [iter 85 : loss : 0.2336 = 0.1587 + 0.0628 + 0.0118 + 0.0003, time: 25.979348]
2023-09-03 10:09:49.497: epoch 85:	0.04430294  	0.09630108  	0.08011080  
2023-09-03 10:10:15.656: [iter 86 : loss : 0.2296 = 0.1559 + 0.0615 + 0.0119 + 0.0003, time: 26.135677]
2023-09-03 10:10:16.324: epoch 86:	0.04447704  	0.09695285  	0.08043138  
2023-09-03 10:10:16.324: Find a better model.
2023-09-03 10:10:42.231: [iter 87 : loss : 0.2279 = 0.1558 + 0.0598 + 0.0121 + 0.0003, time: 25.881487]
2023-09-03 10:10:42.910: epoch 87:	0.04419323  	0.09631889  	0.08005139  
2023-09-03 10:11:09.187: [iter 88 : loss : 0.2260 = 0.1556 + 0.0579 + 0.0122 + 0.0003, time: 26.254798]
2023-09-03 10:11:09.867: epoch 88:	0.04407715  	0.09600338  	0.08001748  
2023-09-03 10:11:35.682: [iter 89 : loss : 0.2224 = 0.1530 + 0.0567 + 0.0124 + 0.0003, time: 25.786889]
2023-09-03 10:11:36.382: epoch 89:	0.04427714  	0.09663084  	0.08024309  
2023-09-03 10:12:02.131: [iter 90 : loss : 0.2203 = 0.1522 + 0.0553 + 0.0126 + 0.0003, time: 25.717014]
2023-09-03 10:12:02.827: epoch 90:	0.04404490  	0.09575699  	0.08000326  
2023-09-03 10:12:28.786: [iter 91 : loss : 0.2204 = 0.1541 + 0.0533 + 0.0127 + 0.0003, time: 25.935264]
2023-09-03 10:12:29.501: epoch 91:	0.04413519  	0.09593172  	0.08014844  
2023-09-03 10:12:55.354: [iter 92 : loss : 0.2170 = 0.1519 + 0.0520 + 0.0129 + 0.0003, time: 25.818451]
2023-09-03 10:12:56.059: epoch 92:	0.04404493  	0.09583957  	0.08010727  
2023-09-03 10:13:21.846: [iter 93 : loss : 0.2131 = 0.1496 + 0.0503 + 0.0130 + 0.0003, time: 25.767359]
2023-09-03 10:13:22.525: epoch 93:	0.04427070  	0.09668177  	0.08044185  
2023-09-03 10:13:48.332: [iter 94 : loss : 0.2139 = 0.1521 + 0.0484 + 0.0132 + 0.0002, time: 25.787351]
2023-09-03 10:13:48.988: epoch 94:	0.04429649  	0.09650652  	0.08028449  
2023-09-03 10:14:15.108: [iter 95 : loss : 0.2089 = 0.1490 + 0.0463 + 0.0133 + 0.0002, time: 26.096624]
2023-09-03 10:14:15.853: epoch 95:	0.04419326  	0.09654776  	0.08019619  
2023-09-03 10:14:41.784: [iter 96 : loss : 0.2096 = 0.1505 + 0.0454 + 0.0135 + 0.0002, time: 25.901495]
2023-09-03 10:14:42.447: epoch 96:	0.04464488  	0.09753580  	0.08086103  
2023-09-03 10:14:42.448: Find a better model.
2023-09-03 10:15:08.337: [iter 97 : loss : 0.2076 = 0.1492 + 0.0445 + 0.0136 + 0.0002, time: 25.865689]
2023-09-03 10:15:08.995: epoch 97:	0.04457390  	0.09736163  	0.08079323  
2023-09-03 10:15:34.996: [iter 98 : loss : 0.2031 = 0.1471 + 0.0420 + 0.0138 + 0.0002, time: 25.973556]
2023-09-03 10:15:35.685: epoch 98:	0.04458677  	0.09745006  	0.08097371  
2023-09-03 10:16:01.682: [iter 99 : loss : 0.2009 = 0.1458 + 0.0409 + 0.0140 + 0.0002, time: 25.975707]
2023-09-03 10:16:02.362: epoch 99:	0.04443196  	0.09703905  	0.08067825  
2023-09-03 10:16:28.345: [iter 100 : loss : 0.1977 = 0.1443 + 0.0391 + 0.0141 + 0.0002, time: 25.960785]
2023-09-03 10:16:29.003: epoch 100:	0.04465131  	0.09752636  	0.08087404  
2023-09-03 10:16:55.047: [iter 101 : loss : 0.1953 = 0.1432 + 0.0377 + 0.0143 + 0.0002, time: 26.021548]
2023-09-03 10:16:55.737: epoch 101:	0.04471584  	0.09770196  	0.08087896  
2023-09-03 10:16:55.737: Find a better model.
2023-09-03 10:17:22.016: [iter 102 : loss : 0.1960 = 0.1457 + 0.0357 + 0.0144 + 0.0002, time: 26.252763]
2023-09-03 10:17:22.696: epoch 102:	0.04504483  	0.09836517  	0.08112682  
2023-09-03 10:17:22.696: Find a better model.
2023-09-03 10:17:48.961: [iter 103 : loss : 0.1935 = 0.1447 + 0.0340 + 0.0146 + 0.0002, time: 26.241313]
2023-09-03 10:17:49.639: epoch 103:	0.04528998  	0.09902386  	0.08148208  
2023-09-03 10:17:49.639: Find a better model.
2023-09-03 10:18:15.545: [iter 104 : loss : 0.1933 = 0.1451 + 0.0333 + 0.0148 + 0.0002, time: 25.879510]
2023-09-03 10:18:16.203: epoch 104:	0.04516740  	0.09856869  	0.08148653  
2023-09-03 10:18:42.174: [iter 105 : loss : 0.1895 = 0.1427 + 0.0318 + 0.0149 + 0.0002, time: 25.943547]
2023-09-03 10:18:42.850: epoch 105:	0.04497386  	0.09841199  	0.08115564  
2023-09-03 10:19:08.806: [iter 106 : loss : 0.1850 = 0.1396 + 0.0302 + 0.0151 + 0.0002, time: 25.925550]
2023-09-03 10:19:09.491: epoch 106:	0.04518026  	0.09872251  	0.08134418  
2023-09-03 10:19:35.478: [iter 107 : loss : 0.1843 = 0.1407 + 0.0282 + 0.0152 + 0.0001, time: 25.956159]
2023-09-03 10:19:36.140: epoch 107:	0.04497381  	0.09803332  	0.08116122  
2023-09-03 10:20:02.144: [iter 108 : loss : 0.1832 = 0.1406 + 0.0270 + 0.0154 + 0.0001, time: 25.980202]
2023-09-03 10:20:02.821: epoch 108:	0.04519965  	0.09883831  	0.08153170  
2023-09-03 10:20:29.025: [iter 109 : loss : 0.1806 = 0.1396 + 0.0253 + 0.0156 + 0.0001, time: 26.168145]
2023-09-03 10:20:29.680: epoch 109:	0.04508352  	0.09842885  	0.08148723  
2023-09-03 10:20:55.711: [iter 110 : loss : 0.1779 = 0.1377 + 0.0244 + 0.0157 + 0.0001, time: 26.005360]
2023-09-03 10:20:56.421: epoch 110:	0.04508999  	0.09855586  	0.08150080  
2023-09-03 10:21:22.146: [iter 111 : loss : 0.1772 = 0.1387 + 0.0225 + 0.0159 + 0.0001, time: 25.702268]
2023-09-03 10:21:22.801: epoch 111:	0.04487712  	0.09802943  	0.08115655  
2023-09-03 10:21:48.807: [iter 112 : loss : 0.1763 = 0.1386 + 0.0215 + 0.0160 + 0.0001, time: 25.974433]
2023-09-03 10:21:49.499: epoch 112:	0.04498678  	0.09807957  	0.08135074  
2023-09-03 10:22:15.324: [iter 113 : loss : 0.1749 = 0.1386 + 0.0200 + 0.0162 + 0.0001, time: 25.799023]
2023-09-03 10:22:15.984: epoch 113:	0.04486421  	0.09806402  	0.08134955  
2023-09-03 10:22:15.984: Early stopping is trigger at epoch: 113
2023-09-03 10:22:15.984: best_result@epoch 103:

2023-09-03 10:22:15.984: 		0.0453      	0.0990      	0.0815      

2023-09-01 19:58:16.764: my pid: 9147
2023-09-01 19:58:16.764: model: model.general_recommender.GNNEC
2023-09-01 19:58:16.764: Dataset statistics:
Name: yelp
The number of users: 7750
The number of items: 28918
The number of ratings: 750318
Average actions of users: 96.82
Average actions of items: 25.95
The sparsity of the dataset: 99.665208%

The number of training: 678579
The number of validation: 0
The number of testing: 71739
2023-09-01 19:58:16.764: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=yelp
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=20
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=yelp
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=20
mf_reg=0.02
svd_q=5
2023-09-01 19:58:37.132: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 19:59:00.399: [iter 1 : loss : 1.2775 = 0.5135 + 0.3819 + 0.0001 + 0.3819, time: 23.266584]
2023-09-01 19:59:01.071: epoch 1:	0.02529729  	0.05463790  	0.04666145  
2023-09-01 19:59:01.071: Find a better model.
2023-09-01 19:59:23.821: [iter 2 : loss : 1.0345 = 0.2765 + 0.3788 + 0.0003 + 0.3789, time: 22.721518]
2023-09-01 19:59:24.518: epoch 2:	0.02524568  	0.05444400  	0.04652183  
2023-09-01 19:59:47.201: [iter 3 : loss : 0.9960 = 0.2398 + 0.3779 + 0.0004 + 0.3779, time: 22.651810]
2023-09-01 19:59:47.873: epoch 3:	0.02516180  	0.05445959  	0.04636090  
2023-09-01 20:00:10.141: [iter 4 : loss : 0.9814 = 0.2261 + 0.3774 + 0.0005 + 0.3774, time: 22.237430]
2023-09-01 20:00:10.814: epoch 4:	0.02551020  	0.05496641  	0.04657501  
2023-09-01 20:00:10.814: Find a better model.
2023-09-01 20:00:33.070: [iter 5 : loss : 0.9728 = 0.2180 + 0.3771 + 0.0006 + 0.3771, time: 22.228622]
2023-09-01 20:00:33.713: epoch 5:	0.02553601  	0.05504636  	0.04666100  
2023-09-01 20:00:33.714: Find a better model.
2023-09-01 20:00:55.925: [iter 6 : loss : 0.9662 = 0.2117 + 0.3770 + 0.0006 + 0.3770, time: 22.188474]
2023-09-01 20:00:56.592: epoch 6:	0.02556827  	0.05520828  	0.04653442  
2023-09-01 20:00:56.592: Find a better model.
2023-09-01 20:01:19.060: [iter 7 : loss : 0.9566 = 0.2024 + 0.3768 + 0.0006 + 0.3768, time: 22.443549]
2023-09-01 20:01:19.776: epoch 7:	0.02561988  	0.05532774  	0.04690574  
2023-09-01 20:01:19.776: Find a better model.
2023-09-01 20:01:42.327: [iter 8 : loss : 0.9502 = 0.1962 + 0.3767 + 0.0007 + 0.3767, time: 22.517591]
2023-09-01 20:01:43.048: epoch 8:	0.02571665  	0.05568191  	0.04707430  
2023-09-01 20:01:43.048: Find a better model.
2023-09-01 20:02:05.308: [iter 9 : loss : 0.9440 = 0.1902 + 0.3765 + 0.0007 + 0.3765, time: 22.236135]
2023-09-01 20:02:05.977: epoch 9:	0.02576181  	0.05585089  	0.04733583  
2023-09-01 20:02:05.977: Find a better model.
2023-09-01 20:02:28.270: [iter 10 : loss : 0.9375 = 0.1839 + 0.3764 + 0.0008 + 0.3764, time: 22.270312]
2023-09-01 20:02:28.979: epoch 10:	0.02601990  	0.05633542  	0.04768553  
2023-09-01 20:02:28.980: Find a better model.
2023-09-01 20:02:51.391: [iter 11 : loss : 0.9321 = 0.1786 + 0.3763 + 0.0008 + 0.3763, time: 22.388892]
2023-09-01 20:02:52.080: epoch 11:	0.02617474  	0.05684624  	0.04801141  
2023-09-01 20:02:52.080: Find a better model.
2023-09-01 20:03:14.861: [iter 12 : loss : 0.9262 = 0.1729 + 0.3762 + 0.0009 + 0.3762, time: 22.754867]
2023-09-01 20:03:15.528: epoch 12:	0.02658765  	0.05767351  	0.04865883  
2023-09-01 20:03:15.528: Find a better model.
2023-09-01 20:03:38.362: [iter 13 : loss : 0.9222 = 0.1690 + 0.3761 + 0.0009 + 0.3761, time: 22.798605]
2023-09-01 20:03:39.011: epoch 13:	0.02668444  	0.05808543  	0.04894578  
2023-09-01 20:03:39.011: Find a better model.
2023-09-01 20:04:01.778: [iter 14 : loss : 0.9163 = 0.1633 + 0.3760 + 0.0010 + 0.3760, time: 22.739228]
2023-09-01 20:04:02.494: epoch 14:	0.02694252  	0.05853269  	0.04929767  
2023-09-01 20:04:02.494: Find a better model.
2023-09-01 20:04:25.161: [iter 15 : loss : 0.9135 = 0.1606 + 0.3759 + 0.0010 + 0.3759, time: 22.630464]
2023-09-01 20:04:25.824: epoch 15:	0.02707157  	0.05872110  	0.04934274  
2023-09-01 20:04:25.824: Find a better model.
2023-09-01 20:04:48.623: [iter 16 : loss : 0.9101 = 0.1573 + 0.3759 + 0.0011 + 0.3758, time: 22.772396]
2023-09-01 20:04:49.305: epoch 16:	0.02725867  	0.05914337  	0.04946116  
2023-09-01 20:04:49.305: Find a better model.
2023-09-01 20:05:11.857: [iter 17 : loss : 0.9055 = 0.1529 + 0.3758 + 0.0011 + 0.3757, time: 22.526489]
2023-09-01 20:05:12.511: epoch 17:	0.02742642  	0.05960285  	0.04971936  
2023-09-01 20:05:12.511: Find a better model.
2023-09-01 20:05:35.239: [iter 18 : loss : 0.9036 = 0.1511 + 0.3757 + 0.0012 + 0.3756, time: 22.701256]
2023-09-01 20:05:35.910: epoch 18:	0.02747803  	0.05962697  	0.04969450  
2023-09-01 20:05:35.910: Find a better model.
2023-09-01 20:05:58.651: [iter 19 : loss : 0.8997 = 0.1473 + 0.3756 + 0.0012 + 0.3755, time: 22.712413]
2023-09-01 20:05:59.313: epoch 19:	0.02751674  	0.05961487  	0.04978584  
2023-09-01 20:06:21.964: [iter 20 : loss : 0.8968 = 0.1445 + 0.3755 + 0.0013 + 0.3755, time: 22.621207]
2023-09-01 20:06:22.616: epoch 20:	0.02762642  	0.05986883  	0.04987999  
2023-09-01 20:06:22.616: Find a better model.
2023-09-01 20:06:45.317: [iter 21 : loss : 0.8933 = 0.1412 + 0.3754 + 0.0013 + 0.3754, time: 22.674997]
2023-09-01 20:06:45.973: epoch 21:	0.02780706  	0.06021691  	0.05035765  
2023-09-01 20:06:45.974: Find a better model.
2023-09-01 20:07:08.585: [iter 22 : loss : 0.8910 = 0.1390 + 0.3754 + 0.0014 + 0.3753, time: 22.582483]
2023-09-01 20:07:09.161: epoch 22:	0.02781998  	0.06015851  	0.05038477  
2023-09-01 20:07:31.846: [iter 23 : loss : 0.8884 = 0.1364 + 0.3753 + 0.0014 + 0.3752, time: 22.656478]
2023-09-01 20:07:32.510: epoch 23:	0.02798128  	0.06051760  	0.05059803  
2023-09-01 20:07:32.510: Find a better model.
2023-09-01 20:07:55.074: [iter 24 : loss : 0.8874 = 0.1356 + 0.3752 + 0.0015 + 0.3751, time: 22.541142]
2023-09-01 20:07:55.737: epoch 24:	0.02794901  	0.06056746  	0.05082773  
2023-09-01 20:07:55.737: Find a better model.
2023-09-01 20:08:18.431: [iter 25 : loss : 0.8846 = 0.1328 + 0.3752 + 0.0015 + 0.3751, time: 22.660500]
2023-09-01 20:08:19.079: epoch 25:	0.02794901  	0.06043806  	0.05080635  
2023-09-01 20:08:41.725: [iter 26 : loss : 0.8828 = 0.1311 + 0.3751 + 0.0016 + 0.3750, time: 22.624955]
2023-09-01 20:08:42.376: epoch 26:	0.02828451  	0.06113545  	0.05122281  
2023-09-01 20:08:42.376: Find a better model.
2023-09-01 20:09:04.934: [iter 27 : loss : 0.8800 = 0.1283 + 0.3751 + 0.0016 + 0.3749, time: 22.527878]
2023-09-01 20:09:05.587: epoch 27:	0.02839419  	0.06128247  	0.05123011  
2023-09-01 20:09:05.587: Find a better model.
2023-09-01 20:09:28.046: [iter 28 : loss : 0.8785 = 0.1269 + 0.3750 + 0.0017 + 0.3749, time: 22.433895]
2023-09-01 20:09:28.629: epoch 28:	0.02840064  	0.06140945  	0.05140516  
2023-09-01 20:09:28.629: Find a better model.
2023-09-01 20:09:51.045: [iter 29 : loss : 0.8775 = 0.1260 + 0.3749 + 0.0017 + 0.3748, time: 22.395220]
2023-09-01 20:09:51.701: epoch 29:	0.02869096  	0.06205957  	0.05180976  
2023-09-01 20:09:51.701: Find a better model.
2023-09-01 20:10:14.149: [iter 30 : loss : 0.8755 = 0.1241 + 0.3749 + 0.0018 + 0.3747, time: 22.417742]
2023-09-01 20:10:14.812: epoch 30:	0.02896194  	0.06275522  	0.05227984  
2023-09-01 20:10:14.812: Find a better model.
2023-09-01 20:10:37.177: [iter 31 : loss : 0.8735 = 0.1222 + 0.3748 + 0.0018 + 0.3747, time: 22.336965]
2023-09-01 20:10:37.783: epoch 31:	0.02907162  	0.06300115  	0.05236562  
2023-09-01 20:10:37.784: Find a better model.
2023-09-01 20:11:00.085: [iter 32 : loss : 0.8714 = 0.1202 + 0.3747 + 0.0019 + 0.3746, time: 22.274266]
2023-09-01 20:11:00.731: epoch 32:	0.02938778  	0.06378007  	0.05273322  
2023-09-01 20:11:00.731: Find a better model.
2023-09-01 20:11:23.010: [iter 33 : loss : 0.8700 = 0.1188 + 0.3747 + 0.0019 + 0.3746, time: 22.251377]
2023-09-01 20:11:23.639: epoch 33:	0.02953617  	0.06393892  	0.05294819  
2023-09-01 20:11:23.639: Find a better model.
2023-09-01 20:11:45.901: [iter 34 : loss : 0.8688 = 0.1177 + 0.3746 + 0.0020 + 0.3745, time: 22.235030]
2023-09-01 20:11:46.531: epoch 34:	0.02958134  	0.06393612  	0.05295091  
2023-09-01 20:12:08.749: [iter 35 : loss : 0.8674 = 0.1163 + 0.3746 + 0.0020 + 0.3744, time: 22.195797]
2023-09-01 20:12:09.379: epoch 35:	0.02977489  	0.06441582  	0.05319583  
2023-09-01 20:12:09.379: Find a better model.
2023-09-01 20:12:31.657: [iter 36 : loss : 0.8661 = 0.1152 + 0.3745 + 0.0021 + 0.3744, time: 22.249525]
2023-09-01 20:12:32.311: epoch 36:	0.02994265  	0.06491740  	0.05338048  
2023-09-01 20:12:32.312: Find a better model.
2023-09-01 20:12:54.658: [iter 37 : loss : 0.8643 = 0.1134 + 0.3745 + 0.0021 + 0.3743, time: 22.315876]
2023-09-01 20:12:55.318: epoch 37:	0.03004588  	0.06513200  	0.05356076  
2023-09-01 20:12:55.318: Find a better model.
2023-09-01 20:13:17.497: [iter 38 : loss : 0.8625 = 0.1116 + 0.3745 + 0.0022 + 0.3743, time: 22.154566]
2023-09-01 20:13:18.108: epoch 38:	0.03017491  	0.06560468  	0.05375894  
2023-09-01 20:13:18.108: Find a better model.
2023-09-01 20:13:40.420: [iter 39 : loss : 0.8614 = 0.1106 + 0.3744 + 0.0022 + 0.3742, time: 22.290880]
2023-09-01 20:13:41.086: epoch 39:	0.03040071  	0.06628085  	0.05406126  
2023-09-01 20:13:41.086: Find a better model.
2023-09-01 20:14:03.386: [iter 40 : loss : 0.8604 = 0.1096 + 0.3743 + 0.0023 + 0.3741, time: 22.271504]
2023-09-01 20:14:03.986: epoch 40:	0.03049749  	0.06633703  	0.05424190  
2023-09-01 20:14:03.986: Find a better model.
2023-09-01 20:14:26.422: [iter 41 : loss : 0.8583 = 0.1076 + 0.3743 + 0.0023 + 0.3741, time: 22.414469]
2023-09-01 20:14:27.090: epoch 41:	0.03075555  	0.06671727  	0.05450578  
2023-09-01 20:14:27.090: Find a better model.
2023-09-01 20:14:49.364: [iter 42 : loss : 0.8577 = 0.1071 + 0.3742 + 0.0024 + 0.3740, time: 22.249698]
2023-09-01 20:14:50.009: epoch 42:	0.03062652  	0.06670946  	0.05450967  
2023-09-01 20:15:12.120: [iter 43 : loss : 0.8566 = 0.1061 + 0.3742 + 0.0024 + 0.3740, time: 22.086227]
2023-09-01 20:15:12.756: epoch 43:	0.03081362  	0.06699150  	0.05485629  
2023-09-01 20:15:12.756: Find a better model.
2023-09-01 20:15:35.612: [iter 44 : loss : 0.8557 = 0.1052 + 0.3741 + 0.0024 + 0.3739, time: 22.835100]
2023-09-01 20:15:36.259: epoch 44:	0.03114269  	0.06787805  	0.05524321  
2023-09-01 20:15:36.259: Find a better model.
2023-09-01 20:15:58.589: [iter 45 : loss : 0.8544 = 0.1040 + 0.3741 + 0.0025 + 0.3739, time: 22.308630]
2023-09-01 20:15:59.237: epoch 45:	0.03135558  	0.06845429  	0.05551111  
2023-09-01 20:15:59.237: Find a better model.
2023-09-01 20:16:21.623: [iter 46 : loss : 0.8538 = 0.1034 + 0.3740 + 0.0025 + 0.3738, time: 22.363418]
2023-09-01 20:16:22.267: epoch 46:	0.03149753  	0.06864879  	0.05575288  
2023-09-01 20:16:22.267: Find a better model.
2023-09-01 20:16:44.636: [iter 47 : loss : 0.8518 = 0.1015 + 0.3740 + 0.0026 + 0.3738, time: 22.346421]
2023-09-01 20:16:45.283: epoch 47:	0.03154268  	0.06883784  	0.05572529  
2023-09-01 20:16:45.283: Find a better model.
2023-09-01 20:17:07.667: [iter 48 : loss : 0.8512 = 0.1010 + 0.3739 + 0.0026 + 0.3737, time: 22.354613]
2023-09-01 20:17:08.311: epoch 48:	0.03177495  	0.06948248  	0.05618453  
2023-09-01 20:17:08.311: Find a better model.
2023-09-01 20:17:30.638: [iter 49 : loss : 0.8502 = 0.1000 + 0.3739 + 0.0027 + 0.3737, time: 22.295684]
2023-09-01 20:17:31.288: epoch 49:	0.03176205  	0.06944819  	0.05635785  
2023-09-01 20:17:53.846: [iter 50 : loss : 0.8498 = 0.0996 + 0.3738 + 0.0027 + 0.3736, time: 22.535167]
2023-09-01 20:17:54.498: epoch 50:	0.03197498  	0.06974813  	0.05668752  
2023-09-01 20:17:54.498: Find a better model.
2023-09-01 20:18:16.843: [iter 51 : loss : 0.8485 = 0.0984 + 0.3738 + 0.0028 + 0.3736, time: 22.318974]
2023-09-01 20:18:17.494: epoch 51:	0.03201369  	0.06988706  	0.05678898  
2023-09-01 20:18:17.494: Find a better model.
2023-09-01 20:18:39.844: [iter 52 : loss : 0.8472 = 0.0971 + 0.3737 + 0.0028 + 0.3735, time: 22.325382]
2023-09-01 20:18:40.503: epoch 52:	0.03220724  	0.07042316  	0.05729184  
2023-09-01 20:18:40.503: Find a better model.
2023-09-01 20:19:02.775: [iter 53 : loss : 0.8466 = 0.0965 + 0.3737 + 0.0029 + 0.3735, time: 22.240829]
2023-09-01 20:19:03.432: epoch 53:	0.03224593  	0.07044933  	0.05737863  
2023-09-01 20:19:03.432: Find a better model.
2023-09-01 20:19:25.767: [iter 54 : loss : 0.8454 = 0.0954 + 0.3737 + 0.0029 + 0.3734, time: 22.312244]
2023-09-01 20:19:26.414: epoch 54:	0.03253627  	0.07082935  	0.05757283  
2023-09-01 20:19:26.414: Find a better model.
2023-09-01 20:19:48.678: [iter 55 : loss : 0.8454 = 0.0954 + 0.3736 + 0.0029 + 0.3734, time: 22.239501]
2023-09-01 20:19:49.329: epoch 55:	0.03258144  	0.07098024  	0.05770150  
2023-09-01 20:19:49.329: Find a better model.
2023-09-01 20:20:11.624: [iter 56 : loss : 0.8439 = 0.0940 + 0.3736 + 0.0030 + 0.3734, time: 22.269924]
2023-09-01 20:20:12.289: epoch 56:	0.03252336  	0.07072511  	0.05771061  
2023-09-01 20:20:34.667: [iter 57 : loss : 0.8432 = 0.0933 + 0.3735 + 0.0030 + 0.3733, time: 22.351936]
2023-09-01 20:20:35.335: epoch 57:	0.03278789  	0.07157936  	0.05818000  
2023-09-01 20:20:35.335: Find a better model.
2023-09-01 20:20:57.436: [iter 58 : loss : 0.8432 = 0.0934 + 0.3735 + 0.0031 + 0.3733, time: 22.070808]
2023-09-01 20:20:58.106: epoch 58:	0.03290401  	0.07182607  	0.05832007  
2023-09-01 20:20:58.106: Find a better model.
2023-09-01 20:21:20.441: [iter 59 : loss : 0.8420 = 0.0922 + 0.3734 + 0.0031 + 0.3732, time: 22.305934]
2023-09-01 20:21:21.038: epoch 59:	0.03316851  	0.07247616  	0.05873635  
2023-09-01 20:21:21.039: Find a better model.
2023-09-01 20:21:43.390: [iter 60 : loss : 0.8412 = 0.0915 + 0.3734 + 0.0032 + 0.3732, time: 22.328151]
2023-09-01 20:21:44.051: epoch 60:	0.03334913  	0.07295720  	0.05923635  
2023-09-01 20:21:44.051: Find a better model.
2023-09-01 20:22:06.002: [iter 61 : loss : 0.8398 = 0.0901 + 0.3733 + 0.0032 + 0.3731, time: 21.926304]
2023-09-01 20:22:06.648: epoch 61:	0.03347170  	0.07309554  	0.05938291  
2023-09-01 20:22:06.648: Find a better model.
2023-09-01 20:22:28.075: [iter 62 : loss : 0.8395 = 0.0898 + 0.3733 + 0.0032 + 0.3731, time: 21.398321]
2023-09-01 20:22:28.647: epoch 62:	0.03351687  	0.07324058  	0.05943062  
2023-09-01 20:22:28.647: Find a better model.
2023-09-01 20:22:50.624: [iter 63 : loss : 0.8380 = 0.0883 + 0.3733 + 0.0033 + 0.3731, time: 21.952975]
2023-09-01 20:22:51.258: epoch 63:	0.03372328  	0.07369322  	0.05984569  
2023-09-01 20:22:51.258: Find a better model.
2023-09-01 20:23:13.629: [iter 64 : loss : 0.8376 = 0.0881 + 0.3732 + 0.0033 + 0.3730, time: 22.350945]
2023-09-01 20:23:14.286: epoch 64:	0.03357492  	0.07339272  	0.05978018  
2023-09-01 20:23:36.723: [iter 65 : loss : 0.8373 = 0.0877 + 0.3732 + 0.0034 + 0.3730, time: 22.410084]
2023-09-01 20:23:37.386: epoch 65:	0.03363943  	0.07352679  	0.05987747  
2023-09-01 20:23:59.668: [iter 66 : loss : 0.8359 = 0.0864 + 0.3731 + 0.0034 + 0.3729, time: 22.258656]
2023-09-01 20:24:00.338: epoch 66:	0.03376846  	0.07367576  	0.06010224  
2023-09-01 20:24:22.334: [iter 67 : loss : 0.8357 = 0.0862 + 0.3731 + 0.0035 + 0.3729, time: 21.969908]
2023-09-01 20:24:22.954: epoch 67:	0.03411037  	0.07437178  	0.06050887  
2023-09-01 20:24:22.954: Find a better model.
2023-09-01 20:24:45.350: [iter 68 : loss : 0.8354 = 0.0860 + 0.3731 + 0.0035 + 0.3728, time: 22.369718]
2023-09-01 20:24:45.976: epoch 68:	0.03447805  	0.07515845  	0.06093685  
2023-09-01 20:24:45.976: Find a better model.
2023-09-01 20:25:08.195: [iter 69 : loss : 0.8342 = 0.0848 + 0.3730 + 0.0035 + 0.3728, time: 22.197632]
2023-09-01 20:25:08.812: epoch 69:	0.03454258  	0.07508995  	0.06095444  
2023-09-01 20:25:31.219: [iter 70 : loss : 0.8342 = 0.0848 + 0.3730 + 0.0036 + 0.3728, time: 22.382736]
2023-09-01 20:25:31.873: epoch 70:	0.03465872  	0.07545247  	0.06131145  
2023-09-01 20:25:31.873: Find a better model.
2023-09-01 20:25:54.410: [iter 71 : loss : 0.8325 = 0.0832 + 0.3730 + 0.0036 + 0.3727, time: 22.512834]
2023-09-01 20:25:55.091: epoch 71:	0.03479419  	0.07560936  	0.06147941  
2023-09-01 20:25:55.091: Find a better model.
2023-09-01 20:26:17.517: [iter 72 : loss : 0.8327 = 0.0834 + 0.3729 + 0.0037 + 0.3727, time: 22.388630]
2023-09-01 20:26:18.167: epoch 72:	0.03485226  	0.07591892  	0.06175757  
2023-09-01 20:26:18.167: Find a better model.
2023-09-01 20:26:40.555: [iter 73 : loss : 0.8318 = 0.0826 + 0.3729 + 0.0037 + 0.3726, time: 22.364031]
2023-09-01 20:26:41.161: epoch 73:	0.03472321  	0.07554231  	0.06169916  
2023-09-01 20:27:03.562: [iter 74 : loss : 0.8309 = 0.0818 + 0.3728 + 0.0038 + 0.3726, time: 22.380032]
2023-09-01 20:27:04.208: epoch 74:	0.03506511  	0.07635942  	0.06217789  
2023-09-01 20:27:04.208: Find a better model.
2023-09-01 20:27:26.384: [iter 75 : loss : 0.8300 = 0.0809 + 0.3728 + 0.0038 + 0.3726, time: 22.154963]
2023-09-01 20:27:27.005: epoch 75:	0.03517478  	0.07665191  	0.06230703  
2023-09-01 20:27:27.005: Find a better model.
2023-09-01 20:27:49.231: [iter 76 : loss : 0.8301 = 0.0810 + 0.3728 + 0.0038 + 0.3725, time: 22.202239]
2023-09-01 20:27:49.886: epoch 76:	0.03549735  	0.07713530  	0.06278272  
2023-09-01 20:27:49.886: Find a better model.
2023-09-01 20:28:11.867: [iter 77 : loss : 0.8291 = 0.0800 + 0.3727 + 0.0039 + 0.3725, time: 21.958344]
2023-09-01 20:28:12.454: epoch 77:	0.03558121  	0.07732076  	0.06290884  
2023-09-01 20:28:12.454: Find a better model.
2023-09-01 20:28:34.726: [iter 78 : loss : 0.8287 = 0.0796 + 0.3727 + 0.0039 + 0.3724, time: 22.249039]
2023-09-01 20:28:35.362: epoch 78:	0.03566509  	0.07741873  	0.06303683  
2023-09-01 20:28:35.363: Find a better model.
2023-09-01 20:28:57.632: [iter 79 : loss : 0.8279 = 0.0789 + 0.3726 + 0.0040 + 0.3724, time: 22.246831]
2023-09-01 20:28:58.223: epoch 79:	0.03557475  	0.07726835  	0.06307652  
2023-09-01 20:29:20.487: [iter 80 : loss : 0.8277 = 0.0788 + 0.3726 + 0.0040 + 0.3724, time: 22.238811]
2023-09-01 20:29:21.130: epoch 80:	0.03573603  	0.07760956  	0.06333781  
2023-09-01 20:29:21.130: Find a better model.
2023-09-01 20:29:43.562: [iter 81 : loss : 0.8269 = 0.0780 + 0.3725 + 0.0040 + 0.3723, time: 22.407486]
2023-09-01 20:29:44.179: epoch 81:	0.03592313  	0.07832625  	0.06370432  
2023-09-01 20:29:44.179: Find a better model.
2023-09-01 20:30:06.459: [iter 82 : loss : 0.8265 = 0.0776 + 0.3725 + 0.0041 + 0.3723, time: 22.257915]
2023-09-01 20:30:07.123: epoch 82:	0.03590376  	0.07797036  	0.06368520  
2023-09-01 20:30:29.526: [iter 83 : loss : 0.8263 = 0.0774 + 0.3725 + 0.0041 + 0.3723, time: 22.377913]
2023-09-01 20:30:30.203: epoch 83:	0.03613601  	0.07866128  	0.06396307  
2023-09-01 20:30:30.203: Find a better model.
2023-09-01 20:30:52.413: [iter 84 : loss : 0.8241 = 0.0752 + 0.3725 + 0.0042 + 0.3722, time: 22.184139]
2023-09-01 20:30:53.068: epoch 84:	0.03632310  	0.07923228  	0.06430260  
2023-09-01 20:30:53.068: Find a better model.
2023-09-01 20:31:15.214: [iter 85 : loss : 0.8250 = 0.0763 + 0.3724 + 0.0042 + 0.3722, time: 22.121076]
2023-09-01 20:31:15.863: epoch 85:	0.03636179  	0.07944714  	0.06463364  
2023-09-01 20:31:15.863: Find a better model.
2023-09-01 20:31:38.006: [iter 86 : loss : 0.8239 = 0.0751 + 0.3724 + 0.0042 + 0.3722, time: 22.117565]
2023-09-01 20:31:38.669: epoch 86:	0.03667784  	0.08003223  	0.06498691  
2023-09-01 20:31:38.670: Find a better model.
2023-09-01 20:32:00.779: [iter 87 : loss : 0.8239 = 0.0751 + 0.3723 + 0.0043 + 0.3721, time: 22.085689]
2023-09-01 20:32:01.426: epoch 87:	0.03673594  	0.08022810  	0.06514325  
2023-09-01 20:32:01.426: Find a better model.
2023-09-01 20:32:23.906: [iter 88 : loss : 0.8236 = 0.0749 + 0.3723 + 0.0043 + 0.3721, time: 22.451690]
2023-09-01 20:32:24.549: epoch 88:	0.03662628  	0.08023909  	0.06527682  
2023-09-01 20:32:24.549: Find a better model.
2023-09-01 20:32:46.861: [iter 89 : loss : 0.8228 = 0.0741 + 0.3723 + 0.0044 + 0.3721, time: 22.287374]
2023-09-01 20:32:47.508: epoch 89:	0.03684562  	0.08042656  	0.06551549  
2023-09-01 20:32:47.508: Find a better model.
2023-09-01 20:33:09.854: [iter 90 : loss : 0.8224 = 0.0737 + 0.3723 + 0.0044 + 0.3720, time: 22.321354]
2023-09-01 20:33:10.526: epoch 90:	0.03672305  	0.07992424  	0.06568284  
2023-09-01 20:33:32.528: [iter 91 : loss : 0.8219 = 0.0733 + 0.3722 + 0.0044 + 0.3720, time: 21.971155]
2023-09-01 20:33:33.175: epoch 91:	0.03699398  	0.08068723  	0.06619123  
2023-09-01 20:33:33.175: Find a better model.
2023-09-01 20:33:54.649: [iter 92 : loss : 0.8216 = 0.0730 + 0.3722 + 0.0045 + 0.3720, time: 21.446286]
2023-09-01 20:33:55.224: epoch 92:	0.03721975  	0.08127932  	0.06669124  
2023-09-01 20:33:55.224: Find a better model.
2023-09-01 20:34:17.127: [iter 93 : loss : 0.8206 = 0.0720 + 0.3721 + 0.0045 + 0.3719, time: 21.877767]
2023-09-01 20:34:17.772: epoch 93:	0.03711655  	0.08115658  	0.06660730  
2023-09-01 20:34:39.983: [iter 94 : loss : 0.8212 = 0.0727 + 0.3721 + 0.0045 + 0.3719, time: 22.188707]
2023-09-01 20:34:40.558: epoch 94:	0.03752937  	0.08198408  	0.06704719  
2023-09-01 20:34:40.558: Find a better model.
2023-09-01 20:35:02.976: [iter 95 : loss : 0.8203 = 0.0719 + 0.3720 + 0.0046 + 0.3719, time: 22.392990]
2023-09-01 20:35:03.639: epoch 95:	0.03747777  	0.08159138  	0.06696703  
2023-09-01 20:35:25.862: [iter 96 : loss : 0.8203 = 0.0718 + 0.3720 + 0.0046 + 0.3718, time: 22.195499]
2023-09-01 20:35:26.508: epoch 96:	0.03754227  	0.08172075  	0.06719948  
2023-09-01 20:35:48.754: [iter 97 : loss : 0.8199 = 0.0714 + 0.3720 + 0.0047 + 0.3718, time: 22.222889]
2023-09-01 20:35:49.402: epoch 97:	0.03785192  	0.08244682  	0.06760157  
2023-09-01 20:35:49.402: Find a better model.
2023-09-01 20:36:11.455: [iter 98 : loss : 0.8191 = 0.0707 + 0.3720 + 0.0047 + 0.3718, time: 22.031449]
2023-09-01 20:36:12.094: epoch 98:	0.03794870  	0.08268625  	0.06783142  
2023-09-01 20:36:12.095: Find a better model.
2023-09-01 20:36:34.373: [iter 99 : loss : 0.8183 = 0.0699 + 0.3720 + 0.0047 + 0.3717, time: 22.253585]
2023-09-01 20:36:35.018: epoch 99:	0.03801323  	0.08290379  	0.06790458  
2023-09-01 20:36:35.018: Find a better model.
2023-09-01 20:36:57.305: [iter 100 : loss : 0.8180 = 0.0696 + 0.3719 + 0.0048 + 0.3717, time: 22.266164]
2023-09-01 20:36:57.952: epoch 100:	0.03822611  	0.08336710  	0.06809801  
2023-09-01 20:36:57.953: Find a better model.
2023-09-01 20:37:20.084: [iter 101 : loss : 0.8172 = 0.0688 + 0.3719 + 0.0048 + 0.3717, time: 22.108920]
2023-09-01 20:37:20.708: epoch 101:	0.03817447  	0.08351433  	0.06823864  
2023-09-01 20:37:20.708: Find a better model.
2023-09-01 20:37:42.687: [iter 102 : loss : 0.8182 = 0.0700 + 0.3718 + 0.0048 + 0.3716, time: 21.950006]
2023-09-01 20:37:43.323: epoch 102:	0.03831640  	0.08367239  	0.06827734  
2023-09-01 20:37:43.324: Find a better model.
2023-09-01 20:38:05.653: [iter 103 : loss : 0.8171 = 0.0688 + 0.3718 + 0.0049 + 0.3716, time: 22.304986]
2023-09-01 20:38:06.324: epoch 103:	0.03835510  	0.08374785  	0.06853718  
2023-09-01 20:38:06.324: Find a better model.
2023-09-01 20:38:28.534: [iter 104 : loss : 0.8171 = 0.0688 + 0.3718 + 0.0049 + 0.3716, time: 22.181723]
2023-09-01 20:38:29.201: epoch 104:	0.03842606  	0.08389071  	0.06860999  
2023-09-01 20:38:29.201: Find a better model.
2023-09-01 20:38:51.553: [iter 105 : loss : 0.8158 = 0.0675 + 0.3718 + 0.0050 + 0.3715, time: 22.321845]
2023-09-01 20:38:52.199: epoch 105:	0.03865829  	0.08447433  	0.06897666  
2023-09-01 20:38:52.199: Find a better model.
2023-09-01 20:39:14.428: [iter 106 : loss : 0.8150 = 0.0667 + 0.3717 + 0.0050 + 0.3715, time: 22.207789]
2023-09-01 20:39:15.071: epoch 106:	0.03863892  	0.08425293  	0.06898735  
2023-09-01 20:39:37.386: [iter 107 : loss : 0.8156 = 0.0674 + 0.3717 + 0.0050 + 0.3715, time: 22.288939]
2023-09-01 20:39:38.068: epoch 107:	0.03851634  	0.08415864  	0.06900224  
2023-09-01 20:40:00.368: [iter 108 : loss : 0.8150 = 0.0669 + 0.3717 + 0.0051 + 0.3714, time: 22.273934]
2023-09-01 20:40:00.994: epoch 108:	0.03857440  	0.08445434  	0.06915305  
2023-09-01 20:40:23.582: [iter 109 : loss : 0.8144 = 0.0663 + 0.3716 + 0.0051 + 0.3714, time: 22.563388]
2023-09-01 20:40:24.225: epoch 109:	0.03861957  	0.08457933  	0.06926289  
2023-09-01 20:40:24.225: Find a better model.
2023-09-01 20:40:46.759: [iter 110 : loss : 0.8135 = 0.0654 + 0.3716 + 0.0051 + 0.3714, time: 22.513539]
2023-09-01 20:40:47.428: epoch 110:	0.03844538  	0.08426538  	0.06904127  
2023-09-01 20:41:09.758: [iter 111 : loss : 0.8137 = 0.0657 + 0.3716 + 0.0052 + 0.3713, time: 22.300804]
2023-09-01 20:41:10.402: epoch 111:	0.03873570  	0.08470978  	0.06945972  
2023-09-01 20:41:10.402: Find a better model.
2023-09-01 20:41:32.717: [iter 112 : loss : 0.8139 = 0.0659 + 0.3715 + 0.0052 + 0.3713, time: 22.290384]
2023-09-01 20:41:33.367: epoch 112:	0.03891629  	0.08501692  	0.06973903  
2023-09-01 20:41:33.367: Find a better model.
2023-09-01 20:41:55.780: [iter 113 : loss : 0.8141 = 0.0661 + 0.3715 + 0.0052 + 0.3713, time: 22.386349]
2023-09-01 20:41:56.426: epoch 113:	0.03925177  	0.08600391  	0.07033489  
2023-09-01 20:41:56.426: Find a better model.
2023-09-01 20:42:18.885: [iter 114 : loss : 0.8126 = 0.0646 + 0.3715 + 0.0053 + 0.3713, time: 22.433419]
2023-09-01 20:42:19.535: epoch 114:	0.03911630  	0.08528428  	0.07001258  
2023-09-01 20:42:42.157: [iter 115 : loss : 0.8127 = 0.0648 + 0.3714 + 0.0053 + 0.3712, time: 22.598250]
2023-09-01 20:42:42.768: epoch 115:	0.03936148  	0.08611958  	0.07043610  
2023-09-01 20:42:42.768: Find a better model.
2023-09-01 20:43:05.133: [iter 116 : loss : 0.8116 = 0.0636 + 0.3714 + 0.0053 + 0.3712, time: 22.341898]
2023-09-01 20:43:05.788: epoch 116:	0.03952920  	0.08655831  	0.07065466  
2023-09-01 20:43:05.788: Find a better model.
2023-09-01 20:43:28.058: [iter 117 : loss : 0.8115 = 0.0636 + 0.3714 + 0.0054 + 0.3712, time: 22.246060]
2023-09-01 20:43:28.721: epoch 117:	0.03959369  	0.08633868  	0.07075090  
2023-09-01 20:43:51.165: [iter 118 : loss : 0.8120 = 0.0641 + 0.3714 + 0.0054 + 0.3711, time: 22.417681]
2023-09-01 20:43:51.774: epoch 118:	0.03948404  	0.08614623  	0.07080190  
2023-09-01 20:44:14.175: [iter 119 : loss : 0.8109 = 0.0630 + 0.3713 + 0.0054 + 0.3711, time: 22.377878]
2023-09-01 20:44:14.834: epoch 119:	0.03953568  	0.08641034  	0.07101869  
2023-09-01 20:44:37.141: [iter 120 : loss : 0.8105 = 0.0626 + 0.3713 + 0.0055 + 0.3711, time: 22.275100]
2023-09-01 20:44:37.795: epoch 120:	0.03961306  	0.08657756  	0.07092402  
2023-09-01 20:44:37.796: Find a better model.
2023-09-01 20:45:00.241: [iter 121 : loss : 0.8108 = 0.0630 + 0.3713 + 0.0055 + 0.3711, time: 22.423468]
2023-09-01 20:45:00.902: epoch 121:	0.03974209  	0.08694912  	0.07118940  
2023-09-01 20:45:00.903: Find a better model.
2023-09-01 20:45:23.147: [iter 122 : loss : 0.8101 = 0.0623 + 0.3712 + 0.0056 + 0.3710, time: 22.219826]
2023-09-01 20:45:23.814: epoch 122:	0.03994205  	0.08732780  	0.07142645  
2023-09-01 20:45:23.814: Find a better model.
2023-09-01 20:45:46.193: [iter 123 : loss : 0.8101 = 0.0623 + 0.3712 + 0.0056 + 0.3710, time: 22.350178]
2023-09-01 20:45:46.836: epoch 123:	0.03996138  	0.08730511  	0.07150360  
2023-09-01 20:46:09.138: [iter 124 : loss : 0.8096 = 0.0619 + 0.3712 + 0.0056 + 0.3710, time: 22.276736]
2023-09-01 20:46:09.777: epoch 124:	0.03994843  	0.08731346  	0.07173269  
2023-09-01 20:46:32.145: [iter 125 : loss : 0.8093 = 0.0616 + 0.3712 + 0.0057 + 0.3709, time: 22.346858]
2023-09-01 20:46:32.807: epoch 125:	0.04007104  	0.08762892  	0.07194225  
2023-09-01 20:46:32.807: Find a better model.
2023-09-01 20:46:55.081: [iter 126 : loss : 0.8093 = 0.0616 + 0.3711 + 0.0057 + 0.3709, time: 22.252257]
2023-09-01 20:46:55.731: epoch 126:	0.04000657  	0.08711730  	0.07169636  
2023-09-01 20:47:17.938: [iter 127 : loss : 0.8093 = 0.0616 + 0.3711 + 0.0057 + 0.3709, time: 22.183964]
2023-09-01 20:47:18.561: epoch 127:	0.03996786  	0.08702858  	0.07172603  
2023-09-01 20:47:40.822: [iter 128 : loss : 0.8087 = 0.0610 + 0.3711 + 0.0058 + 0.3709, time: 22.230805]
2023-09-01 20:47:41.461: epoch 128:	0.04011622  	0.08762221  	0.07211105  
2023-09-01 20:48:03.734: [iter 129 : loss : 0.8086 = 0.0609 + 0.3711 + 0.0058 + 0.3708, time: 22.245386]
2023-09-01 20:48:04.366: epoch 129:	0.04018074  	0.08748530  	0.07209450  
2023-09-01 20:48:26.542: [iter 130 : loss : 0.8078 = 0.0601 + 0.3710 + 0.0058 + 0.3708, time: 22.152673]
2023-09-01 20:48:27.207: epoch 130:	0.04015493  	0.08751927  	0.07230425  
2023-09-01 20:48:49.531: [iter 131 : loss : 0.8085 = 0.0608 + 0.3710 + 0.0059 + 0.3708, time: 22.299196]
2023-09-01 20:48:50.140: epoch 131:	0.04024523  	0.08759387  	0.07241779  
2023-09-01 20:49:12.503: [iter 132 : loss : 0.8065 = 0.0588 + 0.3710 + 0.0059 + 0.3708, time: 22.337509]
2023-09-01 20:49:13.118: epoch 132:	0.04026457  	0.08776471  	0.07254860  
2023-09-01 20:49:13.118: Find a better model.
2023-09-01 20:49:35.534: [iter 133 : loss : 0.8068 = 0.0592 + 0.3709 + 0.0059 + 0.3707, time: 22.395060]
2023-09-01 20:49:36.205: epoch 133:	0.04027101  	0.08803529  	0.07258046  
2023-09-01 20:49:36.206: Find a better model.
2023-09-01 20:49:58.728: [iter 134 : loss : 0.8073 = 0.0598 + 0.3709 + 0.0060 + 0.3707, time: 22.493111]
2023-09-01 20:49:59.379: epoch 134:	0.04054845  	0.08874276  	0.07284078  
2023-09-01 20:49:59.379: Find a better model.
2023-09-01 20:50:21.847: [iter 135 : loss : 0.8068 = 0.0592 + 0.3709 + 0.0060 + 0.3707, time: 22.439250]
2023-09-01 20:50:22.440: epoch 135:	0.04027751  	0.08826610  	0.07264493  
2023-09-01 20:50:44.794: [iter 136 : loss : 0.8061 = 0.0586 + 0.3709 + 0.0060 + 0.3707, time: 22.330379]
2023-09-01 20:50:45.466: epoch 136:	0.04028393  	0.08811944  	0.07262757  
2023-09-01 20:51:07.899: [iter 137 : loss : 0.8060 = 0.0585 + 0.3709 + 0.0060 + 0.3706, time: 22.401859]
2023-09-01 20:51:08.538: epoch 137:	0.04034843  	0.08825245  	0.07288191  
2023-09-01 20:51:30.998: [iter 138 : loss : 0.8062 = 0.0586 + 0.3708 + 0.0061 + 0.3706, time: 22.434632]
2023-09-01 20:51:31.631: epoch 138:	0.04044520  	0.08831108  	0.07290944  
2023-09-01 20:51:54.110: [iter 139 : loss : 0.8054 = 0.0579 + 0.3708 + 0.0061 + 0.3706, time: 22.455636]
2023-09-01 20:51:54.767: epoch 139:	0.04034840  	0.08843691  	0.07295697  
2023-09-01 20:52:17.279: [iter 140 : loss : 0.8055 = 0.0580 + 0.3708 + 0.0061 + 0.3706, time: 22.476016]
2023-09-01 20:52:17.931: epoch 140:	0.04058062  	0.08897822  	0.07334037  
2023-09-01 20:52:17.931: Find a better model.
2023-09-01 20:52:40.352: [iter 141 : loss : 0.8057 = 0.0582 + 0.3708 + 0.0062 + 0.3705, time: 22.399188]
2023-09-01 20:52:41.001: epoch 141:	0.04083867  	0.08947083  	0.07339150  
2023-09-01 20:52:41.002: Find a better model.
2023-09-01 20:53:03.324: [iter 142 : loss : 0.8046 = 0.0572 + 0.3707 + 0.0062 + 0.3705, time: 22.297370]
2023-09-01 20:53:03.986: epoch 142:	0.04081935  	0.08954355  	0.07348777  
2023-09-01 20:53:03.987: Find a better model.
2023-09-01 20:53:26.385: [iter 143 : loss : 0.8049 = 0.0575 + 0.3707 + 0.0062 + 0.3705, time: 22.373146]
2023-09-01 20:53:27.052: epoch 143:	0.04113548  	0.09021568  	0.07386024  
2023-09-01 20:53:27.052: Find a better model.
2023-09-01 20:53:49.527: [iter 144 : loss : 0.8045 = 0.0571 + 0.3707 + 0.0063 + 0.3705, time: 22.444055]
2023-09-01 20:53:50.162: epoch 144:	0.04111611  	0.09020086  	0.07385946  
2023-09-01 20:54:12.509: [iter 145 : loss : 0.8045 = 0.0572 + 0.3706 + 0.0063 + 0.3704, time: 22.322329]
2023-09-01 20:54:13.165: epoch 145:	0.04123224  	0.09039930  	0.07416011  
2023-09-01 20:54:13.166: Find a better model.
2023-09-01 20:54:35.645: [iter 146 : loss : 0.8043 = 0.0569 + 0.3706 + 0.0063 + 0.3704, time: 22.455143]
2023-09-01 20:54:36.287: epoch 146:	0.04130320  	0.09065301  	0.07449202  
2023-09-01 20:54:36.287: Find a better model.
2023-09-01 20:54:58.801: [iter 147 : loss : 0.8041 = 0.0567 + 0.3706 + 0.0064 + 0.3704, time: 22.488925]
2023-09-01 20:54:59.447: epoch 147:	0.04137415  	0.09111491  	0.07454909  
2023-09-01 20:54:59.447: Find a better model.
2023-09-01 20:55:21.734: [iter 148 : loss : 0.8039 = 0.0566 + 0.3706 + 0.0064 + 0.3704, time: 22.260524]
2023-09-01 20:55:22.387: epoch 148:	0.04159994  	0.09173269  	0.07498374  
2023-09-01 20:55:22.387: Find a better model.
2023-09-01 20:55:44.789: [iter 149 : loss : 0.8027 = 0.0553 + 0.3706 + 0.0064 + 0.3704, time: 22.379628]
2023-09-01 20:55:45.439: epoch 149:	0.04165800  	0.09179527  	0.07505817  
2023-09-01 20:55:45.439: Find a better model.
2023-09-01 20:56:07.893: [iter 150 : loss : 0.8035 = 0.0562 + 0.3706 + 0.0065 + 0.3703, time: 22.429594]
2023-09-01 20:56:08.530: epoch 150:	0.04169026  	0.09164220  	0.07500947  
2023-09-01 20:56:30.910: [iter 151 : loss : 0.8032 = 0.0560 + 0.3705 + 0.0065 + 0.3703, time: 22.357348]
2023-09-01 20:56:31.560: epoch 151:	0.04163221  	0.09159349  	0.07503030  
2023-09-01 20:56:54.019: [iter 152 : loss : 0.8034 = 0.0561 + 0.3705 + 0.0065 + 0.3703, time: 22.434049]
2023-09-01 20:56:54.668: epoch 152:	0.04159351  	0.09149556  	0.07512010  
2023-09-01 20:57:17.176: [iter 153 : loss : 0.8032 = 0.0559 + 0.3705 + 0.0065 + 0.3703, time: 22.485080]
2023-09-01 20:57:17.833: epoch 153:	0.04172898  	0.09176071  	0.07506362  
2023-09-01 20:57:40.177: [iter 154 : loss : 0.8025 = 0.0552 + 0.3704 + 0.0066 + 0.3702, time: 22.322922]
2023-09-01 20:57:40.827: epoch 154:	0.04167739  	0.09161404  	0.07531972  
2023-09-01 20:58:03.261: [iter 155 : loss : 0.8018 = 0.0546 + 0.3704 + 0.0066 + 0.3702, time: 22.410767]
2023-09-01 20:58:03.919: epoch 155:	0.04189671  	0.09190801  	0.07533152  
2023-09-01 20:58:03.919: Find a better model.
2023-09-01 20:58:25.983: [iter 156 : loss : 0.8021 = 0.0549 + 0.3704 + 0.0066 + 0.3702, time: 22.034093]
2023-09-01 20:58:26.606: epoch 156:	0.04176768  	0.09162662  	0.07520998  
2023-09-01 20:58:48.936: [iter 157 : loss : 0.8019 = 0.0547 + 0.3704 + 0.0067 + 0.3702, time: 22.307003]
2023-09-01 20:58:49.553: epoch 157:	0.04194829  	0.09205086  	0.07552338  
2023-09-01 20:58:49.553: Find a better model.
2023-09-01 20:59:11.849: [iter 158 : loss : 0.8018 = 0.0547 + 0.3703 + 0.0067 + 0.3702, time: 22.269207]
2023-09-01 20:59:12.490: epoch 158:	0.04208376  	0.09233662  	0.07579698  
2023-09-01 20:59:12.490: Find a better model.
2023-09-01 20:59:34.689: [iter 159 : loss : 0.8010 = 0.0538 + 0.3703 + 0.0067 + 0.3701, time: 22.174027]
2023-09-01 20:59:35.335: epoch 159:	0.04186443  	0.09201910  	0.07566891  
2023-09-01 20:59:57.678: [iter 160 : loss : 0.8009 = 0.0537 + 0.3703 + 0.0068 + 0.3701, time: 22.308724]
2023-09-01 20:59:58.328: epoch 160:	0.04200636  	0.09224803  	0.07578065  
2023-09-01 21:00:20.639: [iter 161 : loss : 0.8009 = 0.0537 + 0.3703 + 0.0068 + 0.3701, time: 22.288227]
2023-09-01 21:00:21.297: epoch 161:	0.04203859  	0.09239115  	0.07591163  
2023-09-01 21:00:21.297: Find a better model.
2023-09-01 21:00:43.444: [iter 162 : loss : 0.8005 = 0.0534 + 0.3703 + 0.0068 + 0.3701, time: 22.120819]
2023-09-01 21:00:44.106: epoch 162:	0.04222567  	0.09291834  	0.07622750  
2023-09-01 21:00:44.106: Find a better model.
2023-09-01 21:01:06.593: [iter 163 : loss : 0.8001 = 0.0530 + 0.3703 + 0.0068 + 0.3700, time: 22.457500]
2023-09-01 21:01:07.237: epoch 163:	0.04201278  	0.09243047  	0.07605264  
2023-09-01 21:01:29.673: [iter 164 : loss : 0.8003 = 0.0533 + 0.3702 + 0.0069 + 0.3700, time: 22.415274]
2023-09-01 21:01:30.340: epoch 164:	0.04209022  	0.09250547  	0.07609784  
2023-09-01 21:01:52.592: [iter 165 : loss : 0.7996 = 0.0525 + 0.3702 + 0.0069 + 0.3700, time: 22.225464]
2023-09-01 21:01:53.244: epoch 165:	0.04222568  	0.09302351  	0.07616936  
2023-09-01 21:01:53.245: Find a better model.
2023-09-01 21:02:15.522: [iter 166 : loss : 0.7996 = 0.0525 + 0.3702 + 0.0069 + 0.3700, time: 22.253188]
2023-09-01 21:02:16.167: epoch 166:	0.04243209  	0.09341358  	0.07637443  
2023-09-01 21:02:16.167: Find a better model.
2023-09-01 21:02:38.640: [iter 167 : loss : 0.8004 = 0.0534 + 0.3701 + 0.0070 + 0.3700, time: 22.451055]
2023-09-01 21:02:39.279: epoch 167:	0.04241920  	0.09345391  	0.07651483  
2023-09-01 21:02:39.280: Find a better model.
2023-09-01 21:03:01.485: [iter 168 : loss : 0.7994 = 0.0523 + 0.3701 + 0.0070 + 0.3699, time: 22.178336]
2023-09-01 21:03:02.127: epoch 168:	0.04230310  	0.09303075  	0.07654260  
2023-09-01 21:03:24.273: [iter 169 : loss : 0.8003 = 0.0532 + 0.3701 + 0.0070 + 0.3699, time: 22.122931]
2023-09-01 21:03:24.892: epoch 169:	0.04230957  	0.09279016  	0.07657246  
2023-09-01 21:03:47.311: [iter 170 : loss : 0.7987 = 0.0517 + 0.3701 + 0.0070 + 0.3699, time: 22.397182]
2023-09-01 21:03:47.962: epoch 170:	0.04234822  	0.09274687  	0.07661477  
2023-09-01 21:04:10.642: [iter 171 : loss : 0.7989 = 0.0519 + 0.3701 + 0.0071 + 0.3699, time: 22.657527]
2023-09-01 21:04:11.304: epoch 171:	0.04232246  	0.09268282  	0.07659984  
2023-09-01 21:04:33.767: [iter 172 : loss : 0.7983 = 0.0513 + 0.3701 + 0.0071 + 0.3698, time: 22.434265]
2023-09-01 21:04:34.400: epoch 172:	0.04233535  	0.09261869  	0.07647889  
2023-09-01 21:04:57.042: [iter 173 : loss : 0.7984 = 0.0514 + 0.3700 + 0.0071 + 0.3698, time: 22.607541]
2023-09-01 21:04:57.676: epoch 173:	0.04268371  	0.09355283  	0.07683056  
2023-09-01 21:04:57.676: Find a better model.
2023-09-01 21:05:20.069: [iter 174 : loss : 0.7986 = 0.0516 + 0.3700 + 0.0072 + 0.3698, time: 22.370314]
2023-09-01 21:05:20.703: epoch 174:	0.04273534  	0.09365273  	0.07707251  
2023-09-01 21:05:20.703: Find a better model.
2023-09-01 21:05:43.366: [iter 175 : loss : 0.7988 = 0.0519 + 0.3700 + 0.0072 + 0.3698, time: 22.634183]
2023-09-01 21:05:44.031: epoch 175:	0.04272244  	0.09365448  	0.07723632  
2023-09-01 21:05:44.032: Find a better model.
2023-09-01 21:06:06.302: [iter 176 : loss : 0.7974 = 0.0505 + 0.3700 + 0.0072 + 0.3698, time: 22.245405]
2023-09-01 21:06:06.925: epoch 176:	0.04277406  	0.09382503  	0.07753518  
2023-09-01 21:06:06.926: Find a better model.
2023-09-01 21:06:29.177: [iter 177 : loss : 0.7982 = 0.0513 + 0.3700 + 0.0072 + 0.3697, time: 22.226816]
2023-09-01 21:06:29.827: epoch 177:	0.04274181  	0.09360281  	0.07725953  
2023-09-01 21:06:52.171: [iter 178 : loss : 0.7971 = 0.0501 + 0.3699 + 0.0073 + 0.3697, time: 22.314324]
2023-09-01 21:06:52.821: epoch 178:	0.04261277  	0.09335794  	0.07721786  
2023-09-01 21:07:15.300: [iter 179 : loss : 0.7976 = 0.0507 + 0.3699 + 0.0073 + 0.3697, time: 22.452529]
2023-09-01 21:07:15.944: epoch 179:	0.04258051  	0.09335294  	0.07710781  
2023-09-01 21:07:38.276: [iter 180 : loss : 0.7980 = 0.0510 + 0.3699 + 0.0073 + 0.3697, time: 22.307179]
2023-09-01 21:07:38.929: epoch 180:	0.04269664  	0.09386736  	0.07733194  
2023-09-01 21:07:38.929: Find a better model.
2023-09-01 21:08:01.266: [iter 181 : loss : 0.7971 = 0.0502 + 0.3699 + 0.0074 + 0.3697, time: 22.309900]
2023-09-01 21:08:01.898: epoch 181:	0.04276758  	0.09404004  	0.07755838  
2023-09-01 21:08:01.898: Find a better model.
2023-09-01 21:08:24.244: [iter 182 : loss : 0.7968 = 0.0499 + 0.3698 + 0.0074 + 0.3697, time: 22.325240]
2023-09-01 21:08:24.901: epoch 182:	0.04252244  	0.09341089  	0.07725583  
2023-09-01 21:08:47.125: [iter 183 : loss : 0.7967 = 0.0498 + 0.3698 + 0.0074 + 0.3696, time: 22.202982]
2023-09-01 21:08:47.775: epoch 183:	0.04280625  	0.09399389  	0.07758491  
2023-09-01 21:09:10.501: [iter 184 : loss : 0.7961 = 0.0492 + 0.3698 + 0.0074 + 0.3696, time: 22.702799]
2023-09-01 21:09:11.152: epoch 184:	0.04288370  	0.09410004  	0.07778305  
2023-09-01 21:09:11.152: Find a better model.
2023-09-01 21:09:33.747: [iter 185 : loss : 0.7962 = 0.0493 + 0.3698 + 0.0075 + 0.3696, time: 22.571843]
2023-09-01 21:09:34.402: epoch 185:	0.04289013  	0.09445057  	0.07794028  
2023-09-01 21:09:34.402: Find a better model.
2023-09-01 21:09:56.980: [iter 186 : loss : 0.7960 = 0.0491 + 0.3698 + 0.0075 + 0.3696, time: 22.548104]
2023-09-01 21:09:57.650: epoch 186:	0.04272885  	0.09378329  	0.07765981  
2023-09-01 21:10:20.280: [iter 187 : loss : 0.7955 = 0.0487 + 0.3698 + 0.0075 + 0.3695, time: 22.596646]
2023-09-01 21:10:20.923: epoch 187:	0.04286435  	0.09405425  	0.07793117  
2023-09-01 21:10:43.417: [iter 188 : loss : 0.7962 = 0.0494 + 0.3697 + 0.0076 + 0.3695, time: 22.472869]
2023-09-01 21:10:44.097: epoch 188:	0.04267082  	0.09362581  	0.07777277  
2023-09-01 21:11:06.713: [iter 189 : loss : 0.7957 = 0.0489 + 0.3697 + 0.0076 + 0.3695, time: 22.584047]
2023-09-01 21:11:07.354: epoch 189:	0.04290307  	0.09410521  	0.07793082  
2023-09-01 21:11:29.998: [iter 190 : loss : 0.7951 = 0.0484 + 0.3697 + 0.0076 + 0.3695, time: 22.623258]
2023-09-01 21:11:30.620: epoch 190:	0.04301272  	0.09433705  	0.07809442  
2023-09-01 21:11:53.180: [iter 191 : loss : 0.7951 = 0.0483 + 0.3697 + 0.0076 + 0.3695, time: 22.530116]
2023-09-01 21:11:53.807: epoch 191:	0.04320626  	0.09472700  	0.07834310  
2023-09-01 21:11:53.807: Find a better model.
2023-09-01 21:12:16.512: [iter 192 : loss : 0.7953 = 0.0485 + 0.3697 + 0.0077 + 0.3694, time: 22.682613]
2023-09-01 21:12:17.182: epoch 192:	0.04314819  	0.09452950  	0.07839252  
2023-09-01 21:12:39.955: [iter 193 : loss : 0.7946 = 0.0478 + 0.3696 + 0.0077 + 0.3694, time: 22.745781]
2023-09-01 21:12:40.595: epoch 193:	0.04287082  	0.09404513  	0.07795813  
2023-09-01 21:13:03.188: [iter 194 : loss : 0.7952 = 0.0485 + 0.3696 + 0.0077 + 0.3694, time: 22.571597]
2023-09-01 21:13:03.843: epoch 194:	0.04307724  	0.09458649  	0.07847656  
2023-09-01 21:13:26.499: [iter 195 : loss : 0.7941 = 0.0474 + 0.3696 + 0.0077 + 0.3694, time: 22.633031]
2023-09-01 21:13:27.157: epoch 195:	0.04300631  	0.09416921  	0.07832498  
2023-09-01 21:13:49.682: [iter 196 : loss : 0.7945 = 0.0479 + 0.3696 + 0.0078 + 0.3694, time: 22.498934]
2023-09-01 21:13:50.346: epoch 196:	0.04321920  	0.09473779  	0.07862227  
2023-09-01 21:13:50.346: Find a better model.
2023-09-01 21:14:13.097: [iter 197 : loss : 0.7933 = 0.0466 + 0.3696 + 0.0078 + 0.3693, time: 22.724129]
2023-09-01 21:14:13.765: epoch 197:	0.04335468  	0.09502853  	0.07873534  
2023-09-01 21:14:13.765: Find a better model.
2023-09-01 21:14:36.040: [iter 198 : loss : 0.7942 = 0.0476 + 0.3695 + 0.0078 + 0.3693, time: 22.250477]
2023-09-01 21:14:36.645: epoch 198:	0.04353530  	0.09563721  	0.07880885  
2023-09-01 21:14:36.645: Find a better model.
2023-09-01 21:14:59.145: [iter 199 : loss : 0.7941 = 0.0474 + 0.3695 + 0.0079 + 0.3693, time: 22.476321]
2023-09-01 21:14:59.796: epoch 199:	0.04312884  	0.09469108  	0.07868424  
2023-09-01 21:15:22.071: [iter 200 : loss : 0.7940 = 0.0474 + 0.3695 + 0.0079 + 0.3693, time: 22.249411]
2023-09-01 21:15:22.685: epoch 200:	0.04331592  	0.09499951  	0.07881250  
2023-09-01 21:15:22.685: best_result@epoch 198:

2023-09-01 21:15:22.685: 		0.0435      	0.0956      	0.0788      

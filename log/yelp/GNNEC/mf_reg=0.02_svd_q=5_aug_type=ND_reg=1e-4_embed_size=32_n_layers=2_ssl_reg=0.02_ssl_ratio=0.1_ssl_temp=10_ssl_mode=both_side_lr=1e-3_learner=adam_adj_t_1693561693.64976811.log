2023-09-01 17:48:13.650: my pid: 29373
2023-09-01 17:48:13.650: model: model.general_recommender.GNNEC
2023-09-01 17:48:13.650: Dataset statistics:
Name: yelp
The number of users: 7750
The number of items: 28918
The number of ratings: 750318
Average actions of users: 96.82
Average actions of items: 25.95
The sparsity of the dataset: 99.665208%

The number of training: 678579
The number of validation: 0
The number of testing: 71739
2023-09-01 17:48:13.650: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=yelp
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=10
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=yelp
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=10
mf_reg=0.02
svd_q=5
2023-09-01 17:48:33.966: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 17:48:56.696: [iter 1 : loss : 1.2702 = 0.5115 + 0.3793 + 0.0001 + 0.3793, time: 22.729819]
2023-09-01 17:48:57.362: epoch 1:	0.02523922  	0.05447098  	0.04658828  
2023-09-01 17:48:57.363: Find a better model.
2023-09-01 17:49:19.571: [iter 2 : loss : 1.0223 = 0.2757 + 0.3731 + 0.0003 + 0.3731, time: 22.182160]
2023-09-01 17:49:20.234: epoch 2:	0.02518116  	0.05425369  	0.04640986  
2023-09-01 17:49:42.679: [iter 3 : loss : 0.9822 = 0.2395 + 0.3711 + 0.0004 + 0.3711, time: 22.418083]
2023-09-01 17:49:43.349: epoch 3:	0.02514245  	0.05433425  	0.04630747  
2023-09-01 17:50:05.625: [iter 4 : loss : 0.9666 = 0.2258 + 0.3702 + 0.0005 + 0.3702, time: 22.244352]
2023-09-01 17:50:06.264: epoch 4:	0.02533600  	0.05457268  	0.04636687  
2023-09-01 17:50:06.264: Find a better model.
2023-09-01 17:50:28.661: [iter 5 : loss : 0.9574 = 0.2176 + 0.3696 + 0.0006 + 0.3696, time: 22.376049]
2023-09-01 17:50:29.330: epoch 5:	0.02549084  	0.05496236  	0.04669001  
2023-09-01 17:50:29.330: Find a better model.
2023-09-01 17:50:51.578: [iter 6 : loss : 0.9503 = 0.2113 + 0.3692 + 0.0006 + 0.3692, time: 22.217358]
2023-09-01 17:50:52.189: epoch 6:	0.02550374  	0.05500096  	0.04642772  
2023-09-01 17:50:52.189: Find a better model.
2023-09-01 17:51:14.369: [iter 7 : loss : 0.9404 = 0.2020 + 0.3689 + 0.0007 + 0.3689, time: 22.158689]
2023-09-01 17:51:15.055: epoch 7:	0.02566504  	0.05531144  	0.04698624  
2023-09-01 17:51:15.056: Find a better model.
2023-09-01 17:51:37.573: [iter 8 : loss : 0.9340 = 0.1961 + 0.3686 + 0.0007 + 0.3686, time: 22.483062]
2023-09-01 17:51:38.223: epoch 8:	0.02568439  	0.05547814  	0.04688017  
2023-09-01 17:51:38.223: Find a better model.
2023-09-01 17:52:00.726: [iter 9 : loss : 0.9278 = 0.1904 + 0.3683 + 0.0008 + 0.3683, time: 22.479222]
2023-09-01 17:52:01.390: epoch 9:	0.02587149  	0.05602909  	0.04730167  
2023-09-01 17:52:01.390: Find a better model.
2023-09-01 17:52:23.887: [iter 10 : loss : 0.9214 = 0.1845 + 0.3681 + 0.0008 + 0.3681, time: 22.475067]
2023-09-01 17:52:24.579: epoch 10:	0.02583924  	0.05590199  	0.04728841  
2023-09-01 17:52:46.911: [iter 11 : loss : 0.9163 = 0.1797 + 0.3678 + 0.0009 + 0.3678, time: 22.305767]
2023-09-01 17:52:47.573: epoch 11:	0.02594892  	0.05632721  	0.04771711  
2023-09-01 17:52:47.573: Find a better model.
2023-09-01 17:53:09.914: [iter 12 : loss : 0.9105 = 0.1743 + 0.3676 + 0.0009 + 0.3676, time: 22.318787]
2023-09-01 17:53:10.633: epoch 12:	0.02634246  	0.05695801  	0.04824420  
2023-09-01 17:53:10.633: Find a better model.
2023-09-01 17:53:33.033: [iter 13 : loss : 0.9066 = 0.1708 + 0.3674 + 0.0010 + 0.3674, time: 22.372204]
2023-09-01 17:53:33.698: epoch 13:	0.02646506  	0.05745358  	0.04860547  
2023-09-01 17:53:33.698: Find a better model.
2023-09-01 17:53:55.844: [iter 14 : loss : 0.9005 = 0.1651 + 0.3672 + 0.0010 + 0.3672, time: 22.120020]
2023-09-01 17:53:56.493: epoch 14:	0.02677476  	0.05803131  	0.04892589  
2023-09-01 17:53:56.493: Find a better model.
2023-09-01 17:54:18.872: [iter 15 : loss : 0.8976 = 0.1626 + 0.3670 + 0.0011 + 0.3670, time: 22.353501]
2023-09-01 17:54:19.515: epoch 15:	0.02686510  	0.05834121  	0.04904731  
2023-09-01 17:54:19.515: Find a better model.
2023-09-01 17:54:41.764: [iter 16 : loss : 0.8939 = 0.1591 + 0.3669 + 0.0011 + 0.3668, time: 22.225958]
2023-09-01 17:54:42.437: epoch 16:	0.02691026  	0.05832584  	0.04907857  
2023-09-01 17:55:04.779: [iter 17 : loss : 0.8889 = 0.1544 + 0.3667 + 0.0012 + 0.3666, time: 22.315256]
2023-09-01 17:55:05.446: epoch 17:	0.02705866  	0.05862380  	0.04913644  
2023-09-01 17:55:05.446: Find a better model.
2023-09-01 17:55:28.020: [iter 18 : loss : 0.8867 = 0.1526 + 0.3665 + 0.0012 + 0.3664, time: 22.547181]
2023-09-01 17:55:28.684: epoch 18:	0.02720060  	0.05886888  	0.04915594  
2023-09-01 17:55:28.684: Find a better model.
2023-09-01 17:55:51.247: [iter 19 : loss : 0.8824 = 0.1485 + 0.3663 + 0.0013 + 0.3662, time: 22.533308]
2023-09-01 17:55:51.934: epoch 19:	0.02732963  	0.05912710  	0.04935354  
2023-09-01 17:55:51.934: Find a better model.
2023-09-01 17:56:14.303: [iter 20 : loss : 0.8790 = 0.1454 + 0.3662 + 0.0013 + 0.3660, time: 22.337050]
2023-09-01 17:56:14.967: epoch 20:	0.02751673  	0.05958730  	0.04970842  
2023-09-01 17:56:14.967: Find a better model.
2023-09-01 17:56:37.485: [iter 21 : loss : 0.8751 = 0.1419 + 0.3660 + 0.0014 + 0.3659, time: 22.486886]
2023-09-01 17:56:38.141: epoch 21:	0.02776836  	0.06017157  	0.05034494  
2023-09-01 17:56:38.141: Find a better model.
2023-09-01 17:57:00.782: [iter 22 : loss : 0.8725 = 0.1395 + 0.3658 + 0.0015 + 0.3657, time: 22.612353]
2023-09-01 17:57:01.476: epoch 22:	0.02778126  	0.06008364  	0.05035099  
2023-09-01 17:57:24.165: [iter 23 : loss : 0.8696 = 0.1369 + 0.3657 + 0.0015 + 0.3655, time: 22.666176]
2023-09-01 17:57:24.814: epoch 23:	0.02792965  	0.06029748  	0.05050821  
2023-09-01 17:57:24.814: Find a better model.
2023-09-01 17:57:47.342: [iter 24 : loss : 0.8685 = 0.1360 + 0.3655 + 0.0016 + 0.3653, time: 22.496909]
2023-09-01 17:57:47.992: epoch 24:	0.02785869  	0.06033449  	0.05053646  
2023-09-01 17:57:47.992: Find a better model.
2023-09-01 17:58:10.638: [iter 25 : loss : 0.8654 = 0.1332 + 0.3654 + 0.0016 + 0.3652, time: 22.615781]
2023-09-01 17:58:11.320: epoch 25:	0.02791030  	0.06036466  	0.05065407  
2023-09-01 17:58:11.320: Find a better model.
2023-09-01 17:58:33.670: [iter 26 : loss : 0.8634 = 0.1314 + 0.3652 + 0.0017 + 0.3650, time: 22.317648]
2023-09-01 17:58:34.327: epoch 26:	0.02818128  	0.06098779  	0.05101764  
2023-09-01 17:58:34.327: Find a better model.
2023-09-01 17:58:56.970: [iter 27 : loss : 0.8603 = 0.1286 + 0.3651 + 0.0017 + 0.3649, time: 22.615543]
2023-09-01 17:58:57.654: epoch 27:	0.02817482  	0.06083697  	0.05096365  
2023-09-01 17:59:20.116: [iter 28 : loss : 0.8587 = 0.1273 + 0.3650 + 0.0018 + 0.3647, time: 22.428524]
2023-09-01 17:59:20.803: epoch 28:	0.02829741  	0.06109049  	0.05115156  
2023-09-01 17:59:20.804: Find a better model.
2023-09-01 17:59:43.370: [iter 29 : loss : 0.8575 = 0.1263 + 0.3648 + 0.0018 + 0.3646, time: 22.528310]
2023-09-01 17:59:44.078: epoch 29:	0.02864579  	0.06193130  	0.05164871  
2023-09-01 17:59:44.079: Find a better model.
2023-09-01 18:00:06.477: [iter 30 : loss : 0.8555 = 0.1244 + 0.3647 + 0.0019 + 0.3645, time: 22.374383]
2023-09-01 18:00:07.172: epoch 30:	0.02872967  	0.06218320  	0.05190260  
2023-09-01 18:00:07.172: Find a better model.
2023-09-01 18:00:29.674: [iter 31 : loss : 0.8533 = 0.1224 + 0.3646 + 0.0019 + 0.3643, time: 22.474709]
2023-09-01 18:00:30.343: epoch 31:	0.02903290  	0.06287145  	0.05220172  
2023-09-01 18:00:30.343: Find a better model.
2023-09-01 18:00:53.127: [iter 32 : loss : 0.8510 = 0.1204 + 0.3644 + 0.0020 + 0.3642, time: 22.755035]
2023-09-01 18:00:53.819: epoch 32:	0.02923938  	0.06336494  	0.05253117  
2023-09-01 18:00:53.820: Find a better model.
2023-09-01 18:01:16.649: [iter 33 : loss : 0.8495 = 0.1190 + 0.3643 + 0.0020 + 0.3641, time: 22.792281]
2023-09-01 18:01:17.370: epoch 33:	0.02937487  	0.06355210  	0.05258464  
2023-09-01 18:01:17.370: Find a better model.
2023-09-01 18:01:39.976: [iter 34 : loss : 0.8481 = 0.1179 + 0.3642 + 0.0021 + 0.3639, time: 22.573269]
2023-09-01 18:01:40.623: epoch 34:	0.02958133  	0.06393214  	0.05282756  
2023-09-01 18:01:40.623: Find a better model.
2023-09-01 18:02:03.331: [iter 35 : loss : 0.8465 = 0.1165 + 0.3641 + 0.0021 + 0.3638, time: 22.681721]
2023-09-01 18:02:04.016: epoch 35:	0.02971681  	0.06438040  	0.05303527  
2023-09-01 18:02:04.016: Find a better model.
2023-09-01 18:02:26.676: [iter 36 : loss : 0.8452 = 0.1154 + 0.3639 + 0.0022 + 0.3637, time: 22.632447]
2023-09-01 18:02:27.336: epoch 36:	0.02979425  	0.06462615  	0.05321686  
2023-09-01 18:02:27.336: Find a better model.
2023-09-01 18:02:50.351: [iter 37 : loss : 0.8432 = 0.1135 + 0.3639 + 0.0022 + 0.3636, time: 22.986243]
2023-09-01 18:02:51.049: epoch 37:	0.02999426  	0.06500622  	0.05349490  
2023-09-01 18:02:51.049: Find a better model.
2023-09-01 18:03:13.716: [iter 38 : loss : 0.8412 = 0.1116 + 0.3638 + 0.0023 + 0.3634, time: 22.640615]
2023-09-01 18:03:14.407: epoch 38:	0.03002006  	0.06488792  	0.05348755  
2023-09-01 18:03:36.997: [iter 39 : loss : 0.8400 = 0.1107 + 0.3636 + 0.0024 + 0.3633, time: 22.560553]
2023-09-01 18:03:37.661: epoch 39:	0.03023296  	0.06550770  	0.05372363  
2023-09-01 18:03:37.661: Find a better model.
2023-09-01 18:04:00.188: [iter 40 : loss : 0.8387 = 0.1097 + 0.3635 + 0.0024 + 0.3632, time: 22.497487]
2023-09-01 18:04:00.847: epoch 40:	0.03025876  	0.06565445  	0.05387419  
2023-09-01 18:04:00.847: Find a better model.
2023-09-01 18:04:23.582: [iter 41 : loss : 0.8364 = 0.1076 + 0.3634 + 0.0025 + 0.3630, time: 22.709556]
2023-09-01 18:04:24.227: epoch 41:	0.03056200  	0.06643464  	0.05423719  
2023-09-01 18:04:24.227: Find a better model.
2023-09-01 18:04:46.744: [iter 42 : loss : 0.8357 = 0.1070 + 0.3633 + 0.0025 + 0.3629, time: 22.490341]
2023-09-01 18:04:47.394: epoch 42:	0.03074910  	0.06695706  	0.05450785  
2023-09-01 18:04:47.395: Find a better model.
2023-09-01 18:05:09.717: [iter 43 : loss : 0.8345 = 0.1060 + 0.3632 + 0.0026 + 0.3628, time: 22.285139]
2023-09-01 18:05:10.368: epoch 43:	0.03077491  	0.06694975  	0.05470636  
2023-09-01 18:05:33.014: [iter 44 : loss : 0.8334 = 0.1051 + 0.3630 + 0.0026 + 0.3627, time: 22.616572]
2023-09-01 18:05:33.727: epoch 44:	0.03098138  	0.06734124  	0.05484287  
2023-09-01 18:05:33.727: Find a better model.
2023-09-01 18:05:56.526: [iter 45 : loss : 0.8320 = 0.1039 + 0.3629 + 0.0027 + 0.3626, time: 22.764379]
2023-09-01 18:05:57.206: epoch 45:	0.03123299  	0.06799719  	0.05525464  
2023-09-01 18:05:57.206: Find a better model.
2023-09-01 18:06:19.590: [iter 46 : loss : 0.8313 = 0.1032 + 0.3628 + 0.0027 + 0.3625, time: 22.350467]
2023-09-01 18:06:20.216: epoch 46:	0.03123299  	0.06808244  	0.05538532  
2023-09-01 18:06:20.216: Find a better model.
2023-09-01 18:06:42.738: [iter 47 : loss : 0.8291 = 0.1013 + 0.3627 + 0.0028 + 0.3624, time: 22.496789]
2023-09-01 18:06:43.401: epoch 47:	0.03132977  	0.06825785  	0.05542855  
2023-09-01 18:06:43.401: Find a better model.
2023-09-01 18:07:05.807: [iter 48 : loss : 0.8284 = 0.1007 + 0.3626 + 0.0028 + 0.3622, time: 22.374551]
2023-09-01 18:07:06.464: epoch 48:	0.03163946  	0.06896064  	0.05587748  
2023-09-01 18:07:06.464: Find a better model.
2023-09-01 18:07:28.809: [iter 49 : loss : 0.8272 = 0.0997 + 0.3625 + 0.0029 + 0.3621, time: 22.310948]
2023-09-01 18:07:29.456: epoch 49:	0.03169752  	0.06913960  	0.05612412  
2023-09-01 18:07:29.456: Find a better model.
2023-09-01 18:07:51.939: [iter 50 : loss : 0.8267 = 0.0994 + 0.3624 + 0.0029 + 0.3620, time: 22.451400]
2023-09-01 18:07:52.577: epoch 50:	0.03171689  	0.06904624  	0.05626656  
2023-09-01 18:08:15.114: [iter 51 : loss : 0.8253 = 0.0981 + 0.3623 + 0.0030 + 0.3619, time: 22.512509]
2023-09-01 18:08:15.762: epoch 51:	0.03191045  	0.06950926  	0.05658410  
2023-09-01 18:08:15.762: Find a better model.
2023-09-01 18:08:38.366: [iter 52 : loss : 0.8239 = 0.0969 + 0.3622 + 0.0030 + 0.3618, time: 22.572986]
2023-09-01 18:08:39.033: epoch 52:	0.03205239  	0.06994358  	0.05685390  
2023-09-01 18:08:39.034: Find a better model.
2023-09-01 18:09:01.427: [iter 53 : loss : 0.8230 = 0.0962 + 0.3621 + 0.0031 + 0.3617, time: 22.360277]
2023-09-01 18:09:02.033: epoch 53:	0.03220721  	0.07033453  	0.05697921  
2023-09-01 18:09:02.033: Find a better model.
2023-09-01 18:09:24.284: [iter 54 : loss : 0.8218 = 0.0951 + 0.3620 + 0.0031 + 0.3616, time: 22.227129]
2023-09-01 18:09:24.941: epoch 54:	0.03243950  	0.07059377  	0.05735819  
2023-09-01 18:09:24.941: Find a better model.
2023-09-01 18:09:47.413: [iter 55 : loss : 0.8216 = 0.0951 + 0.3619 + 0.0032 + 0.3615, time: 22.446053]
2023-09-01 18:09:48.057: epoch 55:	0.03247174  	0.07058317  	0.05735308  
2023-09-01 18:10:10.570: [iter 56 : loss : 0.8201 = 0.0936 + 0.3618 + 0.0032 + 0.3614, time: 22.485758]
2023-09-01 18:10:11.266: epoch 56:	0.03251692  	0.07068267  	0.05753432  
2023-09-01 18:10:11.267: Find a better model.
2023-09-01 18:10:33.979: [iter 57 : loss : 0.8192 = 0.0930 + 0.3617 + 0.0033 + 0.3613, time: 22.678258]
2023-09-01 18:10:34.679: epoch 57:	0.03266531  	0.07126439  	0.05778459  
2023-09-01 18:10:34.679: Find a better model.
2023-09-01 18:10:57.584: [iter 58 : loss : 0.8191 = 0.0930 + 0.3616 + 0.0033 + 0.3612, time: 22.873623]
2023-09-01 18:10:58.264: epoch 58:	0.03290401  	0.07175409  	0.05815000  
2023-09-01 18:10:58.264: Find a better model.
2023-09-01 18:11:21.120: [iter 59 : loss : 0.8178 = 0.0919 + 0.3615 + 0.0034 + 0.3611, time: 22.818331]
2023-09-01 18:11:21.808: epoch 59:	0.03300724  	0.07218138  	0.05843674  
2023-09-01 18:11:21.808: Find a better model.
2023-09-01 18:11:44.565: [iter 60 : loss : 0.8169 = 0.0911 + 0.3614 + 0.0034 + 0.3610, time: 22.722762]
2023-09-01 18:11:45.247: epoch 60:	0.03318140  	0.07260315  	0.05878100  
2023-09-01 18:11:45.247: Find a better model.
2023-09-01 18:12:07.951: [iter 61 : loss : 0.8154 = 0.0897 + 0.3613 + 0.0035 + 0.3609, time: 22.656837]
2023-09-01 18:12:08.600: epoch 61:	0.03337492  	0.07288307  	0.05905936  
2023-09-01 18:12:08.600: Find a better model.
2023-09-01 18:12:31.260: [iter 62 : loss : 0.8150 = 0.0895 + 0.3612 + 0.0035 + 0.3608, time: 22.626488]
2023-09-01 18:12:31.901: epoch 62:	0.03349750  	0.07302723  	0.05916194  
2023-09-01 18:12:31.902: Find a better model.
2023-09-01 18:12:54.704: [iter 63 : loss : 0.8134 = 0.0880 + 0.3611 + 0.0036 + 0.3607, time: 22.780802]
2023-09-01 18:12:55.362: epoch 63:	0.03355557  	0.07334752  	0.05945342  
2023-09-01 18:12:55.362: Find a better model.
2023-09-01 18:13:18.017: [iter 64 : loss : 0.8130 = 0.0877 + 0.3611 + 0.0036 + 0.3606, time: 22.628762]
2023-09-01 18:13:18.652: epoch 64:	0.03357493  	0.07327165  	0.05950306  
2023-09-01 18:13:41.386: [iter 65 : loss : 0.8125 = 0.0874 + 0.3610 + 0.0037 + 0.3605, time: 22.703097]
2023-09-01 18:13:42.063: epoch 65:	0.03382006  	0.07383717  	0.05983432  
2023-09-01 18:13:42.063: Find a better model.
2023-09-01 18:14:04.913: [iter 66 : loss : 0.8109 = 0.0859 + 0.3608 + 0.0037 + 0.3604, time: 22.817598]
2023-09-01 18:14:05.566: epoch 66:	0.03382006  	0.07373033  	0.05996075  
2023-09-01 18:14:28.177: [iter 67 : loss : 0.8107 = 0.0859 + 0.3608 + 0.0038 + 0.3603, time: 22.578201]
2023-09-01 18:14:28.842: epoch 67:	0.03411684  	0.07433649  	0.06031281  
2023-09-01 18:14:28.842: Find a better model.
2023-09-01 18:14:51.355: [iter 68 : loss : 0.8103 = 0.0856 + 0.3607 + 0.0038 + 0.3602, time: 22.482375]
2023-09-01 18:14:52.024: epoch 68:	0.03417487  	0.07446817  	0.06037239  
2023-09-01 18:14:52.024: Find a better model.
2023-09-01 18:15:14.655: [iter 69 : loss : 0.8091 = 0.0845 + 0.3606 + 0.0038 + 0.3601, time: 22.604010]
2023-09-01 18:15:15.319: epoch 69:	0.03425230  	0.07450563  	0.06037586  
2023-09-01 18:15:15.319: Find a better model.
2023-09-01 18:15:37.848: [iter 70 : loss : 0.8090 = 0.0845 + 0.3605 + 0.0039 + 0.3601, time: 22.502959]
2023-09-01 18:15:38.510: epoch 70:	0.03434907  	0.07474347  	0.06080188  
2023-09-01 18:15:38.510: Find a better model.
2023-09-01 18:16:01.337: [iter 71 : loss : 0.8071 = 0.0828 + 0.3604 + 0.0039 + 0.3600, time: 22.792826]
2023-09-01 18:16:02.029: epoch 71:	0.03456841  	0.07519841  	0.06107095  
2023-09-01 18:16:02.029: Find a better model.
2023-09-01 18:16:24.466: [iter 72 : loss : 0.8073 = 0.0831 + 0.3603 + 0.0040 + 0.3599, time: 22.410863]
2023-09-01 18:16:25.079: epoch 72:	0.03460068  	0.07522468  	0.06110785  
2023-09-01 18:16:25.079: Find a better model.
2023-09-01 18:16:47.691: [iter 73 : loss : 0.8062 = 0.0821 + 0.3602 + 0.0040 + 0.3598, time: 22.584195]
2023-09-01 18:16:48.382: epoch 73:	0.03478127  	0.07560864  	0.06134352  
2023-09-01 18:16:48.382: Find a better model.
2023-09-01 18:17:10.900: [iter 74 : loss : 0.8053 = 0.0814 + 0.3601 + 0.0041 + 0.3597, time: 22.493021]
2023-09-01 18:17:11.610: epoch 74:	0.03482644  	0.07584838  	0.06144929  
2023-09-01 18:17:11.611: Find a better model.
2023-09-01 18:17:34.219: [iter 75 : loss : 0.8043 = 0.0806 + 0.3600 + 0.0041 + 0.3596, time: 22.566155]
2023-09-01 18:17:34.865: epoch 75:	0.03510382  	0.07641134  	0.06173900  
2023-09-01 18:17:34.866: Find a better model.
2023-09-01 18:17:57.823: [iter 76 : loss : 0.8044 = 0.0808 + 0.3600 + 0.0042 + 0.3595, time: 22.928083]
2023-09-01 18:17:58.464: epoch 76:	0.03520059  	0.07652821  	0.06204077  
2023-09-01 18:17:58.465: Find a better model.
2023-09-01 18:18:21.022: [iter 77 : loss : 0.8032 = 0.0797 + 0.3599 + 0.0042 + 0.3594, time: 22.525569]
2023-09-01 18:18:21.733: epoch 77:	0.03547153  	0.07722989  	0.06243455  
2023-09-01 18:18:21.733: Find a better model.
2023-09-01 18:18:44.247: [iter 78 : loss : 0.8027 = 0.0793 + 0.3598 + 0.0043 + 0.3593, time: 22.482750]
2023-09-01 18:18:44.956: epoch 78:	0.03548446  	0.07706928  	0.06247950  
2023-09-01 18:19:07.645: [iter 79 : loss : 0.8017 = 0.0785 + 0.3597 + 0.0043 + 0.3592, time: 22.654258]
2023-09-01 18:19:08.265: epoch 79:	0.03542637  	0.07697289  	0.06258383  
2023-09-01 18:19:30.928: [iter 80 : loss : 0.8016 = 0.0785 + 0.3596 + 0.0044 + 0.3592, time: 22.629698]
2023-09-01 18:19:31.551: epoch 80:	0.03554248  	0.07734008  	0.06281381  
2023-09-01 18:19:31.552: Find a better model.
2023-09-01 18:19:54.033: [iter 81 : loss : 0.8007 = 0.0777 + 0.3595 + 0.0044 + 0.3591, time: 22.459597]
2023-09-01 18:19:54.664: epoch 81:	0.03563926  	0.07760368  	0.06299853  
2023-09-01 18:19:54.664: Find a better model.
2023-09-01 18:20:17.236: [iter 82 : loss : 0.8001 = 0.0772 + 0.3594 + 0.0045 + 0.3590, time: 22.546528]
2023-09-01 18:20:17.909: epoch 82:	0.03583925  	0.07792117  	0.06313693  
2023-09-01 18:20:17.909: Find a better model.
2023-09-01 18:20:40.595: [iter 83 : loss : 0.7999 = 0.0771 + 0.3594 + 0.0045 + 0.3589, time: 22.655066]
2023-09-01 18:20:41.263: epoch 83:	0.03580055  	0.07784963  	0.06309597  
2023-09-01 18:21:03.825: [iter 84 : loss : 0.7975 = 0.0748 + 0.3593 + 0.0046 + 0.3588, time: 22.526608]
2023-09-01 18:21:04.459: epoch 84:	0.03596184  	0.07850904  	0.06345885  
2023-09-01 18:21:04.459: Find a better model.
2023-09-01 18:21:27.195: [iter 85 : loss : 0.7984 = 0.0759 + 0.3592 + 0.0046 + 0.3587, time: 22.708943]
2023-09-01 18:21:27.855: epoch 85:	0.03629084  	0.07930495  	0.06410417  
2023-09-01 18:21:27.855: Find a better model.
2023-09-01 18:21:50.624: [iter 86 : loss : 0.7972 = 0.0747 + 0.3591 + 0.0047 + 0.3586, time: 22.733919]
2023-09-01 18:21:51.394: epoch 86:	0.03631017  	0.07952373  	0.06421760  
2023-09-01 18:21:51.394: Find a better model.
2023-09-01 18:22:13.987: [iter 87 : loss : 0.7971 = 0.0748 + 0.3590 + 0.0047 + 0.3586, time: 22.562944]
2023-09-01 18:22:14.615: epoch 87:	0.03634245  	0.07947249  	0.06428550  
2023-09-01 18:22:37.092: [iter 88 : loss : 0.7968 = 0.0746 + 0.3589 + 0.0048 + 0.3585, time: 22.451892]
2023-09-01 18:22:37.738: epoch 88:	0.03654243  	0.08014084  	0.06466208  
2023-09-01 18:22:37.739: Find a better model.
2023-09-01 18:23:00.324: [iter 89 : loss : 0.7960 = 0.0739 + 0.3589 + 0.0048 + 0.3584, time: 22.556379]
2023-09-01 18:23:00.968: epoch 89:	0.03650372  	0.07976975  	0.06467273  
2023-09-01 18:23:23.593: [iter 90 : loss : 0.7954 = 0.0734 + 0.3588 + 0.0048 + 0.3583, time: 22.600450]
2023-09-01 18:23:24.303: epoch 90:	0.03655532  	0.07954482  	0.06496038  
2023-09-01 18:23:47.023: [iter 91 : loss : 0.7949 = 0.0730 + 0.3587 + 0.0049 + 0.3583, time: 22.693675]
2023-09-01 18:23:47.674: epoch 91:	0.03674884  	0.08023255  	0.06535737  
2023-09-01 18:23:47.675: Find a better model.
2023-09-01 18:24:10.458: [iter 92 : loss : 0.7944 = 0.0726 + 0.3587 + 0.0049 + 0.3582, time: 22.759362]
2023-09-01 18:24:11.137: epoch 92:	0.03681979  	0.08048079  	0.06553983  
2023-09-01 18:24:11.137: Find a better model.
2023-09-01 18:24:34.009: [iter 93 : loss : 0.7933 = 0.0717 + 0.3586 + 0.0050 + 0.3581, time: 22.840936]
2023-09-01 18:24:34.721: epoch 93:	0.03711008  	0.08097504  	0.06586222  
2023-09-01 18:24:34.722: Find a better model.
2023-09-01 18:24:57.503: [iter 94 : loss : 0.7939 = 0.0724 + 0.3585 + 0.0050 + 0.3580, time: 22.756696]
2023-09-01 18:24:58.222: epoch 94:	0.03729716  	0.08138695  	0.06614350  
2023-09-01 18:24:58.222: Find a better model.
2023-09-01 18:25:20.776: [iter 95 : loss : 0.7929 = 0.0716 + 0.3583 + 0.0051 + 0.3579, time: 22.529318]
2023-09-01 18:25:21.430: epoch 95:	0.03737457  	0.08170963  	0.06630051  
2023-09-01 18:25:21.430: Find a better model.
2023-09-01 18:25:43.854: [iter 96 : loss : 0.7929 = 0.0716 + 0.3583 + 0.0051 + 0.3579, time: 22.398659]
2023-09-01 18:25:44.547: epoch 96:	0.03727134  	0.08144664  	0.06638827  
2023-09-01 18:26:07.082: [iter 97 : loss : 0.7925 = 0.0712 + 0.3583 + 0.0052 + 0.3578, time: 22.500908]
2023-09-01 18:26:07.742: epoch 97:	0.03741324  	0.08161868  	0.06643989  
2023-09-01 18:26:30.349: [iter 98 : loss : 0.7915 = 0.0705 + 0.3581 + 0.0052 + 0.3577, time: 22.581906]
2023-09-01 18:26:31.015: epoch 98:	0.03753580  	0.08195068  	0.06673837  
2023-09-01 18:26:31.015: Find a better model.
2023-09-01 18:26:53.676: [iter 99 : loss : 0.7905 = 0.0695 + 0.3581 + 0.0052 + 0.3576, time: 22.635858]
2023-09-01 18:26:54.351: epoch 99:	0.03756163  	0.08196317  	0.06674413  
2023-09-01 18:26:54.352: Find a better model.
2023-09-01 18:27:16.853: [iter 100 : loss : 0.7901 = 0.0692 + 0.3580 + 0.0053 + 0.3576, time: 22.475748]
2023-09-01 18:27:17.512: epoch 100:	0.03770358  	0.08227176  	0.06702832  
2023-09-01 18:27:17.512: Find a better model.
2023-09-01 18:27:40.144: [iter 101 : loss : 0.7892 = 0.0685 + 0.3580 + 0.0053 + 0.3575, time: 22.602994]
2023-09-01 18:27:40.765: epoch 101:	0.03765196  	0.08223538  	0.06689939  
2023-09-01 18:28:03.369: [iter 102 : loss : 0.7903 = 0.0697 + 0.3578 + 0.0054 + 0.3574, time: 22.571273]
2023-09-01 18:28:04.033: epoch 102:	0.03793579  	0.08296430  	0.06732909  
2023-09-01 18:28:04.033: Find a better model.
2023-09-01 18:28:26.801: [iter 103 : loss : 0.7891 = 0.0686 + 0.3577 + 0.0054 + 0.3573, time: 22.739188]
2023-09-01 18:28:27.439: epoch 103:	0.03813574  	0.08332399  	0.06772255  
2023-09-01 18:28:27.439: Find a better model.
2023-09-01 18:28:49.903: [iter 104 : loss : 0.7890 = 0.0685 + 0.3577 + 0.0055 + 0.3573, time: 22.432954]
2023-09-01 18:28:50.637: epoch 104:	0.03813573  	0.08326199  	0.06773496  
2023-09-01 18:29:12.972: [iter 105 : loss : 0.7876 = 0.0672 + 0.3577 + 0.0055 + 0.3572, time: 22.306748]
2023-09-01 18:29:13.679: epoch 105:	0.03817445  	0.08338413  	0.06782178  
2023-09-01 18:29:13.679: Find a better model.
2023-09-01 18:29:36.268: [iter 106 : loss : 0.7865 = 0.0663 + 0.3576 + 0.0056 + 0.3571, time: 22.563708]
2023-09-01 18:29:36.915: epoch 106:	0.03828407  	0.08349731  	0.06796278  
2023-09-01 18:29:36.915: Find a better model.
2023-09-01 18:29:59.641: [iter 107 : loss : 0.7871 = 0.0670 + 0.3575 + 0.0056 + 0.3570, time: 22.705339]
2023-09-01 18:30:00.307: epoch 107:	0.03821960  	0.08351891  	0.06805428  
2023-09-01 18:30:00.307: Find a better model.
2023-09-01 18:30:22.990: [iter 108 : loss : 0.7866 = 0.0666 + 0.3574 + 0.0057 + 0.3570, time: 22.650597]
2023-09-01 18:30:23.644: epoch 108:	0.03820673  	0.08353291  	0.06806397  
2023-09-01 18:30:23.644: Find a better model.
2023-09-01 18:30:45.936: [iter 109 : loss : 0.7859 = 0.0661 + 0.3573 + 0.0057 + 0.3569, time: 22.261651]
2023-09-01 18:30:46.590: epoch 109:	0.03831638  	0.08402208  	0.06845827  
2023-09-01 18:30:46.590: Find a better model.
2023-09-01 18:31:09.018: [iter 110 : loss : 0.7849 = 0.0651 + 0.3573 + 0.0057 + 0.3568, time: 22.397151]
2023-09-01 18:31:09.759: epoch 110:	0.03832284  	0.08393080  	0.06834514  
2023-09-01 18:31:31.933: [iter 111 : loss : 0.7849 = 0.0652 + 0.3572 + 0.0058 + 0.3567, time: 22.150149]
2023-09-01 18:31:32.581: epoch 111:	0.03850987  	0.08428039  	0.06862580  
2023-09-01 18:31:32.581: Find a better model.
2023-09-01 18:31:54.854: [iter 112 : loss : 0.7853 = 0.0656 + 0.3571 + 0.0058 + 0.3567, time: 22.248920]
2023-09-01 18:31:55.507: epoch 112:	0.03876795  	0.08468740  	0.06900914  
2023-09-01 18:31:55.507: Find a better model.
2023-09-01 18:32:17.773: [iter 113 : loss : 0.7854 = 0.0658 + 0.3571 + 0.0059 + 0.3566, time: 22.241519]
2023-09-01 18:32:18.437: epoch 113:	0.03889054  	0.08503131  	0.06928206  
2023-09-01 18:32:18.437: Find a better model.
2023-09-01 18:32:41.122: [iter 114 : loss : 0.7837 = 0.0642 + 0.3570 + 0.0059 + 0.3565, time: 22.657918]
2023-09-01 18:32:41.796: epoch 114:	0.03901954  	0.08524710  	0.06947733  
2023-09-01 18:32:41.796: Find a better model.
2023-09-01 18:33:04.616: [iter 115 : loss : 0.7837 = 0.0644 + 0.3569 + 0.0060 + 0.3565, time: 22.788928]
2023-09-01 18:33:05.329: epoch 115:	0.03903891  	0.08535246  	0.06955127  
2023-09-01 18:33:05.329: Find a better model.
2023-09-01 18:33:27.981: [iter 116 : loss : 0.7824 = 0.0631 + 0.3568 + 0.0060 + 0.3564, time: 22.628186]
2023-09-01 18:33:28.640: epoch 116:	0.03916147  	0.08542505  	0.06971945  
2023-09-01 18:33:28.640: Find a better model.
2023-09-01 18:33:51.348: [iter 117 : loss : 0.7824 = 0.0633 + 0.3567 + 0.0060 + 0.3563, time: 22.684339]
2023-09-01 18:33:51.995: epoch 117:	0.03930340  	0.08574761  	0.06996492  
2023-09-01 18:33:51.995: Find a better model.
2023-09-01 18:34:14.779: [iter 118 : loss : 0.7828 = 0.0638 + 0.3567 + 0.0061 + 0.3563, time: 22.761444]
2023-09-01 18:34:15.475: epoch 118:	0.03916792  	0.08571145  	0.06996078  
2023-09-01 18:34:37.984: [iter 119 : loss : 0.7816 = 0.0626 + 0.3566 + 0.0061 + 0.3562, time: 22.470800]
2023-09-01 18:34:38.641: epoch 119:	0.03943887  	0.08611323  	0.07035922  
2023-09-01 18:34:38.641: Find a better model.
2023-09-01 18:35:01.204: [iter 120 : loss : 0.7811 = 0.0623 + 0.3566 + 0.0062 + 0.3561, time: 22.537122]
2023-09-01 18:35:01.842: epoch 120:	0.03950339  	0.08640173  	0.07035650  
2023-09-01 18:35:01.842: Find a better model.
2023-09-01 18:35:24.587: [iter 121 : loss : 0.7815 = 0.0628 + 0.3565 + 0.0062 + 0.3560, time: 22.716525]
2023-09-01 18:35:25.264: epoch 121:	0.03965821  	0.08674917  	0.07072547  
2023-09-01 18:35:25.264: Find a better model.
2023-09-01 18:35:47.970: [iter 122 : loss : 0.7805 = 0.0619 + 0.3564 + 0.0063 + 0.3560, time: 22.671201]
2023-09-01 18:35:48.653: epoch 122:	0.03960661  	0.08644212  	0.07055312  
2023-09-01 18:36:10.963: [iter 123 : loss : 0.7805 = 0.0619 + 0.3564 + 0.0063 + 0.3559, time: 22.285744]
2023-09-01 18:36:11.601: epoch 123:	0.03971627  	0.08654280  	0.07062367  
2023-09-01 18:36:33.930: [iter 124 : loss : 0.7799 = 0.0614 + 0.3563 + 0.0063 + 0.3558, time: 22.303070]
2023-09-01 18:36:34.620: epoch 124:	0.03971628  	0.08646949  	0.07072896  
2023-09-01 18:36:56.785: [iter 125 : loss : 0.7796 = 0.0613 + 0.3562 + 0.0064 + 0.3558, time: 22.143438]
2023-09-01 18:36:57.432: epoch 125:	0.03974209  	0.08642936  	0.07076601  
2023-09-01 18:37:19.762: [iter 126 : loss : 0.7796 = 0.0613 + 0.3562 + 0.0064 + 0.3557, time: 22.304377]
2023-09-01 18:37:20.387: epoch 126:	0.03980014  	0.08672339  	0.07104255  
2023-09-01 18:37:42.755: [iter 127 : loss : 0.7795 = 0.0614 + 0.3561 + 0.0065 + 0.3556, time: 22.331457]
2023-09-01 18:37:43.452: epoch 127:	0.03989043  	0.08694084  	0.07107263  
2023-09-01 18:37:43.452: Find a better model.
2023-09-01 18:38:05.803: [iter 128 : loss : 0.7788 = 0.0607 + 0.3560 + 0.0065 + 0.3556, time: 22.321424]
2023-09-01 18:38:06.542: epoch 128:	0.03989044  	0.08687399  	0.07112940  
2023-09-01 18:38:28.798: [iter 129 : loss : 0.7786 = 0.0606 + 0.3560 + 0.0066 + 0.3555, time: 22.226847]
2023-09-01 18:38:29.415: epoch 129:	0.03992266  	0.08640140  	0.07122533  
2023-09-01 18:38:51.733: [iter 130 : loss : 0.7778 = 0.0598 + 0.3559 + 0.0066 + 0.3555, time: 22.294164]
2023-09-01 18:38:52.442: epoch 130:	0.03978072  	0.08639240  	0.07129622  
2023-09-01 18:39:14.670: [iter 131 : loss : 0.7784 = 0.0606 + 0.3558 + 0.0066 + 0.3554, time: 22.198062]
2023-09-01 18:39:15.308: epoch 131:	0.03996781  	0.08692661  	0.07148028  
2023-09-01 18:39:37.575: [iter 132 : loss : 0.7762 = 0.0584 + 0.3558 + 0.0067 + 0.3553, time: 22.246118]
2023-09-01 18:39:38.251: epoch 132:	0.03999361  	0.08700138  	0.07174684  
2023-09-01 18:39:38.251: Find a better model.
2023-09-01 18:40:00.391: [iter 133 : loss : 0.7765 = 0.0589 + 0.3557 + 0.0067 + 0.3552, time: 22.115852]
2023-09-01 18:40:01.085: epoch 133:	0.03990335  	0.08700646  	0.07166049  
2023-09-01 18:40:01.085: Find a better model.
2023-09-01 18:40:23.391: [iter 134 : loss : 0.7771 = 0.0595 + 0.3556 + 0.0068 + 0.3552, time: 22.284604]
2023-09-01 18:40:24.030: epoch 134:	0.03995498  	0.08746768  	0.07187084  
2023-09-01 18:40:24.031: Find a better model.
2023-09-01 18:40:46.390: [iter 135 : loss : 0.7765 = 0.0590 + 0.3556 + 0.0068 + 0.3551, time: 22.331888]
2023-09-01 18:40:47.044: epoch 135:	0.03994850  	0.08741304  	0.07190458  
2023-09-01 18:41:09.744: [iter 136 : loss : 0.7757 = 0.0582 + 0.3555 + 0.0068 + 0.3551, time: 22.674939]
2023-09-01 18:41:10.389: epoch 136:	0.04006464  	0.08782367  	0.07218181  
2023-09-01 18:41:10.389: Find a better model.
2023-09-01 18:41:33.182: [iter 137 : loss : 0.7755 = 0.0581 + 0.3555 + 0.0069 + 0.3550, time: 22.758880]
2023-09-01 18:41:33.845: epoch 137:	0.04021942  	0.08804151  	0.07253334  
2023-09-01 18:41:33.845: Find a better model.
2023-09-01 18:41:56.090: [iter 138 : loss : 0.7757 = 0.0584 + 0.3554 + 0.0069 + 0.3549, time: 22.224457]
2023-09-01 18:41:56.755: epoch 138:	0.04027750  	0.08795848  	0.07232744  
2023-09-01 18:42:19.286: [iter 139 : loss : 0.7747 = 0.0575 + 0.3553 + 0.0070 + 0.3549, time: 22.496194]
2023-09-01 18:42:19.952: epoch 139:	0.04024523  	0.08815005  	0.07245607  
2023-09-01 18:42:19.952: Find a better model.
2023-09-01 18:42:42.317: [iter 140 : loss : 0.7748 = 0.0577 + 0.3553 + 0.0070 + 0.3548, time: 22.344285]
2023-09-01 18:42:42.969: epoch 140:	0.04047101  	0.08866329  	0.07266545  
2023-09-01 18:42:42.969: Find a better model.
2023-09-01 18:43:05.477: [iter 141 : loss : 0.7750 = 0.0580 + 0.3552 + 0.0070 + 0.3548, time: 22.482368]
2023-09-01 18:43:06.123: epoch 141:	0.04061936  	0.08918374  	0.07296020  
2023-09-01 18:43:06.123: Find a better model.
2023-09-01 18:43:28.838: [iter 142 : loss : 0.7737 = 0.0568 + 0.3551 + 0.0071 + 0.3547, time: 22.687870]
2023-09-01 18:43:29.492: epoch 142:	0.04070970  	0.08942591  	0.07305562  
2023-09-01 18:43:29.492: Find a better model.
2023-09-01 18:43:51.899: [iter 143 : loss : 0.7741 = 0.0572 + 0.3551 + 0.0071 + 0.3546, time: 22.383383]
2023-09-01 18:43:52.601: epoch 143:	0.04080001  	0.08958681  	0.07323056  
2023-09-01 18:43:52.601: Find a better model.
2023-09-01 18:44:15.153: [iter 144 : loss : 0.7736 = 0.0568 + 0.3550 + 0.0072 + 0.3546, time: 22.521374]
2023-09-01 18:44:15.810: epoch 144:	0.04105157  	0.09012701  	0.07350294  
2023-09-01 18:44:15.810: Find a better model.
2023-09-01 18:44:38.263: [iter 145 : loss : 0.7736 = 0.0569 + 0.3549 + 0.0072 + 0.3545, time: 22.419091]
2023-09-01 18:44:38.934: epoch 145:	0.04105802  	0.08993116  	0.07349258  
2023-09-01 18:45:01.524: [iter 146 : loss : 0.7733 = 0.0567 + 0.3549 + 0.0072 + 0.3545, time: 22.562236]
2023-09-01 18:45:02.218: epoch 146:	0.04107738  	0.08998143  	0.07366795  
2023-09-01 18:45:24.646: [iter 147 : loss : 0.7732 = 0.0566 + 0.3549 + 0.0073 + 0.3544, time: 22.394212]
2023-09-01 18:45:25.297: epoch 147:	0.04119994  	0.09040238  	0.07390552  
2023-09-01 18:45:25.297: Find a better model.
2023-09-01 18:45:47.812: [iter 148 : loss : 0.7729 = 0.0564 + 0.3548 + 0.0073 + 0.3544, time: 22.491148]
2023-09-01 18:45:48.543: epoch 148:	0.04134834  	0.09086283  	0.07425036  
2023-09-01 18:45:48.543: Find a better model.
2023-09-01 18:46:10.953: [iter 149 : loss : 0.7715 = 0.0551 + 0.3547 + 0.0074 + 0.3543, time: 22.382024]
2023-09-01 18:46:11.643: epoch 149:	0.04145153  	0.09108080  	0.07431769  
2023-09-01 18:46:11.643: Find a better model.
2023-09-01 18:46:34.191: [iter 150 : loss : 0.7723 = 0.0559 + 0.3547 + 0.0074 + 0.3542, time: 22.522664]
2023-09-01 18:46:34.873: epoch 150:	0.04134833  	0.09080546  	0.07422400  
2023-09-01 18:46:57.383: [iter 151 : loss : 0.7720 = 0.0558 + 0.3546 + 0.0075 + 0.3542, time: 22.479714]
2023-09-01 18:46:58.031: epoch 151:	0.04143219  	0.09095030  	0.07427302  
2023-09-01 18:47:20.484: [iter 152 : loss : 0.7721 = 0.0559 + 0.3546 + 0.0075 + 0.3541, time: 22.431502]
2023-09-01 18:47:21.176: epoch 152:	0.04155477  	0.09113046  	0.07438754  
2023-09-01 18:47:21.176: Find a better model.
2023-09-01 18:47:43.619: [iter 153 : loss : 0.7719 = 0.0558 + 0.3545 + 0.0075 + 0.3541, time: 22.411231]
2023-09-01 18:47:44.271: epoch 153:	0.04130315  	0.09071587  	0.07429896  
2023-09-01 18:48:06.884: [iter 154 : loss : 0.7711 = 0.0551 + 0.3544 + 0.0076 + 0.3540, time: 22.584686]
2023-09-01 18:48:07.607: epoch 154:	0.04152255  	0.09119526  	0.07457525  
2023-09-01 18:48:07.607: Find a better model.
2023-09-01 18:48:30.324: [iter 155 : loss : 0.7703 = 0.0543 + 0.3544 + 0.0076 + 0.3539, time: 22.691097]
2023-09-01 18:48:30.974: epoch 155:	0.04154833  	0.09104422  	0.07442408  
2023-09-01 18:48:53.691: [iter 156 : loss : 0.7706 = 0.0547 + 0.3544 + 0.0076 + 0.3539, time: 22.689652]
2023-09-01 18:48:54.337: epoch 156:	0.04137412  	0.09099517  	0.07433631  
2023-09-01 18:49:17.048: [iter 157 : loss : 0.7703 = 0.0545 + 0.3543 + 0.0077 + 0.3538, time: 22.683377]
2023-09-01 18:49:17.742: epoch 157:	0.04162575  	0.09133465  	0.07463354  
2023-09-01 18:49:17.742: Find a better model.
2023-09-01 18:49:40.508: [iter 158 : loss : 0.7703 = 0.0546 + 0.3542 + 0.0077 + 0.3538, time: 22.743173]
2023-09-01 18:49:41.196: epoch 158:	0.04169023  	0.09153853  	0.07487622  
2023-09-01 18:49:41.196: Find a better model.
2023-09-01 18:50:03.793: [iter 159 : loss : 0.7692 = 0.0536 + 0.3541 + 0.0078 + 0.3537, time: 22.561801]
2023-09-01 18:50:04.443: epoch 159:	0.04171607  	0.09162991  	0.07472309  
2023-09-01 18:50:04.443: Find a better model.
2023-09-01 18:50:27.173: [iter 160 : loss : 0.7691 = 0.0535 + 0.3541 + 0.0078 + 0.3537, time: 22.707513]
2023-09-01 18:50:27.852: epoch 160:	0.04174189  	0.09145666  	0.07486945  
2023-09-01 18:50:50.659: [iter 161 : loss : 0.7692 = 0.0536 + 0.3541 + 0.0078 + 0.3536, time: 22.782620]
2023-09-01 18:50:51.324: epoch 161:	0.04159996  	0.09107249  	0.07480092  
2023-09-01 18:51:13.911: [iter 162 : loss : 0.7686 = 0.0531 + 0.3540 + 0.0079 + 0.3536, time: 22.549150]
2023-09-01 18:51:14.562: epoch 162:	0.04190318  	0.09204024  	0.07525042  
2023-09-01 18:51:14.562: Find a better model.
2023-09-01 18:51:37.236: [iter 163 : loss : 0.7683 = 0.0528 + 0.3540 + 0.0079 + 0.3535, time: 22.648130]
2023-09-01 18:51:37.893: epoch 163:	0.04187736  	0.09212539  	0.07527866  
2023-09-01 18:51:37.894: Find a better model.
2023-09-01 18:52:00.654: [iter 164 : loss : 0.7684 = 0.0532 + 0.3538 + 0.0080 + 0.3535, time: 22.736185]
2023-09-01 18:52:01.339: epoch 164:	0.04183222  	0.09194853  	0.07520752  
2023-09-01 18:52:23.949: [iter 165 : loss : 0.7676 = 0.0524 + 0.3538 + 0.0080 + 0.3534, time: 22.584207]
2023-09-01 18:52:24.633: epoch 165:	0.04195477  	0.09224421  	0.07540572  
2023-09-01 18:52:24.633: Find a better model.
2023-09-01 18:52:47.359: [iter 166 : loss : 0.7675 = 0.0523 + 0.3538 + 0.0080 + 0.3533, time: 22.688330]
2023-09-01 18:52:47.990: epoch 166:	0.04216119  	0.09280623  	0.07557827  
2023-09-01 18:52:47.991: Find a better model.
2023-09-01 18:53:10.654: [iter 167 : loss : 0.7683 = 0.0532 + 0.3537 + 0.0081 + 0.3533, time: 22.634269]
2023-09-01 18:53:11.302: epoch 167:	0.04209668  	0.09248298  	0.07566667  
2023-09-01 18:53:33.999: [iter 168 : loss : 0.7672 = 0.0522 + 0.3537 + 0.0081 + 0.3532, time: 22.660814]
2023-09-01 18:53:34.692: epoch 168:	0.04184507  	0.09197816  	0.07550921  
2023-09-01 18:53:57.227: [iter 169 : loss : 0.7681 = 0.0532 + 0.3536 + 0.0082 + 0.3532, time: 22.508069]
2023-09-01 18:53:57.888: epoch 169:	0.04190313  	0.09197309  	0.07559703  
2023-09-01 18:54:20.488: [iter 170 : loss : 0.7664 = 0.0515 + 0.3536 + 0.0082 + 0.3531, time: 22.574406]
2023-09-01 18:54:21.144: epoch 170:	0.04225793  	0.09265172  	0.07586382  
2023-09-01 18:54:43.458: [iter 171 : loss : 0.7665 = 0.0517 + 0.3535 + 0.0082 + 0.3531, time: 22.288280]
2023-09-01 18:54:44.144: epoch 171:	0.04214183  	0.09256488  	0.07579156  
2023-09-01 18:55:06.692: [iter 172 : loss : 0.7659 = 0.0511 + 0.3535 + 0.0083 + 0.3530, time: 22.520379]
2023-09-01 18:55:07.336: epoch 172:	0.04217406  	0.09264835  	0.07568178  
2023-09-01 18:55:29.922: [iter 173 : loss : 0.7659 = 0.0513 + 0.3534 + 0.0083 + 0.3530, time: 22.560356]
2023-09-01 18:55:30.617: epoch 173:	0.04223214  	0.09264107  	0.07588574  
2023-09-01 18:55:53.114: [iter 174 : loss : 0.7661 = 0.0516 + 0.3533 + 0.0083 + 0.3529, time: 22.467609]
2023-09-01 18:55:53.766: epoch 174:	0.04255473  	0.09338641  	0.07640941  
2023-09-01 18:55:53.766: Find a better model.
2023-09-01 18:56:16.328: [iter 175 : loss : 0.7663 = 0.0518 + 0.3533 + 0.0084 + 0.3529, time: 22.532751]
2023-09-01 18:56:16.987: epoch 175:	0.04245793  	0.09322128  	0.07637598  
2023-09-01 18:56:39.546: [iter 176 : loss : 0.7648 = 0.0503 + 0.3532 + 0.0084 + 0.3528, time: 22.532218]
2023-09-01 18:56:40.201: epoch 176:	0.04267083  	0.09350563  	0.07669313  
2023-09-01 18:56:40.201: Find a better model.
2023-09-01 18:57:02.682: [iter 177 : loss : 0.7658 = 0.0514 + 0.3532 + 0.0085 + 0.3527, time: 22.456088]
2023-09-01 18:57:03.413: epoch 177:	0.04261920  	0.09343665  	0.07656362  
2023-09-01 18:57:26.015: [iter 178 : loss : 0.7643 = 0.0500 + 0.3531 + 0.0085 + 0.3527, time: 22.568342]
2023-09-01 18:57:26.666: epoch 178:	0.04236762  	0.09299285  	0.07629903  
2023-09-01 18:57:49.238: [iter 179 : loss : 0.7650 = 0.0507 + 0.3531 + 0.0085 + 0.3526, time: 22.544257]
2023-09-01 18:57:49.924: epoch 179:	0.04236120  	0.09300413  	0.07642086  
2023-09-01 18:58:12.559: [iter 180 : loss : 0.7652 = 0.0510 + 0.3530 + 0.0086 + 0.3526, time: 22.603617]
2023-09-01 18:58:13.219: epoch 180:	0.04229669  	0.09295447  	0.07630581  
2023-09-01 18:58:35.828: [iter 181 : loss : 0.7644 = 0.0503 + 0.3530 + 0.0086 + 0.3525, time: 22.581044]
2023-09-01 18:58:36.477: epoch 181:	0.04240636  	0.09327383  	0.07667616  
2023-09-01 18:58:59.027: [iter 182 : loss : 0.7638 = 0.0498 + 0.3529 + 0.0087 + 0.3525, time: 22.523620]
2023-09-01 18:58:59.725: epoch 182:	0.04252893  	0.09355969  	0.07690766  
2023-09-01 18:58:59.725: Find a better model.
2023-09-01 18:59:22.266: [iter 183 : loss : 0.7638 = 0.0498 + 0.3528 + 0.0087 + 0.3524, time: 22.511769]
2023-09-01 18:59:22.928: epoch 183:	0.04252247  	0.09344447  	0.07680324  
2023-09-01 18:59:45.349: [iter 184 : loss : 0.7630 = 0.0491 + 0.3529 + 0.0087 + 0.3524, time: 22.396534]
2023-09-01 18:59:46.035: epoch 184:	0.04265795  	0.09368717  	0.07711525  
2023-09-01 18:59:46.036: Find a better model.
2023-09-01 19:00:08.554: [iter 185 : loss : 0.7630 = 0.0492 + 0.3527 + 0.0088 + 0.3523, time: 22.495818]
2023-09-01 19:00:09.231: epoch 185:	0.04259990  	0.09363388  	0.07710762  
2023-09-01 19:00:31.870: [iter 186 : loss : 0.7629 = 0.0491 + 0.3527 + 0.0088 + 0.3523, time: 22.616220]
2023-09-01 19:00:32.584: epoch 186:	0.04245797  	0.09324971  	0.07683472  
2023-09-01 19:00:54.911: [iter 187 : loss : 0.7624 = 0.0487 + 0.3527 + 0.0088 + 0.3522, time: 22.302447]
2023-09-01 19:00:55.495: epoch 187:	0.04238703  	0.09305099  	0.07678691  
2023-09-01 19:01:17.592: [iter 188 : loss : 0.7632 = 0.0496 + 0.3526 + 0.0089 + 0.3522, time: 22.070816]
2023-09-01 19:01:18.272: epoch 188:	0.04252249  	0.09320736  	0.07688066  
2023-09-01 19:01:40.863: [iter 189 : loss : 0.7624 = 0.0488 + 0.3525 + 0.0089 + 0.3521, time: 22.558891]
2023-09-01 19:01:41.519: epoch 189:	0.04280631  	0.09390562  	0.07730757  
2023-09-01 19:01:41.520: Find a better model.
2023-09-01 19:02:04.123: [iter 190 : loss : 0.7617 = 0.0482 + 0.3525 + 0.0090 + 0.3521, time: 22.577643]
2023-09-01 19:02:04.806: epoch 190:	0.04279340  	0.09370119  	0.07698490  
2023-09-01 19:02:27.191: [iter 191 : loss : 0.7618 = 0.0483 + 0.3525 + 0.0090 + 0.3520, time: 22.357636]
2023-09-01 19:02:27.863: epoch 191:	0.04287728  	0.09391111  	0.07723435  
2023-09-01 19:02:27.863: Find a better model.
2023-09-01 19:02:50.488: [iter 192 : loss : 0.7620 = 0.0486 + 0.3524 + 0.0090 + 0.3520, time: 22.600608]
2023-09-01 19:02:51.172: epoch 192:	0.04268374  	0.09350710  	0.07717053  
2023-09-01 19:03:13.848: [iter 193 : loss : 0.7611 = 0.0478 + 0.3523 + 0.0091 + 0.3519, time: 22.649611]
2023-09-01 19:03:14.484: epoch 193:	0.04276760  	0.09362435  	0.07708956  
2023-09-01 19:03:37.030: [iter 194 : loss : 0.7617 = 0.0485 + 0.3523 + 0.0091 + 0.3518, time: 22.522838]
2023-09-01 19:03:37.694: epoch 194:	0.04265796  	0.09371767  	0.07721948  
2023-09-01 19:04:00.289: [iter 195 : loss : 0.7605 = 0.0473 + 0.3522 + 0.0091 + 0.3518, time: 22.570355]
2023-09-01 19:04:00.959: epoch 195:	0.04279985  	0.09385851  	0.07745815  
2023-09-01 19:04:23.600: [iter 196 : loss : 0.7608 = 0.0477 + 0.3521 + 0.0092 + 0.3517, time: 22.600350]
2023-09-01 19:04:24.314: epoch 196:	0.04276760  	0.09368233  	0.07754682  
2023-09-01 19:04:46.993: [iter 197 : loss : 0.7596 = 0.0465 + 0.3521 + 0.0092 + 0.3517, time: 22.652407]
2023-09-01 19:04:47.629: epoch 197:	0.04290951  	0.09399258  	0.07759848  
2023-09-01 19:04:47.629: Find a better model.
2023-09-01 19:05:10.031: [iter 198 : loss : 0.7605 = 0.0476 + 0.3520 + 0.0093 + 0.3516, time: 22.374899]
2023-09-01 19:05:10.669: epoch 198:	0.04289018  	0.09381034  	0.07774497  
2023-09-01 19:05:33.070: [iter 199 : loss : 0.7604 = 0.0475 + 0.3520 + 0.0093 + 0.3516, time: 22.379365]
2023-09-01 19:05:33.744: epoch 199:	0.04290310  	0.09380163  	0.07776780  
2023-09-01 19:05:56.209: [iter 200 : loss : 0.7605 = 0.0476 + 0.3520 + 0.0093 + 0.3515, time: 22.425650]
2023-09-01 19:05:56.887: epoch 200:	0.04299987  	0.09399113  	0.07776133  
2023-09-01 19:05:56.887: best_result@epoch 197:

2023-09-01 19:05:56.887: 		0.0429      	0.0940      	0.0776      

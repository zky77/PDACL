2023-08-31 16:44:21.508: my pid: 40418
2023-08-31 16:44:21.508: model: model.general_recommender.GNNEC
2023-08-31 16:44:21.508: Dataset statistics:
Name: yelp
The number of users: 7750
The number of items: 28918
The number of ratings: 750318
Average actions of users: 96.82
Average actions of items: 25.95
The sparsity of the dataset: 99.665208%

The number of training: 678579
The number of validation: 0
The number of testing: 71739
2023-08-31 16:44:21.508: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=yelp
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=4096
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=yelp
epochs=200
n_layers=2
embed_size=32
batch_size=4096
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
mf_reg=1e-4
svd_q=5
2023-08-31 16:44:40.850: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-08-31 16:45:01.595: [iter 1 : loss : 0.9671 = 0.6078 + 0.3574 + 0.0000 + 0.0018, time: 20.744444]
2023-08-31 16:45:02.279: epoch 1:	0.02523922  	0.05456403  	0.04658057  
2023-08-31 16:45:02.279: Find a better model.
2023-08-31 16:45:22.778: [iter 2 : loss : 0.6782 = 0.3540 + 0.3224 + 0.0002 + 0.0016, time: 20.484519]
2023-08-31 16:45:23.420: epoch 2:	0.02521342  	0.05429143  	0.04648264  
2023-08-31 16:45:43.546: [iter 3 : loss : 0.5848 = 0.2699 + 0.3130 + 0.0003 + 0.0016, time: 20.114029]
2023-08-31 16:45:44.197: epoch 3:	0.02536181  	0.05450145  	0.04653971  
2023-08-31 16:46:04.212: [iter 4 : loss : 0.5561 = 0.2453 + 0.3088 + 0.0004 + 0.0016, time: 20.001027]
2023-08-31 16:46:04.820: epoch 4:	0.02541987  	0.05482193  	0.04663246  
2023-08-31 16:46:04.821: Find a better model.
2023-08-31 16:46:24.682: [iter 5 : loss : 0.5416 = 0.2337 + 0.3059 + 0.0004 + 0.0015, time: 19.852095]
2023-08-31 16:46:25.297: epoch 5:	0.02561988  	0.05531860  	0.04721318  
2023-08-31 16:46:25.297: Find a better model.
2023-08-31 16:46:45.123: [iter 6 : loss : 0.5307 = 0.2256 + 0.3031 + 0.0005 + 0.0015, time: 19.815559]
2023-08-31 16:46:45.830: epoch 6:	0.02578763  	0.05588119  	0.04734516  
2023-08-31 16:46:45.830: Find a better model.
2023-08-31 16:47:05.576: [iter 7 : loss : 0.5178 = 0.2153 + 0.3005 + 0.0005 + 0.0015, time: 19.737273]
2023-08-31 16:47:06.282: epoch 7:	0.02608441  	0.05651622  	0.04766702  
2023-08-31 16:47:06.282: Find a better model.
2023-08-31 16:47:26.273: [iter 8 : loss : 0.5085 = 0.2082 + 0.2982 + 0.0006 + 0.0015, time: 19.977872]
2023-08-31 16:47:26.953: epoch 8:	0.02637473  	0.05726271  	0.04829763  
2023-08-31 16:47:26.953: Find a better model.
2023-08-31 16:47:47.210: [iter 9 : loss : 0.4999 = 0.2016 + 0.2962 + 0.0006 + 0.0015, time: 20.244218]
2023-08-31 16:47:47.803: epoch 9:	0.02669089  	0.05784822  	0.04872704  
2023-08-31 16:47:47.803: Find a better model.
2023-08-31 16:48:07.955: [iter 10 : loss : 0.4911 = 0.1950 + 0.2940 + 0.0006 + 0.0015, time: 20.142802]
2023-08-31 16:48:08.588: epoch 10:	0.02695542  	0.05822367  	0.04895815  
2023-08-31 16:48:08.589: Find a better model.
2023-08-31 16:48:28.927: [iter 11 : loss : 0.4839 = 0.1894 + 0.2923 + 0.0007 + 0.0015, time: 20.327889]
2023-08-31 16:48:29.665: epoch 11:	0.02726511  	0.05896987  	0.04965916  
2023-08-31 16:48:29.666: Find a better model.
2023-08-31 16:48:49.642: [iter 12 : loss : 0.4761 = 0.1835 + 0.2904 + 0.0007 + 0.0015, time: 19.966997]
2023-08-31 16:48:50.344: epoch 12:	0.02763931  	0.05968032  	0.05007496  
2023-08-31 16:48:50.345: Find a better model.
2023-08-31 16:49:10.510: [iter 13 : loss : 0.4707 = 0.1795 + 0.2889 + 0.0008 + 0.0015, time: 20.150575]
2023-08-31 16:49:11.135: epoch 13:	0.02794255  	0.06060611  	0.05066078  
2023-08-31 16:49:11.135: Find a better model.
2023-08-31 16:49:31.385: [iter 14 : loss : 0.4636 = 0.1739 + 0.2874 + 0.0008 + 0.0015, time: 20.239058]
2023-08-31 16:49:32.055: epoch 14:	0.02805868  	0.06075713  	0.05111825  
2023-08-31 16:49:32.055: Find a better model.
2023-08-31 16:49:52.045: [iter 15 : loss : 0.4595 = 0.1712 + 0.2860 + 0.0008 + 0.0015, time: 19.978836]
2023-08-31 16:49:52.673: epoch 15:	0.02810384  	0.06078730  	0.05107920  
2023-08-31 16:49:52.674: Find a better model.
2023-08-31 16:50:13.002: [iter 16 : loss : 0.4553 = 0.1682 + 0.2847 + 0.0009 + 0.0014, time: 20.317260]
2023-08-31 16:50:13.670: epoch 16:	0.02814902  	0.06091906  	0.05092986  
2023-08-31 16:50:13.670: Find a better model.
2023-08-31 16:50:33.999: [iter 17 : loss : 0.4494 = 0.1638 + 0.2833 + 0.0009 + 0.0014, time: 20.318986]
2023-08-31 16:50:34.688: epoch 17:	0.02825225  	0.06101026  	0.05107242  
2023-08-31 16:50:34.688: Find a better model.
2023-08-31 16:50:54.762: [iter 18 : loss : 0.4465 = 0.1622 + 0.2819 + 0.0010 + 0.0014, time: 20.062647]
2023-08-31 16:50:55.394: epoch 18:	0.02833612  	0.06141463  	0.05119083  
2023-08-31 16:50:55.394: Find a better model.
2023-08-31 16:51:15.586: [iter 19 : loss : 0.4414 = 0.1585 + 0.2805 + 0.0010 + 0.0014, time: 20.182082]
2023-08-31 16:51:16.259: epoch 19:	0.02849740  	0.06173243  	0.05146261  
2023-08-31 16:51:16.259: Find a better model.
2023-08-31 16:51:36.376: [iter 20 : loss : 0.4375 = 0.1557 + 0.2793 + 0.0010 + 0.0014, time: 20.104366]
2023-08-31 16:51:37.039: epoch 20:	0.02870388  	0.06224543  	0.05178123  
2023-08-31 16:51:37.039: Find a better model.
2023-08-31 16:51:57.233: [iter 21 : loss : 0.4328 = 0.1524 + 0.2779 + 0.0011 + 0.0014, time: 20.183081]
2023-08-31 16:51:57.860: epoch 21:	0.02891681  	0.06263196  	0.05221960  
2023-08-31 16:51:57.860: Find a better model.
2023-08-31 16:52:17.860: [iter 22 : loss : 0.4294 = 0.1501 + 0.2768 + 0.0011 + 0.0014, time: 19.989993]
2023-08-31 16:52:18.473: epoch 22:	0.02909099  	0.06291972  	0.05257989  
2023-08-31 16:52:18.473: Find a better model.
2023-08-31 16:52:38.639: [iter 23 : loss : 0.4254 = 0.1475 + 0.2754 + 0.0012 + 0.0014, time: 20.154398]
2023-08-31 16:52:39.329: epoch 23:	0.02935553  	0.06339926  	0.05277688  
2023-08-31 16:52:39.329: Find a better model.
2023-08-31 16:52:59.323: [iter 24 : loss : 0.4232 = 0.1464 + 0.2741 + 0.0012 + 0.0014, time: 19.983122]
2023-08-31 16:53:00.033: epoch 24:	0.02921358  	0.06304765  	0.05286595  
2023-08-31 16:53:20.407: [iter 25 : loss : 0.4191 = 0.1436 + 0.2728 + 0.0012 + 0.0014, time: 20.362358]
2023-08-31 16:53:21.066: epoch 25:	0.02943941  	0.06356603  	0.05312697  
2023-08-31 16:53:21.066: Find a better model.
2023-08-31 16:53:41.057: [iter 26 : loss : 0.4161 = 0.1418 + 0.2715 + 0.0013 + 0.0014, time: 19.977214]
2023-08-31 16:53:41.701: epoch 26:	0.02967168  	0.06395201  	0.05358213  
2023-08-31 16:53:41.701: Find a better model.
2023-08-31 16:54:02.033: [iter 27 : loss : 0.4116 = 0.1388 + 0.2701 + 0.0013 + 0.0014, time: 20.318437]
2023-08-31 16:54:02.715: epoch 27:	0.02987814  	0.06447933  	0.05384199  
2023-08-31 16:54:02.715: Find a better model.
2023-08-31 16:54:22.945: [iter 28 : loss : 0.4085 = 0.1370 + 0.2687 + 0.0014 + 0.0014, time: 20.216091]
2023-08-31 16:54:23.576: epoch 28:	0.03027815  	0.06526560  	0.05437275  
2023-08-31 16:54:23.577: Find a better model.
2023-08-31 16:54:43.806: [iter 29 : loss : 0.4060 = 0.1358 + 0.2674 + 0.0014 + 0.0014, time: 20.217634]
2023-08-31 16:54:44.416: epoch 29:	0.03052977  	0.06593721  	0.05491237  
2023-08-31 16:54:44.416: Find a better model.
2023-08-31 16:55:04.498: [iter 30 : loss : 0.4026 = 0.1336 + 0.2662 + 0.0015 + 0.0014, time: 20.072490]
2023-08-31 16:55:05.168: epoch 30:	0.03094268  	0.06676954  	0.05541141  
2023-08-31 16:55:05.168: Find a better model.
2023-08-31 16:55:25.377: [iter 31 : loss : 0.3991 = 0.1314 + 0.2648 + 0.0015 + 0.0013, time: 20.196649]
2023-08-31 16:55:26.009: epoch 31:	0.03118140  	0.06745076  	0.05586128  
2023-08-31 16:55:26.009: Find a better model.
2023-08-31 16:55:46.304: [iter 32 : loss : 0.3955 = 0.1293 + 0.2633 + 0.0016 + 0.0013, time: 20.285201]
2023-08-31 16:55:46.930: epoch 32:	0.03153626  	0.06831031  	0.05653341  
2023-08-31 16:55:46.931: Find a better model.
2023-08-31 16:56:07.170: [iter 33 : loss : 0.3923 = 0.1275 + 0.2618 + 0.0016 + 0.0013, time: 20.226719]
2023-08-31 16:56:07.809: epoch 33:	0.03165238  	0.06835334  	0.05659254  
2023-08-31 16:56:07.809: Find a better model.
2023-08-31 16:56:28.026: [iter 34 : loss : 0.3894 = 0.1261 + 0.2603 + 0.0017 + 0.0013, time: 20.207368]
2023-08-31 16:56:28.685: epoch 34:	0.03184594  	0.06891132  	0.05715393  
2023-08-31 16:56:28.686: Find a better model.
2023-08-31 16:56:49.037: [iter 35 : loss : 0.3863 = 0.1243 + 0.2590 + 0.0017 + 0.0013, time: 20.337704]
2023-08-31 16:56:49.689: epoch 35:	0.03187819  	0.06897835  	0.05729459  
2023-08-31 16:56:49.689: Find a better model.
2023-08-31 16:57:09.854: [iter 36 : loss : 0.3835 = 0.1230 + 0.2574 + 0.0018 + 0.0013, time: 20.152283]
2023-08-31 16:57:10.541: epoch 36:	0.03219434  	0.06964210  	0.05802507  
2023-08-31 16:57:10.541: Find a better model.
2023-08-31 16:57:30.783: [iter 37 : loss : 0.3802 = 0.1210 + 0.2560 + 0.0018 + 0.0013, time: 20.231166]
2023-08-31 16:57:31.433: epoch 37:	0.03247175  	0.07026218  	0.05839277  
2023-08-31 16:57:31.433: Find a better model.
2023-08-31 16:57:51.579: [iter 38 : loss : 0.3769 = 0.1188 + 0.2550 + 0.0019 + 0.0013, time: 20.136936]
2023-08-31 16:57:52.238: epoch 38:	0.03274273  	0.07078443  	0.05869561  
2023-08-31 16:57:52.238: Find a better model.
2023-08-31 16:58:12.489: [iter 39 : loss : 0.3741 = 0.1176 + 0.2532 + 0.0019 + 0.0013, time: 20.240223]
2023-08-31 16:58:13.142: epoch 39:	0.03294273  	0.07141247  	0.05910631  
2023-08-31 16:58:13.142: Find a better model.
2023-08-31 16:58:33.275: [iter 40 : loss : 0.3715 = 0.1163 + 0.2519 + 0.0020 + 0.0013, time: 20.121959]
2023-08-31 16:58:33.929: epoch 40:	0.03319433  	0.07205096  	0.05969961  
2023-08-31 16:58:33.929: Find a better model.
2023-08-31 16:58:54.237: [iter 41 : loss : 0.3678 = 0.1140 + 0.2504 + 0.0020 + 0.0013, time: 20.298799]
2023-08-31 16:58:54.878: epoch 41:	0.03331687  	0.07230454  	0.06005745  
2023-08-31 16:58:54.878: Find a better model.
2023-08-31 16:59:15.207: [iter 42 : loss : 0.3655 = 0.1130 + 0.2491 + 0.0021 + 0.0013, time: 20.316851]
2023-08-31 16:59:15.828: epoch 42:	0.03355554  	0.07263444  	0.06049643  
2023-08-31 16:59:15.829: Find a better model.
2023-08-31 16:59:35.923: [iter 43 : loss : 0.3625 = 0.1115 + 0.2476 + 0.0021 + 0.0013, time: 20.084790]
2023-08-31 16:59:36.544: epoch 43:	0.03363942  	0.07287015  	0.06087848  
2023-08-31 16:59:36.544: Find a better model.
2023-08-31 16:59:56.600: [iter 44 : loss : 0.3603 = 0.1108 + 0.2461 + 0.0022 + 0.0012, time: 20.042680]
2023-08-31 16:59:57.267: epoch 44:	0.03394263  	0.07360289  	0.06138906  
2023-08-31 16:59:57.267: Find a better model.
2023-08-31 17:00:17.421: [iter 45 : loss : 0.3576 = 0.1094 + 0.2447 + 0.0022 + 0.0012, time: 20.145298]
2023-08-31 17:00:18.042: epoch 45:	0.03415554  	0.07406137  	0.06188947  
2023-08-31 17:00:18.042: Find a better model.
2023-08-31 17:00:38.275: [iter 46 : loss : 0.3555 = 0.1086 + 0.2433 + 0.0023 + 0.0012, time: 20.223189]
2023-08-31 17:00:38.935: epoch 46:	0.03454905  	0.07496696  	0.06251352  
2023-08-31 17:00:38.935: Find a better model.
2023-08-31 17:00:59.349: [iter 47 : loss : 0.3518 = 0.1065 + 0.2418 + 0.0024 + 0.0012, time: 20.403115]
2023-08-31 17:00:59.981: epoch 47:	0.03474258  	0.07542807  	0.06276464  
2023-08-31 17:00:59.981: Find a better model.
2023-08-31 17:01:20.227: [iter 48 : loss : 0.3498 = 0.1057 + 0.2405 + 0.0024 + 0.0012, time: 20.237347]
2023-08-31 17:01:20.842: epoch 48:	0.03507155  	0.07616691  	0.06329958  
2023-08-31 17:01:20.842: Find a better model.
2023-08-31 17:01:40.954: [iter 49 : loss : 0.3472 = 0.1044 + 0.2392 + 0.0025 + 0.0012, time: 20.099953]
2023-08-31 17:01:41.566: epoch 49:	0.03528443  	0.07646810  	0.06381648  
2023-08-31 17:01:41.566: Find a better model.
2023-08-31 17:02:01.653: [iter 50 : loss : 0.3456 = 0.1040 + 0.2378 + 0.0025 + 0.0012, time: 20.077809]
2023-08-31 17:02:02.294: epoch 50:	0.03545217  	0.07690869  	0.06429151  
2023-08-31 17:02:02.294: Find a better model.
2023-08-31 17:02:22.519: [iter 51 : loss : 0.3428 = 0.1026 + 0.2364 + 0.0026 + 0.0012, time: 20.215132]
2023-08-31 17:02:23.182: epoch 51:	0.03560698  	0.07726619  	0.06452189  
2023-08-31 17:02:23.182: Find a better model.
2023-08-31 17:02:43.330: [iter 52 : loss : 0.3401 = 0.1012 + 0.2350 + 0.0026 + 0.0012, time: 20.137472]
2023-08-31 17:02:43.999: epoch 52:	0.03580695  	0.07767431  	0.06493318  
2023-08-31 17:02:44.000: Find a better model.
2023-08-31 17:03:04.174: [iter 53 : loss : 0.3381 = 0.1006 + 0.2336 + 0.0027 + 0.0012, time: 20.164634]
2023-08-31 17:03:04.807: epoch 53:	0.03606499  	0.07816341  	0.06527926  
2023-08-31 17:03:04.807: Find a better model.
2023-08-31 17:03:25.051: [iter 54 : loss : 0.3355 = 0.0992 + 0.2324 + 0.0028 + 0.0012, time: 20.230259]
2023-08-31 17:03:25.687: epoch 54:	0.03638756  	0.07889701  	0.06570562  
2023-08-31 17:03:25.687: Find a better model.
2023-08-31 17:03:45.997: [iter 55 : loss : 0.3339 = 0.0989 + 0.2309 + 0.0028 + 0.0012, time: 20.293575]
2023-08-31 17:03:46.650: epoch 55:	0.03652945  	0.07927991  	0.06605912  
2023-08-31 17:03:46.650: Find a better model.
2023-08-31 17:04:07.057: [iter 56 : loss : 0.3313 = 0.0976 + 0.2296 + 0.0029 + 0.0012, time: 20.395867]
2023-08-31 17:04:07.686: epoch 56:	0.03685847  	0.07987399  	0.06652617  
2023-08-31 17:04:07.686: Find a better model.
2023-08-31 17:04:27.892: [iter 57 : loss : 0.3292 = 0.0968 + 0.2283 + 0.0029 + 0.0012, time: 20.196415]
2023-08-31 17:04:28.543: epoch 57:	0.03677460  	0.07967740  	0.06660659  
2023-08-31 17:04:48.961: [iter 58 : loss : 0.3283 = 0.0969 + 0.2272 + 0.0030 + 0.0012, time: 20.408273]
2023-08-31 17:04:49.644: epoch 58:	0.03712939  	0.08050032  	0.06727622  
2023-08-31 17:04:49.644: Find a better model.
2023-08-31 17:05:09.848: [iter 59 : loss : 0.3254 = 0.0956 + 0.2256 + 0.0030 + 0.0011, time: 20.189776]
2023-08-31 17:05:10.513: epoch 59:	0.03726488  	0.08081595  	0.06755101  
2023-08-31 17:05:10.513: Find a better model.
2023-08-31 17:05:30.634: [iter 60 : loss : 0.3235 = 0.0946 + 0.2246 + 0.0031 + 0.0011, time: 20.108767]
2023-08-31 17:05:31.283: epoch 60:	0.03750355  	0.08154620  	0.06794883  
2023-08-31 17:05:31.283: Find a better model.
2023-08-31 17:05:51.583: [iter 61 : loss : 0.3207 = 0.0933 + 0.2231 + 0.0032 + 0.0011, time: 20.289388]
2023-08-31 17:05:52.294: epoch 61:	0.03784546  	0.08221333  	0.06860685  
2023-08-31 17:05:52.294: Find a better model.
2023-08-31 17:06:12.270: [iter 62 : loss : 0.3191 = 0.0930 + 0.2218 + 0.0032 + 0.0011, time: 19.960982]
2023-08-31 17:06:12.895: epoch 62:	0.03807770  	0.08278935  	0.06906763  
2023-08-31 17:06:12.895: Find a better model.
2023-08-31 17:06:32.945: [iter 63 : loss : 0.3164 = 0.0913 + 0.2206 + 0.0033 + 0.0011, time: 20.039811]
2023-08-31 17:06:33.665: epoch 63:	0.03829703  	0.08346382  	0.06948844  
2023-08-31 17:06:33.665: Find a better model.
2023-08-31 17:06:53.734: [iter 64 : loss : 0.3147 = 0.0908 + 0.2195 + 0.0033 + 0.0011, time: 20.054033]
2023-08-31 17:06:54.371: epoch 64:	0.03838088  	0.08371892  	0.06956131  
2023-08-31 17:06:54.371: Find a better model.
2023-08-31 17:07:14.548: [iter 65 : loss : 0.3135 = 0.0908 + 0.2182 + 0.0034 + 0.0011, time: 20.168213]
2023-08-31 17:07:15.282: epoch 65:	0.03838735  	0.08360265  	0.06977012  
2023-08-31 17:07:35.388: [iter 66 : loss : 0.3105 = 0.0891 + 0.2169 + 0.0035 + 0.0011, time: 20.094644]
2023-08-31 17:07:35.993: epoch 66:	0.03857442  	0.08393496  	0.07011954  
2023-08-31 17:07:35.993: Find a better model.
2023-08-31 17:07:56.226: [iter 67 : loss : 0.3091 = 0.0888 + 0.2156 + 0.0035 + 0.0011, time: 20.223201]
2023-08-31 17:07:56.950: epoch 67:	0.03889697  	0.08469342  	0.07064596  
2023-08-31 17:07:56.950: Find a better model.
2023-08-31 17:08:16.828: [iter 68 : loss : 0.3079 = 0.0887 + 0.2145 + 0.0036 + 0.0011, time: 19.869133]
2023-08-31 17:08:17.422: epoch 68:	0.03925825  	0.08545142  	0.07109681  
2023-08-31 17:08:17.422: Find a better model.
2023-08-31 17:08:37.373: [iter 69 : loss : 0.3060 = 0.0880 + 0.2133 + 0.0036 + 0.0011, time: 19.937260]
2023-08-31 17:08:38.079: epoch 69:	0.03928404  	0.08540447  	0.07109574  
2023-08-31 17:08:58.154: [iter 70 : loss : 0.3046 = 0.0876 + 0.2122 + 0.0037 + 0.0011, time: 20.063837]
2023-08-31 17:08:58.816: epoch 70:	0.03945822  	0.08593008  	0.07140817  
2023-08-31 17:08:58.816: Find a better model.
2023-08-31 17:09:19.025: [iter 71 : loss : 0.3017 = 0.0860 + 0.2109 + 0.0038 + 0.0011, time: 20.192057]
2023-08-31 17:09:19.652: epoch 71:	0.03963887  	0.08637212  	0.07169876  
2023-08-31 17:09:19.652: Find a better model.
2023-08-31 17:09:39.720: [iter 72 : loss : 0.3002 = 0.0859 + 0.2095 + 0.0038 + 0.0011, time: 20.059011]
2023-08-31 17:09:40.392: epoch 72:	0.03961951  	0.08618230  	0.07187802  
2023-08-31 17:09:59.975: [iter 73 : loss : 0.2986 = 0.0852 + 0.2085 + 0.0039 + 0.0011, time: 19.573382]
2023-08-31 17:10:00.656: epoch 73:	0.03974854  	0.08656812  	0.07215990  
2023-08-31 17:10:00.657: Find a better model.
2023-08-31 17:10:20.200: [iter 74 : loss : 0.2966 = 0.0844 + 0.2072 + 0.0039 + 0.0010, time: 19.533309]
2023-08-31 17:10:20.926: epoch 74:	0.03983242  	0.08682408  	0.07234447  
2023-08-31 17:10:20.926: Find a better model.
2023-08-31 17:10:40.970: [iter 75 : loss : 0.2947 = 0.0837 + 0.2060 + 0.0040 + 0.0010, time: 20.033577]
2023-08-31 17:10:41.667: epoch 75:	0.03989047  	0.08688185  	0.07236700  
2023-08-31 17:10:41.667: Find a better model.
2023-08-31 17:11:01.823: [iter 76 : loss : 0.2939 = 0.0838 + 0.2050 + 0.0041 + 0.0010, time: 20.143232]
2023-08-31 17:11:02.435: epoch 76:	0.04018075  	0.08750094  	0.07277521  
2023-08-31 17:11:02.435: Find a better model.
2023-08-31 17:11:22.270: [iter 77 : loss : 0.2917 = 0.0827 + 0.2039 + 0.0041 + 0.0010, time: 19.825859]
2023-08-31 17:11:22.911: epoch 77:	0.04036781  	0.08798933  	0.07308216  
2023-08-31 17:11:22.911: Find a better model.
2023-08-31 17:11:42.795: [iter 78 : loss : 0.2902 = 0.0823 + 0.2027 + 0.0042 + 0.0010, time: 19.874911]
2023-08-31 17:11:43.487: epoch 78:	0.04041301  	0.08817741  	0.07312097  
2023-08-31 17:11:43.487: Find a better model.
2023-08-31 17:12:03.583: [iter 79 : loss : 0.2883 = 0.0815 + 0.2016 + 0.0042 + 0.0010, time: 20.078576]
2023-08-31 17:12:04.218: epoch 79:	0.04035494  	0.08797446  	0.07305655  
2023-08-31 17:12:24.283: [iter 80 : loss : 0.2873 = 0.0815 + 0.2005 + 0.0043 + 0.0010, time: 20.050316]
2023-08-31 17:12:24.918: epoch 80:	0.04065171  	0.08874666  	0.07361245  
2023-08-31 17:12:24.918: Find a better model.
2023-08-31 17:12:44.925: [iter 81 : loss : 0.2851 = 0.0806 + 0.1991 + 0.0044 + 0.0010, time: 19.996042]
2023-08-31 17:12:45.548: epoch 81:	0.04080006  	0.08902644  	0.07377727  
2023-08-31 17:12:45.548: Find a better model.
2023-08-31 17:13:05.581: [iter 82 : loss : 0.2838 = 0.0803 + 0.1981 + 0.0044 + 0.0010, time: 20.021966]
2023-08-31 17:13:06.196: epoch 82:	0.04078071  	0.08900718  	0.07379566  
2023-08-31 17:13:25.159: [iter 83 : loss : 0.2825 = 0.0799 + 0.1971 + 0.0045 + 0.0010, time: 18.948187]
2023-08-31 17:13:25.757: epoch 83:	0.04086458  	0.08900373  	0.07392830  
2023-08-31 17:13:45.632: [iter 84 : loss : 0.2793 = 0.0778 + 0.1960 + 0.0045 + 0.0010, time: 19.863778]
2023-08-31 17:13:46.256: epoch 84:	0.04092262  	0.08907151  	0.07408565  
2023-08-31 17:13:46.256: Find a better model.
2023-08-31 17:14:06.027: [iter 85 : loss : 0.2793 = 0.0789 + 0.1949 + 0.0046 + 0.0010, time: 19.761714]
2023-08-31 17:14:06.664: epoch 85:	0.04090328  	0.08901840  	0.07427458  
2023-08-31 17:14:26.746: [iter 86 : loss : 0.2771 = 0.0776 + 0.1939 + 0.0047 + 0.0010, time: 20.064018]
2023-08-31 17:14:27.454: epoch 86:	0.04123871  	0.08983701  	0.07468690  
2023-08-31 17:14:27.454: Find a better model.
2023-08-31 17:14:47.688: [iter 87 : loss : 0.2764 = 0.0779 + 0.1928 + 0.0047 + 0.0010, time: 20.223342]
2023-08-31 17:14:48.396: epoch 87:	0.04137420  	0.09011904  	0.07506858  
2023-08-31 17:14:48.396: Find a better model.
2023-08-31 17:15:08.339: [iter 88 : loss : 0.2750 = 0.0776 + 0.1916 + 0.0048 + 0.0010, time: 19.930158]
2023-08-31 17:15:08.955: epoch 88:	0.04140644  	0.09041272  	0.07512787  
2023-08-31 17:15:08.955: Find a better model.
2023-08-31 17:15:28.962: [iter 89 : loss : 0.2738 = 0.0772 + 0.1908 + 0.0048 + 0.0010, time: 19.996425]
2023-08-31 17:15:29.578: epoch 89:	0.04148383  	0.09044972  	0.07538123  
2023-08-31 17:15:29.579: Find a better model.
2023-08-31 17:15:49.454: [iter 90 : loss : 0.2722 = 0.0765 + 0.1898 + 0.0049 + 0.0010, time: 19.865939]
2023-08-31 17:15:50.029: epoch 90:	0.04150964  	0.09056275  	0.07542469  
2023-08-31 17:15:50.029: Find a better model.
2023-08-31 17:16:09.597: [iter 91 : loss : 0.2712 = 0.0765 + 0.1887 + 0.0050 + 0.0010, time: 19.558516]
2023-08-31 17:16:10.211: epoch 91:	0.04154836  	0.09064153  	0.07578298  
2023-08-31 17:16:10.211: Find a better model.
2023-08-31 17:16:30.343: [iter 92 : loss : 0.2694 = 0.0758 + 0.1877 + 0.0050 + 0.0009, time: 20.119208]
2023-08-31 17:16:30.979: epoch 92:	0.04165800  	0.09103676  	0.07607958  
2023-08-31 17:16:30.979: Find a better model.
2023-08-31 17:16:51.225: [iter 93 : loss : 0.2677 = 0.0750 + 0.1867 + 0.0051 + 0.0009, time: 20.232258]
2023-08-31 17:16:51.881: epoch 93:	0.04172896  	0.09093843  	0.07612297  
2023-08-31 17:17:11.669: [iter 94 : loss : 0.2676 = 0.0759 + 0.1856 + 0.0051 + 0.0009, time: 19.777699]
2023-08-31 17:17:12.303: epoch 94:	0.04176119  	0.09108512  	0.07615183  
2023-08-31 17:17:12.304: Find a better model.
2023-08-31 17:17:32.219: [iter 95 : loss : 0.2656 = 0.0750 + 0.1845 + 0.0052 + 0.0009, time: 19.903945]
2023-08-31 17:17:32.811: epoch 95:	0.04199988  	0.09156285  	0.07642284  
2023-08-31 17:17:32.811: Find a better model.
2023-08-31 17:17:51.763: [iter 96 : loss : 0.2651 = 0.0752 + 0.1837 + 0.0053 + 0.0009, time: 18.939848]
2023-08-31 17:17:52.415: epoch 96:	0.04203214  	0.09182024  	0.07661550  
2023-08-31 17:17:52.415: Find a better model.
2023-08-31 17:18:11.333: [iter 97 : loss : 0.2639 = 0.0748 + 0.1829 + 0.0053 + 0.0009, time: 18.908655]
2023-08-31 17:18:11.920: epoch 97:	0.04194183  	0.09168828  	0.07661412  
2023-08-31 17:18:30.909: [iter 98 : loss : 0.2619 = 0.0739 + 0.1817 + 0.0054 + 0.0009, time: 18.980244]
2023-08-31 17:18:31.507: epoch 98:	0.04210955  	0.09188975  	0.07687997  
2023-08-31 17:18:31.507: Find a better model.
2023-08-31 17:18:50.518: [iter 99 : loss : 0.2600 = 0.0728 + 0.1808 + 0.0054 + 0.0009, time: 19.001087]
2023-08-31 17:18:51.073: epoch 99:	0.04218698  	0.09232972  	0.07707296  
2023-08-31 17:18:51.073: Find a better model.
2023-08-31 17:19:11.018: [iter 100 : loss : 0.2593 = 0.0731 + 0.1798 + 0.0055 + 0.0009, time: 19.932113]
2023-08-31 17:19:11.666: epoch 100:	0.04219344  	0.09224366  	0.07700228  
2023-08-31 17:19:31.574: [iter 101 : loss : 0.2573 = 0.0719 + 0.1789 + 0.0056 + 0.0009, time: 19.896544]
2023-08-31 17:19:32.259: epoch 101:	0.04228374  	0.09223735  	0.07708713  
2023-08-31 17:19:52.201: [iter 102 : loss : 0.2579 = 0.0735 + 0.1779 + 0.0056 + 0.0009, time: 19.931462]
2023-08-31 17:19:52.896: epoch 102:	0.04258692  	0.09296455  	0.07761253  
2023-08-31 17:19:52.896: Find a better model.
2023-08-31 17:20:12.851: [iter 103 : loss : 0.2557 = 0.0722 + 0.1770 + 0.0057 + 0.0009, time: 19.944577]
2023-08-31 17:20:13.553: epoch 103:	0.04267726  	0.09312354  	0.07767218  
2023-08-31 17:20:13.553: Find a better model.
2023-08-31 17:20:33.561: [iter 104 : loss : 0.2554 = 0.0725 + 0.1763 + 0.0057 + 0.0009, time: 19.995959]
2023-08-31 17:20:34.205: epoch 104:	0.04272242  	0.09324702  	0.07768953  
2023-08-31 17:20:34.205: Find a better model.
2023-08-31 17:20:54.324: [iter 105 : loss : 0.2529 = 0.0709 + 0.1753 + 0.0058 + 0.0009, time: 20.107885]
2023-08-31 17:20:54.949: epoch 105:	0.04278693  	0.09332161  	0.07792924  
2023-08-31 17:20:54.949: Find a better model.
2023-08-31 17:21:15.096: [iter 106 : loss : 0.2506 = 0.0695 + 0.1744 + 0.0059 + 0.0009, time: 20.135383]
2023-08-31 17:21:15.724: epoch 106:	0.04267079  	0.09312018  	0.07784590  
2023-08-31 17:21:35.742: [iter 107 : loss : 0.2508 = 0.0706 + 0.1734 + 0.0059 + 0.0009, time: 20.009062]
2023-08-31 17:21:36.425: epoch 107:	0.04279985  	0.09336445  	0.07807849  
2023-08-31 17:21:36.426: Find a better model.
2023-08-31 17:21:56.439: [iter 108 : loss : 0.2499 = 0.0705 + 0.1726 + 0.0060 + 0.0009, time: 20.004372]
2023-08-31 17:21:57.110: epoch 108:	0.04298048  	0.09389375  	0.07840674  
2023-08-31 17:21:57.111: Find a better model.
2023-08-31 17:22:17.186: [iter 109 : loss : 0.2483 = 0.0697 + 0.1716 + 0.0060 + 0.0009, time: 20.065879]
2023-08-31 17:22:17.793: epoch 109:	0.04300629  	0.09420008  	0.07858942  
2023-08-31 17:22:17.793: Find a better model.
2023-08-31 17:22:38.003: [iter 110 : loss : 0.2466 = 0.0688 + 0.1708 + 0.0061 + 0.0009, time: 20.199400]
2023-08-31 17:22:38.689: epoch 110:	0.04307078  	0.09425447  	0.07857861  
2023-08-31 17:22:38.689: Find a better model.
2023-08-31 17:22:58.867: [iter 111 : loss : 0.2455 = 0.0685 + 0.1699 + 0.0062 + 0.0009, time: 20.167907]
2023-08-31 17:22:59.518: epoch 111:	0.04305789  	0.09407053  	0.07861007  
2023-08-31 17:23:19.595: [iter 112 : loss : 0.2461 = 0.0698 + 0.1693 + 0.0062 + 0.0009, time: 20.064429]
2023-08-31 17:23:20.247: epoch 112:	0.04318692  	0.09442598  	0.07876334  
2023-08-31 17:23:20.247: Find a better model.
2023-08-31 17:23:40.183: [iter 113 : loss : 0.2454 = 0.0699 + 0.1684 + 0.0063 + 0.0008, time: 19.926055]
2023-08-31 17:23:40.874: epoch 113:	0.04333529  	0.09487537  	0.07898867  
2023-08-31 17:23:40.874: Find a better model.
2023-08-31 17:24:01.150: [iter 114 : loss : 0.2430 = 0.0682 + 0.1676 + 0.0063 + 0.0008, time: 20.265813]
2023-08-31 17:24:01.849: epoch 114:	0.04325787  	0.09451728  	0.07903317  
2023-08-31 17:24:21.845: [iter 115 : loss : 0.2425 = 0.0686 + 0.1666 + 0.0064 + 0.0008, time: 19.984782]
2023-08-31 17:24:22.483: epoch 115:	0.04326434  	0.09463363  	0.07921554  
2023-08-31 17:24:42.541: [iter 116 : loss : 0.2402 = 0.0672 + 0.1658 + 0.0065 + 0.0008, time: 20.046875]
2023-08-31 17:24:43.210: epoch 116:	0.04325143  	0.09458730  	0.07917485  
2023-08-31 17:25:03.216: [iter 117 : loss : 0.2399 = 0.0676 + 0.1650 + 0.0065 + 0.0008, time: 19.992769]
2023-08-31 17:25:03.857: epoch 117:	0.04332886  	0.09463501  	0.07912637  
2023-08-31 17:25:24.024: [iter 118 : loss : 0.2393 = 0.0675 + 0.1644 + 0.0066 + 0.0008, time: 20.153621]
2023-08-31 17:25:24.662: epoch 118:	0.04339338  	0.09481099  	0.07935471  
2023-08-31 17:25:44.790: [iter 119 : loss : 0.2377 = 0.0668 + 0.1635 + 0.0066 + 0.0008, time: 20.118789]
2023-08-31 17:25:45.510: epoch 119:	0.04346434  	0.09508764  	0.07957184  
2023-08-31 17:25:45.510: Find a better model.
2023-08-31 17:26:05.529: [iter 120 : loss : 0.2370 = 0.0669 + 0.1626 + 0.0067 + 0.0008, time: 20.007357]
2023-08-31 17:26:06.166: epoch 120:	0.04354820  	0.09532391  	0.07965753  
2023-08-31 17:26:06.166: Find a better model.
2023-08-31 17:26:26.271: [iter 121 : loss : 0.2368 = 0.0672 + 0.1620 + 0.0067 + 0.0008, time: 20.092745]
2023-08-31 17:26:26.904: epoch 121:	0.04346432  	0.09504487  	0.07968726  
2023-08-31 17:26:47.132: [iter 122 : loss : 0.2344 = 0.0656 + 0.1611 + 0.0068 + 0.0008, time: 20.212163]
2023-08-31 17:26:47.846: epoch 122:	0.04348371  	0.09505729  	0.07963160  
2023-08-31 17:27:07.497: [iter 123 : loss : 0.2343 = 0.0663 + 0.1604 + 0.0069 + 0.0008, time: 19.640013]
2023-08-31 17:27:08.162: epoch 123:	0.04359982  	0.09538759  	0.07982402  
2023-08-31 17:27:08.162: Find a better model.
2023-08-31 17:27:27.757: [iter 124 : loss : 0.2330 = 0.0656 + 0.1596 + 0.0069 + 0.0008, time: 19.581547]
2023-08-31 17:27:28.382: epoch 124:	0.04363209  	0.09545599  	0.07995517  
2023-08-31 17:27:28.382: Find a better model.
2023-08-31 17:27:48.359: [iter 125 : loss : 0.2325 = 0.0659 + 0.1588 + 0.0070 + 0.0008, time: 19.966483]
2023-08-31 17:27:48.971: epoch 125:	0.04370949  	0.09555814  	0.08008383  
2023-08-31 17:27:48.972: Find a better model.
2023-08-31 17:28:09.203: [iter 126 : loss : 0.2315 = 0.0656 + 0.1581 + 0.0070 + 0.0008, time: 20.219558]
2023-08-31 17:28:09.820: epoch 126:	0.04378689  	0.09565154  	0.08000584  
2023-08-31 17:28:09.820: Find a better model.
2023-08-31 17:28:30.052: [iter 127 : loss : 0.2317 = 0.0665 + 0.1574 + 0.0071 + 0.0008, time: 20.223608]
2023-08-31 17:28:30.688: epoch 127:	0.04378689  	0.09579973  	0.08016331  
2023-08-31 17:28:30.688: Find a better model.
2023-08-31 17:28:51.025: [iter 128 : loss : 0.2300 = 0.0655 + 0.1566 + 0.0071 + 0.0008, time: 20.326531]
2023-08-31 17:28:51.698: epoch 128:	0.04381914  	0.09574375  	0.08020959  
2023-08-31 17:29:12.051: [iter 129 : loss : 0.2292 = 0.0653 + 0.1560 + 0.0072 + 0.0008, time: 20.339878]
2023-08-31 17:29:12.741: epoch 129:	0.04386430  	0.09593777  	0.08036442  
2023-08-31 17:29:12.741: Find a better model.
2023-08-31 17:29:32.982: [iter 130 : loss : 0.2277 = 0.0642 + 0.1554 + 0.0072 + 0.0008, time: 20.229625]
2023-08-31 17:29:33.626: epoch 130:	0.04383205  	0.09575642  	0.08038525  
2023-08-31 17:29:53.820: [iter 131 : loss : 0.2284 = 0.0658 + 0.1546 + 0.0073 + 0.0008, time: 20.181768]
2023-08-31 17:29:54.495: epoch 131:	0.04383852  	0.09615061  	0.08059747  
2023-08-31 17:29:54.495: Find a better model.
2023-08-31 17:30:14.710: [iter 132 : loss : 0.2256 = 0.0635 + 0.1540 + 0.0074 + 0.0008, time: 20.203631]
2023-08-31 17:30:15.319: epoch 132:	0.04382559  	0.09602392  	0.08045550  
2023-08-31 17:30:35.454: [iter 133 : loss : 0.2253 = 0.0639 + 0.1532 + 0.0074 + 0.0008, time: 20.125231]
2023-08-31 17:30:36.130: epoch 133:	0.04381271  	0.09598030  	0.08039316  
2023-08-31 17:30:56.384: [iter 134 : loss : 0.2257 = 0.0647 + 0.1527 + 0.0075 + 0.0008, time: 20.236392]
2023-08-31 17:30:57.038: epoch 134:	0.04389013  	0.09610321  	0.08046336  
2023-08-31 17:31:16.988: [iter 135 : loss : 0.2237 = 0.0635 + 0.1519 + 0.0075 + 0.0008, time: 19.939459]
2023-08-31 17:31:17.656: epoch 135:	0.04388366  	0.09607124  	0.08050387  
2023-08-31 17:31:37.775: [iter 136 : loss : 0.2228 = 0.0631 + 0.1513 + 0.0076 + 0.0008, time: 20.109082]
2023-08-31 17:31:38.462: epoch 136:	0.04394817  	0.09604572  	0.08043109  
2023-08-31 17:31:58.504: [iter 137 : loss : 0.2221 = 0.0631 + 0.1506 + 0.0076 + 0.0008, time: 20.031666]
2023-08-31 17:31:59.221: epoch 137:	0.04406428  	0.09644987  	0.08072396  
2023-08-31 17:31:59.221: Find a better model.
2023-08-31 17:32:19.290: [iter 138 : loss : 0.2216 = 0.0633 + 0.1500 + 0.0077 + 0.0008, time: 20.056334]
2023-08-31 17:32:19.848: epoch 138:	0.04402556  	0.09642472  	0.08076011  
2023-08-31 17:32:39.932: [iter 139 : loss : 0.2202 = 0.0625 + 0.1493 + 0.0077 + 0.0008, time: 20.076083]
2023-08-31 17:32:40.636: epoch 139:	0.04409005  	0.09667534  	0.08080289  
2023-08-31 17:32:40.636: Find a better model.
2023-08-31 17:33:00.477: [iter 140 : loss : 0.2207 = 0.0635 + 0.1487 + 0.0078 + 0.0007, time: 19.831290]
2023-08-31 17:33:01.109: epoch 140:	0.04403199  	0.09638268  	0.08073826  
2023-08-31 17:33:21.067: [iter 141 : loss : 0.2203 = 0.0635 + 0.1482 + 0.0078 + 0.0007, time: 19.948975]
2023-08-31 17:33:21.678: epoch 141:	0.04413525  	0.09672993  	0.08097475  
2023-08-31 17:33:21.678: Find a better model.
2023-08-31 17:33:41.726: [iter 142 : loss : 0.2183 = 0.0622 + 0.1474 + 0.0079 + 0.0007, time: 20.037762]
2023-08-31 17:33:42.420: epoch 142:	0.04403846  	0.09651418  	0.08091553  
2023-08-31 17:34:02.468: [iter 143 : loss : 0.2180 = 0.0624 + 0.1470 + 0.0079 + 0.0007, time: 20.038343]
2023-08-31 17:34:03.192: epoch 143:	0.04397397  	0.09631588  	0.08102215  
2023-08-31 17:34:23.315: [iter 144 : loss : 0.2173 = 0.0622 + 0.1463 + 0.0080 + 0.0007, time: 20.111831]
2023-08-31 17:34:24.014: epoch 144:	0.04407717  	0.09664954  	0.08106536  
2023-08-31 17:34:43.950: [iter 145 : loss : 0.2168 = 0.0623 + 0.1458 + 0.0080 + 0.0007, time: 19.925804]
2023-08-31 17:34:44.653: epoch 145:	0.04429004  	0.09723963  	0.08142032  
2023-08-31 17:34:44.653: Find a better model.
2023-08-31 17:35:04.535: [iter 146 : loss : 0.2164 = 0.0624 + 0.1452 + 0.0081 + 0.0007, time: 19.869444]
2023-08-31 17:35:05.195: epoch 146:	0.04423198  	0.09702091  	0.08139373  
2023-08-31 17:35:25.140: [iter 147 : loss : 0.2157 = 0.0620 + 0.1448 + 0.0081 + 0.0007, time: 19.933429]
2023-08-31 17:35:25.813: epoch 147:	0.04421261  	0.09699896  	0.08150735  
2023-08-31 17:35:45.699: [iter 148 : loss : 0.2152 = 0.0622 + 0.1441 + 0.0082 + 0.0007, time: 19.873049]
2023-08-31 17:35:46.335: epoch 148:	0.04418683  	0.09687846  	0.08143060  
2023-08-31 17:36:06.284: [iter 149 : loss : 0.2132 = 0.0609 + 0.1434 + 0.0082 + 0.0007, time: 19.939937]
2023-08-31 17:36:06.999: epoch 149:	0.04430941  	0.09723787  	0.08150336  
2023-08-31 17:36:27.231: [iter 150 : loss : 0.2137 = 0.0617 + 0.1430 + 0.0083 + 0.0007, time: 20.221896]
2023-08-31 17:36:27.850: epoch 150:	0.04432227  	0.09700539  	0.08145901  
2023-08-31 17:36:47.889: [iter 151 : loss : 0.2133 = 0.0619 + 0.1423 + 0.0083 + 0.0007, time: 20.028175]
2023-08-31 17:36:48.482: epoch 151:	0.04425778  	0.09704953  	0.08150256  
2023-08-31 17:37:07.470: [iter 152 : loss : 0.2126 = 0.0616 + 0.1418 + 0.0084 + 0.0007, time: 18.975567]
2023-08-31 17:37:08.084: epoch 152:	0.04437390  	0.09735581  	0.08160321  
2023-08-31 17:37:08.084: Find a better model.
2023-08-31 17:37:27.870: [iter 153 : loss : 0.2120 = 0.0614 + 0.1414 + 0.0084 + 0.0007, time: 19.776978]
2023-08-31 17:37:28.513: epoch 153:	0.04441904  	0.09728296  	0.08163496  
2023-08-31 17:37:48.276: [iter 154 : loss : 0.2111 = 0.0610 + 0.1408 + 0.0085 + 0.0007, time: 19.752361]
2023-08-31 17:37:48.938: epoch 154:	0.04449001  	0.09745470  	0.08181063  
2023-08-31 17:37:48.938: Find a better model.
2023-08-31 17:38:08.614: [iter 155 : loss : 0.2096 = 0.0601 + 0.1402 + 0.0085 + 0.0007, time: 19.665935]
2023-08-31 17:38:09.238: epoch 155:	0.04447066  	0.09747864  	0.08175154  
2023-08-31 17:38:09.238: Find a better model.
2023-08-31 17:38:29.277: [iter 156 : loss : 0.2094 = 0.0603 + 0.1398 + 0.0086 + 0.0007, time: 20.027558]
2023-08-31 17:38:29.946: epoch 156:	0.04454163  	0.09767520  	0.08193891  
2023-08-31 17:38:29.946: Find a better model.
2023-08-31 17:38:50.239: [iter 157 : loss : 0.2094 = 0.0607 + 0.1393 + 0.0086 + 0.0007, time: 20.280022]
2023-08-31 17:38:50.899: epoch 157:	0.04454162  	0.09769299  	0.08178456  
2023-08-31 17:38:50.899: Find a better model.
2023-08-31 17:39:11.050: [iter 158 : loss : 0.2093 = 0.0612 + 0.1387 + 0.0087 + 0.0007, time: 20.140320]
2023-08-31 17:39:11.671: epoch 158:	0.04451582  	0.09763379  	0.08183795  
2023-08-31 17:39:31.717: [iter 159 : loss : 0.2074 = 0.0598 + 0.1381 + 0.0087 + 0.0007, time: 20.029694]
2023-08-31 17:39:32.420: epoch 159:	0.04454809  	0.09769579  	0.08184108  
2023-08-31 17:39:32.420: Find a better model.
2023-08-31 17:39:52.433: [iter 160 : loss : 0.2071 = 0.0597 + 0.1380 + 0.0088 + 0.0007, time: 20.001849]
2023-08-31 17:39:53.145: epoch 160:	0.04450294  	0.09760667  	0.08170008  
2023-08-31 17:40:13.089: [iter 161 : loss : 0.2068 = 0.0599 + 0.1374 + 0.0088 + 0.0007, time: 19.929447]
2023-08-31 17:40:13.781: epoch 161:	0.04454810  	0.09755138  	0.08170901  
2023-08-31 17:40:32.722: [iter 162 : loss : 0.2060 = 0.0596 + 0.1369 + 0.0089 + 0.0007, time: 18.930758]
2023-08-31 17:40:33.295: epoch 162:	0.04461908  	0.09755731  	0.08179656  
2023-08-31 17:40:52.965: [iter 163 : loss : 0.2055 = 0.0594 + 0.1364 + 0.0089 + 0.0007, time: 19.658896]
2023-08-31 17:40:53.623: epoch 163:	0.04463842  	0.09771063  	0.08192328  
2023-08-31 17:40:53.623: Find a better model.
2023-08-31 17:41:13.766: [iter 164 : loss : 0.2052 = 0.0597 + 0.1358 + 0.0090 + 0.0007, time: 20.130403]
2023-08-31 17:41:14.415: epoch 164:	0.04467712  	0.09784642  	0.08201455  
2023-08-31 17:41:14.416: Find a better model.
2023-08-31 17:41:34.443: [iter 165 : loss : 0.2047 = 0.0597 + 0.1353 + 0.0090 + 0.0007, time: 20.018649]
2023-08-31 17:41:35.063: epoch 165:	0.04466422  	0.09781342  	0.08191559  
2023-08-31 17:41:54.011: [iter 166 : loss : 0.2038 = 0.0592 + 0.1349 + 0.0091 + 0.0007, time: 18.939245]
2023-08-31 17:41:54.649: epoch 166:	0.04472227  	0.09804345  	0.08195719  
2023-08-31 17:41:54.650: Find a better model.
2023-08-31 17:42:14.596: [iter 167 : loss : 0.2044 = 0.0602 + 0.1345 + 0.0091 + 0.0007, time: 19.934247]
2023-08-31 17:42:15.207: epoch 167:	0.04475456  	0.09801610  	0.08207402  
2023-08-31 17:42:35.041: [iter 168 : loss : 0.2027 = 0.0588 + 0.1341 + 0.0092 + 0.0007, time: 19.823586]
2023-08-31 17:42:35.711: epoch 168:	0.04480615  	0.09830844  	0.08225257  
2023-08-31 17:42:35.711: Find a better model.
2023-08-31 17:42:55.664: [iter 169 : loss : 0.2036 = 0.0602 + 0.1335 + 0.0092 + 0.0007, time: 19.944824]
2023-08-31 17:42:56.298: epoch 169:	0.04482552  	0.09812789  	0.08211560  
2023-08-31 17:43:16.076: [iter 170 : loss : 0.2019 = 0.0587 + 0.1333 + 0.0092 + 0.0007, time: 19.767565]
2023-08-31 17:43:16.735: epoch 170:	0.04484489  	0.09822376  	0.08224189  
2023-08-31 17:43:36.577: [iter 171 : loss : 0.2016 = 0.0588 + 0.1328 + 0.0093 + 0.0007, time: 19.831920]
2023-08-31 17:43:37.188: epoch 171:	0.04474166  	0.09798921  	0.08214778  
2023-08-31 17:43:56.805: [iter 172 : loss : 0.2010 = 0.0586 + 0.1324 + 0.0093 + 0.0007, time: 19.605725]
2023-08-31 17:43:57.430: epoch 172:	0.04481907  	0.09817489  	0.08222695  
2023-08-31 17:44:17.061: [iter 173 : loss : 0.2006 = 0.0586 + 0.1320 + 0.0094 + 0.0007, time: 19.621001]
2023-08-31 17:44:17.662: epoch 173:	0.04489004  	0.09835793  	0.08239821  
2023-08-31 17:44:17.662: Find a better model.
2023-08-31 17:44:36.654: [iter 174 : loss : 0.2000 = 0.0585 + 0.1314 + 0.0094 + 0.0007, time: 18.978464]
2023-08-31 17:44:37.310: epoch 174:	0.04472876  	0.09786158  	0.08217091  
2023-08-31 17:44:56.872: [iter 175 : loss : 0.2006 = 0.0594 + 0.1311 + 0.0095 + 0.0007, time: 19.551966]
2023-08-31 17:44:57.483: epoch 175:	0.04483195  	0.09827711  	0.08237872  
2023-08-31 17:45:17.432: [iter 176 : loss : 0.1988 = 0.0580 + 0.1307 + 0.0095 + 0.0007, time: 19.936986]
2023-08-31 17:45:18.116: epoch 176:	0.04485776  	0.09821895  	0.08241740  
2023-08-31 17:45:38.201: [iter 177 : loss : 0.1994 = 0.0588 + 0.1303 + 0.0095 + 0.0007, time: 20.072572]
2023-08-31 17:45:38.830: epoch 177:	0.04472228  	0.09797924  	0.08238246  
2023-08-31 17:45:58.880: [iter 178 : loss : 0.1972 = 0.0570 + 0.1299 + 0.0096 + 0.0007, time: 20.040231]
2023-08-31 17:45:59.556: epoch 178:	0.04478681  	0.09794604  	0.08237558  
2023-08-31 17:46:19.507: [iter 179 : loss : 0.1981 = 0.0582 + 0.1297 + 0.0096 + 0.0007, time: 19.937369]
2023-08-31 17:46:20.136: epoch 179:	0.04473519  	0.09772078  	0.08235017  
2023-08-31 17:46:40.017: [iter 180 : loss : 0.1980 = 0.0585 + 0.1292 + 0.0097 + 0.0007, time: 19.870210]
2023-08-31 17:46:40.641: epoch 180:	0.04474809  	0.09776331  	0.08234816  
2023-08-31 17:47:00.493: [iter 181 : loss : 0.1974 = 0.0582 + 0.1288 + 0.0097 + 0.0006, time: 19.838596]
2023-08-31 17:47:01.106: epoch 181:	0.04479327  	0.09800085  	0.08238112  
2023-08-31 17:47:21.325: [iter 182 : loss : 0.1966 = 0.0578 + 0.1284 + 0.0098 + 0.0006, time: 20.204385]
2023-08-31 17:47:22.026: epoch 182:	0.04478681  	0.09801932  	0.08238841  
2023-08-31 17:47:41.939: [iter 183 : loss : 0.1958 = 0.0574 + 0.1279 + 0.0098 + 0.0006, time: 19.903215]
2023-08-31 17:47:42.560: epoch 183:	0.04475455  	0.09796752  	0.08237367  
2023-08-31 17:47:42.560: Early stopping is trigger at epoch: 183
2023-08-31 17:47:42.560: best_result@epoch 173:

2023-08-31 17:47:42.560: 		0.0449      	0.0984      	0.0824      

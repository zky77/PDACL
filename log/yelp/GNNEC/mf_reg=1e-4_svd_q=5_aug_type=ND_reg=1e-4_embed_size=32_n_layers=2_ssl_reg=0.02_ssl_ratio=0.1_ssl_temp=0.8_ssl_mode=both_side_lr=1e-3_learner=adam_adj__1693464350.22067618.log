2023-08-31 14:45:50.222: my pid: 29739
2023-08-31 14:45:50.222: model: model.general_recommender.GNNEC
2023-08-31 14:45:50.222: Dataset statistics:
Name: yelp
The number of users: 7750
The number of items: 28918
The number of ratings: 750318
Average actions of users: 96.82
Average actions of items: 25.95
The sparsity of the dataset: 99.665208%

The number of training: 678579
The number of validation: 0
The number of testing: 71739
2023-08-31 14:45:50.223: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=yelp
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.8
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=yelp
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.8
mf_reg=1e-4
svd_q=5
2023-08-31 14:46:09.587: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-08-31 14:46:35.011: [iter 1 : loss : 0.8670 = 0.5094 + 0.3558 + 0.0001 + 0.0018, time: 25.423718]
2023-08-31 14:46:35.681: epoch 1:	0.02534246  	0.05478678  	0.04669296  
2023-08-31 14:46:35.681: Find a better model.
2023-08-31 14:47:00.593: [iter 2 : loss : 0.6065 = 0.2754 + 0.3291 + 0.0003 + 0.0017, time: 24.889240]
2023-08-31 14:47:01.262: epoch 2:	0.02521988  	0.05436189  	0.04649296  
2023-08-31 14:47:25.916: [iter 3 : loss : 0.5643 = 0.2397 + 0.3225 + 0.0004 + 0.0016, time: 24.631013]
2023-08-31 14:47:26.601: epoch 3:	0.02531665  	0.05467873  	0.04647856  
2023-08-31 14:47:51.123: [iter 4 : loss : 0.5472 = 0.2259 + 0.3192 + 0.0005 + 0.0016, time: 24.502742]
2023-08-31 14:47:51.763: epoch 4:	0.02551020  	0.05507238  	0.04664078  
2023-08-31 14:47:51.763: Find a better model.
2023-08-31 14:48:16.328: [iter 5 : loss : 0.5365 = 0.2173 + 0.3170 + 0.0006 + 0.0016, time: 24.544855]
2023-08-31 14:48:16.893: epoch 5:	0.02549730  	0.05496517  	0.04672497  
2023-08-31 14:48:41.317: [iter 6 : loss : 0.5275 = 0.2102 + 0.3152 + 0.0006 + 0.0016, time: 24.407560]
2023-08-31 14:48:41.949: epoch 6:	0.02589085  	0.05591834  	0.04701897  
2023-08-31 14:48:41.949: Find a better model.
2023-08-31 14:49:06.616: [iter 7 : loss : 0.5157 = 0.2000 + 0.3134 + 0.0007 + 0.0016, time: 24.642037]
2023-08-31 14:49:07.317: epoch 7:	0.02596183  	0.05605522  	0.04732884  
2023-08-31 14:49:07.317: Find a better model.
2023-08-31 14:49:31.837: [iter 8 : loss : 0.5070 = 0.1929 + 0.3118 + 0.0007 + 0.0016, time: 24.499417]
2023-08-31 14:49:32.459: epoch 8:	0.02625217  	0.05685562  	0.04787092  
2023-08-31 14:49:32.459: Find a better model.
2023-08-31 14:49:57.086: [iter 9 : loss : 0.4991 = 0.1864 + 0.3104 + 0.0008 + 0.0016, time: 24.607170]
2023-08-31 14:49:57.714: epoch 9:	0.02641347  	0.05700777  	0.04820146  
2023-08-31 14:49:57.714: Find a better model.
2023-08-31 14:50:22.441: [iter 10 : loss : 0.4912 = 0.1799 + 0.3089 + 0.0008 + 0.0016, time: 24.706709]
2023-08-31 14:50:23.119: epoch 10:	0.02670380  	0.05763143  	0.04851142  
2023-08-31 14:50:23.119: Find a better model.
2023-08-31 14:50:47.753: [iter 11 : loss : 0.4846 = 0.1744 + 0.3077 + 0.0009 + 0.0016, time: 24.614442]
2023-08-31 14:50:48.432: epoch 11:	0.02694252  	0.05843226  	0.04905927  
2023-08-31 14:50:48.432: Find a better model.
2023-08-31 14:51:13.079: [iter 12 : loss : 0.4778 = 0.1690 + 0.3063 + 0.0009 + 0.0015, time: 24.624703]
2023-08-31 14:51:13.709: epoch 12:	0.02733608  	0.05915328  	0.04966993  
2023-08-31 14:51:13.709: Find a better model.
2023-08-31 14:51:38.379: [iter 13 : loss : 0.4730 = 0.1653 + 0.3052 + 0.0010 + 0.0015, time: 24.650402]
2023-08-31 14:51:39.083: epoch 13:	0.02758125  	0.05961135  	0.05013939  
2023-08-31 14:51:39.084: Find a better model.
2023-08-31 14:52:03.747: [iter 14 : loss : 0.4665 = 0.1598 + 0.3041 + 0.0010 + 0.0015, time: 24.644260]
2023-08-31 14:52:04.473: epoch 14:	0.02767158  	0.05994914  	0.05020241  
2023-08-31 14:52:04.474: Find a better model.
2023-08-31 14:52:29.282: [iter 15 : loss : 0.4633 = 0.1575 + 0.3031 + 0.0011 + 0.0015, time: 24.785049]
2023-08-31 14:52:29.936: epoch 15:	0.02771674  	0.05982272  	0.05020707  
2023-08-31 14:52:54.805: [iter 16 : loss : 0.4595 = 0.1548 + 0.3021 + 0.0012 + 0.0015, time: 24.848738]
2023-08-31 14:52:55.434: epoch 16:	0.02786513  	0.06011220  	0.05025810  
2023-08-31 14:52:55.434: Find a better model.
2023-08-31 14:53:20.122: [iter 17 : loss : 0.4543 = 0.1505 + 0.3011 + 0.0012 + 0.0015, time: 24.669824]
2023-08-31 14:53:20.780: epoch 17:	0.02797483  	0.06045367  	0.05061935  
2023-08-31 14:53:20.780: Find a better model.
2023-08-31 14:53:45.881: [iter 18 : loss : 0.4519 = 0.1490 + 0.3001 + 0.0013 + 0.0015, time: 25.079121]
2023-08-31 14:53:46.592: epoch 18:	0.02817483  	0.06095589  	0.05077951  
2023-08-31 14:53:46.592: Find a better model.
2023-08-31 14:54:11.547: [iter 19 : loss : 0.4473 = 0.1454 + 0.2991 + 0.0013 + 0.0015, time: 24.936082]
2023-08-31 14:54:12.251: epoch 19:	0.02820707  	0.06084998  	0.05082250  
2023-08-31 14:54:37.197: [iter 20 : loss : 0.4439 = 0.1428 + 0.2982 + 0.0014 + 0.0015, time: 24.926462]
2023-08-31 14:54:37.861: epoch 20:	0.02847805  	0.06153127  	0.05127744  
2023-08-31 14:54:37.861: Find a better model.
2023-08-31 14:55:02.692: [iter 21 : loss : 0.4396 = 0.1395 + 0.2972 + 0.0014 + 0.0015, time: 24.810663]
2023-08-31 14:55:03.309: epoch 21:	0.02867807  	0.06193249  	0.05172027  
2023-08-31 14:55:03.309: Find a better model.
2023-08-31 14:55:29.046: [iter 22 : loss : 0.4365 = 0.1372 + 0.2963 + 0.0015 + 0.0015, time: 25.719219]
2023-08-31 14:55:29.751: epoch 22:	0.02884581  	0.06222878  	0.05197274  
2023-08-31 14:55:29.751: Find a better model.
2023-08-31 14:55:54.817: [iter 23 : loss : 0.4332 = 0.1348 + 0.2954 + 0.0016 + 0.0015, time: 25.036490]
2023-08-31 14:55:55.478: epoch 23:	0.02916841  	0.06292664  	0.05242951  
2023-08-31 14:55:55.478: Find a better model.
2023-08-31 14:56:20.047: [iter 24 : loss : 0.4314 = 0.1338 + 0.2945 + 0.0016 + 0.0015, time: 24.544792]
2023-08-31 14:56:20.677: epoch 24:	0.02911033  	0.06288178  	0.05246919  
2023-08-31 14:56:45.862: [iter 25 : loss : 0.4277 = 0.1310 + 0.2936 + 0.0017 + 0.0015, time: 25.163523]
2023-08-31 14:56:46.518: epoch 25:	0.02948456  	0.06367523  	0.05293232  
2023-08-31 14:56:46.519: Find a better model.
2023-08-31 14:57:11.238: [iter 26 : loss : 0.4249 = 0.1291 + 0.2926 + 0.0017 + 0.0015, time: 24.691016]
2023-08-31 14:57:11.894: epoch 26:	0.02978778  	0.06420495  	0.05322928  
2023-08-31 14:57:11.894: Find a better model.
2023-08-31 14:57:36.823: [iter 27 : loss : 0.4210 = 0.1260 + 0.2917 + 0.0018 + 0.0015, time: 24.903543]
2023-08-31 14:57:37.515: epoch 27:	0.02974907  	0.06418087  	0.05340414  
2023-08-31 14:58:02.474: [iter 28 : loss : 0.4188 = 0.1248 + 0.2907 + 0.0018 + 0.0015, time: 24.930776]
2023-08-31 14:58:03.136: epoch 28:	0.03005231  	0.06505772  	0.05393349  
2023-08-31 14:58:03.136: Find a better model.
2023-08-31 14:58:28.039: [iter 29 : loss : 0.4168 = 0.1236 + 0.2898 + 0.0019 + 0.0015, time: 24.878461]
2023-08-31 14:58:28.670: epoch 29:	0.03042007  	0.06577212  	0.05443696  
2023-08-31 14:58:28.670: Find a better model.
2023-08-31 14:58:53.913: [iter 30 : loss : 0.4140 = 0.1216 + 0.2890 + 0.0020 + 0.0015, time: 25.225511]
2023-08-31 14:58:54.639: epoch 30:	0.03072331  	0.06655826  	0.05490093  
2023-08-31 14:58:54.639: Find a better model.
2023-08-31 14:59:19.928: [iter 31 : loss : 0.4110 = 0.1195 + 0.2880 + 0.0020 + 0.0014, time: 25.262186]
2023-08-31 14:59:20.584: epoch 31:	0.03080072  	0.06672801  	0.05507583  
2023-08-31 14:59:20.584: Find a better model.
2023-08-31 14:59:45.742: [iter 32 : loss : 0.4078 = 0.1172 + 0.2870 + 0.0021 + 0.0014, time: 25.134578]
2023-08-31 14:59:46.435: epoch 32:	0.03109107  	0.06753857  	0.05560080  
2023-08-31 14:59:46.435: Find a better model.
2023-08-31 15:00:11.464: [iter 33 : loss : 0.4055 = 0.1158 + 0.2861 + 0.0021 + 0.0014, time: 25.007202]
2023-08-31 15:00:12.132: epoch 33:	0.03116849  	0.06743814  	0.05571222  
2023-08-31 15:00:37.261: [iter 34 : loss : 0.4034 = 0.1146 + 0.2851 + 0.0022 + 0.0014, time: 25.102910]
2023-08-31 15:00:37.942: epoch 34:	0.03140075  	0.06805810  	0.05614194  
2023-08-31 15:00:37.943: Find a better model.
2023-08-31 15:01:03.209: [iter 35 : loss : 0.4012 = 0.1132 + 0.2843 + 0.0023 + 0.0014, time: 25.238172]
2023-08-31 15:01:03.915: epoch 35:	0.03165882  	0.06875301  	0.05656264  
2023-08-31 15:01:03.915: Find a better model.
2023-08-31 15:01:29.156: [iter 36 : loss : 0.3989 = 0.1120 + 0.2832 + 0.0023 + 0.0014, time: 25.212472]
2023-08-31 15:01:29.797: epoch 36:	0.03171044  	0.06890621  	0.05678584  
2023-08-31 15:01:29.797: Find a better model.
2023-08-31 15:01:55.026: [iter 37 : loss : 0.3963 = 0.1101 + 0.2824 + 0.0024 + 0.0014, time: 25.204901]
2023-08-31 15:01:55.660: epoch 37:	0.03207820  	0.06967431  	0.05715830  
2023-08-31 15:01:55.660: Find a better model.
2023-08-31 15:02:20.669: [iter 38 : loss : 0.3936 = 0.1081 + 0.2816 + 0.0024 + 0.0014, time: 24.986273]
2023-08-31 15:02:21.345: epoch 38:	0.03244594  	0.07066135  	0.05776938  
2023-08-31 15:02:21.345: Find a better model.
2023-08-31 15:02:46.504: [iter 39 : loss : 0.3916 = 0.1071 + 0.2806 + 0.0025 + 0.0014, time: 25.135875]
2023-08-31 15:02:47.152: epoch 39:	0.03259433  	0.07079151  	0.05794287  
2023-08-31 15:02:47.152: Find a better model.
2023-08-31 15:03:12.453: [iter 40 : loss : 0.3896 = 0.1060 + 0.2797 + 0.0026 + 0.0014, time: 25.273384]
2023-08-31 15:03:13.101: epoch 40:	0.03299434  	0.07164685  	0.05866044  
2023-08-31 15:03:13.102: Find a better model.
2023-08-31 15:03:38.218: [iter 41 : loss : 0.3868 = 0.1040 + 0.2787 + 0.0026 + 0.0014, time: 25.089096]
2023-08-31 15:03:38.868: epoch 41:	0.03301368  	0.07179999  	0.05877799  
2023-08-31 15:03:38.868: Find a better model.
2023-08-31 15:04:04.083: [iter 42 : loss : 0.3852 = 0.1032 + 0.2779 + 0.0027 + 0.0014, time: 25.186700]
2023-08-31 15:04:04.716: epoch 42:	0.03326526  	0.07240760  	0.05914114  
2023-08-31 15:04:04.716: Find a better model.
2023-08-31 15:04:29.859: [iter 43 : loss : 0.3831 = 0.1019 + 0.2770 + 0.0028 + 0.0014, time: 25.121209]
2023-08-31 15:04:30.529: epoch 43:	0.03358136  	0.07297198  	0.05959526  
2023-08-31 15:04:30.529: Find a better model.
2023-08-31 15:04:55.831: [iter 44 : loss : 0.3812 = 0.1009 + 0.2760 + 0.0028 + 0.0014, time: 25.273024]
2023-08-31 15:04:56.416: epoch 44:	0.03374265  	0.07324814  	0.05995850  
2023-08-31 15:04:56.416: Find a better model.
2023-08-31 15:05:21.477: [iter 45 : loss : 0.3795 = 0.1000 + 0.2752 + 0.0029 + 0.0014, time: 25.037244]
2023-08-31 15:05:22.139: epoch 45:	0.03387813  	0.07363426  	0.06038518  
2023-08-31 15:05:22.139: Find a better model.
2023-08-31 15:05:47.513: [iter 46 : loss : 0.3779 = 0.0993 + 0.2743 + 0.0030 + 0.0014, time: 25.340443]
2023-08-31 15:05:48.110: epoch 46:	0.03392973  	0.07372775  	0.06056489  
2023-08-31 15:05:48.110: Find a better model.
2023-08-31 15:06:13.177: [iter 47 : loss : 0.3749 = 0.0972 + 0.2733 + 0.0030 + 0.0014, time: 25.039250]
2023-08-31 15:06:13.834: epoch 47:	0.03411681  	0.07429253  	0.06106977  
2023-08-31 15:06:13.834: Find a better model.
2023-08-31 15:06:39.010: [iter 48 : loss : 0.3738 = 0.0968 + 0.2726 + 0.0031 + 0.0014, time: 25.149906]
2023-08-31 15:06:39.629: epoch 48:	0.03438776  	0.07486251  	0.06144771  
2023-08-31 15:06:39.630: Find a better model.
2023-08-31 15:07:04.620: [iter 49 : loss : 0.3716 = 0.0955 + 0.2716 + 0.0031 + 0.0014, time: 24.965530]
2023-08-31 15:07:05.266: epoch 49:	0.03469741  	0.07566684  	0.06216133  
2023-08-31 15:07:05.266: Find a better model.
2023-08-31 15:07:30.424: [iter 50 : loss : 0.3705 = 0.0951 + 0.2708 + 0.0032 + 0.0014, time: 25.132827]
2023-08-31 15:07:31.082: epoch 50:	0.03494897  	0.07619864  	0.06263945  
2023-08-31 15:07:31.083: Find a better model.
2023-08-31 15:07:56.363: [iter 51 : loss : 0.3684 = 0.0938 + 0.2699 + 0.0033 + 0.0014, time: 25.252245]
2023-08-31 15:07:56.996: epoch 51:	0.03502638  	0.07629324  	0.06275500  
2023-08-31 15:07:56.996: Find a better model.
2023-08-31 15:08:22.064: [iter 52 : loss : 0.3666 = 0.0929 + 0.2691 + 0.0033 + 0.0013, time: 25.044409]
2023-08-31 15:08:22.639: epoch 52:	0.03520057  	0.07645562  	0.06295687  
2023-08-31 15:08:22.639: Find a better model.
2023-08-31 15:08:47.657: [iter 53 : loss : 0.3650 = 0.0920 + 0.2682 + 0.0034 + 0.0013, time: 24.996642]
2023-08-31 15:08:48.316: epoch 53:	0.03527800  	0.07661122  	0.06330691  
2023-08-31 15:08:48.316: Find a better model.
2023-08-31 15:09:13.536: [iter 54 : loss : 0.3632 = 0.0908 + 0.2675 + 0.0035 + 0.0013, time: 25.190059]
2023-08-31 15:09:14.169: epoch 54:	0.03547799  	0.07699439  	0.06378185  
2023-08-31 15:09:14.169: Find a better model.
2023-08-31 15:09:39.214: [iter 55 : loss : 0.3622 = 0.0908 + 0.2665 + 0.0035 + 0.0013, time: 25.020465]
2023-08-31 15:09:39.833: epoch 55:	0.03569083  	0.07748024  	0.06410015  
2023-08-31 15:09:39.833: Find a better model.
2023-08-31 15:10:05.073: [iter 56 : loss : 0.3602 = 0.0895 + 0.2657 + 0.0036 + 0.0013, time: 25.217934]
2023-08-31 15:10:05.711: epoch 56:	0.03581339  	0.07777697  	0.06438679  
2023-08-31 15:10:05.711: Find a better model.
2023-08-31 15:10:30.871: [iter 57 : loss : 0.3587 = 0.0889 + 0.2649 + 0.0037 + 0.0013, time: 25.133103]
2023-08-31 15:10:31.455: epoch 57:	0.03621984  	0.07859601  	0.06486458  
2023-08-31 15:10:31.455: Find a better model.
2023-08-31 15:10:56.612: [iter 58 : loss : 0.3582 = 0.0890 + 0.2642 + 0.0037 + 0.0013, time: 25.128067]
2023-08-31 15:10:57.275: epoch 58:	0.03638111  	0.07913528  	0.06527347  
2023-08-31 15:10:57.275: Find a better model.
2023-08-31 15:11:22.139: [iter 59 : loss : 0.3560 = 0.0878 + 0.2631 + 0.0038 + 0.0013, time: 24.836176]
2023-08-31 15:11:22.789: epoch 59:	0.03646497  	0.07925967  	0.06539906  
2023-08-31 15:11:22.789: Find a better model.
2023-08-31 15:11:47.790: [iter 60 : loss : 0.3548 = 0.0871 + 0.2626 + 0.0038 + 0.0013, time: 24.978361]
2023-08-31 15:11:48.404: epoch 60:	0.03681978  	0.08007967  	0.06606083  
2023-08-31 15:11:48.404: Find a better model.
2023-08-31 15:12:13.339: [iter 61 : loss : 0.3526 = 0.0857 + 0.2616 + 0.0039 + 0.0013, time: 24.913133]
2023-08-31 15:12:13.963: epoch 61:	0.03711006  	0.08073397  	0.06653421  
2023-08-31 15:12:13.963: Find a better model.
2023-08-31 15:12:38.449: [iter 62 : loss : 0.3518 = 0.0857 + 0.2609 + 0.0040 + 0.0013, time: 24.459533]
2023-08-31 15:12:39.113: epoch 62:	0.03717456  	0.08109734  	0.06687763  
2023-08-31 15:12:39.113: Find a better model.
2023-08-31 15:13:04.152: [iter 63 : loss : 0.3496 = 0.0842 + 0.2601 + 0.0040 + 0.0013, time: 25.016905]
2023-08-31 15:13:04.918: epoch 63:	0.03729713  	0.08122831  	0.06700215  
2023-08-31 15:13:04.918: Find a better model.
2023-08-31 15:13:29.971: [iter 64 : loss : 0.3484 = 0.0836 + 0.2594 + 0.0041 + 0.0013, time: 25.030877]
2023-08-31 15:13:30.617: epoch 64:	0.03743907  	0.08149640  	0.06719178  
2023-08-31 15:13:30.618: Find a better model.
2023-08-31 15:13:55.627: [iter 65 : loss : 0.3477 = 0.0836 + 0.2586 + 0.0042 + 0.0013, time: 24.982304]
2023-08-31 15:13:56.293: epoch 65:	0.03763905  	0.08229555  	0.06769093  
2023-08-31 15:13:56.293: Find a better model.
2023-08-31 15:14:21.381: [iter 66 : loss : 0.3453 = 0.0821 + 0.2577 + 0.0042 + 0.0013, time: 25.071985]
2023-08-31 15:14:22.087: epoch 66:	0.03786483  	0.08263508  	0.06805746  
2023-08-31 15:14:22.087: Find a better model.
2023-08-31 15:14:47.068: [iter 67 : loss : 0.3444 = 0.0819 + 0.2570 + 0.0043 + 0.0013, time: 24.959329]
2023-08-31 15:14:47.713: epoch 67:	0.03805836  	0.08312887  	0.06856305  
2023-08-31 15:14:47.713: Find a better model.
2023-08-31 15:15:12.498: [iter 68 : loss : 0.3439 = 0.0820 + 0.2562 + 0.0044 + 0.0013, time: 24.760672]
2023-08-31 15:15:13.091: epoch 68:	0.03840669  	0.08390465  	0.06907330  
2023-08-31 15:15:13.091: Find a better model.
2023-08-31 15:15:37.643: [iter 69 : loss : 0.3426 = 0.0814 + 0.2555 + 0.0044 + 0.0013, time: 24.531471]
2023-08-31 15:15:38.275: epoch 69:	0.03857440  	0.08405132  	0.06910849  
2023-08-31 15:15:38.275: Find a better model.
2023-08-31 15:16:03.035: [iter 70 : loss : 0.3417 = 0.0811 + 0.2548 + 0.0045 + 0.0013, time: 24.740324]
2023-08-31 15:16:03.648: epoch 70:	0.03863247  	0.08435981  	0.06952355  
2023-08-31 15:16:03.649: Find a better model.
2023-08-31 15:16:28.385: [iter 71 : loss : 0.3393 = 0.0795 + 0.2540 + 0.0045 + 0.0013, time: 24.715470]
2023-08-31 15:16:29.062: epoch 71:	0.03892920  	0.08499534  	0.06997839  
2023-08-31 15:16:29.062: Find a better model.
2023-08-31 15:16:53.721: [iter 72 : loss : 0.3387 = 0.0797 + 0.2531 + 0.0046 + 0.0013, time: 24.638745]
2023-08-31 15:16:54.358: epoch 72:	0.03916791  	0.08563415  	0.07026608  
2023-08-31 15:16:54.358: Find a better model.
2023-08-31 15:17:19.142: [iter 73 : loss : 0.3372 = 0.0787 + 0.2525 + 0.0047 + 0.0013, time: 24.757233]
2023-08-31 15:17:19.787: epoch 73:	0.03910340  	0.08545953  	0.07038965  
2023-08-31 15:17:44.771: [iter 74 : loss : 0.3359 = 0.0782 + 0.2517 + 0.0047 + 0.0013, time: 24.958628]
2023-08-31 15:17:45.470: epoch 74:	0.03940661  	0.08602800  	0.07079490  
2023-08-31 15:17:45.471: Find a better model.
2023-08-31 15:18:10.367: [iter 75 : loss : 0.3346 = 0.0777 + 0.2509 + 0.0048 + 0.0013, time: 24.875721]
2023-08-31 15:18:11.086: epoch 75:	0.03945178  	0.08609229  	0.07075673  
2023-08-31 15:18:11.086: Find a better model.
2023-08-31 15:18:35.808: [iter 76 : loss : 0.3342 = 0.0777 + 0.2504 + 0.0049 + 0.0013, time: 24.700756]
2023-08-31 15:18:36.469: epoch 76:	0.03963889  	0.08649949  	0.07106275  
2023-08-31 15:18:36.469: Find a better model.
2023-08-31 15:19:00.963: [iter 77 : loss : 0.3324 = 0.0766 + 0.2496 + 0.0049 + 0.0012, time: 24.469550]
2023-08-31 15:19:01.594: epoch 77:	0.03947759  	0.08599070  	0.07087639  
2023-08-31 15:19:26.082: [iter 78 : loss : 0.3316 = 0.0765 + 0.2489 + 0.0050 + 0.0012, time: 24.467463]
2023-08-31 15:19:26.799: epoch 78:	0.03954857  	0.08612199  	0.07098801  
2023-08-31 15:19:51.571: [iter 79 : loss : 0.3301 = 0.0756 + 0.2482 + 0.0051 + 0.0012, time: 24.746483]
2023-08-31 15:19:52.189: epoch 79:	0.03963241  	0.08633791  	0.07114505  
2023-08-31 15:20:17.153: [iter 80 : loss : 0.3296 = 0.0758 + 0.2475 + 0.0051 + 0.0012, time: 24.946618]
2023-08-31 15:20:17.804: epoch 80:	0.03980017  	0.08673175  	0.07152142  
2023-08-31 15:20:17.804: Find a better model.
2023-08-31 15:20:43.017: [iter 81 : loss : 0.3280 = 0.0750 + 0.2466 + 0.0052 + 0.0012, time: 25.192102]
2023-08-31 15:20:43.666: epoch 81:	0.04005172  	0.08720865  	0.07173218  
2023-08-31 15:20:43.667: Find a better model.
2023-08-31 15:21:08.728: [iter 82 : loss : 0.3273 = 0.0748 + 0.2460 + 0.0052 + 0.0012, time: 25.034352]
2023-08-31 15:21:09.384: epoch 82:	0.03994208  	0.08691826  	0.07171956  
2023-08-31 15:21:34.725: [iter 83 : loss : 0.3263 = 0.0744 + 0.2453 + 0.0053 + 0.0012, time: 25.315775]
2023-08-31 15:21:35.395: epoch 83:	0.04016786  	0.08763501  	0.07203183  
2023-08-31 15:21:35.395: Find a better model.
2023-08-31 15:22:00.531: [iter 84 : loss : 0.3239 = 0.0726 + 0.2447 + 0.0054 + 0.0012, time: 25.103117]
2023-08-31 15:22:01.173: epoch 84:	0.04021302  	0.08769813  	0.07216269  
2023-08-31 15:22:01.173: Find a better model.
2023-08-31 15:22:26.410: [iter 85 : loss : 0.3242 = 0.0737 + 0.2439 + 0.0054 + 0.0012, time: 25.213083]
2023-08-31 15:22:27.047: epoch 85:	0.04029689  	0.08795554  	0.07251907  
2023-08-31 15:22:27.048: Find a better model.
2023-08-31 15:22:52.437: [iter 86 : loss : 0.3225 = 0.0726 + 0.2433 + 0.0055 + 0.0012, time: 25.368397]
2023-08-31 15:22:53.057: epoch 86:	0.04045172  	0.08813901  	0.07270987  
2023-08-31 15:22:53.057: Find a better model.
2023-08-31 15:23:18.213: [iter 87 : loss : 0.3221 = 0.0728 + 0.2425 + 0.0056 + 0.0012, time: 25.137788]
2023-08-31 15:23:18.894: epoch 87:	0.04056140  	0.08846963  	0.07286815  
2023-08-31 15:23:18.894: Find a better model.
2023-08-31 15:23:44.195: [iter 88 : loss : 0.3215 = 0.0728 + 0.2418 + 0.0056 + 0.0012, time: 25.280061]
2023-08-31 15:23:44.882: epoch 88:	0.04064529  	0.08866704  	0.07306866  
2023-08-31 15:23:44.883: Find a better model.
2023-08-31 15:24:10.186: [iter 89 : loss : 0.3205 = 0.0722 + 0.2414 + 0.0057 + 0.0012, time: 25.269525]
2023-08-31 15:24:10.778: epoch 89:	0.04089037  	0.08929116  	0.07348744  
2023-08-31 15:24:10.779: Find a better model.
2023-08-31 15:24:35.838: [iter 90 : loss : 0.3193 = 0.0717 + 0.2407 + 0.0058 + 0.0012, time: 25.034313]
2023-08-31 15:24:36.494: epoch 90:	0.04089041  	0.08922082  	0.07358984  
2023-08-31 15:25:01.820: [iter 91 : loss : 0.3188 = 0.0719 + 0.2399 + 0.0058 + 0.0012, time: 25.301981]
2023-08-31 15:25:02.478: epoch 91:	0.04100007  	0.08937909  	0.07369296  
2023-08-31 15:25:02.478: Find a better model.
2023-08-31 15:25:27.521: [iter 92 : loss : 0.3174 = 0.0710 + 0.2393 + 0.0059 + 0.0012, time: 25.019769]
2023-08-31 15:25:28.177: epoch 92:	0.04105166  	0.08942384  	0.07382509  
2023-08-31 15:25:28.177: Find a better model.
2023-08-31 15:25:53.354: [iter 93 : loss : 0.3162 = 0.0704 + 0.2387 + 0.0059 + 0.0012, time: 25.149884]
2023-08-31 15:25:54.011: epoch 93:	0.04124517  	0.08990105  	0.07417896  
2023-08-31 15:25:54.011: Find a better model.
2023-08-31 15:26:19.500: [iter 94 : loss : 0.3165 = 0.0714 + 0.2379 + 0.0060 + 0.0012, time: 25.460801]
2023-08-31 15:26:20.143: epoch 94:	0.04115485  	0.08984245  	0.07421535  
2023-08-31 15:26:45.333: [iter 95 : loss : 0.3149 = 0.0704 + 0.2372 + 0.0061 + 0.0012, time: 25.167373]
2023-08-31 15:26:45.967: epoch 95:	0.04130321  	0.09016559  	0.07434720  
2023-08-31 15:26:45.967: Find a better model.
2023-08-31 15:27:11.131: [iter 96 : loss : 0.3147 = 0.0706 + 0.2367 + 0.0061 + 0.0012, time: 25.141744]
2023-08-31 15:27:11.793: epoch 96:	0.04153549  	0.09071411  	0.07467758  
2023-08-31 15:27:11.794: Find a better model.
2023-08-31 15:27:37.129: [iter 97 : loss : 0.3139 = 0.0704 + 0.2361 + 0.0062 + 0.0012, time: 25.316197]
2023-08-31 15:27:37.795: epoch 97:	0.04161289  	0.09056742  	0.07468429  
2023-08-31 15:28:02.808: [iter 98 : loss : 0.3122 = 0.0694 + 0.2353 + 0.0063 + 0.0012, time: 24.986331]
2023-08-31 15:28:03.470: epoch 98:	0.04174835  	0.09113467  	0.07493635  
2023-08-31 15:28:03.470: Find a better model.
2023-08-31 15:28:28.583: [iter 99 : loss : 0.3107 = 0.0684 + 0.2348 + 0.0063 + 0.0012, time: 25.095282]
2023-08-31 15:28:29.249: epoch 99:	0.04158704  	0.09059166  	0.07482166  
2023-08-31 15:28:54.524: [iter 100 : loss : 0.3104 = 0.0686 + 0.2342 + 0.0064 + 0.0012, time: 25.254941]
2023-08-31 15:28:55.227: epoch 100:	0.04190958  	0.09155366  	0.07552060  
2023-08-31 15:28:55.227: Find a better model.
2023-08-31 15:29:20.221: [iter 101 : loss : 0.3087 = 0.0675 + 0.2335 + 0.0065 + 0.0012, time: 24.962148]
2023-08-31 15:29:20.861: epoch 101:	0.04170316  	0.09092715  	0.07526538  
2023-08-31 15:29:46.261: [iter 102 : loss : 0.3098 = 0.0693 + 0.2328 + 0.0065 + 0.0012, time: 25.376121]
2023-08-31 15:29:46.922: epoch 102:	0.04174184  	0.09092964  	0.07521791  
2023-08-31 15:30:12.493: [iter 103 : loss : 0.3082 = 0.0682 + 0.2322 + 0.0066 + 0.0012, time: 25.547756]
2023-08-31 15:30:13.159: epoch 103:	0.04185149  	0.09117301  	0.07546182  
2023-08-31 15:30:38.473: [iter 104 : loss : 0.3080 = 0.0685 + 0.2317 + 0.0066 + 0.0012, time: 25.286296]
2023-08-31 15:30:39.131: epoch 104:	0.04177408  	0.09110074  	0.07558468  
2023-08-31 15:31:04.518: [iter 105 : loss : 0.3059 = 0.0669 + 0.2311 + 0.0067 + 0.0012, time: 25.366619]
2023-08-31 15:31:05.170: epoch 105:	0.04181926  	0.09120376  	0.07567530  
2023-08-31 15:31:30.449: [iter 106 : loss : 0.3039 = 0.0655 + 0.2304 + 0.0068 + 0.0012, time: 25.256303]
2023-08-31 15:31:31.052: epoch 106:	0.04208374  	0.09181550  	0.07599979  
2023-08-31 15:31:31.052: Find a better model.
2023-08-31 15:31:56.057: [iter 107 : loss : 0.3044 = 0.0666 + 0.2298 + 0.0068 + 0.0011, time: 24.988959]
2023-08-31 15:31:56.713: epoch 107:	0.04205795  	0.09183113  	0.07603292  
2023-08-31 15:31:56.714: Find a better model.
2023-08-31 15:32:21.551: [iter 108 : loss : 0.3038 = 0.0665 + 0.2293 + 0.0069 + 0.0011, time: 24.809914]
2023-08-31 15:32:22.167: epoch 108:	0.04204504  	0.09179840  	0.07611916  
2023-08-31 15:32:46.987: [iter 109 : loss : 0.3026 = 0.0660 + 0.2285 + 0.0070 + 0.0011, time: 24.802534]
2023-08-31 15:32:47.615: epoch 109:	0.04220632  	0.09202699  	0.07622211  
2023-08-31 15:32:47.615: Find a better model.
2023-08-31 15:33:12.536: [iter 110 : loss : 0.3011 = 0.0649 + 0.2280 + 0.0070 + 0.0011, time: 24.897705]
2023-08-31 15:33:13.268: epoch 110:	0.04229020  	0.09215192  	0.07644506  
2023-08-31 15:33:13.268: Find a better model.
2023-08-31 15:33:37.939: [iter 111 : loss : 0.3003 = 0.0646 + 0.2274 + 0.0071 + 0.0011, time: 24.651444]
2023-08-31 15:33:38.595: epoch 111:	0.04225794  	0.09204729  	0.07653137  
2023-08-31 15:34:03.348: [iter 112 : loss : 0.3013 = 0.0661 + 0.2269 + 0.0072 + 0.0011, time: 24.733285]
2023-08-31 15:34:03.968: epoch 112:	0.04241923  	0.09255779  	0.07702135  
2023-08-31 15:34:03.969: Find a better model.
2023-08-31 15:34:28.671: [iter 113 : loss : 0.3007 = 0.0661 + 0.2263 + 0.0072 + 0.0011, time: 24.676054]
2023-08-31 15:34:29.318: epoch 113:	0.04260631  	0.09297364  	0.07727608  
2023-08-31 15:34:29.319: Find a better model.
2023-08-31 15:34:54.005: [iter 114 : loss : 0.2984 = 0.0642 + 0.2257 + 0.0073 + 0.0011, time: 24.655200]
2023-08-31 15:34:54.612: epoch 114:	0.04260631  	0.09289158  	0.07727540  
2023-08-31 15:35:19.415: [iter 115 : loss : 0.2984 = 0.0650 + 0.2250 + 0.0073 + 0.0011, time: 24.781767]
2023-08-31 15:35:20.047: epoch 115:	0.04253534  	0.09271134  	0.07736792  
2023-08-31 15:35:44.881: [iter 116 : loss : 0.2965 = 0.0635 + 0.2244 + 0.0074 + 0.0011, time: 24.813345]
2023-08-31 15:35:45.501: epoch 116:	0.04273530  	0.09323333  	0.07764633  
2023-08-31 15:35:45.502: Find a better model.
2023-08-31 15:36:10.563: [iter 117 : loss : 0.2965 = 0.0641 + 0.2238 + 0.0075 + 0.0011, time: 25.043275]
2023-08-31 15:36:11.203: epoch 117:	0.04275467  	0.09327430  	0.07763769  
2023-08-31 15:36:11.203: Find a better model.
2023-08-31 15:36:35.956: [iter 118 : loss : 0.2964 = 0.0643 + 0.2234 + 0.0075 + 0.0011, time: 24.735488]
2023-08-31 15:36:36.592: epoch 118:	0.04275467  	0.09326068  	0.07764120  
2023-08-31 15:37:01.764: [iter 119 : loss : 0.2949 = 0.0634 + 0.2228 + 0.0076 + 0.0011, time: 25.151937]
2023-08-31 15:37:02.472: epoch 119:	0.04292240  	0.09347649  	0.07785062  
2023-08-31 15:37:02.472: Find a better model.
2023-08-31 15:37:27.294: [iter 120 : loss : 0.2941 = 0.0632 + 0.2221 + 0.0077 + 0.0011, time: 24.799285]
2023-08-31 15:37:27.948: epoch 120:	0.04296111  	0.09375741  	0.07801817  
2023-08-31 15:37:27.948: Find a better model.
2023-08-31 15:37:52.909: [iter 121 : loss : 0.2944 = 0.0639 + 0.2216 + 0.0077 + 0.0011, time: 24.942991]
2023-08-31 15:37:53.612: epoch 121:	0.04306428  	0.09412152  	0.07814769  
2023-08-31 15:37:53.612: Find a better model.
2023-08-31 15:38:18.629: [iter 122 : loss : 0.2924 = 0.0625 + 0.2210 + 0.0078 + 0.0011, time: 24.998120]
2023-08-31 15:38:19.294: epoch 122:	0.04310944  	0.09409531  	0.07821783  
2023-08-31 15:38:44.428: [iter 123 : loss : 0.2923 = 0.0630 + 0.2204 + 0.0079 + 0.0011, time: 25.109495]
2023-08-31 15:38:45.120: epoch 123:	0.04329009  	0.09458858  	0.07850377  
2023-08-31 15:38:45.120: Find a better model.
2023-08-31 15:39:10.233: [iter 124 : loss : 0.2911 = 0.0623 + 0.2199 + 0.0079 + 0.0011, time: 25.093718]
2023-08-31 15:39:10.886: epoch 124:	0.04323205  	0.09450227  	0.07861277  
2023-08-31 15:39:35.784: [iter 125 : loss : 0.2908 = 0.0625 + 0.2192 + 0.0080 + 0.0011, time: 24.874618]
2023-08-31 15:39:36.418: epoch 125:	0.04343206  	0.09496665  	0.07885242  
2023-08-31 15:39:36.418: Find a better model.
2023-08-31 15:40:01.493: [iter 126 : loss : 0.2901 = 0.0623 + 0.2187 + 0.0081 + 0.0011, time: 25.057725]
2023-08-31 15:40:02.133: epoch 126:	0.04343204  	0.09497853  	0.07882049  
2023-08-31 15:40:02.133: Find a better model.
2023-08-31 15:40:27.027: [iter 127 : loss : 0.2904 = 0.0631 + 0.2181 + 0.0081 + 0.0011, time: 24.874825]
2023-08-31 15:40:27.736: epoch 127:	0.04338687  	0.09443408  	0.07874100  
2023-08-31 15:40:52.852: [iter 128 : loss : 0.2892 = 0.0623 + 0.2176 + 0.0082 + 0.0011, time: 25.095875]
2023-08-31 15:40:53.585: epoch 128:	0.04332880  	0.09439807  	0.07862252  
2023-08-31 15:41:18.515: [iter 129 : loss : 0.2887 = 0.0622 + 0.2171 + 0.0082 + 0.0011, time: 24.911699]
2023-08-31 15:41:19.113: epoch 129:	0.04344495  	0.09457687  	0.07875633  
2023-08-31 15:41:43.531: [iter 130 : loss : 0.2871 = 0.0610 + 0.2166 + 0.0083 + 0.0011, time: 24.398752]
2023-08-31 15:41:44.168: epoch 130:	0.04351589  	0.09475201  	0.07893156  
2023-08-31 15:42:08.633: [iter 131 : loss : 0.2878 = 0.0624 + 0.2160 + 0.0084 + 0.0011, time: 24.444742]
2023-08-31 15:42:09.262: epoch 131:	0.04354172  	0.09504509  	0.07906312  
2023-08-31 15:42:09.262: Find a better model.
2023-08-31 15:42:34.081: [iter 132 : loss : 0.2851 = 0.0601 + 0.2155 + 0.0084 + 0.0011, time: 24.800557]
2023-08-31 15:42:34.703: epoch 132:	0.04341267  	0.09479570  	0.07892896  
2023-08-31 15:42:59.606: [iter 133 : loss : 0.2852 = 0.0607 + 0.2149 + 0.0085 + 0.0011, time: 24.887215]
2023-08-31 15:43:00.263: epoch 133:	0.04346430  	0.09504224  	0.07904334  
2023-08-31 15:43:24.986: [iter 134 : loss : 0.2858 = 0.0617 + 0.2144 + 0.0086 + 0.0011, time: 24.700135]
2023-08-31 15:43:25.635: epoch 134:	0.04351591  	0.09527045  	0.07932191  
2023-08-31 15:43:25.635: Find a better model.
2023-08-31 15:43:50.452: [iter 135 : loss : 0.2842 = 0.0607 + 0.2138 + 0.0086 + 0.0011, time: 24.795371]
2023-08-31 15:43:51.082: epoch 135:	0.04356106  	0.09504987  	0.07931907  
2023-08-31 15:44:16.286: [iter 136 : loss : 0.2830 = 0.0600 + 0.2133 + 0.0087 + 0.0011, time: 25.184954]
2023-08-31 15:44:16.898: epoch 136:	0.04353525  	0.09508497  	0.07925356  
2023-08-31 15:44:41.879: [iter 137 : loss : 0.2826 = 0.0600 + 0.2128 + 0.0088 + 0.0011, time: 24.959214]
2023-08-31 15:44:42.522: epoch 137:	0.04341912  	0.09480726  	0.07920775  
2023-08-31 15:45:07.448: [iter 138 : loss : 0.2826 = 0.0605 + 0.2123 + 0.0088 + 0.0011, time: 24.905005]
2023-08-31 15:45:08.084: epoch 138:	0.04358689  	0.09505849  	0.07942633  
2023-08-31 15:45:32.928: [iter 139 : loss : 0.2813 = 0.0597 + 0.2116 + 0.0089 + 0.0011, time: 24.826972]
2023-08-31 15:45:33.589: epoch 139:	0.04367722  	0.09522032  	0.07950404  
2023-08-31 15:45:58.331: [iter 140 : loss : 0.2815 = 0.0603 + 0.2112 + 0.0089 + 0.0011, time: 24.721868]
2023-08-31 15:45:58.990: epoch 140:	0.04362560  	0.09529486  	0.07947440  
2023-08-31 15:45:58.990: Find a better model.
2023-08-31 15:46:23.731: [iter 141 : loss : 0.2811 = 0.0603 + 0.2107 + 0.0090 + 0.0011, time: 24.722354]
2023-08-31 15:46:24.365: epoch 141:	0.04368366  	0.09534229  	0.07946395  
2023-08-31 15:46:24.366: Find a better model.
2023-08-31 15:46:49.068: [iter 142 : loss : 0.2793 = 0.0591 + 0.2101 + 0.0091 + 0.0010, time: 24.674173]
2023-08-31 15:46:49.710: epoch 142:	0.04352883  	0.09496616  	0.07929292  
2023-08-31 15:47:14.524: [iter 143 : loss : 0.2792 = 0.0593 + 0.2097 + 0.0091 + 0.0010, time: 24.782506]
2023-08-31 15:47:15.102: epoch 143:	0.04370303  	0.09537337  	0.07958487  
2023-08-31 15:47:15.102: Find a better model.
2023-08-31 15:47:39.744: [iter 144 : loss : 0.2790 = 0.0596 + 0.2091 + 0.0092 + 0.0010, time: 24.617877]
2023-08-31 15:47:40.374: epoch 144:	0.04379980  	0.09563902  	0.07988530  
2023-08-31 15:47:40.374: Find a better model.
2023-08-31 15:48:04.986: [iter 145 : loss : 0.2785 = 0.0596 + 0.2086 + 0.0093 + 0.0010, time: 24.593997]
2023-08-31 15:48:05.694: epoch 145:	0.04385788  	0.09580657  	0.07999016  
2023-08-31 15:48:05.694: Find a better model.
2023-08-31 15:48:30.571: [iter 146 : loss : 0.2781 = 0.0596 + 0.2082 + 0.0093 + 0.0010, time: 24.857999]
2023-08-31 15:48:31.203: epoch 146:	0.04379982  	0.09572224  	0.08000835  
2023-08-31 15:48:55.928: [iter 147 : loss : 0.2776 = 0.0593 + 0.2078 + 0.0094 + 0.0010, time: 24.704018]
2023-08-31 15:48:56.513: epoch 147:	0.04398044  	0.09595399  	0.08026589  
2023-08-31 15:48:56.513: Find a better model.
2023-08-31 15:49:21.444: [iter 148 : loss : 0.2771 = 0.0594 + 0.2072 + 0.0095 + 0.0010, time: 24.912921]
2023-08-31 15:49:22.171: epoch 148:	0.04396109  	0.09580304  	0.08018705  
2023-08-31 15:49:47.205: [iter 149 : loss : 0.2753 = 0.0581 + 0.2066 + 0.0095 + 0.0010, time: 25.001140]
2023-08-31 15:49:47.938: epoch 149:	0.04403849  	0.09587667  	0.08027671  
2023-08-31 15:50:12.916: [iter 150 : loss : 0.2761 = 0.0592 + 0.2062 + 0.0096 + 0.0010, time: 24.957067]
2023-08-31 15:50:13.587: epoch 150:	0.04397399  	0.09592290  	0.08030137  
2023-08-31 15:50:38.361: [iter 151 : loss : 0.2755 = 0.0592 + 0.2056 + 0.0096 + 0.0010, time: 24.752533]
2023-08-31 15:50:38.961: epoch 151:	0.04389655  	0.09583393  	0.08028439  
2023-08-31 15:51:03.781: [iter 152 : loss : 0.2750 = 0.0591 + 0.2052 + 0.0097 + 0.0010, time: 24.802583]
2023-08-31 15:51:04.408: epoch 152:	0.04403849  	0.09629015  	0.08060185  
2023-08-31 15:51:04.408: Find a better model.
2023-08-31 15:51:29.642: [iter 153 : loss : 0.2745 = 0.0589 + 0.2048 + 0.0098 + 0.0010, time: 25.213421]
2023-08-31 15:51:30.282: epoch 153:	0.04407075  	0.09616841  	0.08061688  
2023-08-31 15:51:55.011: [iter 154 : loss : 0.2735 = 0.0584 + 0.2043 + 0.0098 + 0.0010, time: 24.708364]
2023-08-31 15:51:55.619: epoch 154:	0.04401916  	0.09616104  	0.08061330  
2023-08-31 15:52:20.463: [iter 155 : loss : 0.2723 = 0.0577 + 0.2037 + 0.0099 + 0.0010, time: 24.825491]
2023-08-31 15:52:21.058: epoch 155:	0.04405788  	0.09630734  	0.08065001  
2023-08-31 15:52:21.058: Find a better model.
2023-08-31 15:52:45.858: [iter 156 : loss : 0.2718 = 0.0575 + 0.2033 + 0.0100 + 0.0010, time: 24.781026]
2023-08-31 15:52:46.511: epoch 156:	0.04405787  	0.09628021  	0.08058816  
2023-08-31 15:53:11.244: [iter 157 : loss : 0.2716 = 0.0578 + 0.2029 + 0.0100 + 0.0010, time: 24.712420]
2023-08-31 15:53:11.875: epoch 157:	0.04429010  	0.09671655  	0.08092441  
2023-08-31 15:53:11.876: Find a better model.
2023-08-31 15:53:36.621: [iter 158 : loss : 0.2720 = 0.0586 + 0.2023 + 0.0101 + 0.0010, time: 24.721709]
2023-08-31 15:53:37.272: epoch 158:	0.04408364  	0.09646367  	0.08078729  
2023-08-31 15:54:02.257: [iter 159 : loss : 0.2701 = 0.0572 + 0.2018 + 0.0101 + 0.0010, time: 24.949325]
2023-08-31 15:54:02.862: epoch 159:	0.04415460  	0.09643554  	0.08082428  
2023-08-31 15:54:27.767: [iter 160 : loss : 0.2698 = 0.0571 + 0.2015 + 0.0102 + 0.0010, time: 24.878824]
2023-08-31 15:54:28.396: epoch 160:	0.04420622  	0.09651686  	0.08091632  
2023-08-31 15:54:53.160: [iter 161 : loss : 0.2698 = 0.0575 + 0.2011 + 0.0103 + 0.0010, time: 24.743903]
2023-08-31 15:54:53.817: epoch 161:	0.04426428  	0.09669800  	0.08100142  
2023-08-31 15:55:18.525: [iter 162 : loss : 0.2691 = 0.0572 + 0.2006 + 0.0103 + 0.0010, time: 24.685730]
2023-08-31 15:55:19.179: epoch 162:	0.04416754  	0.09648161  	0.08095571  
2023-08-31 15:55:44.002: [iter 163 : loss : 0.2685 = 0.0569 + 0.2002 + 0.0104 + 0.0010, time: 24.800719]
2023-08-31 15:55:44.601: epoch 163:	0.04410947  	0.09626212  	0.08096502  
2023-08-31 15:56:09.539: [iter 164 : loss : 0.2682 = 0.0572 + 0.1996 + 0.0104 + 0.0010, time: 24.917765]
2023-08-31 15:56:10.182: epoch 164:	0.04439334  	0.09694691  	0.08120923  
2023-08-31 15:56:10.182: Find a better model.
2023-08-31 15:56:35.091: [iter 165 : loss : 0.2678 = 0.0572 + 0.1991 + 0.0105 + 0.0010, time: 24.886701]
2023-08-31 15:56:35.711: epoch 165:	0.04432239  	0.09673673  	0.08115746  
2023-08-31 15:57:00.786: [iter 166 : loss : 0.2668 = 0.0565 + 0.1987 + 0.0106 + 0.0010, time: 25.056154]
2023-08-31 15:57:01.506: epoch 166:	0.04443850  	0.09705843  	0.08130788  
2023-08-31 15:57:01.506: Find a better model.
2023-08-31 15:57:26.320: [iter 167 : loss : 0.2676 = 0.0578 + 0.1983 + 0.0106 + 0.0010, time: 24.794466]
2023-08-31 15:57:26.951: epoch 167:	0.04445785  	0.09701002  	0.08142730  
2023-08-31 15:57:51.948: [iter 168 : loss : 0.2660 = 0.0565 + 0.1978 + 0.0107 + 0.0010, time: 24.967832]
2023-08-31 15:57:52.657: epoch 168:	0.04457396  	0.09726581  	0.08158234  
2023-08-31 15:57:52.657: Find a better model.
2023-08-31 15:58:17.243: [iter 169 : loss : 0.2674 = 0.0583 + 0.1973 + 0.0108 + 0.0010, time: 24.565753]
2023-08-31 15:58:17.878: epoch 169:	0.04441271  	0.09686572  	0.08155737  
2023-08-31 15:58:42.548: [iter 170 : loss : 0.2648 = 0.0559 + 0.1971 + 0.0108 + 0.0010, time: 24.649940]
2023-08-31 15:58:43.186: epoch 170:	0.04438044  	0.09681004  	0.08139031  
2023-08-31 15:59:07.798: [iter 171 : loss : 0.2648 = 0.0564 + 0.1966 + 0.0109 + 0.0010, time: 24.590343]
2023-08-31 15:59:08.434: epoch 171:	0.04453526  	0.09710629  	0.08162851  
2023-08-31 15:59:33.219: [iter 172 : loss : 0.2640 = 0.0560 + 0.1961 + 0.0109 + 0.0010, time: 24.762924]
2023-08-31 15:59:33.831: epoch 172:	0.04452880  	0.09712313  	0.08170072  
2023-08-31 15:59:58.441: [iter 173 : loss : 0.2640 = 0.0563 + 0.1957 + 0.0110 + 0.0010, time: 24.589566]
2023-08-31 15:59:59.042: epoch 173:	0.04463204  	0.09736920  	0.08179391  
2023-08-31 15:59:59.042: Find a better model.
2023-08-31 16:00:23.790: [iter 174 : loss : 0.2633 = 0.0561 + 0.1952 + 0.0111 + 0.0010, time: 24.727790]
2023-08-31 16:00:24.397: epoch 174:	0.04461267  	0.09722179  	0.08183386  
2023-08-31 16:00:49.269: [iter 175 : loss : 0.2636 = 0.0567 + 0.1948 + 0.0111 + 0.0010, time: 24.852860]
2023-08-31 16:00:49.920: epoch 175:	0.04465783  	0.09727328  	0.08197191  
2023-08-31 16:01:15.001: [iter 176 : loss : 0.2622 = 0.0556 + 0.1944 + 0.0112 + 0.0010, time: 25.054873]
2023-08-31 16:01:15.729: epoch 176:	0.04461910  	0.09719849  	0.08192524  
2023-08-31 16:01:40.479: [iter 177 : loss : 0.2628 = 0.0567 + 0.1939 + 0.0112 + 0.0010, time: 24.730622]
2023-08-31 16:01:41.088: epoch 177:	0.04461266  	0.09714987  	0.08195093  
2023-08-31 16:02:06.042: [iter 178 : loss : 0.2603 = 0.0546 + 0.1935 + 0.0113 + 0.0010, time: 24.933180]
2023-08-31 16:02:06.655: epoch 178:	0.04458686  	0.09723172  	0.08199175  
2023-08-31 16:02:31.484: [iter 179 : loss : 0.2614 = 0.0559 + 0.1932 + 0.0114 + 0.0010, time: 24.809530]
2023-08-31 16:02:32.104: epoch 179:	0.04461266  	0.09733001  	0.08198740  
2023-08-31 16:02:56.859: [iter 180 : loss : 0.2611 = 0.0560 + 0.1927 + 0.0114 + 0.0010, time: 24.736322]
2023-08-31 16:02:57.503: epoch 180:	0.04460620  	0.09720895  	0.08206362  
2023-08-31 16:03:22.359: [iter 181 : loss : 0.2606 = 0.0558 + 0.1923 + 0.0115 + 0.0010, time: 24.835398]
2023-08-31 16:03:22.999: epoch 181:	0.04449007  	0.09696586  	0.08190493  
2023-08-31 16:03:47.768: [iter 182 : loss : 0.2599 = 0.0556 + 0.1918 + 0.0115 + 0.0010, time: 24.749265]
2023-08-31 16:03:48.402: epoch 182:	0.04452878  	0.09703398  	0.08192980  
2023-08-31 16:04:13.119: [iter 183 : loss : 0.2591 = 0.0552 + 0.1914 + 0.0116 + 0.0010, time: 24.699410]
2023-08-31 16:04:13.748: epoch 183:	0.04443844  	0.09686417  	0.08184279  
2023-08-31 16:04:13.749: Early stopping is trigger at epoch: 183
2023-08-31 16:04:13.749: best_result@epoch 173:

2023-08-31 16:04:13.749: 		0.0446      	0.0974      	0.0818      

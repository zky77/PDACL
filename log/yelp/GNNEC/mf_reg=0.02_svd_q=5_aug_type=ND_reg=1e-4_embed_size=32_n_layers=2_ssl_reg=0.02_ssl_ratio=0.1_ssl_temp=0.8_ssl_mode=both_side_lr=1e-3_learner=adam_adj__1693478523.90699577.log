2023-08-31 18:42:03.907: my pid: 34602
2023-08-31 18:42:03.907: model: model.general_recommender.GNNEC
2023-08-31 18:42:03.907: Dataset statistics:
Name: yelp
The number of users: 7750
The number of items: 28918
The number of ratings: 750318
Average actions of users: 96.82
Average actions of items: 25.95
The sparsity of the dataset: 99.665208%

The number of training: 678579
The number of validation: 0
The number of testing: 71739
2023-08-31 18:42:03.907: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=yelp
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.8
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=4096
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=yelp
epochs=200
n_layers=2
embed_size=32
batch_size=4096
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.8
mf_reg=0.02
svd_q=5
2023-08-31 18:42:23.215: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-08-31 18:42:43.841: [iter 1 : loss : 1.3401 = 0.6069 + 0.3664 + 0.0000 + 0.3668, time: 20.625021]
2023-08-31 18:42:44.484: epoch 1:	0.02525213  	0.05449506  	0.04655744  
2023-08-31 18:42:44.484: Find a better model.
2023-08-31 18:43:04.639: [iter 2 : loss : 1.0290 = 0.3504 + 0.3383 + 0.0002 + 0.3401, time: 20.143646]
2023-08-31 18:43:05.301: epoch 2:	0.02518762  	0.05428459  	0.04647198  
2023-08-31 18:43:25.512: [iter 3 : loss : 0.9240 = 0.2664 + 0.3274 + 0.0003 + 0.3298, time: 20.198852]
2023-08-31 18:43:26.171: epoch 3:	0.02534246  	0.05449173  	0.04655918  
2023-08-31 18:43:46.273: [iter 4 : loss : 0.8910 = 0.2430 + 0.3225 + 0.0004 + 0.3251, time: 20.088154]
2023-08-31 18:43:46.913: epoch 4:	0.02527793  	0.05435657  	0.04637517  
2023-08-31 18:44:06.897: [iter 5 : loss : 0.8747 = 0.2325 + 0.3196 + 0.0005 + 0.3222, time: 19.973273]
2023-08-31 18:44:07.611: epoch 5:	0.02548439  	0.05496604  	0.04683976  
2023-08-31 18:44:07.611: Find a better model.
2023-08-31 18:44:27.616: [iter 6 : loss : 0.8629 = 0.2251 + 0.3173 + 0.0005 + 0.3200, time: 19.995148]
2023-08-31 18:44:28.254: epoch 6:	0.02567150  	0.05545573  	0.04711019  
2023-08-31 18:44:28.254: Find a better model.
2023-08-31 18:44:48.339: [iter 7 : loss : 0.8492 = 0.2153 + 0.3153 + 0.0006 + 0.3181, time: 20.074662]
2023-08-31 18:44:49.048: epoch 7:	0.02599408  	0.05634776  	0.04760699  
2023-08-31 18:44:49.048: Find a better model.
2023-08-31 18:45:08.857: [iter 8 : loss : 0.8392 = 0.2086 + 0.3136 + 0.0006 + 0.3164, time: 19.800090]
2023-08-31 18:45:09.495: epoch 8:	0.02627796  	0.05682835  	0.04781131  
2023-08-31 18:45:09.495: Find a better model.
2023-08-31 18:45:29.448: [iter 9 : loss : 0.8299 = 0.2024 + 0.3120 + 0.0006 + 0.3149, time: 19.940683]
2023-08-31 18:45:30.088: epoch 9:	0.02649733  	0.05726818  	0.04839014  
2023-08-31 18:45:30.089: Find a better model.
2023-08-31 18:45:50.017: [iter 10 : loss : 0.8203 = 0.1958 + 0.3104 + 0.0007 + 0.3134, time: 19.913657]
2023-08-31 18:45:50.645: epoch 10:	0.02668444  	0.05762780  	0.04854117  
2023-08-31 18:45:50.645: Find a better model.
2023-08-31 18:46:10.449: [iter 11 : loss : 0.8124 = 0.1904 + 0.3092 + 0.0007 + 0.3120, time: 19.795197]
2023-08-31 18:46:11.045: epoch 11:	0.02694251  	0.05830801  	0.04900425  
2023-08-31 18:46:11.046: Find a better model.
2023-08-31 18:46:29.956: [iter 12 : loss : 0.8038 = 0.1846 + 0.3077 + 0.0008 + 0.3107, time: 18.901865]
2023-08-31 18:46:30.609: epoch 12:	0.02720059  	0.05894804  	0.04965230  
2023-08-31 18:46:30.609: Find a better model.
2023-08-31 18:46:50.724: [iter 13 : loss : 0.7976 = 0.1807 + 0.3065 + 0.0008 + 0.3095, time: 20.105674]
2023-08-31 18:46:51.382: epoch 13:	0.02764576  	0.05978023  	0.05019887  
2023-08-31 18:46:51.383: Find a better model.
2023-08-31 18:47:11.294: [iter 14 : loss : 0.7895 = 0.1749 + 0.3054 + 0.0009 + 0.3083, time: 19.902309]
2023-08-31 18:47:11.979: epoch 14:	0.02781997  	0.06011378  	0.05063351  
2023-08-31 18:47:11.980: Find a better model.
2023-08-31 18:47:32.310: [iter 15 : loss : 0.7850 = 0.1725 + 0.3043 + 0.0009 + 0.3073, time: 20.320208]
2023-08-31 18:47:32.945: epoch 15:	0.02786513  	0.06020443  	0.05075662  
2023-08-31 18:47:32.946: Find a better model.
2023-08-31 18:47:53.174: [iter 16 : loss : 0.7801 = 0.1697 + 0.3033 + 0.0009 + 0.3062, time: 20.217759]
2023-08-31 18:47:53.822: epoch 16:	0.02785868  	0.06010021  	0.05061064  
2023-08-31 18:48:13.938: [iter 17 : loss : 0.7737 = 0.1652 + 0.3023 + 0.0010 + 0.3052, time: 20.104117]
2023-08-31 18:48:14.565: epoch 17:	0.02803934  	0.06058112  	0.05095343  
2023-08-31 18:48:14.565: Find a better model.
2023-08-31 18:48:34.804: [iter 18 : loss : 0.7705 = 0.1639 + 0.3013 + 0.0010 + 0.3042, time: 20.229731]
2023-08-31 18:48:35.413: epoch 18:	0.02805224  	0.06044780  	0.05085138  
2023-08-31 18:48:55.683: [iter 19 : loss : 0.7649 = 0.1602 + 0.3003 + 0.0011 + 0.3032, time: 20.261246]
2023-08-31 18:48:56.359: epoch 19:	0.02818772  	0.06079520  	0.05104026  
2023-08-31 18:48:56.359: Find a better model.
2023-08-31 18:49:16.496: [iter 20 : loss : 0.7605 = 0.1576 + 0.2995 + 0.0011 + 0.3023, time: 20.128875]
2023-08-31 18:49:17.200: epoch 20:	0.02835548  	0.06130416  	0.05129828  
2023-08-31 18:49:17.200: Find a better model.
2023-08-31 18:49:37.263: [iter 21 : loss : 0.7552 = 0.1542 + 0.2985 + 0.0012 + 0.3013, time: 20.045733]
2023-08-31 18:49:37.931: epoch 21:	0.02860066  	0.06175799  	0.05183165  
2023-08-31 18:49:37.931: Find a better model.
2023-08-31 18:49:57.613: [iter 22 : loss : 0.7513 = 0.1520 + 0.2976 + 0.0012 + 0.3004, time: 19.673389]
2023-08-31 18:49:58.257: epoch 22:	0.02866518  	0.06189223  	0.05199319  
2023-08-31 18:49:58.257: Find a better model.
2023-08-31 18:50:18.447: [iter 23 : loss : 0.7468 = 0.1495 + 0.2967 + 0.0013 + 0.2994, time: 20.181078]
2023-08-31 18:50:19.228: epoch 23:	0.02891681  	0.06238166  	0.05219743  
2023-08-31 18:50:19.228: Find a better model.
2023-08-31 18:50:39.332: [iter 24 : loss : 0.7444 = 0.1488 + 0.2958 + 0.0013 + 0.2985, time: 20.092438]
2023-08-31 18:50:39.965: epoch 24:	0.02899423  	0.06265239  	0.05233832  
2023-08-31 18:50:39.966: Find a better model.
2023-08-31 18:50:59.774: [iter 25 : loss : 0.7398 = 0.1459 + 0.2949 + 0.0014 + 0.2976, time: 19.800427]
2023-08-31 18:51:00.427: epoch 25:	0.02922003  	0.06312298  	0.05261416  
2023-08-31 18:51:00.427: Find a better model.
2023-08-31 18:51:20.567: [iter 26 : loss : 0.7361 = 0.1441 + 0.2940 + 0.0014 + 0.2966, time: 20.130215]
2023-08-31 18:51:21.161: epoch 26:	0.02927165  	0.06322406  	0.05276660  
2023-08-31 18:51:21.162: Find a better model.
2023-08-31 18:51:41.236: [iter 27 : loss : 0.7312 = 0.1410 + 0.2931 + 0.0015 + 0.2956, time: 20.065428]
2023-08-31 18:51:41.924: epoch 27:	0.02942649  	0.06357821  	0.05304712  
2023-08-31 18:51:41.924: Find a better model.
2023-08-31 18:52:01.554: [iter 28 : loss : 0.7278 = 0.1395 + 0.2922 + 0.0015 + 0.2946, time: 19.620579]
2023-08-31 18:52:02.249: epoch 28:	0.02952326  	0.06356484  	0.05328015  
2023-08-31 18:52:21.873: [iter 29 : loss : 0.7248 = 0.1383 + 0.2913 + 0.0016 + 0.2936, time: 19.615230]
2023-08-31 18:52:22.505: epoch 29:	0.02981359  	0.06422560  	0.05368335  
2023-08-31 18:52:22.506: Find a better model.
2023-08-31 18:52:41.992: [iter 30 : loss : 0.7208 = 0.1361 + 0.2904 + 0.0016 + 0.2927, time: 19.478575]
2023-08-31 18:52:42.688: epoch 30:	0.03007167  	0.06511367  	0.05404760  
2023-08-31 18:52:42.688: Find a better model.
2023-08-31 18:53:02.785: [iter 31 : loss : 0.7167 = 0.1340 + 0.2894 + 0.0017 + 0.2916, time: 20.088377]
2023-08-31 18:53:03.421: epoch 31:	0.03030393  	0.06546122  	0.05439725  
2023-08-31 18:53:03.421: Find a better model.
2023-08-31 18:53:23.493: [iter 32 : loss : 0.7125 = 0.1318 + 0.2884 + 0.0017 + 0.2906, time: 20.059392]
2023-08-31 18:53:24.114: epoch 32:	0.03069105  	0.06633831  	0.05508092  
2023-08-31 18:53:24.114: Find a better model.
2023-08-31 18:53:43.865: [iter 33 : loss : 0.7088 = 0.1300 + 0.2874 + 0.0018 + 0.2896, time: 19.742973]
2023-08-31 18:53:44.532: epoch 33:	0.03087815  	0.06671879  	0.05530371  
2023-08-31 18:53:44.533: Find a better model.
2023-08-31 18:54:04.283: [iter 34 : loss : 0.7053 = 0.1285 + 0.2864 + 0.0018 + 0.2885, time: 19.741345]
2023-08-31 18:54:04.902: epoch 34:	0.03114913  	0.06735622  	0.05557582  
2023-08-31 18:54:04.903: Find a better model.
2023-08-31 18:54:24.763: [iter 35 : loss : 0.7018 = 0.1269 + 0.2855 + 0.0019 + 0.2875, time: 19.851460]
2023-08-31 18:54:25.445: epoch 35:	0.03152334  	0.06820162  	0.05616455  
2023-08-31 18:54:25.445: Find a better model.
2023-08-31 18:54:45.259: [iter 36 : loss : 0.6984 = 0.1256 + 0.2844 + 0.0020 + 0.2864, time: 19.801563]
2023-08-31 18:54:45.900: epoch 36:	0.03148463  	0.06808791  	0.05631396  
2023-08-31 18:55:05.900: [iter 37 : loss : 0.6944 = 0.1235 + 0.2835 + 0.0020 + 0.2854, time: 19.989981]
2023-08-31 18:55:06.595: epoch 37:	0.03160077  	0.06857016  	0.05664064  
2023-08-31 18:55:06.595: Find a better model.
2023-08-31 18:55:26.423: [iter 38 : loss : 0.6904 = 0.1213 + 0.2826 + 0.0021 + 0.2844, time: 19.813631]
2023-08-31 18:55:27.082: epoch 38:	0.03180076  	0.06897476  	0.05699324  
2023-08-31 18:55:27.082: Find a better model.
2023-08-31 18:55:47.226: [iter 39 : loss : 0.6870 = 0.1200 + 0.2815 + 0.0021 + 0.2833, time: 20.132913]
2023-08-31 18:55:47.870: epoch 39:	0.03211690  	0.06971082  	0.05749208  
2023-08-31 18:55:47.870: Find a better model.
2023-08-31 18:56:07.947: [iter 40 : loss : 0.6839 = 0.1189 + 0.2805 + 0.0022 + 0.2823, time: 20.067570]
2023-08-31 18:56:08.594: epoch 40:	0.03234916  	0.07028171  	0.05792771  
2023-08-31 18:56:08.594: Find a better model.
2023-08-31 18:56:28.729: [iter 41 : loss : 0.6794 = 0.1165 + 0.2795 + 0.0023 + 0.2812, time: 20.124453]
2023-08-31 18:56:29.361: epoch 41:	0.03258143  	0.07084213  	0.05835086  
2023-08-31 18:56:29.361: Find a better model.
2023-08-31 18:56:49.384: [iter 42 : loss : 0.6765 = 0.1155 + 0.2786 + 0.0023 + 0.2801, time: 20.015112]
2023-08-31 18:56:50.007: epoch 42:	0.03274272  	0.07113918  	0.05862053  
2023-08-31 18:56:50.007: Find a better model.
2023-08-31 18:57:10.064: [iter 43 : loss : 0.6731 = 0.1141 + 0.2775 + 0.0024 + 0.2791, time: 20.046203]
2023-08-31 18:57:10.692: epoch 43:	0.03278789  	0.07127488  	0.05896501  
2023-08-31 18:57:10.692: Find a better model.
2023-08-31 18:57:30.794: [iter 44 : loss : 0.6705 = 0.1135 + 0.2765 + 0.0024 + 0.2780, time: 20.093148]
2023-08-31 18:57:31.502: epoch 44:	0.03312337  	0.07205258  	0.05950173  
2023-08-31 18:57:31.502: Find a better model.
2023-08-31 18:57:51.567: [iter 45 : loss : 0.6672 = 0.1122 + 0.2755 + 0.0025 + 0.2770, time: 20.055245]
2023-08-31 18:57:52.173: epoch 45:	0.03325238  	0.07239863  	0.05975933  
2023-08-31 18:57:52.173: Find a better model.
2023-08-31 18:58:12.463: [iter 46 : loss : 0.6645 = 0.1115 + 0.2745 + 0.0026 + 0.2759, time: 20.278317]
2023-08-31 18:58:13.143: epoch 46:	0.03350396  	0.07301646  	0.06014672  
2023-08-31 18:58:13.144: Find a better model.
2023-08-31 18:58:33.072: [iter 47 : loss : 0.6600 = 0.1091 + 0.2734 + 0.0026 + 0.2749, time: 19.919618]
2023-08-31 18:58:33.705: epoch 47:	0.03371039  	0.07331998  	0.06055386  
2023-08-31 18:58:33.705: Find a better model.
2023-08-31 18:58:53.575: [iter 48 : loss : 0.6576 = 0.1085 + 0.2725 + 0.0027 + 0.2739, time: 19.860096]
2023-08-31 18:58:54.213: epoch 48:	0.03400069  	0.07393887  	0.06100260  
2023-08-31 18:58:54.213: Find a better model.
2023-08-31 18:59:14.453: [iter 49 : loss : 0.6543 = 0.1073 + 0.2715 + 0.0028 + 0.2728, time: 20.230068]
2023-08-31 18:59:15.193: epoch 49:	0.03412972  	0.07422627  	0.06131553  
2023-08-31 18:59:15.193: Find a better model.
2023-08-31 18:59:35.316: [iter 50 : loss : 0.6522 = 0.1070 + 0.2705 + 0.0028 + 0.2718, time: 20.112819]
2023-08-31 18:59:35.934: epoch 50:	0.03429100  	0.07464677  	0.06168149  
2023-08-31 18:59:35.934: Find a better model.
2023-08-31 18:59:56.156: [iter 51 : loss : 0.6491 = 0.1058 + 0.2696 + 0.0029 + 0.2708, time: 20.213405]
2023-08-31 18:59:56.854: epoch 51:	0.03446517  	0.07491270  	0.06199681  
2023-08-31 18:59:56.854: Find a better model.
2023-08-31 19:00:16.760: [iter 52 : loss : 0.6458 = 0.1044 + 0.2686 + 0.0030 + 0.2698, time: 19.896565]
2023-08-31 19:00:17.398: epoch 52:	0.03476837  	0.07537978  	0.06242803  
2023-08-31 19:00:17.398: Find a better model.
2023-08-31 19:00:37.418: [iter 53 : loss : 0.6433 = 0.1039 + 0.2676 + 0.0030 + 0.2688, time: 20.011733]
2023-08-31 19:00:38.117: epoch 53:	0.03474255  	0.07532371  	0.06249203  
2023-08-31 19:00:58.405: [iter 54 : loss : 0.6400 = 0.1024 + 0.2667 + 0.0031 + 0.2678, time: 20.278656]
2023-08-31 19:00:59.098: epoch 54:	0.03501993  	0.07579792  	0.06289221  
2023-08-31 19:00:59.098: Find a better model.
2023-08-31 19:01:19.085: [iter 55 : loss : 0.6380 = 0.1024 + 0.2657 + 0.0032 + 0.2668, time: 19.970268]
2023-08-31 19:01:19.711: epoch 55:	0.03518121  	0.07619533  	0.06325293  
2023-08-31 19:01:19.711: Find a better model.
2023-08-31 19:01:39.644: [iter 56 : loss : 0.6350 = 0.1013 + 0.2647 + 0.0033 + 0.2657, time: 19.923397]
2023-08-31 19:01:40.272: epoch 56:	0.03548442  	0.07689652  	0.06376038  
2023-08-31 19:01:40.273: Find a better model.
2023-08-31 19:02:00.152: [iter 57 : loss : 0.6322 = 0.1003 + 0.2637 + 0.0033 + 0.2648, time: 19.869354]
2023-08-31 19:02:00.781: epoch 57:	0.03580051  	0.07757145  	0.06418794  
2023-08-31 19:02:00.781: Find a better model.
2023-08-31 19:02:20.706: [iter 58 : loss : 0.6310 = 0.1009 + 0.2629 + 0.0034 + 0.2639, time: 19.904883]
2023-08-31 19:02:21.398: epoch 58:	0.03583922  	0.07771291  	0.06444319  
2023-08-31 19:02:21.399: Find a better model.
2023-08-31 19:02:41.166: [iter 59 : loss : 0.6277 = 0.0995 + 0.2619 + 0.0035 + 0.2629, time: 19.757620]
2023-08-31 19:02:41.864: epoch 59:	0.03613598  	0.07841179  	0.06499726  
2023-08-31 19:02:41.864: Find a better model.
2023-08-31 19:03:01.946: [iter 60 : loss : 0.6250 = 0.0984 + 0.2611 + 0.0035 + 0.2619, time: 20.072817]
2023-08-31 19:03:02.662: epoch 60:	0.03631660  	0.07886413  	0.06537485  
2023-08-31 19:03:02.662: Find a better model.
2023-08-31 19:03:22.681: [iter 61 : loss : 0.6219 = 0.0973 + 0.2600 + 0.0036 + 0.2610, time: 20.007981]
2023-08-31 19:03:23.383: epoch 61:	0.03640691  	0.07904928  	0.06570040  
2023-08-31 19:03:23.383: Find a better model.
2023-08-31 19:03:43.275: [iter 62 : loss : 0.6199 = 0.0972 + 0.2591 + 0.0037 + 0.2600, time: 19.881862]
2023-08-31 19:03:43.942: epoch 62:	0.03668429  	0.07962527  	0.06609569  
2023-08-31 19:03:43.942: Find a better model.
2023-08-31 19:04:03.689: [iter 63 : loss : 0.6166 = 0.0956 + 0.2582 + 0.0038 + 0.2591, time: 19.736373]
2023-08-31 19:04:04.399: epoch 63:	0.03683266  	0.07996818  	0.06642766  
2023-08-31 19:04:04.399: Find a better model.
2023-08-31 19:04:24.587: [iter 64 : loss : 0.6143 = 0.0950 + 0.2573 + 0.0038 + 0.2581, time: 20.174556]
2023-08-31 19:04:25.249: epoch 64:	0.03704553  	0.08044245  	0.06680781  
2023-08-31 19:04:25.249: Find a better model.
2023-08-31 19:04:45.510: [iter 65 : loss : 0.6127 = 0.0953 + 0.2564 + 0.0039 + 0.2571, time: 20.251960]
2023-08-31 19:04:46.182: epoch 65:	0.03724552  	0.08082404  	0.06711727  
2023-08-31 19:04:46.182: Find a better model.
2023-08-31 19:05:06.524: [iter 66 : loss : 0.6091 = 0.0934 + 0.2555 + 0.0040 + 0.2563, time: 20.332073]
2023-08-31 19:05:07.165: epoch 66:	0.03725198  	0.08093214  	0.06727009  
2023-08-31 19:05:07.165: Find a better model.
2023-08-31 19:05:27.165: [iter 67 : loss : 0.6072 = 0.0933 + 0.2545 + 0.0040 + 0.2553, time: 19.990645]
2023-08-31 19:05:27.889: epoch 67:	0.03752936  	0.08153675  	0.06765410  
2023-08-31 19:05:27.889: Find a better model.
2023-08-31 19:05:47.875: [iter 68 : loss : 0.6057 = 0.0936 + 0.2537 + 0.0041 + 0.2544, time: 19.973215]
2023-08-31 19:05:48.475: epoch 68:	0.03763258  	0.08169461  	0.06789439  
2023-08-31 19:05:48.475: Find a better model.
2023-08-31 19:06:08.072: [iter 69 : loss : 0.6033 = 0.0929 + 0.2528 + 0.0042 + 0.2534, time: 19.587076]
2023-08-31 19:06:08.696: epoch 69:	0.03783256  	0.08217952  	0.06826848  
2023-08-31 19:06:08.697: Find a better model.
2023-08-31 19:06:28.460: [iter 70 : loss : 0.6014 = 0.0926 + 0.2520 + 0.0043 + 0.2526, time: 19.755365]
2023-08-31 19:06:29.092: epoch 70:	0.03802609  	0.08262127  	0.06851310  
2023-08-31 19:06:29.092: Find a better model.
2023-08-31 19:06:48.764: [iter 71 : loss : 0.5981 = 0.0911 + 0.2510 + 0.0043 + 0.2517, time: 19.662724]
2023-08-31 19:06:49.430: epoch 71:	0.03825188  	0.08308246  	0.06863518  
2023-08-31 19:06:49.430: Find a better model.
2023-08-31 19:07:09.377: [iter 72 : loss : 0.5964 = 0.0911 + 0.2501 + 0.0044 + 0.2508, time: 19.937557]
2023-08-31 19:07:10.030: epoch 72:	0.03832931  	0.08326166  	0.06885419  
2023-08-31 19:07:10.031: Find a better model.
2023-08-31 19:07:29.770: [iter 73 : loss : 0.5939 = 0.0902 + 0.2493 + 0.0045 + 0.2499, time: 19.730567]
2023-08-31 19:07:30.378: epoch 73:	0.03844543  	0.08343448  	0.06914998  
2023-08-31 19:07:30.378: Find a better model.
2023-08-31 19:07:50.052: [iter 74 : loss : 0.5914 = 0.0896 + 0.2483 + 0.0046 + 0.2490, time: 19.666368]
2023-08-31 19:07:50.666: epoch 74:	0.03867766  	0.08402894  	0.06953037  
2023-08-31 19:07:50.666: Find a better model.
2023-08-31 19:08:10.565: [iter 75 : loss : 0.5893 = 0.0892 + 0.2474 + 0.0046 + 0.2481, time: 19.890411]
2023-08-31 19:08:11.245: epoch 75:	0.03888410  	0.08453429  	0.06991851  
2023-08-31 19:08:11.245: Find a better model.
2023-08-31 19:08:31.310: [iter 76 : loss : 0.5881 = 0.0894 + 0.2467 + 0.0047 + 0.2472, time: 20.055922]
2023-08-31 19:08:31.984: epoch 76:	0.03886474  	0.08449139  	0.07002234  
2023-08-31 19:08:51.028: [iter 77 : loss : 0.5853 = 0.0884 + 0.2458 + 0.0048 + 0.2464, time: 19.036057]
2023-08-31 19:08:51.636: epoch 77:	0.03898083  	0.08485170  	0.07021880  
2023-08-31 19:08:51.636: Find a better model.
2023-08-31 19:09:11.391: [iter 78 : loss : 0.5834 = 0.0881 + 0.2450 + 0.0049 + 0.2455, time: 19.745595]
2023-08-31 19:09:12.016: epoch 78:	0.03903244  	0.08486737  	0.07042267  
2023-08-31 19:09:12.016: Find a better model.
2023-08-31 19:09:31.886: [iter 79 : loss : 0.5810 = 0.0873 + 0.2441 + 0.0049 + 0.2447, time: 19.860520]
2023-08-31 19:09:32.555: epoch 79:	0.03931631  	0.08573670  	0.07091630  
2023-08-31 19:09:32.555: Find a better model.
2023-08-31 19:09:52.365: [iter 80 : loss : 0.5796 = 0.0875 + 0.2433 + 0.0050 + 0.2438, time: 19.796556]
2023-08-31 19:09:53.045: epoch 80:	0.03932275  	0.08572000  	0.07101159  
2023-08-31 19:10:13.135: [iter 81 : loss : 0.5772 = 0.0868 + 0.2424 + 0.0051 + 0.2429, time: 20.080385]
2023-08-31 19:10:13.822: epoch 81:	0.03944531  	0.08608948  	0.07112937  
2023-08-31 19:10:13.822: Find a better model.
2023-08-31 19:10:33.874: [iter 82 : loss : 0.5753 = 0.0864 + 0.2416 + 0.0052 + 0.2421, time: 20.042481]
2023-08-31 19:10:34.606: epoch 82:	0.03949692  	0.08613337  	0.07129303  
2023-08-31 19:10:34.606: Find a better model.
2023-08-31 19:10:54.334: [iter 83 : loss : 0.5735 = 0.0862 + 0.2408 + 0.0053 + 0.2413, time: 19.717880]
2023-08-31 19:10:54.931: epoch 83:	0.03956791  	0.08635079  	0.07141937  
2023-08-31 19:10:54.931: Find a better model.
2023-08-31 19:11:14.685: [iter 84 : loss : 0.5697 = 0.0839 + 0.2400 + 0.0053 + 0.2404, time: 19.741237]
2023-08-31 19:11:15.335: epoch 84:	0.03967760  	0.08676545  	0.07165635  
2023-08-31 19:11:15.335: Find a better model.
2023-08-31 19:11:35.096: [iter 85 : loss : 0.5695 = 0.0854 + 0.2391 + 0.0054 + 0.2396, time: 19.753221]
2023-08-31 19:11:35.713: epoch 85:	0.03978081  	0.08694781  	0.07191791  
2023-08-31 19:11:35.713: Find a better model.
2023-08-31 19:11:55.797: [iter 86 : loss : 0.5667 = 0.0841 + 0.2383 + 0.0055 + 0.2388, time: 20.074487]
2023-08-31 19:11:56.514: epoch 86:	0.03983888  	0.08718017  	0.07212888  
2023-08-31 19:11:56.514: Find a better model.
2023-08-31 19:12:16.487: [iter 87 : loss : 0.5656 = 0.0846 + 0.2375 + 0.0056 + 0.2379, time: 19.961221]
2023-08-31 19:12:17.107: epoch 87:	0.03979371  	0.08700693  	0.07213185  
2023-08-31 19:12:37.406: [iter 88 : loss : 0.5639 = 0.0845 + 0.2366 + 0.0056 + 0.2371, time: 20.287310]
2023-08-31 19:12:38.042: epoch 88:	0.03984534  	0.08727473  	0.07229527  
2023-08-31 19:12:38.042: Find a better model.
2023-08-31 19:12:58.054: [iter 89 : loss : 0.5622 = 0.0841 + 0.2360 + 0.0057 + 0.2363, time: 20.000243]
2023-08-31 19:12:58.696: epoch 89:	0.03999368  	0.08732510  	0.07249597  
2023-08-31 19:12:58.696: Find a better model.
2023-08-31 19:13:18.882: [iter 90 : loss : 0.5600 = 0.0835 + 0.2352 + 0.0058 + 0.2355, time: 20.176792]
2023-08-31 19:13:19.544: epoch 90:	0.04016785  	0.08772327  	0.07273410  
2023-08-31 19:13:19.544: Find a better model.
2023-08-31 19:13:39.548: [iter 91 : loss : 0.5587 = 0.0838 + 0.2343 + 0.0059 + 0.2347, time: 19.994315]
2023-08-31 19:13:40.177: epoch 91:	0.04026460  	0.08819268  	0.07292511  
2023-08-31 19:13:40.178: Find a better model.
2023-08-31 19:13:59.930: [iter 92 : loss : 0.5562 = 0.0828 + 0.2336 + 0.0060 + 0.2339, time: 19.742760]
2023-08-31 19:14:00.625: epoch 92:	0.04023881  	0.08805692  	0.07290899  
2023-08-31 19:14:20.498: [iter 93 : loss : 0.5542 = 0.0822 + 0.2328 + 0.0060 + 0.2332, time: 19.863619]
2023-08-31 19:14:21.124: epoch 93:	0.04025172  	0.08811542  	0.07299270  
2023-08-31 19:14:41.311: [iter 94 : loss : 0.5541 = 0.0837 + 0.2319 + 0.0061 + 0.2323, time: 20.177054]
2023-08-31 19:14:41.955: epoch 94:	0.04052265  	0.08875164  	0.07342932  
2023-08-31 19:14:41.955: Find a better model.
2023-08-31 19:15:01.877: [iter 95 : loss : 0.5513 = 0.0824 + 0.2312 + 0.0062 + 0.2316, time: 19.910838]
2023-08-31 19:15:02.508: epoch 95:	0.04049040  	0.08859687  	0.07332540  
2023-08-31 19:15:22.575: [iter 96 : loss : 0.5506 = 0.0830 + 0.2305 + 0.0063 + 0.2308, time: 20.058236]
2023-08-31 19:15:23.270: epoch 96:	0.04061296  	0.08893273  	0.07356618  
2023-08-31 19:15:23.270: Find a better model.
2023-08-31 19:15:43.431: [iter 97 : loss : 0.5488 = 0.0827 + 0.2297 + 0.0063 + 0.2301, time: 20.152478]
2023-08-31 19:15:44.078: epoch 97:	0.04068392  	0.08904005  	0.07362118  
2023-08-31 19:15:44.078: Find a better model.
2023-08-31 19:16:03.981: [iter 98 : loss : 0.5464 = 0.0819 + 0.2289 + 0.0064 + 0.2292, time: 19.893879]
2023-08-31 19:16:04.635: epoch 98:	0.04084519  	0.08932011  	0.07390133  
2023-08-31 19:16:04.635: Find a better model.
2023-08-31 19:16:24.875: [iter 99 : loss : 0.5437 = 0.0805 + 0.2282 + 0.0065 + 0.2285, time: 20.229633]
2023-08-31 19:16:25.594: epoch 99:	0.04089035  	0.08934658  	0.07407091  
2023-08-31 19:16:25.594: Find a better model.
2023-08-31 19:16:45.219: [iter 100 : loss : 0.5427 = 0.0810 + 0.2274 + 0.0066 + 0.2277, time: 19.614650]
2023-08-31 19:16:45.916: epoch 100:	0.04095486  	0.08938204  	0.07415623  
2023-08-31 19:16:45.916: Find a better model.
2023-08-31 19:17:05.897: [iter 101 : loss : 0.5402 = 0.0799 + 0.2266 + 0.0067 + 0.2270, time: 19.971871]
2023-08-31 19:17:06.527: epoch 101:	0.04107097  	0.08956988  	0.07432342  
2023-08-31 19:17:06.527: Find a better model.
2023-08-31 19:17:26.417: [iter 102 : loss : 0.5409 = 0.0820 + 0.2259 + 0.0067 + 0.2262, time: 19.879962]
2023-08-31 19:17:27.117: epoch 102:	0.04116128  	0.08994491  	0.07455232  
2023-08-31 19:17:27.117: Find a better model.
2023-08-31 19:17:46.999: [iter 103 : loss : 0.5380 = 0.0805 + 0.2252 + 0.0068 + 0.2255, time: 19.873661]
2023-08-31 19:17:47.686: epoch 103:	0.04136125  	0.09033085  	0.07482073  
2023-08-31 19:17:47.686: Find a better model.
2023-08-31 19:18:07.575: [iter 104 : loss : 0.5374 = 0.0813 + 0.2245 + 0.0069 + 0.2247, time: 19.879431]
2023-08-31 19:18:08.182: epoch 104:	0.04148380  	0.09057616  	0.07507923  
2023-08-31 19:18:08.182: Find a better model.
2023-08-31 19:18:27.956: [iter 105 : loss : 0.5341 = 0.0793 + 0.2237 + 0.0070 + 0.2240, time: 19.763009]
2023-08-31 19:18:28.611: epoch 105:	0.04157412  	0.09076951  	0.07531819  
2023-08-31 19:18:28.611: Find a better model.
2023-08-31 19:18:48.622: [iter 106 : loss : 0.5309 = 0.0776 + 0.2230 + 0.0071 + 0.2233, time: 20.002126]
2023-08-31 19:18:49.303: epoch 106:	0.04166443  	0.09101215  	0.07553188  
2023-08-31 19:18:49.303: Find a better model.
2023-08-31 19:19:09.236: [iter 107 : loss : 0.5313 = 0.0793 + 0.2222 + 0.0071 + 0.2225, time: 19.922649]
2023-08-31 19:19:09.865: epoch 107:	0.04177412  	0.09120750  	0.07557153  
2023-08-31 19:19:09.865: Find a better model.
2023-08-31 19:19:29.806: [iter 108 : loss : 0.5300 = 0.0794 + 0.2216 + 0.0072 + 0.2218, time: 19.932034]
2023-08-31 19:19:30.521: epoch 108:	0.04164508  	0.09098691  	0.07553764  
2023-08-31 19:19:50.489: [iter 109 : loss : 0.5276 = 0.0785 + 0.2208 + 0.0073 + 0.2210, time: 19.955697]
2023-08-31 19:19:51.140: epoch 109:	0.04167091  	0.09110910  	0.07561274  
2023-08-31 19:20:11.281: [iter 110 : loss : 0.5252 = 0.0774 + 0.2201 + 0.0074 + 0.2203, time: 20.131889]
2023-08-31 19:20:12.009: epoch 110:	0.04179994  	0.09125736  	0.07583392  
2023-08-31 19:20:12.009: Find a better model.
2023-08-31 19:20:31.812: [iter 111 : loss : 0.5236 = 0.0772 + 0.2194 + 0.0075 + 0.2196, time: 19.793488]
2023-08-31 19:20:32.500: epoch 111:	0.04189671  	0.09142671  	0.07590649  
2023-08-31 19:20:32.500: Find a better model.
2023-08-31 19:20:52.531: [iter 112 : loss : 0.5244 = 0.0792 + 0.2188 + 0.0075 + 0.2189, time: 20.022310]
2023-08-31 19:20:53.153: epoch 112:	0.04192251  	0.09152340  	0.07615332  
2023-08-31 19:20:53.154: Find a better model.
2023-08-31 19:21:13.484: [iter 113 : loss : 0.5230 = 0.0792 + 0.2180 + 0.0076 + 0.2182, time: 20.320481]
2023-08-31 19:21:14.211: epoch 113:	0.04212249  	0.09216982  	0.07641926  
2023-08-31 19:21:14.211: Find a better model.
2023-08-31 19:21:34.590: [iter 114 : loss : 0.5197 = 0.0772 + 0.2173 + 0.0077 + 0.2175, time: 20.367547]
2023-08-31 19:21:35.250: epoch 114:	0.04199991  	0.09183806  	0.07627755  
2023-08-31 19:21:55.511: [iter 115 : loss : 0.5191 = 0.0779 + 0.2166 + 0.0078 + 0.2168, time: 20.252369]
2023-08-31 19:21:56.223: epoch 115:	0.04204505  	0.09186434  	0.07644351  
2023-08-31 19:22:16.172: [iter 116 : loss : 0.5162 = 0.0764 + 0.2159 + 0.0079 + 0.2161, time: 19.938689]
2023-08-31 19:22:16.802: epoch 116:	0.04218054  	0.09227931  	0.07669583  
2023-08-31 19:22:16.802: Find a better model.
2023-08-31 19:22:36.714: [iter 117 : loss : 0.5156 = 0.0771 + 0.2151 + 0.0080 + 0.2154, time: 19.901855]
2023-08-31 19:22:37.347: epoch 117:	0.04222569  	0.09229818  	0.07687743  
2023-08-31 19:22:37.348: Find a better model.
2023-08-31 19:22:57.002: [iter 118 : loss : 0.5147 = 0.0773 + 0.2146 + 0.0080 + 0.2147, time: 19.644779]
2023-08-31 19:22:57.718: epoch 118:	0.04234825  	0.09246828  	0.07697901  
2023-08-31 19:22:57.718: Find a better model.
2023-08-31 19:23:17.676: [iter 119 : loss : 0.5121 = 0.0762 + 0.2138 + 0.0081 + 0.2140, time: 19.948238]
2023-08-31 19:23:18.313: epoch 119:	0.04236761  	0.09260114  	0.07707831  
2023-08-31 19:23:18.314: Find a better model.
2023-08-31 19:23:38.141: [iter 120 : loss : 0.5111 = 0.0765 + 0.2131 + 0.0082 + 0.2133, time: 19.813004]
2023-08-31 19:23:38.773: epoch 120:	0.04245145  	0.09271748  	0.07716048  
2023-08-31 19:23:38.773: Find a better model.
2023-08-31 19:23:58.893: [iter 121 : loss : 0.5108 = 0.0774 + 0.2125 + 0.0083 + 0.2126, time: 20.109496]
2023-08-31 19:23:59.519: epoch 121:	0.04253533  	0.09285317  	0.07721092  
2023-08-31 19:23:59.519: Find a better model.
2023-08-31 19:24:19.492: [iter 122 : loss : 0.5074 = 0.0753 + 0.2118 + 0.0084 + 0.2119, time: 19.960199]
2023-08-31 19:24:20.180: epoch 122:	0.04259986  	0.09297652  	0.07732690  
2023-08-31 19:24:20.181: Find a better model.
2023-08-31 19:24:40.108: [iter 123 : loss : 0.5071 = 0.0763 + 0.2111 + 0.0084 + 0.2113, time: 19.918641]
2023-08-31 19:24:40.712: epoch 123:	0.04265145  	0.09313647  	0.07744000  
2023-08-31 19:24:40.713: Find a better model.
2023-08-31 19:25:00.590: [iter 124 : loss : 0.5051 = 0.0756 + 0.2104 + 0.0085 + 0.2106, time: 19.869331]
2023-08-31 19:25:01.272: epoch 124:	0.04258693  	0.09315673  	0.07749119  
2023-08-31 19:25:01.272: Find a better model.
2023-08-31 19:25:21.270: [iter 125 : loss : 0.5041 = 0.0758 + 0.2097 + 0.0086 + 0.2099, time: 19.988405]
2023-08-31 19:25:21.942: epoch 125:	0.04265791  	0.09321248  	0.07758782  
2023-08-31 19:25:21.942: Find a better model.
2023-08-31 19:25:41.844: [iter 126 : loss : 0.5029 = 0.0758 + 0.2091 + 0.0087 + 0.2093, time: 19.889784]
2023-08-31 19:25:42.543: epoch 126:	0.04266436  	0.09332772  	0.07770310  
2023-08-31 19:25:42.543: Find a better model.
2023-08-31 19:26:02.285: [iter 127 : loss : 0.5028 = 0.0770 + 0.2084 + 0.0088 + 0.2086, time: 19.733602]
2023-08-31 19:26:02.923: epoch 127:	0.04281917  	0.09359061  	0.07785180  
2023-08-31 19:26:02.923: Find a better model.
2023-08-31 19:26:22.687: [iter 128 : loss : 0.5005 = 0.0759 + 0.2078 + 0.0089 + 0.2080, time: 19.755820]
2023-08-31 19:26:23.325: epoch 128:	0.04263209  	0.09314246  	0.07769208  
2023-08-31 19:26:43.413: [iter 129 : loss : 0.4992 = 0.0758 + 0.2072 + 0.0089 + 0.2073, time: 20.079258]
2023-08-31 19:26:44.048: epoch 129:	0.04286433  	0.09374043  	0.07802828  
2023-08-31 19:26:44.048: Find a better model.
2023-08-31 19:27:04.417: [iter 130 : loss : 0.4970 = 0.0746 + 0.2066 + 0.0090 + 0.2067, time: 20.355589]
2023-08-31 19:27:05.060: epoch 130:	0.04286433  	0.09358612  	0.07808984  
2023-08-31 19:27:25.015: [iter 131 : loss : 0.4977 = 0.0767 + 0.2059 + 0.0091 + 0.2060, time: 19.944183]
2023-08-31 19:27:25.682: epoch 131:	0.04289659  	0.09365464  	0.07812269  
2023-08-31 19:27:45.649: [iter 132 : loss : 0.4939 = 0.0741 + 0.2053 + 0.0092 + 0.2054, time: 19.957253]
2023-08-31 19:27:46.307: epoch 132:	0.04287726  	0.09357555  	0.07817691  
2023-08-31 19:28:06.119: [iter 133 : loss : 0.4932 = 0.0746 + 0.2046 + 0.0093 + 0.2047, time: 19.799980]
2023-08-31 19:28:06.747: epoch 133:	0.04289017  	0.09370910  	0.07821044  
2023-08-31 19:28:27.049: [iter 134 : loss : 0.4935 = 0.0759 + 0.2040 + 0.0093 + 0.2042, time: 20.291049]
2023-08-31 19:28:27.737: epoch 134:	0.04293533  	0.09383649  	0.07826228  
2023-08-31 19:28:27.737: Find a better model.
2023-08-31 19:28:48.064: [iter 135 : loss : 0.4909 = 0.0746 + 0.2034 + 0.0094 + 0.2035, time: 20.314619]
2023-08-31 19:28:48.682: epoch 135:	0.04297399  	0.09388825  	0.07831950  
2023-08-31 19:28:48.683: Find a better model.
2023-08-31 19:29:08.883: [iter 136 : loss : 0.4890 = 0.0740 + 0.2027 + 0.0095 + 0.2029, time: 20.188319]
2023-08-31 19:29:09.511: epoch 136:	0.04295464  	0.09392597  	0.07845157  
2023-08-31 19:29:09.511: Find a better model.
2023-08-31 19:29:30.311: [iter 137 : loss : 0.4880 = 0.0741 + 0.2021 + 0.0096 + 0.2022, time: 20.787651]
2023-08-31 19:29:31.032: epoch 137:	0.04299980  	0.09410620  	0.07853080  
2023-08-31 19:29:31.032: Find a better model.
2023-08-31 19:29:51.170: [iter 138 : loss : 0.4876 = 0.0749 + 0.2015 + 0.0097 + 0.2016, time: 20.118406]
2023-08-31 19:29:51.872: epoch 138:	0.04307078  	0.09415220  	0.07866716  
2023-08-31 19:29:51.872: Find a better model.
2023-08-31 19:30:12.336: [iter 139 : loss : 0.4852 = 0.0736 + 0.2008 + 0.0098 + 0.2010, time: 20.443462]
2023-08-31 19:30:12.995: epoch 139:	0.04301915  	0.09413470  	0.07867906  
2023-08-31 19:30:33.401: [iter 140 : loss : 0.4856 = 0.0751 + 0.2003 + 0.0098 + 0.2004, time: 20.393262]
2023-08-31 19:30:34.125: epoch 140:	0.04317400  	0.09445491  	0.07886901  
2023-08-31 19:30:34.126: Find a better model.
2023-08-31 19:30:54.120: [iter 141 : loss : 0.4844 = 0.0750 + 0.1997 + 0.0099 + 0.1998, time: 19.982579]
2023-08-31 19:30:54.818: epoch 141:	0.04321917  	0.09459633  	0.07890081  
2023-08-31 19:30:54.818: Find a better model.

2023-08-31 19:31:50.608: my pid: 24439
2023-08-31 19:31:50.608: model: model.general_recommender.GNNEC
2023-08-31 19:31:50.608: Dataset statistics:
Name: yelp
The number of users: 7750
The number of items: 28918
The number of ratings: 750318
Average actions of users: 96.82
Average actions of items: 25.95
The sparsity of the dataset: 99.665208%

The number of training: 678579
The number of validation: 0
The number of testing: 71739
2023-08-31 19:31:50.608: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=yelp
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.2
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=100
batch_size=4096
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=yelp
epochs=100
n_layers=2
embed_size=32
batch_size=4096
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.2
mf_reg=0.02
svd_q=5
2023-08-31 19:32:11.194: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-08-31 19:32:32.015: [iter 1 : loss : 1.2921 = 0.6226 + 0.3343 + 0.0000 + 0.3352, time: 20.820813]
2023-08-31 19:32:32.678: epoch 1:	0.02547795  	0.05498080  	0.04688417  
2023-08-31 19:32:32.678: Find a better model.
2023-08-31 19:32:52.724: [iter 2 : loss : 0.9991 = 0.4003 + 0.3024 + 0.0001 + 0.2964, time: 20.034300]
2023-08-31 19:32:53.390: epoch 2:	0.02630378  	0.05689172  	0.04825901  
2023-08-31 19:32:53.395: Find a better model.
2023-08-31 19:33:13.560: [iter 3 : loss : 0.8747 = 0.2932 + 0.2956 + 0.0003 + 0.2857, time: 20.151119]
2023-08-31 19:33:14.204: epoch 3:	0.02786514  	0.06043925  	0.05075212  
2023-08-31 19:33:14.205: Find a better model.
2023-08-31 19:33:34.141: [iter 4 : loss : 0.8156 = 0.2511 + 0.2864 + 0.0003 + 0.2777, time: 19.922786]
2023-08-31 19:33:34.762: epoch 4:	0.02912324  	0.06329309  	0.05272022  
2023-08-31 19:33:34.762: Find a better model.
2023-08-31 19:33:54.842: [iter 5 : loss : 0.7773 = 0.2297 + 0.2770 + 0.0004 + 0.2702, time: 20.069464]
2023-08-31 19:33:55.478: epoch 5:	0.03018135  	0.06516114  	0.05462107  
2023-08-31 19:33:55.478: Find a better model.
2023-08-31 19:34:15.414: [iter 6 : loss : 0.7455 = 0.2151 + 0.2674 + 0.0005 + 0.2625, time: 19.926528]
2023-08-31 19:34:16.062: epoch 6:	0.03105237  	0.06695815  	0.05652506  
2023-08-31 19:34:16.062: Find a better model.
2023-08-31 19:34:35.930: [iter 7 : loss : 0.7147 = 0.2014 + 0.2581 + 0.0006 + 0.2547, time: 19.859751]
2023-08-31 19:34:36.558: epoch 7:	0.03211691  	0.06916727  	0.05789100  
2023-08-31 19:34:36.558: Find a better model.
2023-08-31 19:34:56.417: [iter 8 : loss : 0.6875 = 0.1915 + 0.2487 + 0.0006 + 0.2466, time: 19.848063]
2023-08-31 19:34:57.084: epoch 8:	0.03302016  	0.07099628  	0.05980869  
2023-08-31 19:34:57.084: Find a better model.
2023-08-31 19:35:16.997: [iter 9 : loss : 0.6610 = 0.1825 + 0.2394 + 0.0007 + 0.2384, time: 19.903019]
2023-08-31 19:35:17.682: epoch 9:	0.03382008  	0.07300664  	0.06106439  
2023-08-31 19:35:17.682: Find a better model.
2023-08-31 19:35:37.523: [iter 10 : loss : 0.6351 = 0.1744 + 0.2300 + 0.0008 + 0.2298, time: 19.824853]
2023-08-31 19:35:38.161: epoch 10:	0.03481998  	0.07513959  	0.06297250  
2023-08-31 19:35:38.161: Find a better model.
2023-08-31 19:35:58.065: [iter 11 : loss : 0.6100 = 0.1670 + 0.2210 + 0.0009 + 0.2211, time: 19.895825]
2023-08-31 19:35:58.738: epoch 11:	0.03579408  	0.07740524  	0.06472080  
2023-08-31 19:35:58.738: Find a better model.
2023-08-31 19:36:18.746: [iter 12 : loss : 0.5843 = 0.1600 + 0.2112 + 0.0009 + 0.2121, time: 19.996217]
2023-08-31 19:36:19.400: epoch 12:	0.03655525  	0.07906028  	0.06595889  
2023-08-31 19:36:19.400: Find a better model.
2023-08-31 19:36:39.957: [iter 13 : loss : 0.5602 = 0.1546 + 0.2019 + 0.0010 + 0.2027, time: 20.546506]
2023-08-31 19:36:40.655: epoch 13:	0.03714876  	0.08043438  	0.06722134  
2023-08-31 19:36:40.656: Find a better model.
2023-08-31 19:37:00.704: [iter 14 : loss : 0.5347 = 0.1482 + 0.1922 + 0.0011 + 0.1932, time: 20.032139]
2023-08-31 19:37:01.337: epoch 14:	0.03769713  	0.08177076  	0.06858912  
2023-08-31 19:37:01.337: Find a better model.
2023-08-31 19:37:21.431: [iter 15 : loss : 0.5109 = 0.1439 + 0.1823 + 0.0012 + 0.1836, time: 20.079835]
2023-08-31 19:37:22.034: epoch 15:	0.03779389  	0.08213928  	0.06909093  
2023-08-31 19:37:22.035: Find a better model.
2023-08-31 19:37:42.213: [iter 16 : loss : 0.4871 = 0.1390 + 0.1729 + 0.0013 + 0.1739, time: 20.168237]
2023-08-31 19:37:42.856: epoch 16:	0.03801323  	0.08274870  	0.07002397  
2023-08-31 19:37:42.856: Find a better model.
2023-08-31 19:38:02.924: [iter 17 : loss : 0.4631 = 0.1347 + 0.1628 + 0.0014 + 0.1642, time: 20.058385]
2023-08-31 19:38:03.589: epoch 17:	0.03827121  	0.08356412  	0.07051468  
2023-08-31 19:38:03.589: Find a better model.
2023-08-31 19:38:23.700: [iter 18 : loss : 0.4403 = 0.1307 + 0.1534 + 0.0016 + 0.1546, time: 20.101688]
2023-08-31 19:38:24.336: epoch 18:	0.03845184  	0.08386663  	0.07084857  
2023-08-31 19:38:24.336: Find a better model.
2023-08-31 19:38:44.466: [iter 19 : loss : 0.4175 = 0.1266 + 0.1439 + 0.0017 + 0.1453, time: 20.118133]
2023-08-31 19:38:45.106: epoch 19:	0.03868406  	0.08463552  	0.07139232  
2023-08-31 19:38:45.106: Find a better model.
2023-08-31 19:39:05.153: [iter 20 : loss : 0.3966 = 0.1232 + 0.1352 + 0.0018 + 0.1364, time: 20.037425]
2023-08-31 19:39:05.773: epoch 20:	0.03887117  	0.08500100  	0.07152382  
2023-08-31 19:39:05.774: Find a better model.
2023-08-31 19:39:25.921: [iter 21 : loss : 0.3762 = 0.1195 + 0.1267 + 0.0019 + 0.1280, time: 20.133342]
2023-08-31 19:39:26.538: epoch 21:	0.03900665  	0.08517503  	0.07139717  
2023-08-31 19:39:26.538: Find a better model.
2023-08-31 19:39:46.626: [iter 22 : loss : 0.3579 = 0.1165 + 0.1192 + 0.0021 + 0.1201, time: 20.077787]
2023-08-31 19:39:47.315: epoch 22:	0.03928404  	0.08588051  	0.07177458  
2023-08-31 19:39:47.315: Find a better model.
2023-08-31 19:40:07.326: [iter 23 : loss : 0.3404 = 0.1134 + 0.1120 + 0.0022 + 0.1128, time: 19.994506]
2023-08-31 19:40:08.014: epoch 23:	0.03946467  	0.08604572  	0.07206140  
2023-08-31 19:40:08.015: Find a better model.
2023-08-31 19:40:27.957: [iter 24 : loss : 0.3253 = 0.1114 + 0.1055 + 0.0023 + 0.1061, time: 19.932668]
2023-08-31 19:40:28.632: epoch 24:	0.03948401  	0.08600838  	0.07210131  
2023-08-31 19:40:48.695: [iter 25 : loss : 0.3108 = 0.1086 + 0.0996 + 0.0025 + 0.1001, time: 20.050778]
2023-08-31 19:40:49.382: epoch 25:	0.03947112  	0.08578543  	0.07167941  
2023-08-31 19:41:09.452: [iter 26 : loss : 0.2982 = 0.1065 + 0.0944 + 0.0026 + 0.0948, time: 20.054776]
2023-08-31 19:41:10.118: epoch 26:	0.03952273  	0.08576002  	0.07178940  
2023-08-31 19:41:30.230: [iter 27 : loss : 0.2858 = 0.1036 + 0.0895 + 0.0027 + 0.0899, time: 20.101425]
2023-08-31 19:41:30.861: epoch 27:	0.03962592  	0.08588712  	0.07178144  
2023-08-31 19:41:51.011: [iter 28 : loss : 0.2752 = 0.1015 + 0.0852 + 0.0028 + 0.0856, time: 20.139202]
2023-08-31 19:41:51.663: epoch 28:	0.03949044  	0.08571150  	0.07154648  
2023-08-31 19:42:11.783: [iter 29 : loss : 0.2662 = 0.1001 + 0.0815 + 0.0030 + 0.0817, time: 20.109960]
2023-08-31 19:42:12.457: epoch 29:	0.03946464  	0.08581416  	0.07159855  
2023-08-31 19:42:31.378: [iter 30 : loss : 0.2574 = 0.0980 + 0.0781 + 0.0031 + 0.0782, time: 18.910430]
2023-08-31 19:42:32.051: epoch 30:	0.03938724  	0.08563988  	0.07134787  
2023-08-31 19:42:50.965: [iter 31 : loss : 0.2490 = 0.0958 + 0.0750 + 0.0032 + 0.0750, time: 18.901442]
2023-08-31 19:42:51.603: epoch 31:	0.03940659  	0.08559199  	0.07141602  
2023-08-31 19:43:11.279: [iter 32 : loss : 0.2412 = 0.0938 + 0.0720 + 0.0033 + 0.0721, time: 19.667501]
2023-08-31 19:43:11.948: epoch 32:	0.03920660  	0.08491968  	0.07095242  
2023-08-31 19:43:31.964: [iter 33 : loss : 0.2344 = 0.0923 + 0.0693 + 0.0034 + 0.0693, time: 20.004349]
2023-08-31 19:43:32.665: epoch 33:	0.03920013  	0.08495178  	0.07097035  
2023-08-31 19:43:32.665: Early stopping is trigger at epoch: 33
2023-08-31 19:43:32.665: best_result@epoch 23:

2023-08-31 19:43:32.665: 		0.0395      	0.0860      	0.0721      

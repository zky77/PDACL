2023-11-02 12:04:41.472: my pid: 13146
2023-11-02 12:04:41.472: model: model.general_recommender.GNNEC
2023-11-02 12:04:41.472: Dataset statistics:
Name: amazon-book
The number of users: 7928
The number of items: 29346
The number of ratings: 460224
Average actions of users: 58.05
Average actions of items: 15.68
The sparsity of the dataset: 99.802186%

The number of training: 417417
The number of validation: 0
The number of testing: 42807
2023-11-02 12:04:41.472: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=amazon-book
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=2
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=amazon-book
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=2
mf_reg=1e-4
svd_q=5
2023-11-02 12:04:46.205: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-11-02 12:04:59.536: [iter 1 : loss : 0.9843 = 0.6131 + 0.3693 + 0.0000 + 0.0018, time: 13.330063]
2023-11-02 12:05:00.210: epoch 1:	0.00951689  	0.03605069  	0.02357339  
2023-11-02 12:05:00.210: Find a better model.
2023-11-02 12:05:12.899: [iter 2 : loss : 0.8419 = 0.4898 + 0.3502 + 0.0001 + 0.0018, time: 12.670805]
2023-11-02 12:05:13.563: epoch 2:	0.01043141  	0.03962213  	0.02620228  
2023-11-02 12:05:13.563: Find a better model.
2023-11-02 12:05:26.182: [iter 3 : loss : 0.7753 = 0.4312 + 0.3422 + 0.0002 + 0.0017, time: 12.598966]
2023-11-02 12:05:26.807: epoch 3:	0.01096750  	0.04193069  	0.02814336  
2023-11-02 12:05:26.807: Find a better model.
2023-11-02 12:05:39.205: [iter 4 : loss : 0.7300 = 0.3914 + 0.3366 + 0.0003 + 0.0017, time: 12.378849]
2023-11-02 12:05:39.854: epoch 4:	0.01150360  	0.04419579  	0.02984364  
2023-11-02 12:05:39.855: Find a better model.
2023-11-02 12:05:52.436: [iter 5 : loss : 0.6944 = 0.3601 + 0.3323 + 0.0004 + 0.0017, time: 12.563160]
2023-11-02 12:05:53.064: epoch 5:	0.01219737  	0.04689990  	0.03174790  
2023-11-02 12:05:53.065: Find a better model.
2023-11-02 12:06:05.182: [iter 6 : loss : 0.6682 = 0.3374 + 0.3287 + 0.0005 + 0.0016, time: 12.099085]
2023-11-02 12:06:05.817: epoch 6:	0.01268931  	0.04879557  	0.03306890  
2023-11-02 12:06:05.817: Find a better model.
2023-11-02 12:06:18.326: [iter 7 : loss : 0.6466 = 0.3187 + 0.3257 + 0.0006 + 0.0016, time: 12.490336]
2023-11-02 12:06:19.014: epoch 7:	0.01312450  	0.05058226  	0.03455696  
2023-11-02 12:06:19.015: Find a better model.
2023-11-02 12:06:31.400: [iter 8 : loss : 0.6286 = 0.3031 + 0.3232 + 0.0007 + 0.0016, time: 12.364005]
2023-11-02 12:06:32.084: epoch 8:	0.01364798  	0.05289294  	0.03610034  
2023-11-02 12:06:32.084: Find a better model.
2023-11-02 12:06:44.291: [iter 9 : loss : 0.6107 = 0.2876 + 0.3208 + 0.0007 + 0.0016, time: 12.185995]
2023-11-02 12:06:44.909: epoch 9:	0.01374258  	0.05304559  	0.03663826  
2023-11-02 12:06:44.910: Find a better model.
2023-11-02 12:06:57.205: [iter 10 : loss : 0.5971 = 0.2759 + 0.3188 + 0.0008 + 0.0016, time: 12.279611]
2023-11-02 12:06:57.790: epoch 10:	0.01411470  	0.05442996  	0.03775901  
2023-11-02 12:06:57.790: Find a better model.
2023-11-02 12:07:10.115: [iter 11 : loss : 0.5839 = 0.2646 + 0.3168 + 0.0009 + 0.0016, time: 12.309836]
2023-11-02 12:07:10.762: epoch 11:	0.01443634  	0.05565702  	0.03862724  
2023-11-02 12:07:10.762: Find a better model.
2023-11-02 12:07:23.100: [iter 12 : loss : 0.5724 = 0.2548 + 0.3151 + 0.0010 + 0.0016, time: 12.322042]
2023-11-02 12:07:23.752: epoch 12:	0.01473908  	0.05688701  	0.03957018  
2023-11-02 12:07:23.752: Find a better model.
2023-11-02 12:07:36.190: [iter 13 : loss : 0.5626 = 0.2465 + 0.3135 + 0.0010 + 0.0016, time: 12.423797]
2023-11-02 12:07:36.827: epoch 13:	0.01507965  	0.05861696  	0.04059128  
2023-11-02 12:07:36.828: Find a better model.
2023-11-02 12:07:49.182: [iter 14 : loss : 0.5522 = 0.2377 + 0.3119 + 0.0011 + 0.0015, time: 12.337988]
2023-11-02 12:07:49.832: epoch 14:	0.01550852  	0.06029768  	0.04136861  
2023-11-02 12:07:49.832: Find a better model.
2023-11-02 12:08:02.335: [iter 15 : loss : 0.5414 = 0.2285 + 0.3102 + 0.0012 + 0.0015, time: 12.474311]
2023-11-02 12:08:03.017: epoch 15:	0.01576080  	0.06154815  	0.04238141  
2023-11-02 12:08:03.017: Find a better model.
2023-11-02 12:08:15.514: [iter 16 : loss : 0.5340 = 0.2224 + 0.3088 + 0.0012 + 0.0015, time: 12.477675]
2023-11-02 12:08:16.167: epoch 16:	0.01613292  	0.06296101  	0.04362035  
2023-11-02 12:08:16.167: Find a better model.
2023-11-02 12:08:28.450: [iter 17 : loss : 0.5263 = 0.2163 + 0.3073 + 0.0013 + 0.0015, time: 12.267179]
2023-11-02 12:08:29.082: epoch 17:	0.01650503  	0.06452074  	0.04474328  
2023-11-02 12:08:29.082: Find a better model.
2023-11-02 12:08:41.332: [iter 18 : loss : 0.5194 = 0.2106 + 0.3059 + 0.0014 + 0.0015, time: 12.234129]
2023-11-02 12:08:42.008: epoch 18:	0.01690237  	0.06625619  	0.04569586  
2023-11-02 12:08:42.008: Find a better model.
2023-11-02 12:08:54.514: [iter 19 : loss : 0.5121 = 0.2045 + 0.3047 + 0.0015 + 0.0015, time: 12.490491]
2023-11-02 12:08:55.165: epoch 19:	0.01716727  	0.06748374  	0.04630718  
2023-11-02 12:08:55.166: Find a better model.
2023-11-02 12:09:07.682: [iter 20 : loss : 0.5053 = 0.1988 + 0.3035 + 0.0015 + 0.0015, time: 12.500427]
2023-11-02 12:09:08.319: epoch 20:	0.01744478  	0.06882752  	0.04701200  
2023-11-02 12:09:08.319: Find a better model.
2023-11-02 12:09:20.782: [iter 21 : loss : 0.4983 = 0.1931 + 0.3021 + 0.0016 + 0.0015, time: 12.447338]
2023-11-02 12:09:21.450: epoch 21:	0.01771598  	0.06998411  	0.04793290  
2023-11-02 12:09:21.451: Find a better model.
2023-11-02 12:09:34.022: [iter 22 : loss : 0.4928 = 0.1889 + 0.3007 + 0.0017 + 0.0015, time: 12.553664]
2023-11-02 12:09:34.657: epoch 22:	0.01782320  	0.07066789  	0.04839616  
2023-11-02 12:09:34.657: Find a better model.
2023-11-02 12:09:47.142: [iter 23 : loss : 0.4877 = 0.1848 + 0.2997 + 0.0017 + 0.0015, time: 12.470316]
2023-11-02 12:09:47.773: epoch 23:	0.01804395  	0.07112177  	0.04884404  
2023-11-02 12:09:47.773: Find a better model.
2023-11-02 12:10:00.108: [iter 24 : loss : 0.4834 = 0.1813 + 0.2988 + 0.0018 + 0.0015, time: 12.311038]
2023-11-02 12:10:00.750: epoch 24:	0.01828992  	0.07234599  	0.04973314  
2023-11-02 12:10:00.750: Find a better model.
2023-11-02 12:10:13.132: [iter 25 : loss : 0.4776 = 0.1765 + 0.2979 + 0.0019 + 0.0015, time: 12.368217]
2023-11-02 12:10:13.765: epoch 25:	0.01868097  	0.07408655  	0.05065063  
2023-11-02 12:10:13.766: Find a better model.
2023-11-02 12:10:26.328: [iter 26 : loss : 0.4714 = 0.1716 + 0.2964 + 0.0019 + 0.0015, time: 12.548664]
2023-11-02 12:10:26.993: epoch 26:	0.01888278  	0.07478755  	0.05125334  
2023-11-02 12:10:26.993: Find a better model.
2023-11-02 12:10:39.255: [iter 27 : loss : 0.4675 = 0.1685 + 0.2956 + 0.0020 + 0.0015, time: 12.244042]
2023-11-02 12:10:39.907: epoch 27:	0.01907829  	0.07548214  	0.05174346  
2023-11-02 12:10:39.907: Find a better model.
2023-11-02 12:10:52.275: [iter 28 : loss : 0.4623 = 0.1647 + 0.2941 + 0.0021 + 0.0015, time: 12.353301]
2023-11-02 12:10:52.923: epoch 28:	0.01917290  	0.07590558  	0.05200192  
2023-11-02 12:10:52.923: Find a better model.
2023-11-02 12:11:05.313: [iter 29 : loss : 0.4578 = 0.1609 + 0.2933 + 0.0021 + 0.0014, time: 12.375175]
2023-11-02 12:11:05.978: epoch 29:	0.01923597  	0.07605252  	0.05221420  
2023-11-02 12:11:05.979: Find a better model.
2023-11-02 12:11:18.238: [iter 30 : loss : 0.4550 = 0.1591 + 0.2923 + 0.0022 + 0.0014, time: 12.246572]
2023-11-02 12:11:18.894: epoch 30:	0.01934320  	0.07677547  	0.05259245  
2023-11-02 12:11:18.894: Find a better model.
2023-11-02 12:11:31.078: [iter 31 : loss : 0.4495 = 0.1544 + 0.2914 + 0.0023 + 0.0014, time: 12.168603]
2023-11-02 12:11:31.691: epoch 31:	0.01960179  	0.07773646  	0.05328000  
2023-11-02 12:11:31.691: Find a better model.
2023-11-02 12:11:44.084: [iter 32 : loss : 0.4474 = 0.1534 + 0.2902 + 0.0023 + 0.0014, time: 12.377841]
2023-11-02 12:11:44.738: epoch 32:	0.01989190  	0.07877943  	0.05389460  
2023-11-02 12:11:44.738: Find a better model.
2023-11-02 12:11:57.179: [iter 33 : loss : 0.4420 = 0.1489 + 0.2893 + 0.0024 + 0.0014, time: 12.423563]
2023-11-02 12:11:57.845: epoch 33:	0.02007481  	0.07962030  	0.05446618  
2023-11-02 12:11:57.846: Find a better model.
2023-11-02 12:12:10.287: [iter 34 : loss : 0.4399 = 0.1477 + 0.2883 + 0.0025 + 0.0014, time: 12.421416]
2023-11-02 12:12:10.941: epoch 34:	0.02011265  	0.07980779  	0.05484475  
2023-11-02 12:12:10.942: Find a better model.
2023-11-02 12:12:23.307: [iter 35 : loss : 0.4348 = 0.1434 + 0.2874 + 0.0025 + 0.0014, time: 12.352266]
2023-11-02 12:12:23.975: epoch 35:	0.02035231  	0.08068681  	0.05527232  
2023-11-02 12:12:23.975: Find a better model.
2023-11-02 12:12:36.281: [iter 36 : loss : 0.4315 = 0.1410 + 0.2865 + 0.0026 + 0.0014, time: 12.290758]
2023-11-02 12:12:36.922: epoch 36:	0.02059828  	0.08176340  	0.05578756  
2023-11-02 12:12:36.922: Find a better model.
2023-11-02 12:12:49.572: [iter 37 : loss : 0.4285 = 0.1387 + 0.2857 + 0.0027 + 0.0014, time: 12.619159]
2023-11-02 12:12:50.199: epoch 37:	0.02078750  	0.08253296  	0.05622150  
2023-11-02 12:12:50.200: Find a better model.
2023-11-02 12:13:02.783: [iter 38 : loss : 0.4260 = 0.1370 + 0.2848 + 0.0027 + 0.0014, time: 12.565198]
2023-11-02 12:13:03.459: epoch 38:	0.02098301  	0.08340109  	0.05669641  
2023-11-02 12:13:03.460: Find a better model.
2023-11-02 12:13:16.160: [iter 39 : loss : 0.4215 = 0.1333 + 0.2839 + 0.0028 + 0.0014, time: 12.685362]
2023-11-02 12:13:16.828: epoch 39:	0.02118484  	0.08420058  	0.05724943  
2023-11-02 12:13:16.828: Find a better model.
2023-11-02 12:13:29.378: [iter 40 : loss : 0.4197 = 0.1325 + 0.2830 + 0.0029 + 0.0014, time: 12.536177]
2023-11-02 12:13:30.037: epoch 40:	0.02141189  	0.08510171  	0.05768662  
2023-11-02 12:13:30.037: Find a better model.
2023-11-02 12:13:42.603: [iter 41 : loss : 0.4160 = 0.1295 + 0.2821 + 0.0029 + 0.0014, time: 12.550957]
2023-11-02 12:13:43.253: epoch 41:	0.02144974  	0.08552002  	0.05798385  
2023-11-02 12:13:43.253: Find a better model.
2023-11-02 12:13:55.881: [iter 42 : loss : 0.4132 = 0.1275 + 0.2814 + 0.0030 + 0.0014, time: 12.613739]
2023-11-02 12:13:56.519: epoch 42:	0.02151280  	0.08564122  	0.05822090  
2023-11-02 12:13:56.520: Find a better model.
2023-11-02 12:14:08.741: [iter 43 : loss : 0.4106 = 0.1258 + 0.2803 + 0.0031 + 0.0014, time: 12.206603]
2023-11-02 12:14:09.399: epoch 43:	0.02164524  	0.08588401  	0.05846941  
2023-11-02 12:14:09.399: Find a better model.
2023-11-02 12:14:21.683: [iter 44 : loss : 0.4086 = 0.1244 + 0.2797 + 0.0031 + 0.0014, time: 12.271530]
2023-11-02 12:14:22.289: epoch 44:	0.02175877  	0.08672703  	0.05908667  
2023-11-02 12:14:22.289: Find a better model.
2023-11-02 12:14:34.880: [iter 45 : loss : 0.4052 = 0.1217 + 0.2789 + 0.0032 + 0.0014, time: 12.572185]
2023-11-02 12:14:35.566: epoch 45:	0.02204889  	0.08790920  	0.05953784  
2023-11-02 12:14:35.566: Find a better model.
2023-11-02 12:14:47.919: [iter 46 : loss : 0.4026 = 0.1200 + 0.2780 + 0.0033 + 0.0014, time: 12.337857]
2023-11-02 12:14:48.524: epoch 46:	0.02204890  	0.08792745  	0.05987539  
2023-11-02 12:14:48.524: Find a better model.
2023-11-02 12:15:00.767: [iter 47 : loss : 0.4008 = 0.1189 + 0.2772 + 0.0033 + 0.0014, time: 12.230119]
2023-11-02 12:15:01.426: epoch 47:	0.02219396  	0.08817251  	0.06015729  
2023-11-02 12:15:01.426: Find a better model.
2023-11-02 12:15:13.787: [iter 48 : loss : 0.3978 = 0.1163 + 0.2767 + 0.0034 + 0.0014, time: 12.346638]
2023-11-02 12:15:14.460: epoch 48:	0.02231378  	0.08870355  	0.06042483  
2023-11-02 12:15:14.460: Find a better model.
2023-11-02 12:15:26.861: [iter 49 : loss : 0.3950 = 0.1144 + 0.2758 + 0.0035 + 0.0014, time: 12.385807]
2023-11-02 12:15:27.474: epoch 49:	0.02240839  	0.08936540  	0.06070932  
2023-11-02 12:15:27.474: Find a better model.
2023-11-02 12:15:39.625: [iter 50 : loss : 0.3922 = 0.1126 + 0.2747 + 0.0035 + 0.0013, time: 12.134382]
2023-11-02 12:15:40.286: epoch 50:	0.02253452  	0.08956954  	0.06114771  
2023-11-02 12:15:40.286: Find a better model.
2023-11-02 12:15:52.767: [iter 51 : loss : 0.3911 = 0.1120 + 0.2742 + 0.0036 + 0.0013, time: 12.461854]
2023-11-02 12:15:53.434: epoch 51:	0.02261020  	0.08985818  	0.06133787  
2023-11-02 12:15:53.434: Find a better model.
2023-11-02 12:16:05.890: [iter 52 : loss : 0.3885 = 0.1102 + 0.2733 + 0.0037 + 0.0013, time: 12.439690]
2023-11-02 12:16:06.554: epoch 52:	0.02281203  	0.09075873  	0.06204554  
2023-11-02 12:16:06.554: Find a better model.
2023-11-02 12:16:18.891: [iter 53 : loss : 0.3863 = 0.1086 + 0.2726 + 0.0037 + 0.0013, time: 12.323203]
2023-11-02 12:16:19.538: epoch 53:	0.02278681  	0.09089173  	0.06222928  
2023-11-02 12:16:19.538: Find a better model.
2023-11-02 12:16:32.017: [iter 54 : loss : 0.3842 = 0.1073 + 0.2718 + 0.0038 + 0.0013, time: 12.465859]
2023-11-02 12:16:32.676: epoch 54:	0.02302017  	0.09206138  	0.06269857  
2023-11-02 12:16:32.676: Find a better model.
2023-11-02 12:16:45.121: [iter 55 : loss : 0.3810 = 0.1045 + 0.2713 + 0.0039 + 0.0013, time: 12.431510]
2023-11-02 12:16:45.774: epoch 55:	0.02299493  	0.09181658  	0.06279019  
2023-11-02 12:16:58.250: [iter 56 : loss : 0.3798 = 0.1040 + 0.2705 + 0.0039 + 0.0013, time: 12.460887]
2023-11-02 12:16:58.915: epoch 56:	0.02307062  	0.09232084  	0.06310611  
2023-11-02 12:16:58.915: Find a better model.
2023-11-02 12:17:11.295: [iter 57 : loss : 0.3785 = 0.1035 + 0.2697 + 0.0040 + 0.0013, time: 12.366414]
2023-11-02 12:17:11.968: epoch 57:	0.02327875  	0.09311936  	0.06358553  
2023-11-02 12:17:11.968: Find a better model.
2023-11-02 12:17:24.468: [iter 58 : loss : 0.3748 = 0.1007 + 0.2687 + 0.0041 + 0.0013, time: 12.485002]
2023-11-02 12:17:25.139: epoch 58:	0.02341119  	0.09359524  	0.06385173  
2023-11-02 12:17:25.140: Find a better model.
2023-11-02 12:17:37.769: [iter 59 : loss : 0.3739 = 0.1003 + 0.2681 + 0.0041 + 0.0013, time: 12.614263]
2023-11-02 12:17:38.426: epoch 59:	0.02349318  	0.09403113  	0.06401799  
2023-11-02 12:17:38.426: Find a better model.
2023-11-02 12:17:50.916: [iter 60 : loss : 0.3727 = 0.0997 + 0.2675 + 0.0042 + 0.0013, time: 12.473469]
2023-11-02 12:17:51.564: epoch 60:	0.02359409  	0.09424726  	0.06429450  
2023-11-02 12:17:51.564: Find a better model.
2023-11-02 12:18:03.953: [iter 61 : loss : 0.3696 = 0.0972 + 0.2668 + 0.0042 + 0.0013, time: 12.376439]
2023-11-02 12:18:04.550: epoch 61:	0.02375808  	0.09495684  	0.06468584  
2023-11-02 12:18:04.550: Find a better model.
2023-11-02 12:18:17.026: [iter 62 : loss : 0.3677 = 0.0960 + 0.2661 + 0.0043 + 0.0013, time: 12.463440]
2023-11-02 12:18:17.691: epoch 62:	0.02387791  	0.09514598  	0.06495076  
2023-11-02 12:18:17.691: Find a better model.
2023-11-02 12:18:30.003: [iter 63 : loss : 0.3672 = 0.0964 + 0.2651 + 0.0044 + 0.0013, time: 12.296662]
2023-11-02 12:18:30.620: epoch 63:	0.02394097  	0.09578817  	0.06517550  
2023-11-02 12:18:30.620: Find a better model.
2023-11-02 12:18:42.990: [iter 64 : loss : 0.3639 = 0.0936 + 0.2646 + 0.0044 + 0.0013, time: 12.356391]
2023-11-02 12:18:43.645: epoch 64:	0.02407342  	0.09620549  	0.06569747  
2023-11-02 12:18:43.645: Find a better model.
2023-11-02 12:18:56.166: [iter 65 : loss : 0.3614 = 0.0914 + 0.2641 + 0.0045 + 0.0013, time: 12.508775]
2023-11-02 12:18:56.844: epoch 65:	0.02418695  	0.09687498  	0.06607531  
2023-11-02 12:18:56.844: Find a better model.
2023-11-02 12:19:09.204: [iter 66 : loss : 0.3602 = 0.0912 + 0.2631 + 0.0046 + 0.0013, time: 12.340542]
2023-11-02 12:19:09.863: epoch 66:	0.02423110  	0.09696835  	0.06615185  
2023-11-02 12:19:09.863: Find a better model.
2023-11-02 12:19:22.308: [iter 67 : loss : 0.3602 = 0.0916 + 0.2627 + 0.0046 + 0.0013, time: 12.431135]
2023-11-02 12:19:22.941: epoch 67:	0.02446446  	0.09774791  	0.06677760  
2023-11-02 12:19:22.941: Find a better model.
2023-11-02 12:19:35.446: [iter 68 : loss : 0.3581 = 0.0904 + 0.2617 + 0.0047 + 0.0013, time: 12.488976]
2023-11-02 12:19:36.083: epoch 68:	0.02454645  	0.09796061  	0.06692972  
2023-11-02 12:19:36.083: Find a better model.
2023-11-02 12:19:48.575: [iter 69 : loss : 0.3559 = 0.0886 + 0.2613 + 0.0048 + 0.0013, time: 12.477411]
2023-11-02 12:19:49.242: epoch 69:	0.02462213  	0.09808280  	0.06740884  
2023-11-02 12:19:49.242: Find a better model.
2023-11-02 12:20:01.427: [iter 70 : loss : 0.3554 = 0.0890 + 0.2602 + 0.0048 + 0.0013, time: 12.168567]
2023-11-02 12:20:02.094: epoch 70:	0.02484288  	0.09924046  	0.06795515  
2023-11-02 12:20:02.094: Find a better model.
2023-11-02 12:20:14.540: [iter 71 : loss : 0.3528 = 0.0868 + 0.2598 + 0.0049 + 0.0013, time: 12.433419]
2023-11-02 12:20:15.207: epoch 71:	0.02495641  	0.09960515  	0.06822266  
2023-11-02 12:20:15.207: Find a better model.
2023-11-02 12:20:27.605: [iter 72 : loss : 0.3515 = 0.0862 + 0.2591 + 0.0050 + 0.0013, time: 12.383673]
2023-11-02 12:20:28.217: epoch 72:	0.02510778  	0.10014361  	0.06851467  
2023-11-02 12:20:28.218: Find a better model.
2023-11-02 12:20:40.443: [iter 73 : loss : 0.3498 = 0.0851 + 0.2584 + 0.0050 + 0.0013, time: 12.213038]
2023-11-02 12:20:41.087: epoch 73:	0.02520238  	0.10047764  	0.06887554  
2023-11-02 12:20:41.087: Find a better model.
2023-11-02 12:20:53.610: [iter 74 : loss : 0.3486 = 0.0844 + 0.2578 + 0.0051 + 0.0013, time: 12.509118]
2023-11-02 12:20:54.270: epoch 74:	0.02530331  	0.10118280  	0.06917061  
2023-11-02 12:20:54.270: Find a better model.
2023-11-02 12:21:06.488: [iter 75 : loss : 0.3461 = 0.0824 + 0.2573 + 0.0052 + 0.0013, time: 12.202803]
2023-11-02 12:21:07.126: epoch 75:	0.02529700  	0.10116706  	0.06923380  
2023-11-02 12:21:19.304: [iter 76 : loss : 0.3468 = 0.0838 + 0.2565 + 0.0052 + 0.0013, time: 12.165006]
2023-11-02 12:21:19.940: epoch 76:	0.02544206  	0.10189702  	0.06967885  
2023-11-02 12:21:19.940: Find a better model.
2023-11-02 12:21:32.367: [iter 77 : loss : 0.3441 = 0.0816 + 0.2560 + 0.0053 + 0.0013, time: 12.410736]
2023-11-02 12:21:32.990: epoch 77:	0.02541683  	0.10214054  	0.06967899  
2023-11-02 12:21:32.990: Find a better model.
2023-11-02 12:21:45.395: [iter 78 : loss : 0.3424 = 0.0806 + 0.2552 + 0.0053 + 0.0012, time: 12.390213]
2023-11-02 12:21:46.031: epoch 78:	0.02549252  	0.10221978  	0.06966777  
2023-11-02 12:21:46.031: Find a better model.
2023-11-02 12:21:58.316: [iter 79 : loss : 0.3419 = 0.0806 + 0.2547 + 0.0054 + 0.0012, time: 12.271260]
2023-11-02 12:21:58.926: epoch 79:	0.02566912  	0.10286118  	0.07009757  
2023-11-02 12:21:58.926: Find a better model.
2023-11-02 12:22:11.341: [iter 80 : loss : 0.3395 = 0.0788 + 0.2539 + 0.0055 + 0.0012, time: 12.402143]
2023-11-02 12:22:11.939: epoch 80:	0.02579525  	0.10367185  	0.07061160  
2023-11-02 12:22:11.939: Find a better model.
2023-11-02 12:22:24.180: [iter 81 : loss : 0.3388 = 0.0789 + 0.2532 + 0.0055 + 0.0012, time: 12.228109]
2023-11-02 12:22:24.792: epoch 81:	0.02575741  	0.10339698  	0.07069665  
2023-11-02 12:22:37.046: [iter 82 : loss : 0.3386 = 0.0791 + 0.2526 + 0.0056 + 0.0012, time: 12.238711]
2023-11-02 12:22:37.650: epoch 82:	0.02592139  	0.10404680  	0.07123804  
2023-11-02 12:22:37.650: Find a better model.
2023-11-02 12:22:50.162: [iter 83 : loss : 0.3350 = 0.0761 + 0.2520 + 0.0057 + 0.0012, time: 12.498112]
2023-11-02 12:22:50.813: epoch 83:	0.02612321  	0.10494306  	0.07149103  
2023-11-02 12:22:50.813: Find a better model.
2023-11-02 12:23:03.219: [iter 84 : loss : 0.3340 = 0.0758 + 0.2513 + 0.0057 + 0.0012, time: 12.385222]
2023-11-02 12:23:03.865: epoch 84:	0.02627458  	0.10557655  	0.07176195  
2023-11-02 12:23:03.865: Find a better model.
2023-11-02 12:23:16.291: [iter 85 : loss : 0.3326 = 0.0750 + 0.2506 + 0.0058 + 0.0012, time: 12.411732]
2023-11-02 12:23:16.955: epoch 85:	0.02636917  	0.10596833  	0.07212140  
2023-11-02 12:23:16.955: Find a better model.
2023-11-02 12:23:29.511: [iter 86 : loss : 0.3318 = 0.0748 + 0.2499 + 0.0059 + 0.0012, time: 12.537204]
2023-11-02 12:23:30.170: epoch 86:	0.02647008  	0.10646718  	0.07237428  
2023-11-02 12:23:30.171: Find a better model.
2023-11-02 12:23:42.632: [iter 87 : loss : 0.3313 = 0.0748 + 0.2493 + 0.0059 + 0.0012, time: 12.445694]
2023-11-02 12:23:43.252: epoch 87:	0.02659624  	0.10730217  	0.07262926  
2023-11-02 12:23:43.252: Find a better model.
2023-11-02 12:23:55.958: [iter 88 : loss : 0.3299 = 0.0741 + 0.2486 + 0.0060 + 0.0012, time: 12.692429]
2023-11-02 12:23:56.610: epoch 88:	0.02665931  	0.10758337  	0.07300289  
2023-11-02 12:23:56.610: Find a better model.
2023-11-02 12:24:09.083: [iter 89 : loss : 0.3288 = 0.0732 + 0.2483 + 0.0061 + 0.0012, time: 12.457671]
2023-11-02 12:24:09.752: epoch 89:	0.02666562  	0.10758060  	0.07320745  
2023-11-02 12:24:22.059: [iter 90 : loss : 0.3275 = 0.0725 + 0.2476 + 0.0061 + 0.0012, time: 12.293285]
2023-11-02 12:24:22.679: epoch 90:	0.02685482  	0.10830527  	0.07363330  
2023-11-02 12:24:22.679: Find a better model.
2023-11-02 12:24:35.126: [iter 91 : loss : 0.3263 = 0.0720 + 0.2469 + 0.0062 + 0.0012, time: 12.431894]
2023-11-02 12:24:35.768: epoch 91:	0.02687373  	0.10835369  	0.07381254  
2023-11-02 12:24:35.768: Find a better model.
2023-11-02 12:24:48.134: [iter 92 : loss : 0.3262 = 0.0725 + 0.2462 + 0.0063 + 0.0012, time: 12.349705]
2023-11-02 12:24:48.793: epoch 92:	0.02708817  	0.10929186  	0.07421276  
2023-11-02 12:24:48.793: Find a better model.
2023-11-02 12:25:01.262: [iter 93 : loss : 0.3239 = 0.0703 + 0.2461 + 0.0063 + 0.0012, time: 12.449399]
2023-11-02 12:25:01.900: epoch 93:	0.02699988  	0.10919748  	0.07416813  
2023-11-02 12:25:14.307: [iter 94 : loss : 0.3235 = 0.0707 + 0.2452 + 0.0064 + 0.0012, time: 12.391641]
2023-11-02 12:25:14.974: epoch 94:	0.02711971  	0.10960787  	0.07430466  
2023-11-02 12:25:14.975: Find a better model.
2023-11-02 12:25:27.207: [iter 95 : loss : 0.3220 = 0.0699 + 0.2445 + 0.0065 + 0.0012, time: 12.216630]
2023-11-02 12:25:27.883: epoch 95:	0.02710078  	0.10957073  	0.07454829  
2023-11-02 12:25:40.333: [iter 96 : loss : 0.3212 = 0.0692 + 0.2442 + 0.0065 + 0.0012, time: 12.434740]
2023-11-02 12:25:40.997: epoch 96:	0.02725847  	0.11007047  	0.07468521  
2023-11-02 12:25:40.997: Find a better model.
2023-11-02 12:25:53.480: [iter 97 : loss : 0.3183 = 0.0671 + 0.2435 + 0.0066 + 0.0012, time: 12.467148]
2023-11-02 12:25:54.137: epoch 97:	0.02720800  	0.10989133  	0.07474160  
2023-11-02 12:26:06.373: [iter 98 : loss : 0.3184 = 0.0680 + 0.2426 + 0.0067 + 0.0012, time: 12.217612]
2023-11-02 12:26:07.032: epoch 98:	0.02730262  	0.11024527  	0.07523823  
2023-11-02 12:26:07.033: Find a better model.
2023-11-02 12:26:19.352: [iter 99 : loss : 0.3171 = 0.0671 + 0.2421 + 0.0067 + 0.0012, time: 12.305302]
2023-11-02 12:26:20.016: epoch 99:	0.02754859  	0.11126631  	0.07568309  
2023-11-02 12:26:20.016: Find a better model.
2023-11-02 12:26:32.434: [iter 100 : loss : 0.3161 = 0.0665 + 0.2416 + 0.0068 + 0.0012, time: 12.401364]
2023-11-02 12:26:33.103: epoch 100:	0.02764950  	0.11183541  	0.07598677  
2023-11-02 12:26:33.103: Find a better model.
2023-11-02 12:26:45.549: [iter 101 : loss : 0.3166 = 0.0677 + 0.2409 + 0.0069 + 0.0012, time: 12.432961]
2023-11-02 12:26:46.197: epoch 101:	0.02766842  	0.11184838  	0.07610896  
2023-11-02 12:26:46.197: Find a better model.
2023-11-02 12:26:58.619: [iter 102 : loss : 0.3159 = 0.0675 + 0.2403 + 0.0069 + 0.0012, time: 12.408653]
2023-11-02 12:26:59.276: epoch 102:	0.02770626  	0.11188144  	0.07601427  
2023-11-02 12:26:59.276: Find a better model.
2023-11-02 12:27:11.746: [iter 103 : loss : 0.3142 = 0.0662 + 0.2398 + 0.0070 + 0.0012, time: 12.450955]
2023-11-02 12:27:12.417: epoch 103:	0.02778194  	0.11221965  	0.07631844  
2023-11-02 12:27:12.417: Find a better model.
2023-11-02 12:27:24.685: [iter 104 : loss : 0.3121 = 0.0648 + 0.2392 + 0.0071 + 0.0012, time: 12.252469]
2023-11-02 12:27:25.330: epoch 104:	0.02782610  	0.11235681  	0.07647146  
2023-11-02 12:27:25.330: Find a better model.
2023-11-02 12:27:37.737: [iter 105 : loss : 0.3113 = 0.0642 + 0.2388 + 0.0071 + 0.0012, time: 12.394896]
2023-11-02 12:27:38.400: epoch 105:	0.02787655  	0.11256643  	0.07684137  
2023-11-02 12:27:38.400: Find a better model.
2023-11-02 12:27:50.950: [iter 106 : loss : 0.3117 = 0.0653 + 0.2381 + 0.0072 + 0.0012, time: 12.537086]
2023-11-02 12:27:51.579: epoch 106:	0.02795854  	0.11300850  	0.07704511  
2023-11-02 12:27:51.580: Find a better model.
2023-11-02 12:28:04.072: [iter 107 : loss : 0.3098 = 0.0638 + 0.2375 + 0.0073 + 0.0012, time: 12.477547]
2023-11-02 12:28:04.727: epoch 107:	0.02800900  	0.11311979  	0.07694505  
2023-11-02 12:28:04.728: Find a better model.
2023-11-02 12:28:17.295: [iter 108 : loss : 0.3097 = 0.0644 + 0.2369 + 0.0073 + 0.0012, time: 12.549295]
2023-11-02 12:28:17.980: epoch 108:	0.02812253  	0.11361375  	0.07758177  
2023-11-02 12:28:17.980: Find a better model.
2023-11-02 12:28:30.364: [iter 109 : loss : 0.3066 = 0.0618 + 0.2362 + 0.0074 + 0.0012, time: 12.369862]
2023-11-02 12:28:30.976: epoch 109:	0.02829282  	0.11430580  	0.07791304  
2023-11-02 12:28:30.976: Find a better model.
2023-11-02 12:28:43.447: [iter 110 : loss : 0.3073 = 0.0630 + 0.2358 + 0.0075 + 0.0011, time: 12.458036]
2023-11-02 12:28:44.100: epoch 110:	0.02846311  	0.11519492  	0.07832047  
2023-11-02 12:28:44.106: Find a better model.
2023-11-02 12:28:56.458: [iter 111 : loss : 0.3045 = 0.0607 + 0.2351 + 0.0075 + 0.0011, time: 12.338940]
2023-11-02 12:28:57.091: epoch 111:	0.02836220  	0.11471491  	0.07815318  
2023-11-02 12:29:09.551: [iter 112 : loss : 0.3054 = 0.0623 + 0.2344 + 0.0076 + 0.0011, time: 12.444608]
2023-11-02 12:29:10.208: epoch 112:	0.02837481  	0.11496895  	0.07824924  
2023-11-02 12:29:22.762: [iter 113 : loss : 0.3027 = 0.0598 + 0.2340 + 0.0077 + 0.0011, time: 12.538019]
2023-11-02 12:29:23.400: epoch 113:	0.02834328  	0.11502673  	0.07808642  
2023-11-02 12:29:35.731: [iter 114 : loss : 0.3024 = 0.0604 + 0.2331 + 0.0077 + 0.0011, time: 12.315049]
2023-11-02 12:29:36.335: epoch 114:	0.02851987  	0.11545758  	0.07848819  
2023-11-02 12:29:36.335: Find a better model.
2023-11-02 12:29:48.858: [iter 115 : loss : 0.3028 = 0.0611 + 0.2328 + 0.0078 + 0.0011, time: 12.509074]
2023-11-02 12:29:49.455: epoch 115:	0.02851987  	0.11547098  	0.07870246  
2023-11-02 12:29:49.456: Find a better model.
2023-11-02 12:30:01.966: [iter 116 : loss : 0.3018 = 0.0608 + 0.2320 + 0.0079 + 0.0011, time: 12.496730]
2023-11-02 12:30:02.627: epoch 116:	0.02859556  	0.11588073  	0.07891802  
2023-11-02 12:30:02.628: Find a better model.
2023-11-02 12:30:15.122: [iter 117 : loss : 0.3003 = 0.0595 + 0.2317 + 0.0079 + 0.0011, time: 12.479874]
2023-11-02 12:30:15.755: epoch 117:	0.02862077  	0.11610168  	0.07893166  
2023-11-02 12:30:15.755: Find a better model.
2023-11-02 12:30:28.104: [iter 118 : loss : 0.2985 = 0.0583 + 0.2311 + 0.0080 + 0.0011, time: 12.331815]
2023-11-02 12:30:28.763: epoch 118:	0.02865862  	0.11622393  	0.07891648  
2023-11-02 12:30:28.764: Find a better model.
2023-11-02 12:30:41.216: [iter 119 : loss : 0.2995 = 0.0597 + 0.2306 + 0.0081 + 0.0011, time: 12.438359]
2023-11-02 12:30:41.842: epoch 119:	0.02887937  	0.11713751  	0.07934064  
2023-11-02 12:30:41.842: Find a better model.
2023-11-02 12:30:54.386: [iter 120 : loss : 0.2984 = 0.0593 + 0.2299 + 0.0081 + 0.0011, time: 12.523881]
2023-11-02 12:30:55.040: epoch 120:	0.02884783  	0.11699678  	0.07946791  
2023-11-02 12:31:07.503: [iter 121 : loss : 0.2980 = 0.0593 + 0.2293 + 0.0082 + 0.0011, time: 12.447620]
2023-11-02 12:31:08.171: epoch 121:	0.02880369  	0.11673927  	0.07954121  
2023-11-02 12:31:20.622: [iter 122 : loss : 0.2966 = 0.0585 + 0.2287 + 0.0083 + 0.0011, time: 12.437669]
2023-11-02 12:31:21.251: epoch 122:	0.02882892  	0.11706862  	0.07968906  
2023-11-02 12:31:33.570: [iter 123 : loss : 0.2954 = 0.0579 + 0.2281 + 0.0083 + 0.0011, time: 12.303369]
2023-11-02 12:31:34.231: epoch 123:	0.02869646  	0.11639947  	0.07944398  
2023-11-02 12:31:46.481: [iter 124 : loss : 0.2949 = 0.0578 + 0.2276 + 0.0084 + 0.0011, time: 12.235135]
2023-11-02 12:31:47.143: epoch 124:	0.02878476  	0.11665962  	0.07953189  
2023-11-02 12:31:59.445: [iter 125 : loss : 0.2956 = 0.0590 + 0.2271 + 0.0085 + 0.0011, time: 12.287869]
2023-11-02 12:32:00.103: epoch 125:	0.02876584  	0.11653975  	0.07959881  
2023-11-02 12:32:12.648: [iter 126 : loss : 0.2925 = 0.0563 + 0.2266 + 0.0085 + 0.0011, time: 12.526864]
2023-11-02 12:32:13.299: epoch 126:	0.02893613  	0.11731439  	0.07991154  
2023-11-02 12:32:13.299: Find a better model.
2023-11-02 12:32:25.820: [iter 127 : loss : 0.2915 = 0.0559 + 0.2259 + 0.0086 + 0.0011, time: 12.499519]
2023-11-02 12:32:26.501: epoch 127:	0.02896136  	0.11755464  	0.08018392  
2023-11-02 12:32:26.502: Find a better model.
2023-11-02 12:32:38.895: [iter 128 : loss : 0.2919 = 0.0568 + 0.2254 + 0.0087 + 0.0011, time: 12.378820]
2023-11-02 12:32:39.566: epoch 128:	0.02911274  	0.11829837  	0.08061944  
2023-11-02 12:32:39.566: Find a better model.
2023-11-02 12:32:52.088: [iter 129 : loss : 0.2914 = 0.0568 + 0.2248 + 0.0087 + 0.0011, time: 12.506567]
2023-11-02 12:32:52.715: epoch 129:	0.02911904  	0.11830589  	0.08064423  
2023-11-02 12:32:52.715: Find a better model.
2023-11-02 12:33:05.269: [iter 130 : loss : 0.2907 = 0.0565 + 0.2243 + 0.0088 + 0.0011, time: 12.539519]
2023-11-02 12:33:05.942: epoch 130:	0.02915688  	0.11865625  	0.08098121  
2023-11-02 12:33:05.942: Find a better model.
2023-11-02 12:33:18.336: [iter 131 : loss : 0.2883 = 0.0547 + 0.2236 + 0.0089 + 0.0011, time: 12.372905]
2023-11-02 12:33:19.011: epoch 131:	0.02916319  	0.11843027  	0.08091251  
2023-11-02 12:33:31.366: [iter 132 : loss : 0.2900 = 0.0567 + 0.2233 + 0.0089 + 0.0011, time: 12.341805]
2023-11-02 12:33:31.983: epoch 132:	0.02923258  	0.11888284  	0.08108968  
2023-11-02 12:33:31.983: Find a better model.
2023-11-02 12:33:44.340: [iter 133 : loss : 0.2886 = 0.0559 + 0.2226 + 0.0090 + 0.0011, time: 12.341246]
2023-11-02 12:33:44.971: epoch 133:	0.02937763  	0.11945578  	0.08150240  
2023-11-02 12:33:44.971: Find a better model.
2023-11-02 12:33:57.254: [iter 134 : loss : 0.2880 = 0.0557 + 0.2221 + 0.0091 + 0.0011, time: 12.269476]
2023-11-02 12:33:57.915: epoch 134:	0.02949115  	0.12003515  	0.08179612  
2023-11-02 12:33:57.915: Find a better model.
2023-11-02 12:34:10.396: [iter 135 : loss : 0.2867 = 0.0549 + 0.2216 + 0.0091 + 0.0011, time: 12.465965]
2023-11-02 12:34:11.062: epoch 135:	0.02952900  	0.12018475  	0.08200929  
2023-11-02 12:34:11.062: Find a better model.
2023-11-02 12:34:23.536: [iter 136 : loss : 0.2847 = 0.0534 + 0.2210 + 0.0092 + 0.0011, time: 12.453925]
2023-11-02 12:34:24.204: epoch 136:	0.02954792  	0.12032659  	0.08200463  
2023-11-02 12:34:24.204: Find a better model.
2023-11-02 12:34:36.539: [iter 137 : loss : 0.2856 = 0.0549 + 0.2204 + 0.0093 + 0.0011, time: 12.314592]
2023-11-02 12:34:37.161: epoch 137:	0.02949114  	0.11966038  	0.08186990  
2023-11-02 12:34:49.693: [iter 138 : loss : 0.2850 = 0.0544 + 0.2202 + 0.0093 + 0.0011, time: 12.518136]
2023-11-02 12:34:50.354: epoch 138:	0.02961099  	0.12053315  	0.08241704  
2023-11-02 12:34:50.354: Find a better model.
2023-11-02 12:35:02.599: [iter 139 : loss : 0.2841 = 0.0544 + 0.2192 + 0.0094 + 0.0011, time: 12.232299]
2023-11-02 12:35:03.244: epoch 139:	0.02968666  	0.12067271  	0.08255483  
2023-11-02 12:35:03.244: Find a better model.
2023-11-02 12:35:15.707: [iter 140 : loss : 0.2841 = 0.0550 + 0.2186 + 0.0095 + 0.0011, time: 12.446625]
2023-11-02 12:35:16.371: epoch 140:	0.02963620  	0.12058997  	0.08251764  
2023-11-02 12:35:28.993: [iter 141 : loss : 0.2826 = 0.0539 + 0.2181 + 0.0095 + 0.0011, time: 12.606910]
2023-11-02 12:35:29.628: epoch 141:	0.02968034  	0.12065453  	0.08275011  
2023-11-02 12:35:42.326: [iter 142 : loss : 0.2822 = 0.0536 + 0.2179 + 0.0096 + 0.0011, time: 12.680689]
2023-11-02 12:35:42.955: epoch 142:	0.02978126  	0.12113341  	0.08283544  
2023-11-02 12:35:42.955: Find a better model.
2023-11-02 12:35:55.189: [iter 143 : loss : 0.2822 = 0.0544 + 0.2171 + 0.0097 + 0.0011, time: 12.214521]
2023-11-02 12:35:55.828: epoch 143:	0.02993261  	0.12178046  	0.08324219  
2023-11-02 12:35:55.828: Find a better model.
2023-11-02 12:36:08.289: [iter 144 : loss : 0.2805 = 0.0530 + 0.2167 + 0.0098 + 0.0011, time: 12.445048]
2023-11-02 12:36:08.954: epoch 144:	0.02985693  	0.12125604  	0.08325282  
2023-11-02 12:36:21.562: [iter 145 : loss : 0.2792 = 0.0522 + 0.2162 + 0.0098 + 0.0011, time: 12.588898]
2023-11-02 12:36:22.241: epoch 145:	0.03000200  	0.12214120  	0.08346625  
2023-11-02 12:36:22.241: Find a better model.
2023-11-02 12:36:34.643: [iter 146 : loss : 0.2800 = 0.0535 + 0.2156 + 0.0099 + 0.0010, time: 12.383468]
2023-11-02 12:36:35.307: epoch 146:	0.03007768  	0.12217353  	0.08371594  
2023-11-02 12:36:35.307: Find a better model.
2023-11-02 12:36:47.865: [iter 147 : loss : 0.2794 = 0.0534 + 0.2150 + 0.0100 + 0.0010, time: 12.540590]
2023-11-02 12:36:48.517: epoch 147:	0.03004614  	0.12198933  	0.08387377  
2023-11-02 12:37:00.962: [iter 148 : loss : 0.2782 = 0.0528 + 0.2144 + 0.0100 + 0.0010, time: 12.429196]
2023-11-02 12:37:01.606: epoch 148:	0.03019750  	0.12259854  	0.08418757  
2023-11-02 12:37:01.606: Find a better model.
2023-11-02 12:37:14.195: [iter 149 : loss : 0.2770 = 0.0517 + 0.2141 + 0.0101 + 0.0010, time: 12.576324]
2023-11-02 12:37:14.839: epoch 149:	0.03017227  	0.12246642  	0.08395504  
2023-11-02 12:37:27.356: [iter 150 : loss : 0.2779 = 0.0533 + 0.2134 + 0.0102 + 0.0010, time: 12.503443]
2023-11-02 12:37:27.955: epoch 150:	0.03029211  	0.12292512  	0.08410730  
2023-11-02 12:37:27.955: Find a better model.
2023-11-02 12:37:40.424: [iter 151 : loss : 0.2759 = 0.0517 + 0.2129 + 0.0102 + 0.0010, time: 12.453444]
2023-11-02 12:37:41.071: epoch 151:	0.03032995  	0.12293668  	0.08436580  
2023-11-02 12:37:41.071: Find a better model.
2023-11-02 12:37:53.737: [iter 152 : loss : 0.2761 = 0.0523 + 0.2124 + 0.0103 + 0.0010, time: 12.650161]
2023-11-02 12:37:54.407: epoch 152:	0.03036148  	0.12306227  	0.08447808  
2023-11-02 12:37:54.407: Find a better model.
2023-11-02 12:38:06.953: [iter 153 : loss : 0.2745 = 0.0512 + 0.2118 + 0.0104 + 0.0010, time: 12.532318]
2023-11-02 12:38:07.610: epoch 153:	0.03038671  	0.12335045  	0.08453580  
2023-11-02 12:38:07.610: Find a better model.
2023-11-02 12:38:20.053: [iter 154 : loss : 0.2758 = 0.0530 + 0.2113 + 0.0104 + 0.0010, time: 12.424237]
2023-11-02 12:38:20.706: epoch 154:	0.03050024  	0.12374848  	0.08477717  
2023-11-02 12:38:20.706: Find a better model.
2023-11-02 12:38:33.254: [iter 155 : loss : 0.2727 = 0.0504 + 0.2108 + 0.0105 + 0.0010, time: 12.534186]
2023-11-02 12:38:33.918: epoch 155:	0.03048132  	0.12388037  	0.08465172  
2023-11-02 12:38:33.918: Find a better model.
2023-11-02 12:38:46.361: [iter 156 : loss : 0.2726 = 0.0506 + 0.2104 + 0.0106 + 0.0010, time: 12.427868]
2023-11-02 12:38:47.009: epoch 156:	0.03056331  	0.12422731  	0.08509897  
2023-11-02 12:38:47.009: Find a better model.
2023-11-02 12:38:59.584: [iter 157 : loss : 0.2712 = 0.0497 + 0.2099 + 0.0106 + 0.0010, time: 12.557532]
2023-11-02 12:39:00.220: epoch 157:	0.03055070  	0.12397843  	0.08492784  
2023-11-02 12:39:12.489: [iter 158 : loss : 0.2719 = 0.0508 + 0.2094 + 0.0107 + 0.0010, time: 12.254179]
2023-11-02 12:39:13.161: epoch 158:	0.03067054  	0.12457598  	0.08528837  
2023-11-02 12:39:13.161: Find a better model.
2023-11-02 12:39:25.732: [iter 159 : loss : 0.2710 = 0.0506 + 0.2086 + 0.0108 + 0.0010, time: 12.556385]
2023-11-02 12:39:26.405: epoch 159:	0.03071469  	0.12501708  	0.08543769  
2023-11-02 12:39:26.405: Find a better model.
2023-11-02 12:39:38.833: [iter 160 : loss : 0.2698 = 0.0498 + 0.2081 + 0.0109 + 0.0010, time: 12.408113]
2023-11-02 12:39:39.474: epoch 160:	0.03070207  	0.12501036  	0.08555763  
2023-11-02 12:39:51.989: [iter 161 : loss : 0.2702 = 0.0505 + 0.2078 + 0.0109 + 0.0010, time: 12.502178]
2023-11-02 12:39:52.607: epoch 161:	0.03085345  	0.12572286  	0.08584423  
2023-11-02 12:39:52.607: Find a better model.
2023-11-02 12:40:04.721: [iter 162 : loss : 0.2691 = 0.0499 + 0.2072 + 0.0110 + 0.0010, time: 12.100433]
2023-11-02 12:40:05.379: epoch 162:	0.03085345  	0.12585926  	0.08588697  
2023-11-02 12:40:05.379: Find a better model.
2023-11-02 12:40:17.650: [iter 163 : loss : 0.2690 = 0.0502 + 0.2068 + 0.0111 + 0.0010, time: 12.256957]
2023-11-02 12:40:18.307: epoch 163:	0.03103005  	0.12629651  	0.08630835  
2023-11-02 12:40:18.307: Find a better model.
2023-11-02 12:40:30.616: [iter 164 : loss : 0.2682 = 0.0499 + 0.2062 + 0.0111 + 0.0010, time: 12.295879]
2023-11-02 12:40:31.260: epoch 164:	0.03106789  	0.12651585  	0.08620535  
2023-11-02 12:40:31.260: Find a better model.
2023-11-02 12:40:43.450: [iter 165 : loss : 0.2676 = 0.0500 + 0.2054 + 0.0112 + 0.0010, time: 12.177943]
2023-11-02 12:40:44.117: epoch 165:	0.03104266  	0.12641798  	0.08617815  
2023-11-02 12:40:56.337: [iter 166 : loss : 0.2671 = 0.0499 + 0.2050 + 0.0113 + 0.0010, time: 12.200885]
2023-11-02 12:40:57.010: epoch 166:	0.03111834  	0.12676406  	0.08648643  
2023-11-02 12:40:57.010: Find a better model.
2023-11-02 12:41:09.645: [iter 167 : loss : 0.2653 = 0.0487 + 0.2043 + 0.0113 + 0.0010, time: 12.621555]
2023-11-02 12:41:10.307: epoch 167:	0.03104267  	0.12658849  	0.08626287  
2023-11-02 12:41:22.837: [iter 168 : loss : 0.2654 = 0.0492 + 0.2038 + 0.0114 + 0.0010, time: 12.514562]
2023-11-02 12:41:23.495: epoch 168:	0.03116249  	0.12699889  	0.08671247  
2023-11-02 12:41:23.496: Find a better model.
2023-11-02 12:41:35.942: [iter 169 : loss : 0.2665 = 0.0505 + 0.2035 + 0.0115 + 0.0010, time: 12.428415]
2023-11-02 12:41:36.598: epoch 169:	0.03115618  	0.12671258  	0.08672523  
2023-11-02 12:41:49.143: [iter 170 : loss : 0.2648 = 0.0491 + 0.2032 + 0.0115 + 0.0010, time: 12.530836]
2023-11-02 12:41:49.782: epoch 170:	0.03120032  	0.12667190  	0.08662139  
2023-11-02 12:42:02.164: [iter 171 : loss : 0.2640 = 0.0490 + 0.2024 + 0.0116 + 0.0010, time: 12.367904]
2023-11-02 12:42:02.838: epoch 171:	0.03123816  	0.12684952  	0.08685698  
2023-11-02 12:42:15.205: [iter 172 : loss : 0.2621 = 0.0476 + 0.2018 + 0.0117 + 0.0010, time: 12.351995]
2023-11-02 12:42:15.835: epoch 172:	0.03133908  	0.12728986  	0.08727304  
2023-11-02 12:42:15.836: Find a better model.
2023-11-02 12:42:28.469: [iter 173 : loss : 0.2635 = 0.0493 + 0.2015 + 0.0118 + 0.0010, time: 12.621856]
2023-11-02 12:42:29.124: epoch 173:	0.03125077  	0.12685512  	0.08717788  
2023-11-02 12:42:41.608: [iter 174 : loss : 0.2623 = 0.0486 + 0.2009 + 0.0118 + 0.0010, time: 12.471123]
2023-11-02 12:42:42.276: epoch 174:	0.03131385  	0.12709473  	0.08738011  
2023-11-02 12:42:54.859: [iter 175 : loss : 0.2621 = 0.0488 + 0.2004 + 0.0119 + 0.0010, time: 12.568104]
2023-11-02 12:42:55.525: epoch 175:	0.03125710  	0.12686205  	0.08717674  
2023-11-02 12:43:07.980: [iter 176 : loss : 0.2611 = 0.0483 + 0.1998 + 0.0120 + 0.0010, time: 12.441375]
2023-11-02 12:43:08.626: epoch 176:	0.03149045  	0.12772225  	0.08759512  
2023-11-02 12:43:08.626: Find a better model.
2023-11-02 12:43:20.983: [iter 177 : loss : 0.2612 = 0.0488 + 0.1993 + 0.0120 + 0.0010, time: 12.339667]
2023-11-02 12:43:21.639: epoch 177:	0.03164812  	0.12851734  	0.08797029  
2023-11-02 12:43:21.639: Find a better model.
2023-11-02 12:43:34.083: [iter 178 : loss : 0.2599 = 0.0481 + 0.1988 + 0.0121 + 0.0010, time: 12.428192]
2023-11-02 12:43:34.739: epoch 178:	0.03164812  	0.12843908  	0.08801168  
2023-11-02 12:43:47.071: [iter 179 : loss : 0.2598 = 0.0484 + 0.1982 + 0.0122 + 0.0010, time: 12.319314]
2023-11-02 12:43:47.724: epoch 179:	0.03164181  	0.12861238  	0.08813926  
2023-11-02 12:43:47.724: Find a better model.
2023-11-02 12:44:00.045: [iter 180 : loss : 0.2602 = 0.0491 + 0.1979 + 0.0122 + 0.0010, time: 12.306806]
2023-11-02 12:44:00.712: epoch 180:	0.03162289  	0.12832901  	0.08810551  
2023-11-02 12:44:13.180: [iter 181 : loss : 0.2610 = 0.0504 + 0.1973 + 0.0123 + 0.0010, time: 12.452390]
2023-11-02 12:44:13.834: epoch 181:	0.03166074  	0.12870660  	0.08841250  
2023-11-02 12:44:13.834: Find a better model.
2023-11-02 12:44:26.300: [iter 182 : loss : 0.2576 = 0.0476 + 0.1967 + 0.0124 + 0.0010, time: 12.449043]
2023-11-02 12:44:26.947: epoch 182:	0.03146522  	0.12799515  	0.08813630  
2023-11-02 12:44:39.221: [iter 183 : loss : 0.2575 = 0.0475 + 0.1966 + 0.0125 + 0.0010, time: 12.259650]
2023-11-02 12:44:39.850: epoch 183:	0.03162920  	0.12850635  	0.08833907  
2023-11-02 12:44:52.735: [iter 184 : loss : 0.2570 = 0.0476 + 0.1959 + 0.0125 + 0.0009, time: 12.870254]
2023-11-02 12:44:53.414: epoch 184:	0.03172381  	0.12881339  	0.08852877  
2023-11-02 12:44:53.414: Find a better model.
2023-11-02 12:45:05.957: [iter 185 : loss : 0.2556 = 0.0466 + 0.1954 + 0.0126 + 0.0009, time: 12.524797]
2023-11-02 12:45:06.634: epoch 185:	0.03171120  	0.12895027  	0.08858515  
2023-11-02 12:45:06.634: Find a better model.
2023-11-02 12:45:19.185: [iter 186 : loss : 0.2567 = 0.0481 + 0.1949 + 0.0127 + 0.0009, time: 12.531264]
2023-11-02 12:45:19.825: epoch 186:	0.03177427  	0.12887634  	0.08859732  
2023-11-02 12:45:32.486: [iter 187 : loss : 0.2558 = 0.0479 + 0.1942 + 0.0127 + 0.0009, time: 12.641393]
2023-11-02 12:45:33.148: epoch 187:	0.03190671  	0.12976991  	0.08887291  
2023-11-02 12:45:33.148: Find a better model.
2023-11-02 12:45:45.649: [iter 188 : loss : 0.2568 = 0.0490 + 0.1940 + 0.0128 + 0.0009, time: 12.482321]
2023-11-02 12:45:46.342: epoch 188:	0.03209592  	0.13047135  	0.08926798  
2023-11-02 12:45:46.342: Find a better model.
2023-11-02 12:45:58.997: [iter 189 : loss : 0.2545 = 0.0473 + 0.1935 + 0.0129 + 0.0009, time: 12.635343]
2023-11-02 12:45:59.685: epoch 189:	0.03191933  	0.12979577  	0.08922639  
2023-11-02 12:46:12.291: [iter 190 : loss : 0.2552 = 0.0484 + 0.1929 + 0.0130 + 0.0009, time: 12.590398]
2023-11-02 12:46:12.914: epoch 190:	0.03206439  	0.13016863  	0.08939961  
2023-11-02 12:46:25.635: [iter 191 : loss : 0.2536 = 0.0473 + 0.1924 + 0.0130 + 0.0009, time: 12.703099]
2023-11-02 12:46:26.255: epoch 191:	0.03198240  	0.12989797  	0.08932903  
2023-11-02 12:46:38.866: [iter 192 : loss : 0.2541 = 0.0481 + 0.1919 + 0.0131 + 0.0009, time: 12.592151]
2023-11-02 12:46:39.547: epoch 192:	0.03210223  	0.13054098  	0.08980385  
2023-11-02 12:46:39.547: Find a better model.
2023-11-02 12:46:52.339: [iter 193 : loss : 0.2529 = 0.0474 + 0.1914 + 0.0132 + 0.0009, time: 12.778394]
2023-11-02 12:46:53.021: epoch 193:	0.03218422  	0.13096285  	0.09000587  
2023-11-02 12:46:53.021: Find a better model.
2023-11-02 12:47:05.726: [iter 194 : loss : 0.2515 = 0.0463 + 0.1910 + 0.0132 + 0.0009, time: 12.684193]
2023-11-02 12:47:06.393: epoch 194:	0.03228514  	0.13146727  	0.09020406  
2023-11-02 12:47:06.393: Find a better model.
2023-11-02 12:47:18.904: [iter 195 : loss : 0.2511 = 0.0464 + 0.1905 + 0.0133 + 0.0009, time: 12.491682]
2023-11-02 12:47:19.575: epoch 195:	0.03223468  	0.13133906  	0.09003277  
2023-11-02 12:47:32.086: [iter 196 : loss : 0.2526 = 0.0483 + 0.1900 + 0.0134 + 0.0009, time: 12.493945]
2023-11-02 12:47:32.723: epoch 196:	0.03232928  	0.13122711  	0.09004886  
2023-11-02 12:47:45.288: [iter 197 : loss : 0.2510 = 0.0472 + 0.1894 + 0.0134 + 0.0009, time: 12.551297]
2023-11-02 12:47:45.960: epoch 197:	0.03225360  	0.13088584  	0.08991703  
2023-11-02 12:47:58.497: [iter 198 : loss : 0.2497 = 0.0463 + 0.1889 + 0.0135 + 0.0009, time: 12.521424]
2023-11-02 12:47:59.168: epoch 198:	0.03241757  	0.13157180  	0.09015964  
2023-11-02 12:47:59.168: Find a better model.
2023-11-02 12:48:11.798: [iter 199 : loss : 0.2485 = 0.0453 + 0.1886 + 0.0136 + 0.0009, time: 12.607875]
2023-11-02 12:48:12.455: epoch 199:	0.03246801  	0.13155501  	0.09033193  
2023-11-02 12:48:24.950: [iter 200 : loss : 0.2510 = 0.0485 + 0.1880 + 0.0137 + 0.0009, time: 12.483467]
2023-11-02 12:48:25.619: epoch 200:	0.03250586  	0.13194285  	0.09058962  
2023-11-02 12:48:25.619: Find a better model.
2023-11-02 12:48:25.619: best_result@epoch 200:

2023-11-02 12:48:25.619: 		0.0325      	0.1319      	0.0906      

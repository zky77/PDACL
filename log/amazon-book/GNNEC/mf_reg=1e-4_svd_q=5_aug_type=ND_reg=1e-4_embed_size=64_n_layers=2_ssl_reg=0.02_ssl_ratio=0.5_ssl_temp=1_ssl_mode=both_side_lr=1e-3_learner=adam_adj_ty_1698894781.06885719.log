2023-11-02 11:13:01.069: my pid: 33720
2023-11-02 11:13:01.069: model: model.general_recommender.GNNEC
2023-11-02 11:13:01.069: Dataset statistics:
Name: amazon-book
The number of users: 7928
The number of items: 29346
The number of ratings: 460224
Average actions of users: 58.05
Average actions of items: 15.68
The sparsity of the dataset: 99.802186%

The number of training: 417417
The number of validation: 0
The number of testing: 42807
2023-11-02 11:13:01.069: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=amazon-book
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=1
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=amazon-book
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=1
mf_reg=1e-4
svd_q=5
2023-11-02 11:13:05.576: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-11-02 11:13:18.779: [iter 1 : loss : 0.9682 = 0.6124 + 0.3540 + 0.0000 + 0.0018, time: 13.201850]
2023-11-02 11:13:19.447: epoch 1:	0.00984486  	0.03724389  	0.02452204  
2023-11-02 11:13:19.448: Find a better model.
2023-11-02 11:13:31.917: [iter 2 : loss : 0.7999 = 0.4822 + 0.3160 + 0.0002 + 0.0016, time: 12.453375]
2023-11-02 11:13:32.586: epoch 2:	0.01084767  	0.04150824  	0.02772947  
2023-11-02 11:13:32.586: Find a better model.
2023-11-02 11:13:45.037: [iter 3 : loss : 0.7223 = 0.4210 + 0.2996 + 0.0003 + 0.0015, time: 12.430699]
2023-11-02 11:13:45.678: epoch 3:	0.01139638  	0.04380886  	0.02962026  
2023-11-02 11:13:45.679: Find a better model.
2023-11-02 11:13:58.222: [iter 4 : loss : 0.6714 = 0.3813 + 0.2883 + 0.0004 + 0.0014, time: 12.523641]
2023-11-02 11:13:58.910: epoch 4:	0.01192617  	0.04569970  	0.03142318  
2023-11-02 11:13:58.910: Find a better model.
2023-11-02 11:14:11.489: [iter 5 : loss : 0.6316 = 0.3504 + 0.2793 + 0.0004 + 0.0014, time: 12.559069]
2023-11-02 11:14:12.152: epoch 5:	0.01261363  	0.04840364  	0.03338132  
2023-11-02 11:14:12.152: Find a better model.
2023-11-02 11:14:24.568: [iter 6 : loss : 0.6020 = 0.3280 + 0.2721 + 0.0005 + 0.0014, time: 12.398968]
2023-11-02 11:14:25.231: epoch 6:	0.01311188  	0.05061453  	0.03475675  
2023-11-02 11:14:25.232: Find a better model.
2023-11-02 11:14:37.617: [iter 7 : loss : 0.5771 = 0.3095 + 0.2657 + 0.0006 + 0.0013, time: 12.367367]
2023-11-02 11:14:38.248: epoch 7:	0.01357860  	0.05259932  	0.03619234  
2023-11-02 11:14:38.248: Find a better model.
2023-11-02 11:14:50.653: [iter 8 : loss : 0.5568 = 0.2944 + 0.2604 + 0.0007 + 0.0013, time: 12.382503]
2023-11-02 11:14:51.292: epoch 8:	0.01409578  	0.05483953  	0.03754115  
2023-11-02 11:14:51.292: Find a better model.
2023-11-02 11:15:03.609: [iter 9 : loss : 0.5365 = 0.2792 + 0.2553 + 0.0008 + 0.0013, time: 12.298953]
2023-11-02 11:15:04.275: epoch 9:	0.01430390  	0.05547383  	0.03843623  
2023-11-02 11:15:04.275: Find a better model.
2023-11-02 11:15:16.756: [iter 10 : loss : 0.5209 = 0.2680 + 0.2507 + 0.0009 + 0.0012, time: 12.462115]
2023-11-02 11:15:17.444: epoch 10:	0.01472646  	0.05695796  	0.03958336  
2023-11-02 11:15:17.445: Find a better model.
2023-11-02 11:15:30.003: [iter 11 : loss : 0.5057 = 0.2570 + 0.2465 + 0.0010 + 0.0012, time: 12.537735]
2023-11-02 11:15:30.677: epoch 11:	0.01516796  	0.05872197  	0.04058705  
2023-11-02 11:15:30.677: Find a better model.
2023-11-02 11:15:43.210: [iter 12 : loss : 0.4922 = 0.2474 + 0.2426 + 0.0010 + 0.0012, time: 12.515465]
2023-11-02 11:15:43.874: epoch 12:	0.01537608  	0.05971126  	0.04146266  
2023-11-02 11:15:43.874: Find a better model.
2023-11-02 11:15:56.450: [iter 13 : loss : 0.4808 = 0.2395 + 0.2390 + 0.0011 + 0.0012, time: 12.554924]
2023-11-02 11:15:57.126: epoch 13:	0.01585541  	0.06183367  	0.04281894  
2023-11-02 11:15:57.126: Find a better model.
2023-11-02 11:16:09.665: [iter 14 : loss : 0.4682 = 0.2306 + 0.2352 + 0.0012 + 0.0012, time: 12.520396]
2023-11-02 11:16:10.297: epoch 14:	0.01618337  	0.06336134  	0.04402474  
2023-11-02 11:16:10.297: Find a better model.
2023-11-02 11:16:22.705: [iter 15 : loss : 0.4555 = 0.2214 + 0.2316 + 0.0013 + 0.0011, time: 12.391184]
2023-11-02 11:16:23.379: epoch 15:	0.01653026  	0.06466994  	0.04512531  
2023-11-02 11:16:23.379: Find a better model.
2023-11-02 11:16:36.016: [iter 16 : loss : 0.4464 = 0.2156 + 0.2283 + 0.0014 + 0.0011, time: 12.618733]
2023-11-02 11:16:36.668: epoch 16:	0.01695283  	0.06655187  	0.04639243  
2023-11-02 11:16:36.668: Find a better model.
2023-11-02 11:16:49.170: [iter 17 : loss : 0.4370 = 0.2097 + 0.2247 + 0.0015 + 0.0011, time: 12.484073]
2023-11-02 11:16:49.834: epoch 17:	0.01732495  	0.06835264  	0.04757552  
2023-11-02 11:16:49.834: Find a better model.
2023-11-02 11:17:01.751: [iter 18 : loss : 0.4286 = 0.2044 + 0.2216 + 0.0015 + 0.0011, time: 11.903198]
2023-11-02 11:17:02.367: epoch 18:	0.01779167  	0.07032562  	0.04864056  
2023-11-02 11:17:02.367: Find a better model.
2023-11-02 11:17:14.887: [iter 19 : loss : 0.4196 = 0.1983 + 0.2186 + 0.0016 + 0.0011, time: 12.506041]
2023-11-02 11:17:15.469: epoch 19:	0.01801873  	0.07116067  	0.04923322  
2023-11-02 11:17:15.469: Find a better model.
2023-11-02 11:17:28.037: [iter 20 : loss : 0.4108 = 0.1925 + 0.2155 + 0.0017 + 0.0011, time: 12.555983]
2023-11-02 11:17:28.705: epoch 20:	0.01831515  	0.07239902  	0.04996819  
2023-11-02 11:17:28.705: Find a better model.
2023-11-02 11:17:41.010: [iter 21 : loss : 0.4025 = 0.1871 + 0.2126 + 0.0018 + 0.0010, time: 12.284991]
2023-11-02 11:17:41.642: epoch 21:	0.01854851  	0.07340744  	0.05061826  
2023-11-02 11:17:41.642: Find a better model.
2023-11-02 11:17:53.769: [iter 22 : loss : 0.3956 = 0.1831 + 0.2095 + 0.0019 + 0.0010, time: 12.109483]
2023-11-02 11:17:54.362: epoch 22:	0.01887647  	0.07499044  	0.05147131  
2023-11-02 11:17:54.362: Find a better model.
2023-11-02 11:18:06.963: [iter 23 : loss : 0.3891 = 0.1792 + 0.2069 + 0.0020 + 0.0010, time: 12.586808]
2023-11-02 11:18:07.640: epoch 23:	0.01905937  	0.07559345  	0.05199881  
2023-11-02 11:18:07.640: Find a better model.
2023-11-02 11:18:20.142: [iter 24 : loss : 0.3832 = 0.1759 + 0.2043 + 0.0020 + 0.0010, time: 12.487611]
2023-11-02 11:18:20.843: epoch 24:	0.01940626  	0.07693473  	0.05289447  
2023-11-02 11:18:20.843: Find a better model.
2023-11-02 11:18:33.525: [iter 25 : loss : 0.3762 = 0.1713 + 0.2018 + 0.0021 + 0.0010, time: 12.661445]
2023-11-02 11:18:34.128: epoch 25:	0.01977838  	0.07834322  	0.05370096  
2023-11-02 11:18:34.128: Find a better model.
2023-11-02 11:18:46.747: [iter 26 : loss : 0.3686 = 0.1665 + 0.1989 + 0.0022 + 0.0010, time: 12.603419]
2023-11-02 11:18:47.429: epoch 26:	0.01993604  	0.07883452  	0.05426085  
2023-11-02 11:18:47.429: Find a better model.
2023-11-02 11:19:00.001: [iter 27 : loss : 0.3634 = 0.1637 + 0.1965 + 0.0023 + 0.0010, time: 12.555066]
2023-11-02 11:19:00.676: epoch 27:	0.02015679  	0.07976499  	0.05480036  
2023-11-02 11:19:00.676: Find a better model.
2023-11-02 11:19:13.232: [iter 28 : loss : 0.3567 = 0.1599 + 0.1935 + 0.0024 + 0.0009, time: 12.537930]
2023-11-02 11:19:13.885: epoch 28:	0.02027663  	0.08055303  	0.05505375  
2023-11-02 11:19:13.885: Find a better model.
2023-11-02 11:19:26.441: [iter 29 : loss : 0.3510 = 0.1565 + 0.1911 + 0.0025 + 0.0009, time: 12.534714]
2023-11-02 11:19:27.063: epoch 29:	0.02037123  	0.08106218  	0.05542037  
2023-11-02 11:19:27.063: Find a better model.
2023-11-02 11:19:39.653: [iter 30 : loss : 0.3471 = 0.1550 + 0.1887 + 0.0025 + 0.0009, time: 12.571873]
2023-11-02 11:19:40.319: epoch 30:	0.02075596  	0.08243853  	0.05623809  
2023-11-02 11:19:40.319: Find a better model.
2023-11-02 11:19:52.855: [iter 31 : loss : 0.3402 = 0.1503 + 0.1864 + 0.0026 + 0.0009, time: 12.520387]
2023-11-02 11:19:53.505: epoch 31:	0.02113438  	0.08409648  	0.05722358  
2023-11-02 11:19:53.505: Find a better model.
2023-11-02 11:20:06.046: [iter 32 : loss : 0.3372 = 0.1498 + 0.1838 + 0.0027 + 0.0009, time: 12.522033]
2023-11-02 11:20:06.663: epoch 32:	0.02128575  	0.08445450  	0.05751200  
2023-11-02 11:20:06.663: Find a better model.
2023-11-02 11:20:19.293: [iter 33 : loss : 0.3306 = 0.1455 + 0.1814 + 0.0028 + 0.0009, time: 12.612239]
2023-11-02 11:20:19.958: epoch 33:	0.02154433  	0.08559582  	0.05817975  
2023-11-02 11:20:19.958: Find a better model.
2023-11-02 11:20:32.581: [iter 34 : loss : 0.3274 = 0.1445 + 0.1791 + 0.0029 + 0.0009, time: 12.600916]
2023-11-02 11:20:33.280: epoch 34:	0.02167047  	0.08591107  	0.05870296  
2023-11-02 11:20:33.280: Find a better model.
2023-11-02 11:20:45.804: [iter 35 : loss : 0.3212 = 0.1406 + 0.1769 + 0.0030 + 0.0009, time: 12.508706]
2023-11-02 11:20:46.422: epoch 35:	0.02176507  	0.08615447  	0.05911245  
2023-11-02 11:20:46.422: Find a better model.
2023-11-02 11:20:58.862: [iter 36 : loss : 0.3167 = 0.1382 + 0.1746 + 0.0030 + 0.0008, time: 12.421272]
2023-11-02 11:20:59.524: epoch 36:	0.02180291  	0.08617187  	0.05936082  
2023-11-02 11:20:59.524: Find a better model.
2023-11-02 11:21:12.149: [iter 37 : loss : 0.3127 = 0.1362 + 0.1725 + 0.0031 + 0.0008, time: 12.606850]
2023-11-02 11:21:12.819: epoch 37:	0.02203627  	0.08723930  	0.05983192  
2023-11-02 11:21:12.820: Find a better model.
2023-11-02 11:21:25.508: [iter 38 : loss : 0.3091 = 0.1348 + 0.1703 + 0.0032 + 0.0008, time: 12.670072]
2023-11-02 11:21:26.191: epoch 38:	0.02219395  	0.08802906  	0.06042423  
2023-11-02 11:21:26.191: Find a better model.
2023-11-02 11:21:38.958: [iter 39 : loss : 0.3031 = 0.1310 + 0.1680 + 0.0033 + 0.0008, time: 12.747996]
2023-11-02 11:21:39.625: epoch 39:	0.02255345  	0.08946755  	0.06120062  
2023-11-02 11:21:39.626: Find a better model.
2023-11-02 11:21:52.283: [iter 40 : loss : 0.3006 = 0.1307 + 0.1657 + 0.0034 + 0.0008, time: 12.635951]
2023-11-02 11:21:52.910: epoch 40:	0.02262913  	0.08985501  	0.06144076  
2023-11-02 11:21:52.910: Find a better model.
2023-11-02 11:22:05.510: [iter 41 : loss : 0.2957 = 0.1279 + 0.1636 + 0.0035 + 0.0008, time: 12.579970]
2023-11-02 11:22:06.180: epoch 41:	0.02273004  	0.09014449  	0.06195348  
2023-11-02 11:22:06.180: Find a better model.
2023-11-02 11:22:18.904: [iter 42 : loss : 0.2917 = 0.1257 + 0.1616 + 0.0036 + 0.0008, time: 12.706734]
2023-11-02 11:22:19.510: epoch 42:	0.02298233  	0.09114330  	0.06246100  
2023-11-02 11:22:19.510: Find a better model.
2023-11-02 11:22:31.943: [iter 43 : loss : 0.2882 = 0.1246 + 0.1591 + 0.0036 + 0.0008, time: 12.416468]
2023-11-02 11:22:32.556: epoch 43:	0.02305170  	0.09142417  	0.06267423  
2023-11-02 11:22:32.556: Find a better model.
2023-11-02 11:22:44.984: [iter 44 : loss : 0.2852 = 0.1234 + 0.1573 + 0.0037 + 0.0008, time: 12.412561]
2023-11-02 11:22:45.607: epoch 44:	0.02337337  	0.09263374  	0.06350777  
2023-11-02 11:22:45.607: Find a better model.
2023-11-02 11:22:58.134: [iter 45 : loss : 0.2807 = 0.1208 + 0.1553 + 0.0038 + 0.0007, time: 12.509537]
2023-11-02 11:22:58.828: epoch 45:	0.02363825  	0.09385618  	0.06407350  
2023-11-02 11:22:58.828: Find a better model.
2023-11-02 11:23:11.033: [iter 46 : loss : 0.2771 = 0.1194 + 0.1530 + 0.0039 + 0.0007, time: 12.179404]
2023-11-02 11:23:11.653: epoch 46:	0.02371394  	0.09431351  	0.06438620  
2023-11-02 11:23:11.653: Find a better model.
2023-11-02 11:23:24.149: [iter 47 : loss : 0.2743 = 0.1185 + 0.1511 + 0.0040 + 0.0007, time: 12.481734]
2023-11-02 11:23:24.810: epoch 47:	0.02394098  	0.09506233  	0.06493361  
2023-11-02 11:23:24.811: Find a better model.
2023-11-02 11:23:36.802: [iter 48 : loss : 0.2703 = 0.1164 + 0.1491 + 0.0041 + 0.0007, time: 11.969845]
2023-11-02 11:23:37.421: epoch 48:	0.02414280  	0.09550138  	0.06519793  
2023-11-02 11:23:37.421: Find a better model.
2023-11-02 11:23:50.008: [iter 49 : loss : 0.2662 = 0.1141 + 0.1473 + 0.0042 + 0.0007, time: 12.564877]
2023-11-02 11:23:50.620: epoch 49:	0.02421848  	0.09590000  	0.06540272  
2023-11-02 11:23:50.620: Find a better model.
2023-11-02 11:24:03.173: [iter 50 : loss : 0.2624 = 0.1126 + 0.1448 + 0.0042 + 0.0007, time: 12.534572]
2023-11-02 11:24:03.867: epoch 50:	0.02438877  	0.09666356  	0.06590797  
2023-11-02 11:24:03.868: Find a better model.
2023-11-02 11:24:16.501: [iter 51 : loss : 0.2611 = 0.1131 + 0.1431 + 0.0043 + 0.0007, time: 12.613319]
2023-11-02 11:24:17.171: epoch 51:	0.02444553  	0.09690709  	0.06632417  
2023-11-02 11:24:17.171: Find a better model.
2023-11-02 11:24:29.762: [iter 52 : loss : 0.2570 = 0.1109 + 0.1410 + 0.0044 + 0.0007, time: 12.576030]
2023-11-02 11:24:30.427: epoch 52:	0.02456537  	0.09741814  	0.06668501  
2023-11-02 11:24:30.427: Find a better model.
2023-11-02 11:24:42.854: [iter 53 : loss : 0.2537 = 0.1094 + 0.1391 + 0.0045 + 0.0007, time: 12.413376]
2023-11-02 11:24:43.520: epoch 53:	0.02462213  	0.09749734  	0.06705647  
2023-11-02 11:24:43.520: Find a better model.
2023-11-02 11:24:56.014: [iter 54 : loss : 0.2507 = 0.1084 + 0.1371 + 0.0046 + 0.0007, time: 12.478502]
2023-11-02 11:24:56.675: epoch 54:	0.02483657  	0.09865606  	0.06746735  
2023-11-02 11:24:56.676: Find a better model.
2023-11-02 11:25:09.337: [iter 55 : loss : 0.2464 = 0.1057 + 0.1353 + 0.0047 + 0.0006, time: 12.622752]
2023-11-02 11:25:09.944: epoch 55:	0.02495009  	0.09924493  	0.06780620  
2023-11-02 11:25:09.944: Find a better model.
2023-11-02 11:25:22.518: [iter 56 : loss : 0.2445 = 0.1059 + 0.1332 + 0.0048 + 0.0006, time: 12.558261]
2023-11-02 11:25:23.182: epoch 56:	0.02515822  	0.10004652  	0.06835406  
2023-11-02 11:25:23.182: Find a better model.
2023-11-02 11:25:35.706: [iter 57 : loss : 0.2421 = 0.1053 + 0.1313 + 0.0049 + 0.0006, time: 12.507412]
2023-11-02 11:25:36.365: epoch 57:	0.02533481  	0.10061382  	0.06876735  
2023-11-02 11:25:36.365: Find a better model.
2023-11-02 11:25:48.836: [iter 58 : loss : 0.2377 = 0.1030 + 0.1292 + 0.0050 + 0.0006, time: 12.453428]
2023-11-02 11:25:49.519: epoch 58:	0.02544833  	0.10115816  	0.06913111  
2023-11-02 11:25:49.519: Find a better model.
2023-11-02 11:26:02.060: [iter 59 : loss : 0.2353 = 0.1025 + 0.1272 + 0.0051 + 0.0006, time: 12.521880]
2023-11-02 11:26:02.686: epoch 59:	0.02566908  	0.10222720  	0.06972710  
2023-11-02 11:26:02.686: Find a better model.
2023-11-02 11:26:15.366: [iter 60 : loss : 0.2337 = 0.1024 + 0.1255 + 0.0051 + 0.0006, time: 12.664957]
2023-11-02 11:26:16.033: epoch 60:	0.02575738  	0.10292447  	0.07025012  
2023-11-02 11:26:16.033: Find a better model.
2023-11-02 11:26:28.512: [iter 61 : loss : 0.2297 = 0.1003 + 0.1236 + 0.0052 + 0.0006, time: 12.462514]
2023-11-02 11:26:29.109: epoch 61:	0.02593397  	0.10339558  	0.07053392  
2023-11-02 11:26:29.109: Find a better model.
2023-11-02 11:26:41.799: [iter 62 : loss : 0.2266 = 0.0989 + 0.1218 + 0.0053 + 0.0006, time: 12.672499]
2023-11-02 11:26:42.455: epoch 62:	0.02615472  	0.10434679  	0.07103463  
2023-11-02 11:26:42.455: Find a better model.
2023-11-02 11:26:54.954: [iter 63 : loss : 0.2253 = 0.0996 + 0.1197 + 0.0054 + 0.0006, time: 12.484119]
2023-11-02 11:26:55.618: epoch 63:	0.02629347  	0.10493500  	0.07150998  
2023-11-02 11:26:55.618: Find a better model.
2023-11-02 11:27:08.068: [iter 64 : loss : 0.2210 = 0.0971 + 0.1179 + 0.0055 + 0.0006, time: 12.433231]
2023-11-02 11:27:08.762: epoch 64:	0.02635656  	0.10510068  	0.07168151  
2023-11-02 11:27:08.762: Find a better model.
2023-11-02 11:27:21.417: [iter 65 : loss : 0.2170 = 0.0946 + 0.1162 + 0.0056 + 0.0006, time: 12.634220]
2023-11-02 11:27:22.088: epoch 65:	0.02655838  	0.10597609  	0.07211743  
2023-11-02 11:27:22.088: Find a better model.
2023-11-02 11:27:34.547: [iter 66 : loss : 0.2154 = 0.0950 + 0.1142 + 0.0057 + 0.0005, time: 12.445675]
2023-11-02 11:27:35.226: epoch 66:	0.02661514  	0.10624515  	0.07229961  
2023-11-02 11:27:35.226: Find a better model.
2023-11-02 11:27:47.884: [iter 67 : loss : 0.2144 = 0.0956 + 0.1125 + 0.0058 + 0.0005, time: 12.644094]
2023-11-02 11:27:48.546: epoch 67:	0.02669083  	0.10659660  	0.07265576  
2023-11-02 11:27:48.546: Find a better model.
2023-11-02 11:28:01.328: [iter 68 : loss : 0.2116 = 0.0949 + 0.1103 + 0.0059 + 0.0005, time: 12.762750]
2023-11-02 11:28:01.993: epoch 68:	0.02691789  	0.10755970  	0.07331111  
2023-11-02 11:28:01.993: Find a better model.
2023-11-02 11:28:14.540: [iter 69 : loss : 0.2084 = 0.0931 + 0.1088 + 0.0060 + 0.0005, time: 12.531503]
2023-11-02 11:28:15.232: epoch 69:	0.02714493  	0.10859583  	0.07385122  
2023-11-02 11:28:15.233: Find a better model.
2023-11-02 11:28:27.692: [iter 70 : loss : 0.2077 = 0.0944 + 0.1067 + 0.0061 + 0.0005, time: 12.441800]
2023-11-02 11:28:28.300: epoch 70:	0.02721431  	0.10892969  	0.07419514  
2023-11-02 11:28:28.300: Find a better model.
2023-11-02 11:28:40.991: [iter 71 : loss : 0.2038 = 0.0921 + 0.1051 + 0.0062 + 0.0005, time: 12.671608]
2023-11-02 11:28:41.620: epoch 71:	0.02725847  	0.10922246  	0.07443444  
2023-11-02 11:28:41.620: Find a better model.
2023-11-02 11:28:54.250: [iter 72 : loss : 0.2014 = 0.0915 + 0.1032 + 0.0063 + 0.0005, time: 12.607052]
2023-11-02 11:28:54.923: epoch 72:	0.02747291  	0.10975209  	0.07480463  
2023-11-02 11:28:54.923: Find a better model.
2023-11-02 11:29:07.339: [iter 73 : loss : 0.1985 = 0.0902 + 0.1015 + 0.0064 + 0.0005, time: 12.399157]
2023-11-02 11:29:08.019: epoch 73:	0.02743507  	0.10981108  	0.07498815  
2023-11-02 11:29:08.019: Find a better model.
2023-11-02 11:29:20.766: [iter 74 : loss : 0.1967 = 0.0899 + 0.0998 + 0.0065 + 0.0005, time: 12.727643]
2023-11-02 11:29:21.379: epoch 74:	0.02762428  	0.11044849  	0.07537685  
2023-11-02 11:29:21.380: Find a better model.
2023-11-02 11:29:33.840: [iter 75 : loss : 0.1928 = 0.0878 + 0.0979 + 0.0065 + 0.0005, time: 12.441831]
2023-11-02 11:29:34.529: epoch 75:	0.02771258  	0.11072800  	0.07552102  
2023-11-02 11:29:34.529: Find a better model.
2023-11-02 11:29:47.064: [iter 76 : loss : 0.1934 = 0.0903 + 0.0960 + 0.0066 + 0.0004, time: 12.514835]
2023-11-02 11:29:47.742: epoch 76:	0.02777566  	0.11130908  	0.07599968  
2023-11-02 11:29:47.742: Find a better model.
2023-11-02 11:30:00.300: [iter 77 : loss : 0.1892 = 0.0877 + 0.0943 + 0.0067 + 0.0004, time: 12.540565]
2023-11-02 11:30:00.974: epoch 77:	0.02780087  	0.11129090  	0.07603059  
2023-11-02 11:30:13.575: [iter 78 : loss : 0.1867 = 0.0869 + 0.0925 + 0.0068 + 0.0004, time: 12.577058]
2023-11-02 11:30:14.242: epoch 78:	0.02782610  	0.11148601  	0.07626395  
2023-11-02 11:30:14.243: Find a better model.
2023-11-02 11:30:26.750: [iter 79 : loss : 0.1850 = 0.0869 + 0.0908 + 0.0069 + 0.0004, time: 12.491483]
2023-11-02 11:30:27.400: epoch 79:	0.02792071  	0.11191047  	0.07654908  
2023-11-02 11:30:27.400: Find a better model.
2023-11-02 11:30:40.106: [iter 80 : loss : 0.1820 = 0.0855 + 0.0890 + 0.0070 + 0.0004, time: 12.688377]
2023-11-02 11:30:40.775: epoch 80:	0.02805946  	0.11240285  	0.07696680  
2023-11-02 11:30:40.775: Find a better model.
2023-11-02 11:30:53.308: [iter 81 : loss : 0.1810 = 0.0863 + 0.0871 + 0.0071 + 0.0004, time: 12.516960]
2023-11-02 11:30:53.917: epoch 81:	0.02826759  	0.11342894  	0.07740904  
2023-11-02 11:30:53.917: Find a better model.
2023-11-02 11:31:06.418: [iter 82 : loss : 0.1794 = 0.0863 + 0.0855 + 0.0072 + 0.0004, time: 12.483829]
2023-11-02 11:31:07.104: epoch 82:	0.02832435  	0.11365464  	0.07769322  
2023-11-02 11:31:07.104: Find a better model.
2023-11-02 11:31:19.832: [iter 83 : loss : 0.1749 = 0.0834 + 0.0838 + 0.0073 + 0.0004, time: 12.708650]
2023-11-02 11:31:20.506: epoch 83:	0.02838742  	0.11399610  	0.07790119  
2023-11-02 11:31:20.506: Find a better model.
2023-11-02 11:31:33.084: [iter 84 : loss : 0.1729 = 0.0832 + 0.0819 + 0.0074 + 0.0004, time: 12.564225]
2023-11-02 11:31:33.766: epoch 84:	0.02841264  	0.11393680  	0.07815094  
2023-11-02 11:31:46.231: [iter 85 : loss : 0.1707 = 0.0828 + 0.0801 + 0.0075 + 0.0004, time: 12.450424]
2023-11-02 11:31:46.898: epoch 85:	0.02851356  	0.11464851  	0.07852481  
2023-11-02 11:31:46.898: Find a better model.
2023-11-02 11:31:59.492: [iter 86 : loss : 0.1696 = 0.0832 + 0.0783 + 0.0076 + 0.0004, time: 12.580648]
2023-11-02 11:32:00.191: epoch 86:	0.02867123  	0.11540116  	0.07896774  
2023-11-02 11:32:00.192: Find a better model.
2023-11-02 11:32:12.548: [iter 87 : loss : 0.1679 = 0.0833 + 0.0765 + 0.0077 + 0.0004, time: 12.339648]
2023-11-02 11:32:13.211: epoch 87:	0.02882261  	0.11615196  	0.07933695  
2023-11-02 11:32:13.211: Find a better model.
2023-11-02 11:32:25.903: [iter 88 : loss : 0.1662 = 0.0831 + 0.0749 + 0.0078 + 0.0003, time: 12.678277]
2023-11-02 11:32:26.548: epoch 88:	0.02888568  	0.11623499  	0.07961919  
2023-11-02 11:32:26.549: Find a better model.
2023-11-02 11:32:39.161: [iter 89 : loss : 0.1639 = 0.0823 + 0.0734 + 0.0079 + 0.0003, time: 12.595801]
2023-11-02 11:32:39.817: epoch 89:	0.02899290  	0.11665909  	0.08002441  
2023-11-02 11:32:39.817: Find a better model.
2023-11-02 11:32:52.314: [iter 90 : loss : 0.1612 = 0.0812 + 0.0716 + 0.0080 + 0.0003, time: 12.482179]
2023-11-02 11:32:52.987: epoch 90:	0.02902442  	0.11691426  	0.08026952  
2023-11-02 11:32:52.987: Find a better model.
2023-11-02 11:33:05.546: [iter 91 : loss : 0.1596 = 0.0813 + 0.0698 + 0.0081 + 0.0003, time: 12.543710]
2023-11-02 11:33:06.206: epoch 91:	0.02914426  	0.11735280  	0.08069330  
2023-11-02 11:33:06.206: Find a better model.
2023-11-02 11:33:18.682: [iter 92 : loss : 0.1590 = 0.0826 + 0.0679 + 0.0082 + 0.0003, time: 12.458277]
2023-11-02 11:33:19.356: epoch 92:	0.02923256  	0.11744328  	0.08080193  
2023-11-02 11:33:19.356: Find a better model.
2023-11-02 11:33:32.002: [iter 93 : loss : 0.1555 = 0.0800 + 0.0668 + 0.0083 + 0.0003, time: 12.628800]
2023-11-02 11:33:32.648: epoch 93:	0.02937130  	0.11825988  	0.08109594  
2023-11-02 11:33:32.648: Find a better model.
2023-11-02 11:33:45.365: [iter 94 : loss : 0.1542 = 0.0805 + 0.0650 + 0.0084 + 0.0003, time: 12.699326]
2023-11-02 11:33:46.045: epoch 94:	0.02953529  	0.11872936  	0.08127776  
2023-11-02 11:33:46.045: Find a better model.
2023-11-02 11:33:58.406: [iter 95 : loss : 0.1525 = 0.0805 + 0.0632 + 0.0085 + 0.0003, time: 12.342423]
2023-11-02 11:33:59.063: epoch 95:	0.02948483  	0.11861312  	0.08144008  
2023-11-02 11:34:11.578: [iter 96 : loss : 0.1503 = 0.0797 + 0.0617 + 0.0086 + 0.0003, time: 12.496111]
2023-11-02 11:34:12.242: epoch 96:	0.02960466  	0.11908270  	0.08167960  
2023-11-02 11:34:12.242: Find a better model.
2023-11-02 11:34:24.903: [iter 97 : loss : 0.1460 = 0.0769 + 0.0601 + 0.0087 + 0.0003, time: 12.643209]
2023-11-02 11:34:25.501: epoch 97:	0.02969296  	0.11939403  	0.08194910  
2023-11-02 11:34:25.502: Find a better model.
2023-11-02 11:34:37.888: [iter 98 : loss : 0.1459 = 0.0789 + 0.0579 + 0.0089 + 0.0003, time: 12.369663]
2023-11-02 11:34:38.573: epoch 98:	0.02988848  	0.12021396  	0.08234623  
2023-11-02 11:34:38.573: Find a better model.
2023-11-02 11:34:51.211: [iter 99 : loss : 0.1431 = 0.0774 + 0.0565 + 0.0090 + 0.0002, time: 12.619339]
2023-11-02 11:34:51.875: epoch 99:	0.02992001  	0.12045008  	0.08254637  
2023-11-02 11:34:51.875: Find a better model.
2023-11-02 11:35:04.471: [iter 100 : loss : 0.1414 = 0.0771 + 0.0550 + 0.0091 + 0.0002, time: 12.579207]
2023-11-02 11:35:05.152: epoch 100:	0.03006507  	0.12079827  	0.08290423  
2023-11-02 11:35:05.152: Find a better model.
2023-11-02 11:35:17.724: [iter 101 : loss : 0.1421 = 0.0796 + 0.0531 + 0.0092 + 0.0002, time: 12.552500]
2023-11-02 11:35:18.381: epoch 101:	0.03009660  	0.12092885  	0.08287679  
2023-11-02 11:35:18.381: Find a better model.
2023-11-02 11:35:30.882: [iter 102 : loss : 0.1407 = 0.0797 + 0.0515 + 0.0093 + 0.0002, time: 12.485962]
2023-11-02 11:35:31.552: epoch 102:	0.03015336  	0.12117775  	0.08315420  
2023-11-02 11:35:31.552: Find a better model.
2023-11-02 11:35:44.307: [iter 103 : loss : 0.1378 = 0.0783 + 0.0499 + 0.0094 + 0.0002, time: 12.733665]
2023-11-02 11:35:44.996: epoch 103:	0.03033626  	0.12205771  	0.08347351  
2023-11-02 11:35:44.996: Find a better model.
2023-11-02 11:35:57.340: [iter 104 : loss : 0.1348 = 0.0766 + 0.0485 + 0.0095 + 0.0002, time: 12.323029]
2023-11-02 11:35:57.999: epoch 104:	0.03033626  	0.12214806  	0.08357882  
2023-11-02 11:35:57.999: Find a better model.
2023-11-02 11:36:10.504: [iter 105 : loss : 0.1322 = 0.0756 + 0.0469 + 0.0096 + 0.0002, time: 12.484506]
2023-11-02 11:36:11.179: epoch 105:	0.03041825  	0.12244021  	0.08399267  
2023-11-02 11:36:11.179: Find a better model.
2023-11-02 11:36:23.972: [iter 106 : loss : 0.1330 = 0.0780 + 0.0451 + 0.0097 + 0.0002, time: 12.775151]
2023-11-02 11:36:24.664: epoch 106:	0.03055699  	0.12292431  	0.08410005  
2023-11-02 11:36:24.664: Find a better model.
2023-11-02 11:36:37.255: [iter 107 : loss : 0.1299 = 0.0763 + 0.0437 + 0.0098 + 0.0002, time: 12.570124]
2023-11-02 11:36:37.883: epoch 107:	0.03056330  	0.12325335  	0.08432387  
2023-11-02 11:36:37.883: Find a better model.
2023-11-02 11:36:50.597: [iter 108 : loss : 0.1291 = 0.0771 + 0.0419 + 0.0099 + 0.0002, time: 12.694916]
2023-11-02 11:36:51.261: epoch 108:	0.03053177  	0.12311082  	0.08441553  
2023-11-02 11:37:03.866: [iter 109 : loss : 0.1247 = 0.0742 + 0.0403 + 0.0100 + 0.0002, time: 12.585889]
2023-11-02 11:37:04.537: epoch 109:	0.03060115  	0.12332407  	0.08455836  
2023-11-02 11:37:04.538: Find a better model.
2023-11-02 11:37:17.232: [iter 110 : loss : 0.1253 = 0.0764 + 0.0387 + 0.0101 + 0.0002, time: 12.674517]
2023-11-02 11:37:17.905: epoch 110:	0.03082189  	0.12405366  	0.08504259  
2023-11-02 11:37:17.905: Find a better model.
2023-11-02 11:37:30.495: [iter 111 : loss : 0.1207 = 0.0732 + 0.0371 + 0.0102 + 0.0002, time: 12.571313]
2023-11-02 11:37:31.147: epoch 111:	0.03081559  	0.12414455  	0.08508018  
2023-11-02 11:37:31.147: Find a better model.
2023-11-02 11:37:43.704: [iter 112 : loss : 0.1228 = 0.0767 + 0.0356 + 0.0103 + 0.0001, time: 12.539101]
2023-11-02 11:37:44.390: epoch 112:	0.03082821  	0.12431866  	0.08549104  
2023-11-02 11:37:44.390: Find a better model.
2023-11-02 11:37:56.836: [iter 113 : loss : 0.1177 = 0.0728 + 0.0342 + 0.0104 + 0.0001, time: 12.428776]
2023-11-02 11:37:57.541: epoch 113:	0.03089127  	0.12444753  	0.08565697  
2023-11-02 11:37:57.542: Find a better model.
2023-11-02 11:38:10.180: [iter 114 : loss : 0.1171 = 0.0742 + 0.0323 + 0.0105 + 0.0001, time: 12.617264]
2023-11-02 11:38:10.828: epoch 114:	0.03087866  	0.12450442  	0.08572207  
2023-11-02 11:38:10.828: Find a better model.
2023-11-02 11:38:23.451: [iter 115 : loss : 0.1172 = 0.0757 + 0.0308 + 0.0106 + 0.0001, time: 12.607232]
2023-11-02 11:38:24.136: epoch 115:	0.03089128  	0.12458926  	0.08574601  
2023-11-02 11:38:24.137: Find a better model.
2023-11-02 11:38:36.816: [iter 116 : loss : 0.1153 = 0.0754 + 0.0291 + 0.0107 + 0.0001, time: 12.661132]
2023-11-02 11:38:37.498: epoch 116:	0.03079667  	0.12426556  	0.08564347  
2023-11-02 11:38:50.161: [iter 117 : loss : 0.1129 = 0.0741 + 0.0278 + 0.0109 + 0.0001, time: 12.646469]
2023-11-02 11:38:50.838: epoch 117:	0.03090389  	0.12467939  	0.08600271  
2023-11-02 11:38:50.838: Find a better model.
2023-11-02 11:39:03.412: [iter 118 : loss : 0.1097 = 0.0724 + 0.0262 + 0.0110 + 0.0001, time: 12.555459]
2023-11-02 11:39:04.082: epoch 118:	0.03091650  	0.12474943  	0.08605389  
2023-11-02 11:39:04.083: Find a better model.
2023-11-02 11:39:16.758: [iter 119 : loss : 0.1102 = 0.0744 + 0.0246 + 0.0111 + 0.0001, time: 12.658931]
2023-11-02 11:39:17.442: epoch 119:	0.03100480  	0.12514414  	0.08630854  
2023-11-02 11:39:17.443: Find a better model.
2023-11-02 11:39:30.193: [iter 120 : loss : 0.1085 = 0.0741 + 0.0231 + 0.0112 + 0.0001, time: 12.730282]
2023-11-02 11:39:30.872: epoch 120:	0.03108048  	0.12553161  	0.08649193  
2023-11-02 11:39:30.872: Find a better model.
2023-11-02 11:39:43.437: [iter 121 : loss : 0.1076 = 0.0748 + 0.0214 + 0.0113 + 0.0001, time: 12.549498]
2023-11-02 11:39:44.116: epoch 121:	0.03106156  	0.12523979  	0.08663535  
2023-11-02 11:39:56.840: [iter 122 : loss : 0.1055 = 0.0740 + 0.0201 + 0.0114 + 0.0001, time: 12.704895]
2023-11-02 11:39:57.532: epoch 122:	0.03116247  	0.12559080  	0.08690681  
2023-11-02 11:39:57.533: Find a better model.
2023-11-02 11:40:10.118: [iter 123 : loss : 0.1034 = 0.0735 + 0.0184 + 0.0115 + 0.0001, time: 12.560499]
2023-11-02 11:40:10.795: epoch 123:	0.03118770  	0.12586059  	0.08698696  
2023-11-02 11:40:10.795: Find a better model.
2023-11-02 11:40:23.333: [iter 124 : loss : 0.1021 = 0.0735 + 0.0169 + 0.0116 + 0.0000, time: 12.519023]
2023-11-02 11:40:24.005: epoch 124:	0.03121293  	0.12588999  	0.08704615  
2023-11-02 11:40:24.005: Find a better model.
2023-11-02 11:40:36.566: [iter 125 : loss : 0.1030 = 0.0758 + 0.0154 + 0.0117 + 0.0000, time: 12.544667]
2023-11-02 11:40:37.248: epoch 125:	0.03138952  	0.12671198  	0.08727337  
2023-11-02 11:40:37.248: Find a better model.
2023-11-02 11:40:49.980: [iter 126 : loss : 0.0985 = 0.0725 + 0.0141 + 0.0118 + 0.0000, time: 12.715950]
2023-11-02 11:40:50.599: epoch 126:	0.03139582  	0.12673779  	0.08745683  
2023-11-02 11:40:50.599: Find a better model.
2023-11-02 11:41:03.238: [iter 127 : loss : 0.0960 = 0.0716 + 0.0125 + 0.0119 + 0.0000, time: 12.620784]
2023-11-02 11:41:03.896: epoch 127:	0.03147781  	0.12703441  	0.08770475  
2023-11-02 11:41:03.897: Find a better model.
2023-11-02 11:41:16.576: [iter 128 : loss : 0.0967 = 0.0734 + 0.0113 + 0.0120 + 0.0000, time: 12.663886]
2023-11-02 11:41:17.275: epoch 128:	0.03155348  	0.12728253  	0.08787498  
2023-11-02 11:41:17.276: Find a better model.
2023-11-02 11:41:29.935: [iter 129 : loss : 0.0953 = 0.0736 + 0.0095 + 0.0122 + 0.0000, time: 12.633059]
2023-11-02 11:41:30.592: epoch 129:	0.03163549  	0.12770079  	0.08816567  
2023-11-02 11:41:30.592: Find a better model.
2023-11-02 11:41:43.219: [iter 130 : loss : 0.0936 = 0.0732 + 0.0082 + 0.0123 + 0.0000, time: 12.610122]
2023-11-02 11:41:43.900: epoch 130:	0.03159134  	0.12761007  	0.08821297  
2023-11-02 11:41:56.561: [iter 131 : loss : 0.0902 = 0.0711 + 0.0067 + 0.0124 + -0.0000, time: 12.644254]
2023-11-02 11:41:57.258: epoch 131:	0.03167334  	0.12793820  	0.08846708  
2023-11-02 11:41:57.258: Find a better model.
2023-11-02 11:42:09.838: [iter 132 : loss : 0.0922 = 0.0743 + 0.0054 + 0.0125 + -0.0000, time: 12.561876]
2023-11-02 11:42:10.473: epoch 132:	0.03178687  	0.12834318  	0.08861209  
2023-11-02 11:42:10.473: Find a better model.
2023-11-02 11:42:22.970: [iter 133 : loss : 0.0900 = 0.0735 + 0.0039 + 0.0126 + -0.0000, time: 12.479103]
2023-11-02 11:42:23.637: epoch 133:	0.03174902  	0.12821086  	0.08856481  
2023-11-02 11:42:36.192: [iter 134 : loss : 0.0880 = 0.0730 + 0.0023 + 0.0127 + -0.0000, time: 12.537201]
2023-11-02 11:42:36.866: epoch 134:	0.03178687  	0.12817979  	0.08866949  
2023-11-02 11:42:49.620: [iter 135 : loss : 0.0859 = 0.0721 + 0.0010 + 0.0128 + -0.0000, time: 12.733936]
2023-11-02 11:42:50.248: epoch 135:	0.03190670  	0.12883651  	0.08898205  
2023-11-02 11:42:50.248: Find a better model.
2023-11-02 11:43:02.832: [iter 136 : loss : 0.0829 = 0.0706 + -0.0006 + 0.0129 + -0.0000, time: 12.568799]
2023-11-02 11:43:03.504: epoch 136:	0.03200761  	0.12909746  	0.08912613  
2023-11-02 11:43:03.504: Find a better model.
2023-11-02 11:43:16.010: [iter 137 : loss : 0.0838 = 0.0729 + -0.0020 + 0.0130 + -0.0000, time: 12.487547]
2023-11-02 11:43:16.679: epoch 137:	0.03199499  	0.12895733  	0.08934735  
2023-11-02 11:43:29.399: [iter 138 : loss : 0.0822 = 0.0722 + -0.0030 + 0.0131 + -0.0001, time: 12.701509]
2023-11-02 11:43:30.044: epoch 138:	0.03206437  	0.12922746  	0.08945603  
2023-11-02 11:43:30.044: Find a better model.
2023-11-02 11:43:42.568: [iter 139 : loss : 0.0804 = 0.0722 + -0.0051 + 0.0132 + -0.0001, time: 12.506572]
2023-11-02 11:43:43.240: epoch 139:	0.03208960  	0.12935366  	0.08954399  
2023-11-02 11:43:43.240: Find a better model.
2023-11-02 11:43:55.761: [iter 140 : loss : 0.0812 = 0.0743 + -0.0064 + 0.0134 + -0.0001, time: 12.503173]
2023-11-02 11:43:56.438: epoch 140:	0.03212112  	0.12971017  	0.08976228  
2023-11-02 11:43:56.438: Find a better model.
2023-11-02 11:44:09.150: [iter 141 : loss : 0.0782 = 0.0724 + -0.0076 + 0.0135 + -0.0001, time: 12.692913]
2023-11-02 11:44:09.793: epoch 141:	0.03212743  	0.12952474  	0.08987663  
2023-11-02 11:44:22.366: [iter 142 : loss : 0.0770 = 0.0723 + -0.0088 + 0.0136 + -0.0001, time: 12.552313]
2023-11-02 11:44:22.989: epoch 142:	0.03213374  	0.12955070  	0.08985983  
2023-11-02 11:44:35.634: [iter 143 : loss : 0.0771 = 0.0738 + -0.0103 + 0.0137 + -0.0001, time: 12.628491]
2023-11-02 11:44:36.311: epoch 143:	0.03213375  	0.12977555  	0.08997139  
2023-11-02 11:44:36.311: Find a better model.
2023-11-02 11:44:48.756: [iter 144 : loss : 0.0739 = 0.0719 + -0.0117 + 0.0138 + -0.0001, time: 12.423999]
2023-11-02 11:44:49.424: epoch 144:	0.03223466  	0.13003801  	0.09004396  
2023-11-02 11:44:49.424: Find a better model.
2023-11-02 11:45:02.019: [iter 145 : loss : 0.0715 = 0.0707 + -0.0130 + 0.0139 + -0.0001, time: 12.577412]
2023-11-02 11:45:02.631: epoch 145:	0.03234817  	0.13020061  	0.09024479  
2023-11-02 11:45:02.632: Find a better model.
2023-11-02 11:45:15.171: [iter 146 : loss : 0.0728 = 0.0732 + -0.0143 + 0.0140 + -0.0001, time: 12.522232]
2023-11-02 11:45:15.844: epoch 146:	0.03231034  	0.12995280  	0.09011042  
2023-11-02 11:45:28.517: [iter 147 : loss : 0.0713 = 0.0729 + -0.0156 + 0.0141 + -0.0001, time: 12.654442]
2023-11-02 11:45:29.136: epoch 147:	0.03223466  	0.13009813  	0.09028284  
2023-11-02 11:45:41.662: [iter 148 : loss : 0.0696 = 0.0726 + -0.0170 + 0.0142 + -0.0001, time: 12.511906]
2023-11-02 11:45:42.328: epoch 148:	0.03239233  	0.13061509  	0.09055173  
2023-11-02 11:45:42.328: Find a better model.
2023-11-02 11:45:55.065: [iter 149 : loss : 0.0676 = 0.0717 + -0.0184 + 0.0143 + -0.0001, time: 12.722258]
2023-11-02 11:45:55.740: epoch 149:	0.03238602  	0.13046031  	0.09052210  
2023-11-02 11:46:08.388: [iter 150 : loss : 0.0691 = 0.0746 + -0.0198 + 0.0144 + -0.0001, time: 12.631877]
2023-11-02 11:46:09.012: epoch 150:	0.03248061  	0.13100855  	0.09074602  
2023-11-02 11:46:09.012: Find a better model.
2023-11-02 11:46:21.612: [iter 151 : loss : 0.0648 = 0.0715 + -0.0211 + 0.0145 + -0.0001, time: 12.585184]
2023-11-02 11:46:22.283: epoch 151:	0.03242386  	0.13059007  	0.09089362  
2023-11-02 11:46:34.892: [iter 152 : loss : 0.0649 = 0.0727 + -0.0223 + 0.0146 + -0.0001, time: 12.592664]
2023-11-02 11:46:35.532: epoch 152:	0.03247429  	0.13097087  	0.09107839  
2023-11-02 11:46:48.247: [iter 153 : loss : 0.0624 = 0.0715 + -0.0237 + 0.0148 + -0.0002, time: 12.695087]
2023-11-02 11:46:48.911: epoch 153:	0.03248059  	0.13093837  	0.09113231  
2023-11-02 11:47:01.397: [iter 154 : loss : 0.0638 = 0.0741 + -0.0250 + 0.0149 + -0.0002, time: 12.467247]
2023-11-02 11:47:02.068: epoch 154:	0.03258152  	0.13131894  	0.09133965  
2023-11-02 11:47:02.069: Find a better model.
2023-11-02 11:47:14.597: [iter 155 : loss : 0.0589 = 0.0703 + -0.0262 + 0.0150 + -0.0002, time: 12.511392]
2023-11-02 11:47:15.270: epoch 155:	0.03258152  	0.13149896  	0.09140791  
2023-11-02 11:47:15.271: Find a better model.
2023-11-02 11:47:27.673: [iter 156 : loss : 0.0586 = 0.0711 + -0.0275 + 0.0151 + -0.0002, time: 12.384640]
2023-11-02 11:47:28.372: epoch 156:	0.03267611  	0.13214521  	0.09163193  
2023-11-02 11:47:28.372: Find a better model.
2023-11-02 11:47:41.000: [iter 157 : loss : 0.0564 = 0.0703 + -0.0289 + 0.0152 + -0.0002, time: 12.599599]
2023-11-02 11:47:41.678: epoch 157:	0.03274547  	0.13224638  	0.09175974  
2023-11-02 11:47:41.678: Find a better model.
2023-11-02 11:47:54.241: [iter 158 : loss : 0.0568 = 0.0717 + -0.0300 + 0.0153 + -0.0002, time: 12.547269]
2023-11-02 11:47:54.915: epoch 158:	0.03275809  	0.13228932  	0.09189892  
2023-11-02 11:47:54.915: Find a better model.
2023-11-02 11:48:07.490: [iter 159 : loss : 0.0549 = 0.0713 + -0.0316 + 0.0154 + -0.0002, time: 12.557316]
2023-11-02 11:48:08.151: epoch 159:	0.03273916  	0.13202065  	0.09187455  
2023-11-02 11:48:20.749: [iter 160 : loss : 0.0529 = 0.0705 + -0.0328 + 0.0155 + -0.0002, time: 12.581311]
2023-11-02 11:48:21.360: epoch 160:	0.03278963  	0.13229665  	0.09183059  
2023-11-02 11:48:21.360: Find a better model.
2023-11-02 11:48:33.984: [iter 161 : loss : 0.0534 = 0.0720 + -0.0340 + 0.0156 + -0.0002, time: 12.607876]
2023-11-02 11:48:34.656: epoch 161:	0.03285900  	0.13258347  	0.09198397  
2023-11-02 11:48:34.656: Find a better model.
2023-11-02 11:48:47.171: [iter 162 : loss : 0.0524 = 0.0723 + -0.0354 + 0.0157 + -0.0002, time: 12.498791]
2023-11-02 11:48:47.826: epoch 162:	0.03297251  	0.13325357  	0.09236322  
2023-11-02 11:48:47.827: Find a better model.
2023-11-02 11:49:00.417: [iter 163 : loss : 0.0506 = 0.0715 + -0.0365 + 0.0158 + -0.0002, time: 12.571116]
2023-11-02 11:49:01.028: epoch 163:	0.03297882  	0.13319865  	0.09258745  
2023-11-02 11:49:13.658: [iter 164 : loss : 0.0499 = 0.0721 + -0.0379 + 0.0160 + -0.0002, time: 12.609914]
2023-11-02 11:49:14.313: epoch 164:	0.03297882  	0.13321351  	0.09271048  
2023-11-02 11:49:26.917: [iter 165 : loss : 0.0487 = 0.0721 + -0.0393 + 0.0161 + -0.0002, time: 12.584740]
2023-11-02 11:49:27.553: epoch 165:	0.03300404  	0.13340589  	0.09279608  
2023-11-02 11:49:27.553: Find a better model.
2023-11-02 11:49:39.965: [iter 166 : loss : 0.0475 = 0.0720 + -0.0405 + 0.0162 + -0.0002, time: 12.394323]
2023-11-02 11:49:40.610: epoch 166:	0.03308602  	0.13382939  	0.09285578  
2023-11-02 11:49:40.610: Find a better model.
2023-11-02 11:49:53.386: [iter 167 : loss : 0.0448 = 0.0705 + -0.0417 + 0.0163 + -0.0002, time: 12.753374]
2023-11-02 11:49:54.081: epoch 167:	0.03312385  	0.13391447  	0.09307228  
2023-11-02 11:49:54.081: Find a better model.
2023-11-02 11:50:06.713: [iter 168 : loss : 0.0446 = 0.0714 + -0.0430 + 0.0164 + -0.0003, time: 12.613087]
2023-11-02 11:50:07.418: epoch 168:	0.03304188  	0.13354012  	0.09300002  
2023-11-02 11:50:19.969: [iter 169 : loss : 0.0456 = 0.0734 + -0.0440 + 0.0165 + -0.0003, time: 12.527746]
2023-11-02 11:50:20.612: epoch 169:	0.03301034  	0.13343093  	0.09315379  
2023-11-02 11:50:33.211: [iter 170 : loss : 0.0427 = 0.0715 + -0.0452 + 0.0166 + -0.0003, time: 12.584553]
2023-11-02 11:50:33.889: epoch 170:	0.03314278  	0.13389169  	0.09325590  
2023-11-02 11:50:46.383: [iter 171 : loss : 0.0409 = 0.0711 + -0.0466 + 0.0167 + -0.0003, time: 12.475431]
2023-11-02 11:50:47.044: epoch 171:	0.03318062  	0.13423094  	0.09346795  
2023-11-02 11:50:47.045: Find a better model.
2023-11-02 11:50:59.459: [iter 172 : loss : 0.0383 = 0.0697 + -0.0479 + 0.0168 + -0.0003, time: 12.398274]
2023-11-02 11:51:00.129: epoch 172:	0.03331305  	0.13453761  	0.09362614  
2023-11-02 11:51:00.129: Find a better model.
2023-11-02 11:51:12.782: [iter 173 : loss : 0.0398 = 0.0721 + -0.0490 + 0.0169 + -0.0003, time: 12.634490]
2023-11-02 11:51:13.466: epoch 173:	0.03329412  	0.13444231  	0.09361461  
2023-11-02 11:51:26.031: [iter 174 : loss : 0.0383 = 0.0719 + -0.0503 + 0.0170 + -0.0003, time: 12.547136]
2023-11-02 11:51:26.647: epoch 174:	0.03322475  	0.13417070  	0.09358671  
2023-11-02 11:51:39.234: [iter 175 : loss : 0.0375 = 0.0721 + -0.0514 + 0.0172 + -0.0003, time: 12.565506]
2023-11-02 11:51:39.905: epoch 175:	0.03331935  	0.13437173  	0.09360078  
2023-11-02 11:51:52.411: [iter 176 : loss : 0.0357 = 0.0712 + -0.0525 + 0.0173 + -0.0003, time: 12.485782]
2023-11-02 11:51:53.073: epoch 176:	0.03331304  	0.13441573  	0.09372891  
2023-11-02 11:52:05.568: [iter 177 : loss : 0.0359 = 0.0727 + -0.0539 + 0.0174 + -0.0003, time: 12.477907]
2023-11-02 11:52:06.233: epoch 177:	0.03341394  	0.13488592  	0.09398433  
2023-11-02 11:52:06.233: Find a better model.
2023-11-02 11:52:18.927: [iter 178 : loss : 0.0337 = 0.0716 + -0.0551 + 0.0175 + -0.0003, time: 12.673270]
2023-11-02 11:52:19.576: epoch 178:	0.03339502  	0.13483685  	0.09407513  
2023-11-02 11:52:32.127: [iter 179 : loss : 0.0328 = 0.0718 + -0.0562 + 0.0176 + -0.0003, time: 12.532683]
2023-11-02 11:52:32.804: epoch 179:	0.03338242  	0.13472813  	0.09417454  
2023-11-02 11:52:45.272: [iter 180 : loss : 0.0339 = 0.0737 + -0.0572 + 0.0177 + -0.0003, time: 12.449787]
2023-11-02 11:52:45.942: epoch 180:	0.03338242  	0.13476229  	0.09411556  
2023-11-02 11:52:58.426: [iter 181 : loss : 0.0343 = 0.0755 + -0.0586 + 0.0178 + -0.0003, time: 12.468479]
2023-11-02 11:52:59.124: epoch 181:	0.03345179  	0.13528542  	0.09439250  
2023-11-02 11:52:59.124: Find a better model.
2023-11-02 11:53:11.773: [iter 182 : loss : 0.0290 = 0.0712 + -0.0598 + 0.0179 + -0.0003, time: 12.623696]
2023-11-02 11:53:12.414: epoch 182:	0.03360314  	0.13570036  	0.09456910  
2023-11-02 11:53:12.414: Find a better model.
2023-11-02 11:53:24.907: [iter 183 : loss : 0.0282 = 0.0711 + -0.0606 + 0.0180 + -0.0003, time: 12.479204]
2023-11-02 11:53:25.544: epoch 183:	0.03351485  	0.13519560  	0.09428975  
2023-11-02 11:53:38.169: [iter 184 : loss : 0.0279 = 0.0719 + -0.0618 + 0.0181 + -0.0003, time: 12.608028]
2023-11-02 11:53:38.816: epoch 184:	0.03354638  	0.13542411  	0.09448265  
2023-11-02 11:53:51.349: [iter 185 : loss : 0.0250 = 0.0701 + -0.0630 + 0.0182 + -0.0004, time: 12.517931]
2023-11-02 11:53:52.018: epoch 185:	0.03371663  	0.13591181  	0.09480704  
2023-11-02 11:53:52.018: Find a better model.
2023-11-02 11:54:04.527: [iter 186 : loss : 0.0259 = 0.0720 + -0.0641 + 0.0183 + -0.0004, time: 12.488831]
2023-11-02 11:54:05.208: epoch 186:	0.03362205  	0.13553931  	0.09480925  
2023-11-02 11:54:17.894: [iter 187 : loss : 0.0250 = 0.0724 + -0.0655 + 0.0184 + -0.0004, time: 12.667027]
2023-11-02 11:54:18.520: epoch 187:	0.03371032  	0.13599403  	0.09493167  
2023-11-02 11:54:18.520: Find a better model.
2023-11-02 11:54:31.078: [iter 188 : loss : 0.0265 = 0.0745 + -0.0662 + 0.0185 + -0.0004, time: 12.541732]
2023-11-02 11:54:31.755: epoch 188:	0.03376077  	0.13624163  	0.09505282  
2023-11-02 11:54:31.755: Find a better model.
2023-11-02 11:54:44.327: [iter 189 : loss : 0.0222 = 0.0715 + -0.0676 + 0.0186 + -0.0004, time: 12.552247]
2023-11-02 11:54:44.998: epoch 189:	0.03367880  	0.13597395  	0.09503751  
2023-11-02 11:54:57.547: [iter 190 : loss : 0.0234 = 0.0735 + -0.0685 + 0.0188 + -0.0004, time: 12.529322]
2023-11-02 11:54:58.249: epoch 190:	0.03376709  	0.13625692  	0.09524360  
2023-11-02 11:54:58.250: Find a better model.
2023-11-02 11:55:10.907: [iter 191 : loss : 0.0214 = 0.0728 + -0.0698 + 0.0189 + -0.0004, time: 12.634469]
2023-11-02 11:55:11.567: epoch 191:	0.03376709  	0.13613941  	0.09529956  
2023-11-02 11:55:24.048: [iter 192 : loss : 0.0208 = 0.0731 + -0.0709 + 0.0190 + -0.0004, time: 12.465970]
2023-11-02 11:55:24.755: epoch 192:	0.03378600  	0.13644879  	0.09559824  
2023-11-02 11:55:24.761: Find a better model.
2023-11-02 11:55:37.476: [iter 193 : loss : 0.0197 = 0.0731 + -0.0720 + 0.0191 + -0.0004, time: 12.690621]
2023-11-02 11:55:38.119: epoch 193:	0.03394997  	0.13702102  	0.09588119  
2023-11-02 11:55:38.119: Find a better model.
2023-11-02 11:55:50.775: [iter 194 : loss : 0.0172 = 0.0714 + -0.0730 + 0.0192 + -0.0004, time: 12.638349]
2023-11-02 11:55:51.461: epoch 194:	0.03396887  	0.13727902  	0.09592493  
2023-11-02 11:55:51.462: Find a better model.
2023-11-02 11:56:03.951: [iter 195 : loss : 0.0159 = 0.0710 + -0.0740 + 0.0193 + -0.0004, time: 12.471072]
2023-11-02 11:56:04.638: epoch 195:	0.03390582  	0.13695177  	0.09590282  
2023-11-02 11:56:17.155: [iter 196 : loss : 0.0178 = 0.0741 + -0.0752 + 0.0194 + -0.0004, time: 12.499235]
2023-11-02 11:56:17.839: epoch 196:	0.03390582  	0.13706779  	0.09583634  
2023-11-02 11:56:30.185: [iter 197 : loss : 0.0161 = 0.0734 + -0.0764 + 0.0195 + -0.0004, time: 12.326302]
2023-11-02 11:56:30.865: epoch 197:	0.03393735  	0.13711850  	0.09591205  
2023-11-02 11:56:43.338: [iter 198 : loss : 0.0135 = 0.0717 + -0.0774 + 0.0196 + -0.0004, time: 12.459184]
2023-11-02 11:56:43.995: epoch 198:	0.03400672  	0.13730586  	0.09614931  
2023-11-02 11:56:43.995: Find a better model.
2023-11-02 11:56:56.692: [iter 199 : loss : 0.0113 = 0.0703 + -0.0783 + 0.0197 + -0.0004, time: 12.683233]
2023-11-02 11:56:57.356: epoch 199:	0.03411392  	0.13754006  	0.09631596  
2023-11-02 11:56:57.356: Find a better model.
2023-11-02 11:57:09.790: [iter 200 : loss : 0.0150 = 0.0751 + -0.0795 + 0.0198 + -0.0004, time: 12.418903]
2023-11-02 11:57:10.457: epoch 200:	0.03408240  	0.13750206  	0.09637365  
2023-11-02 11:57:10.457: best_result@epoch 199:

2023-11-02 11:57:10.457: 		0.0341      	0.1375      	0.0963      

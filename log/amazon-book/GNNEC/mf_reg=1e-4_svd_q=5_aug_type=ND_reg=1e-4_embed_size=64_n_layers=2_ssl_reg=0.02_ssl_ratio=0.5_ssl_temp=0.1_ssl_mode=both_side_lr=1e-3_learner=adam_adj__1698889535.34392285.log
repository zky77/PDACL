2023-11-02 09:45:35.344: my pid: 35063
2023-11-02 09:45:35.344: model: model.general_recommender.GNNEC
2023-11-02 09:45:35.344: Dataset statistics:
Name: amazon-book
The number of users: 7928
The number of items: 29346
The number of ratings: 460224
Average actions of users: 58.05
Average actions of items: 15.68
The sparsity of the dataset: 99.802186%

The number of training: 417417
The number of validation: 0
The number of testing: 42807
2023-11-02 09:45:35.344: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=amazon-book
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.1
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=amazon-book
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.1
mf_reg=1e-4
svd_q=5
2023-11-02 09:45:40.498: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-11-02 09:45:54.085: [iter 1 : loss : 0.7824 = 0.6219 + 0.1598 + 0.0000 + 0.0008, time: 13.585927]
2023-11-02 09:45:54.744: epoch 1:	0.01347768  	0.05311122  	0.03573683  
2023-11-02 09:45:54.744: Find a better model.
2023-11-02 09:46:07.185: [iter 2 : loss : 0.2765 = 0.4176 + -0.1405 + 0.0002 + -0.0009, time: 12.425762]
2023-11-02 09:46:07.872: epoch 2:	0.01706003  	0.06853951  	0.04637631  
2023-11-02 09:46:07.873: Find a better model.
2023-11-02 09:46:20.188: [iter 3 : loss : -0.0241 = 0.3122 + -0.3349 + 0.0004 + -0.0019, time: 12.291148]
2023-11-02 09:46:20.848: epoch 3:	0.01883863  	0.07511010  	0.05099970  
2023-11-02 09:46:20.849: Find a better model.
2023-11-02 09:46:33.566: [iter 4 : loss : -0.2163 = 0.2613 + -0.4756 + 0.0006 + -0.0026, time: 12.699010]
2023-11-02 09:46:34.223: epoch 4:	0.02022616  	0.08105100  	0.05531130  
2023-11-02 09:46:34.223: Find a better model.
2023-11-02 09:46:46.931: [iter 5 : loss : -0.3697 = 0.2302 + -0.5975 + 0.0009 + -0.0032, time: 12.691977]
2023-11-02 09:46:47.588: epoch 5:	0.02130467  	0.08551752  	0.05818324  
2023-11-02 09:46:47.588: Find a better model.
2023-11-02 09:47:00.211: [iter 6 : loss : -0.4933 = 0.2114 + -0.7021 + 0.0011 + -0.0038, time: 12.608381]
2023-11-02 09:47:00.905: epoch 6:	0.02247145  	0.09034393  	0.06153163  
2023-11-02 09:47:00.905: Find a better model.
2023-11-02 09:47:13.415: [iter 7 : loss : -0.5998 = 0.1994 + -0.7962 + 0.0014 + -0.0043, time: 12.491493]
2023-11-02 09:47:14.088: epoch 7:	0.02276789  	0.09114753  	0.06264348  
2023-11-02 09:47:14.088: Find a better model.
2023-11-02 09:47:26.823: [iter 8 : loss : -0.6905 = 0.1918 + -0.8792 + 0.0016 + -0.0047, time: 12.717102]
2023-11-02 09:47:27.504: epoch 8:	0.02308324  	0.09259783  	0.06350984  
2023-11-02 09:47:27.504: Find a better model.
2023-11-02 09:47:39.946: [iter 9 : loss : nan = nan + nan + nan + nan, time: 12.422669]
2023-11-02 09:47:40.581: epoch 9:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:47:53.141: [iter 10 : loss : nan = nan + nan + nan + nan, time: 12.540582]
2023-11-02 09:47:53.749: epoch 10:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:48:06.277: [iter 11 : loss : nan = nan + nan + nan + nan, time: 12.511734]
2023-11-02 09:48:06.909: epoch 11:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:48:19.430: [iter 12 : loss : nan = nan + nan + nan + nan, time: 12.502473]
2023-11-02 09:48:20.064: epoch 12:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:48:32.603: [iter 13 : loss : nan = nan + nan + nan + nan, time: 12.525538]
2023-11-02 09:48:33.243: epoch 13:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:48:45.813: [iter 14 : loss : nan = nan + nan + nan + nan, time: 12.553620]
2023-11-02 09:48:46.438: epoch 14:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:48:58.968: [iter 15 : loss : nan = nan + nan + nan + nan, time: 12.514643]
2023-11-02 09:48:59.579: epoch 15:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:49:12.204: [iter 16 : loss : nan = nan + nan + nan + nan, time: 12.610074]
2023-11-02 09:49:12.823: epoch 16:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:49:25.329: [iter 17 : loss : nan = nan + nan + nan + nan, time: 12.489697]
2023-11-02 09:49:25.959: epoch 17:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:49:38.393: [iter 18 : loss : nan = nan + nan + nan + nan, time: 12.417879]
2023-11-02 09:49:39.032: epoch 18:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:49:39.032: Early stopping is trigger at epoch: 18
2023-11-02 09:49:39.032: best_result@epoch 8:

2023-11-02 09:49:39.032: 		0.0231      	0.0926      	0.0635      

2023-11-02 16:14:42.915: my pid: 8802
2023-11-02 16:14:42.916: model: model.general_recommender.GNNEC
2023-11-02 16:14:42.916: Dataset statistics:
Name: amazon-book
The number of users: 7928
The number of items: 29346
The number of ratings: 460224
Average actions of users: 58.05
Average actions of items: 15.68
The sparsity of the dataset: 99.802186%

The number of training: 417417
The number of validation: 0
The number of testing: 42807
2023-11-02 16:14:42.916: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=amazon-book
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=amazon-book
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
mf_reg=1e-4
svd_q=5
2023-11-02 16:14:47.409: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-11-02 16:15:00.810: [iter 1 : loss : 0.8757 = 0.6173 + 0.2570 + 0.0000 + 0.0013, time: 13.400490]
2023-11-02 16:15:01.477: epoch 1:	0.01114410  	0.04298246  	0.02943794  
2023-11-02 16:15:01.477: Find a better model.
2023-11-02 16:15:14.492: [iter 2 : loss : 0.5668 = 0.4642 + 0.1020 + 0.0002 + 0.0005, time: 12.998387]
2023-11-02 16:15:15.283: epoch 2:	0.01364798  	0.05294946  	0.03723493  
2023-11-02 16:15:15.283: Find a better model.
2023-11-02 16:15:28.031: [iter 3 : loss : 0.4076 = 0.3881 + 0.0191 + 0.0003 + 0.0001, time: 12.727269]
2023-11-02 16:15:28.687: epoch 3:	0.01542023  	0.06063943  	0.04138337  
2023-11-02 16:15:28.687: Find a better model.
2023-11-02 16:15:41.235: [iter 4 : loss : 0.3032 = 0.3422 + -0.0393 + 0.0005 + -0.0002, time: 12.527361]
2023-11-02 16:15:41.855: epoch 4:	0.01660594  	0.06537705  	0.04413267  
2023-11-02 16:15:41.855: Find a better model.
2023-11-02 16:15:54.492: [iter 5 : loss : 0.2200 = 0.3085 + -0.0886 + 0.0006 + -0.0005, time: 12.617671]
2023-11-02 16:15:55.130: epoch 5:	0.01791781  	0.07074542  	0.04825328  
2023-11-02 16:15:55.130: Find a better model.
2023-11-02 16:16:07.639: [iter 6 : loss : 0.1534 = 0.2845 + -0.1311 + 0.0008 + -0.0007, time: 12.489610]
2023-11-02 16:16:08.310: epoch 6:	0.01881341  	0.07505681  	0.05068595  
2023-11-02 16:16:08.310: Find a better model.
2023-11-02 16:16:20.845: [iter 7 : loss : 0.0950 = 0.2650 + -0.1699 + 0.0009 + -0.0009, time: 12.514264]
2023-11-02 16:16:21.468: epoch 7:	0.01995496  	0.07913490  	0.05323064  
2023-11-02 16:16:21.469: Find a better model.
2023-11-02 16:16:34.239: [iter 8 : loss : 0.0459 = 0.2498 + -0.2038 + 0.0011 + -0.0011, time: 12.752613]
2023-11-02 16:16:34.904: epoch 8:	0.02050366  	0.08168952  	0.05578217  
2023-11-02 16:16:34.904: Find a better model.
2023-11-02 16:16:47.348: [iter 9 : loss : -0.0030 = 0.2345 + -0.2374 + 0.0012 + -0.0012, time: 12.427231]
2023-11-02 16:16:47.991: epoch 9:	0.02114697  	0.08401507  	0.05724974  
2023-11-02 16:16:47.991: Find a better model.
2023-11-02 16:17:00.554: [iter 10 : loss : -0.0453 = 0.2238 + -0.2691 + 0.0014 + -0.0014, time: 12.548598]
2023-11-02 16:17:01.192: epoch 10:	0.02175876  	0.08646675  	0.05875466  
2023-11-02 16:17:01.192: Find a better model.
2023-11-02 16:17:13.757: [iter 11 : loss : -0.0851 = 0.2132 + -0.2984 + 0.0015 + -0.0015, time: 12.549902]
2023-11-02 16:17:14.399: epoch 11:	0.02234531  	0.08892047  	0.06092906  
2023-11-02 16:17:14.399: Find a better model.
2023-11-02 16:17:26.954: [iter 12 : loss : -0.1215 = 0.2051 + -0.3266 + 0.0017 + -0.0017, time: 12.538063]
2023-11-02 16:17:27.631: epoch 12:	0.02293817  	0.09141542  	0.06213802  
2023-11-02 16:17:27.631: Find a better model.
2023-11-02 16:17:40.177: [iter 13 : loss : -0.1551 = 0.1977 + -0.3529 + 0.0019 + -0.0018, time: 12.531053]
2023-11-02 16:17:40.819: epoch 13:	0.02346165  	0.09332302  	0.06386677  
2023-11-02 16:17:40.820: Find a better model.
2023-11-02 16:17:53.491: [iter 14 : loss : -0.1885 = 0.1886 + -0.3772 + 0.0021 + -0.0019, time: 12.657392]
2023-11-02 16:17:54.152: epoch 14:	0.02391574  	0.09509996  	0.06539735  
2023-11-02 16:17:54.152: Find a better model.
2023-11-02 16:18:06.680: [iter 15 : loss : -0.2205 = 0.1814 + -0.4021 + 0.0022 + -0.0021, time: 12.513102]
2023-11-02 16:18:07.305: epoch 15:	0.02447076  	0.09737474  	0.06685506  
2023-11-02 16:18:07.305: Find a better model.
2023-11-02 16:18:19.832: [iter 16 : loss : -0.2479 = 0.1772 + -0.4254 + 0.0024 + -0.0022, time: 12.512473]
2023-11-02 16:18:20.499: epoch 16:	0.02490595  	0.09931407  	0.06788909  
2023-11-02 16:18:20.499: Find a better model.
2023-11-02 16:18:32.895: [iter 17 : loss : -0.2757 = 0.1728 + -0.4488 + 0.0026 + -0.0023, time: 12.382356]
2023-11-02 16:18:33.560: epoch 17:	0.02520238  	0.10077648  	0.06929493  
2023-11-02 16:18:33.560: Find a better model.
2023-11-02 16:18:45.917: [iter 18 : loss : -0.3008 = 0.1700 + -0.4711 + 0.0028 + -0.0024, time: 12.343745]
2023-11-02 16:18:46.558: epoch 18:	0.02580786  	0.10300453  	0.07030066  
2023-11-02 16:18:46.558: Find a better model.
2023-11-02 16:18:59.335: [iter 19 : loss : -0.3273 = 0.1650 + -0.4928 + 0.0030 + -0.0025, time: 12.759819]
2023-11-02 16:19:00.000: epoch 19:	0.02593400  	0.10337183  	0.07135921  
2023-11-02 16:19:00.000: Find a better model.
2023-11-02 16:19:12.545: [iter 20 : loss : -0.3503 = 0.1619 + -0.5128 + 0.0032 + -0.0026, time: 12.527924]
2023-11-02 16:19:13.152: epoch 20:	0.02611691  	0.10411231  	0.07194611  
2023-11-02 16:19:13.152: Find a better model.
2023-11-02 16:19:25.817: [iter 21 : loss : -0.3755 = 0.1575 + -0.5336 + 0.0034 + -0.0027, time: 12.650877]
2023-11-02 16:19:26.490: epoch 21:	0.02651425  	0.10598980  	0.07272334  
2023-11-02 16:19:26.490: Find a better model.
2023-11-02 16:19:39.438: [iter 22 : loss : -0.3973 = 0.1556 + -0.5537 + 0.0036 + -0.0028, time: 12.934212]
2023-11-02 16:19:40.122: epoch 22:	0.02664670  	0.10671103  	0.07313046  
2023-11-02 16:19:40.122: Find a better model.
2023-11-02 16:19:53.010: [iter 23 : loss : -0.4178 = 0.1537 + -0.5723 + 0.0038 + -0.0029, time: 12.863784]
2023-11-02 16:19:53.687: epoch 23:	0.02658993  	0.10613292  	0.07339566  
2023-11-02 16:20:06.468: [iter 24 : loss : -0.4367 = 0.1524 + -0.5900 + 0.0040 + -0.0030, time: 12.760069]
2023-11-02 16:20:07.147: epoch 24:	0.02707557  	0.10814775  	0.07461012  
2023-11-02 16:20:07.147: Find a better model.
2023-11-02 16:20:19.930: [iter 25 : loss : -0.4560 = 0.1506 + -0.6078 + 0.0042 + -0.0031, time: 12.766886]
2023-11-02 16:20:20.589: epoch 25:	0.02721432  	0.10885787  	0.07502393  
2023-11-02 16:20:20.589: Find a better model.
2023-11-02 16:20:33.348: [iter 26 : loss : -0.4781 = 0.1468 + -0.6262 + 0.0045 + -0.0032, time: 12.740771]
2023-11-02 16:20:34.019: epoch 26:	0.02722062  	0.10887577  	0.07545073  
2023-11-02 16:20:34.019: Find a better model.
2023-11-02 16:20:46.655: [iter 27 : loss : -0.4945 = 0.1472 + -0.6431 + 0.0047 + -0.0033, time: 12.619700]
2023-11-02 16:20:47.315: epoch 27:	0.02750443  	0.10993177  	0.07621489  
2023-11-02 16:20:47.315: Find a better model.
2023-11-02 16:21:00.008: [iter 28 : loss : -0.5139 = 0.1452 + -0.6607 + 0.0049 + -0.0034, time: 12.670261]
2023-11-02 16:21:00.691: epoch 28:	0.02748551  	0.11047524  	0.07638264  
2023-11-02 16:21:00.691: Find a better model.
2023-11-02 16:21:13.371: [iter 29 : loss : -0.5323 = 0.1437 + -0.6776 + 0.0051 + -0.0035, time: 12.659493]
2023-11-02 16:21:13.988: epoch 29:	0.02783239  	0.11159340  	0.07727350  
2023-11-02 16:21:13.988: Find a better model.
2023-11-02 16:21:26.664: [iter 30 : loss : -0.5468 = 0.1451 + -0.6937 + 0.0053 + -0.0036, time: 12.655959]
2023-11-02 16:21:27.323: epoch 30:	0.02804682  	0.11240673  	0.07765404  
2023-11-02 16:21:27.323: Find a better model.
2023-11-02 16:21:39.999: [iter 31 : loss : -0.5644 = 0.1427 + -0.7090 + 0.0056 + -0.0036, time: 12.660872]
2023-11-02 16:21:40.670: epoch 31:	0.02816666  	0.11278605  	0.07815914  
2023-11-02 16:21:40.670: Find a better model.
2023-11-02 16:21:53.374: [iter 32 : loss : -0.5777 = 0.1448 + -0.7245 + 0.0058 + -0.0037, time: 12.684700]
2023-11-02 16:21:54.040: epoch 32:	0.02842524  	0.11388710  	0.07877602  
2023-11-02 16:21:54.040: Find a better model.
2023-11-02 16:22:06.786: [iter 33 : loss : -0.5954 = 0.1425 + -0.7401 + 0.0060 + -0.0038, time: 12.728975]
2023-11-02 16:22:07.461: epoch 33:	0.02848200  	0.11416126  	0.07917948  
2023-11-02 16:22:07.461: Find a better model.
2023-11-02 16:22:20.160: [iter 34 : loss : -0.6085 = 0.1443 + -0.7552 + 0.0063 + -0.0039, time: 12.680124]
2023-11-02 16:22:20.803: epoch 34:	0.02874058  	0.11508480  	0.07968666  
2023-11-02 16:22:20.803: Find a better model.
2023-11-02 16:22:33.445: [iter 35 : loss : -0.6244 = 0.1427 + -0.7696 + 0.0065 + -0.0040, time: 12.620245]
2023-11-02 16:22:34.121: epoch 35:	0.02874690  	0.11520022  	0.07969216  
2023-11-02 16:22:34.121: Find a better model.
2023-11-02 16:22:46.729: [iter 36 : loss : -0.6407 = 0.1412 + -0.7845 + 0.0067 + -0.0040, time: 12.590363]
2023-11-02 16:22:47.425: epoch 36:	0.02895504  	0.11612652  	0.08027095  
2023-11-02 16:22:47.425: Find a better model.
2023-11-02 16:23:00.245: [iter 37 : loss : -0.6537 = 0.1422 + -0.7988 + 0.0070 + -0.0041, time: 12.797220]
2023-11-02 16:23:00.871: epoch 37:	0.02899918  	0.11618847  	0.08088845  
2023-11-02 16:23:00.871: Find a better model.
2023-11-02 16:23:13.674: [iter 38 : loss : -0.6658 = 0.1439 + -0.8128 + 0.0072 + -0.0042, time: 12.784374]
2023-11-02 16:23:14.355: epoch 38:	0.02910009  	0.11660886  	0.08113863  
2023-11-02 16:23:14.355: Find a better model.
2023-11-02 16:23:27.252: [iter 39 : loss : -0.6833 = 0.1402 + -0.8267 + 0.0074 + -0.0042, time: 12.878915]
2023-11-02 16:23:27.925: epoch 39:	0.02927669  	0.11744219  	0.08152015  
2023-11-02 16:23:27.925: Find a better model.
2023-11-02 16:23:40.583: [iter 40 : loss : -0.6945 = 0.1433 + -0.8411 + 0.0077 + -0.0043, time: 12.640094]
2023-11-02 16:23:41.272: epoch 40:	0.02935867  	0.11790377  	0.08183293  
2023-11-02 16:23:41.273: Find a better model.
2023-11-02 16:23:54.064: [iter 41 : loss : -0.7084 = 0.1423 + -0.8543 + 0.0079 + -0.0044, time: 12.772557]
2023-11-02 16:23:54.735: epoch 41:	0.02952896  	0.11856540  	0.08221302  
2023-11-02 16:23:54.735: Find a better model.
2023-11-02 16:24:07.624: [iter 42 : loss : -0.7221 = 0.1418 + -0.8676 + 0.0082 + -0.0045, time: 12.869898]
2023-11-02 16:24:08.287: epoch 42:	0.02965510  	0.11904576  	0.08245917  
2023-11-02 16:24:08.287: Find a better model.
2023-11-02 16:24:20.964: [iter 43 : loss : -0.7329 = 0.1437 + -0.8805 + 0.0084 + -0.0045, time: 12.660459]
2023-11-02 16:24:21.632: epoch 43:	0.02982537  	0.11945243  	0.08250864  
2023-11-02 16:24:21.632: Find a better model.
2023-11-02 16:24:34.319: [iter 44 : loss : -0.7447 = 0.1449 + -0.8937 + 0.0087 + -0.0046, time: 12.671589]
2023-11-02 16:24:35.004: epoch 44:	0.02986953  	0.11989399  	0.08280310  
2023-11-02 16:24:35.004: Find a better model.
2023-11-02 16:24:47.911: [iter 45 : loss : -0.7584 = 0.1434 + -0.9061 + 0.0089 + -0.0047, time: 12.886100]
2023-11-02 16:24:48.563: epoch 45:	0.02994521  	0.12033565  	0.08314230  
2023-11-02 16:24:48.563: Find a better model.
2023-11-02 16:25:01.098: [iter 46 : loss : -0.7698 = 0.1453 + -0.9195 + 0.0092 + -0.0047, time: 12.516863]
2023-11-02 16:25:01.736: epoch 46:	0.02993260  	0.12036277  	0.08331745  
2023-11-02 16:25:01.736: Find a better model.
2023-11-02 16:25:14.389: [iter 47 : loss : -0.7803 = 0.1467 + -0.9316 + 0.0094 + -0.0048, time: 12.634116]
2023-11-02 16:25:15.035: epoch 47:	0.03005872  	0.12075114  	0.08361440  
2023-11-02 16:25:15.035: Find a better model.
2023-11-02 16:25:27.825: [iter 48 : loss : -0.7922 = 0.1468 + -0.9439 + 0.0097 + -0.0048, time: 12.773144]
2023-11-02 16:25:28.471: epoch 48:	0.02995782  	0.12036500  	0.08376342  
2023-11-02 16:25:41.301: [iter 49 : loss : -0.8072 = 0.1433 + -0.9555 + 0.0099 + -0.0049, time: 12.814698]
2023-11-02 16:25:41.928: epoch 49:	0.03014072  	0.12120105  	0.08409677  
2023-11-02 16:25:41.928: Find a better model.
2023-11-02 16:25:54.665: [iter 50 : loss : -0.8196 = 0.1446 + -0.9694 + 0.0102 + -0.0050, time: 12.717519]
2023-11-02 16:25:55.332: epoch 50:	0.03024163  	0.12170420  	0.08459386  
2023-11-02 16:25:55.332: Find a better model.
2023-11-02 16:26:08.085: [iter 51 : loss : -0.8255 = 0.1497 + -0.9805 + 0.0104 + -0.0050, time: 12.734961]
2023-11-02 16:26:08.696: epoch 51:	0.03030470  	0.12189915  	0.08466289  
2023-11-02 16:26:08.696: Find a better model.
2023-11-02 16:26:21.538: [iter 52 : loss : -0.8371 = 0.1488 + -0.9916 + 0.0107 + -0.0051, time: 12.824952]
2023-11-02 16:26:22.179: epoch 52:	0.03030470  	0.12196074  	0.08486651  
2023-11-02 16:26:22.179: Find a better model.
2023-11-02 16:26:34.872: [iter 53 : loss : -0.8489 = 0.1486 + -1.0033 + 0.0109 + -0.0052, time: 12.676601]
2023-11-02 16:26:35.568: epoch 53:	0.03036146  	0.12196916  	0.08490427  
2023-11-02 16:26:35.569: Find a better model.
2023-11-02 16:26:48.213: [iter 54 : loss : -0.8612 = 0.1488 + -1.0159 + 0.0112 + -0.0052, time: 12.620596]
2023-11-02 16:26:48.881: epoch 54:	0.03042454  	0.12228735  	0.08497384  
2023-11-02 16:26:48.881: Find a better model.
2023-11-02 16:27:01.510: [iter 55 : loss : -0.8719 = 0.1486 + -1.0267 + 0.0115 + -0.0053, time: 12.610620]
2023-11-02 16:27:02.166: epoch 55:	0.03056959  	0.12274668  	0.08494689  
2023-11-02 16:27:02.166: Find a better model.
2023-11-02 16:27:14.944: [iter 56 : loss : -0.8802 = 0.1512 + -1.0378 + 0.0117 + -0.0053, time: 12.758251]
2023-11-02 16:27:15.613: epoch 56:	0.03060744  	0.12308088  	0.08520772  
2023-11-02 16:27:15.613: Find a better model.
2023-11-02 16:27:28.075: [iter 57 : loss : -0.8921 = 0.1509 + -1.0496 + 0.0120 + -0.0054, time: 12.436894]
2023-11-02 16:27:28.744: epoch 57:	0.03062636  	0.12327939  	0.08537017  
2023-11-02 16:27:28.744: Find a better model.
2023-11-02 16:27:41.676: [iter 58 : loss : -0.9044 = 0.1504 + -1.0616 + 0.0122 + -0.0054, time: 12.914226]
2023-11-02 16:27:42.355: epoch 58:	0.03063267  	0.12311085  	0.08514359  
2023-11-02 16:27:55.243: [iter 59 : loss : -0.9121 = 0.1529 + -1.0720 + 0.0125 + -0.0055, time: 12.868436]
2023-11-02 16:27:55.914: epoch 59:	0.03067050  	0.12333239  	0.08533435  
2023-11-02 16:27:55.914: Find a better model.
2023-11-02 16:28:08.670: [iter 60 : loss : -0.9196 = 0.1560 + -1.0829 + 0.0128 + -0.0056, time: 12.735368]
2023-11-02 16:28:09.288: epoch 60:	0.03079664  	0.12381222  	0.08596427  
2023-11-02 16:28:09.288: Find a better model.
2023-11-02 16:28:21.795: [iter 61 : loss : -0.9331 = 0.1541 + -1.0946 + 0.0130 + -0.0056, time: 12.488790]
2023-11-02 16:28:22.486: epoch 61:	0.03087233  	0.12422584  	0.08588122  
2023-11-02 16:28:22.486: Find a better model.
2023-11-02 16:28:35.210: [iter 62 : loss : -0.9428 = 0.1544 + -1.1049 + 0.0133 + -0.0057, time: 12.705143]
2023-11-02 16:28:35.889: epoch 62:	0.03082187  	0.12418600  	0.08599740  
2023-11-02 16:28:48.467: [iter 63 : loss : -0.9508 = 0.1572 + -1.1159 + 0.0136 + -0.0057, time: 12.558903]
2023-11-02 16:28:49.138: epoch 63:	0.03095432  	0.12439593  	0.08618329  
2023-11-02 16:28:49.138: Find a better model.
2023-11-02 16:29:01.934: [iter 64 : loss : -0.9639 = 0.1537 + -1.1257 + 0.0138 + -0.0058, time: 12.774640]
2023-11-02 16:29:02.607: epoch 64:	0.03098585  	0.12451022  	0.08620545  
2023-11-02 16:29:02.607: Find a better model.
2023-11-02 16:29:15.420: [iter 65 : loss : -0.9738 = 0.1543 + -1.1364 + 0.0141 + -0.0058, time: 12.797311]
2023-11-02 16:29:16.092: epoch 65:	0.03099847  	0.12448691  	0.08644870  
2023-11-02 16:29:28.679: [iter 66 : loss : -0.9815 = 0.1569 + -1.1470 + 0.0144 + -0.0059, time: 12.569600]
2023-11-02 16:29:29.336: epoch 66:	0.03099846  	0.12452892  	0.08644097  
2023-11-02 16:29:29.337: Find a better model.
2023-11-02 16:29:42.187: [iter 67 : loss : -0.9890 = 0.1591 + -1.1567 + 0.0146 + -0.0059, time: 12.823813]
2023-11-02 16:29:42.861: epoch 67:	0.03097325  	0.12471649  	0.08650137  
2023-11-02 16:29:42.861: Find a better model.
2023-11-02 16:29:55.783: [iter 68 : loss : -0.9979 = 0.1607 + -1.1675 + 0.0149 + -0.0060, time: 12.903587]
2023-11-02 16:29:56.459: epoch 68:	0.03104261  	0.12480748  	0.08674160  
2023-11-02 16:29:56.459: Find a better model.
2023-11-02 16:30:09.069: [iter 69 : loss : -1.0071 = 0.1608 + -1.1770 + 0.0152 + -0.0060, time: 12.593452]
2023-11-02 16:30:09.743: epoch 69:	0.03103000  	0.12480833  	0.08666230  
2023-11-02 16:30:09.744: Find a better model.
2023-11-02 16:30:22.449: [iter 70 : loss : -1.0123 = 0.1662 + -1.1879 + 0.0155 + -0.0061, time: 12.687847]
2023-11-02 16:30:23.080: epoch 70:	0.03105524  	0.12480672  	0.08691036  
2023-11-02 16:30:35.840: [iter 71 : loss : -1.0249 = 0.1629 + -1.1974 + 0.0157 + -0.0061, time: 12.741059]
2023-11-02 16:30:36.510: epoch 71:	0.03103001  	0.12491724  	0.08691665  
2023-11-02 16:30:36.510: Find a better model.
2023-11-02 16:30:49.131: [iter 72 : loss : -1.0346 = 0.1632 + -1.2076 + 0.0160 + -0.0062, time: 12.601237]
2023-11-02 16:30:49.822: epoch 72:	0.03096693  	0.12449043  	0.08684691  
2023-11-02 16:31:02.409: [iter 73 : loss : -1.0435 = 0.1632 + -1.2168 + 0.0163 + -0.0062, time: 12.564087]
2023-11-02 16:31:03.051: epoch 73:	0.03105522  	0.12486964  	0.08703055  
2023-11-02 16:31:15.804: [iter 74 : loss : -1.0521 = 0.1639 + -1.2263 + 0.0165 + -0.0063, time: 12.735215]
2023-11-02 16:31:16.525: epoch 74:	0.03112460  	0.12515570  	0.08720546  
2023-11-02 16:31:16.525: Find a better model.
2023-11-02 16:31:29.003: [iter 75 : loss : -1.0646 = 0.1620 + -1.2371 + 0.0168 + -0.0063, time: 12.453956]
2023-11-02 16:31:29.664: epoch 75:	0.03122552  	0.12563717  	0.08754518  
2023-11-02 16:31:29.665: Find a better model.
2023-11-02 16:31:42.237: [iter 76 : loss : -1.0649 = 0.1707 + -1.2463 + 0.0171 + -0.0064, time: 12.557013]
2023-11-02 16:31:42.905: epoch 76:	0.03121290  	0.12568668  	0.08774082  
2023-11-02 16:31:42.905: Find a better model.
2023-11-02 16:31:55.438: [iter 77 : loss : nan = nan + nan + nan + nan, time: 12.515554]
2023-11-02 16:31:56.062: epoch 77:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:32:08.677: [iter 78 : loss : nan = nan + nan + nan + nan, time: 12.594836]
2023-11-02 16:32:09.231: epoch 78:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:32:21.608: [iter 79 : loss : nan = nan + nan + nan + nan, time: 12.357803]
2023-11-02 16:32:22.257: epoch 79:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:32:34.825: [iter 80 : loss : nan = nan + nan + nan + nan, time: 12.547376]
2023-11-02 16:32:35.470: epoch 80:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:32:47.879: [iter 81 : loss : nan = nan + nan + nan + nan, time: 12.389240]
2023-11-02 16:32:48.514: epoch 81:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:33:00.897: [iter 82 : loss : nan = nan + nan + nan + nan, time: 12.363009]
2023-11-02 16:33:01.548: epoch 82:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:33:14.114: [iter 83 : loss : nan = nan + nan + nan + nan, time: 12.546086]
2023-11-02 16:33:14.727: epoch 83:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:33:27.292: [iter 84 : loss : nan = nan + nan + nan + nan, time: 12.543079]
2023-11-02 16:33:27.922: epoch 84:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:33:40.337: [iter 85 : loss : nan = nan + nan + nan + nan, time: 12.395503]
2023-11-02 16:33:40.913: epoch 85:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:33:53.523: [iter 86 : loss : nan = nan + nan + nan + nan, time: 12.590077]
2023-11-02 16:33:54.074: epoch 86:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 16:33:54.074: Early stopping is trigger at epoch: 86
2023-11-02 16:33:54.074: best_result@epoch 76:

2023-11-02 16:33:54.075: 		0.0312      	0.1257      	0.0877      

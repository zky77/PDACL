2023-11-02 10:16:59.626: my pid: 13488
2023-11-02 10:16:59.626: model: model.general_recommender.GNNEC
2023-11-02 10:16:59.626: Dataset statistics:
Name: amazon-book
The number of users: 7928
The number of items: 29346
The number of ratings: 460224
Average actions of users: 58.05
Average actions of items: 15.68
The sparsity of the dataset: 99.802186%

The number of training: 417417
The number of validation: 0
The number of testing: 42807
2023-11-02 10:16:59.626: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=amazon-book
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=1
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=amazon-book
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=1
mf_reg=1e-4
svd_q=5
2023-11-02 10:17:04.168: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-11-02 10:17:17.406: [iter 1 : loss : 0.9411 = 0.5887 + 0.3506 + 0.0001 + 0.0018, time: 13.237309]
2023-11-02 10:17:18.064: epoch 1:	0.00966196  	0.03647967  	0.02415226  
2023-11-02 10:17:18.064: Find a better model.
2023-11-02 10:17:30.349: [iter 2 : loss : 0.7186 = 0.4117 + 0.3052 + 0.0002 + 0.0015, time: 12.266914]
2023-11-02 10:17:30.999: epoch 2:	0.01046294  	0.03997861  	0.02672457  
2023-11-02 10:17:30.999: Find a better model.
2023-11-02 10:17:43.180: [iter 3 : loss : 0.6378 = 0.3497 + 0.2863 + 0.0003 + 0.0014, time: 12.166373]
2023-11-02 10:17:43.839: epoch 3:	0.01089812  	0.04168788  	0.02827888  
2023-11-02 10:17:43.839: Find a better model.
2023-11-02 10:17:56.113: [iter 4 : loss : 0.5888 = 0.3128 + 0.2742 + 0.0004 + 0.0014, time: 12.255937]
2023-11-02 10:17:56.776: epoch 4:	0.01136484  	0.04382002  	0.02962665  
2023-11-02 10:17:56.776: Find a better model.
2023-11-02 10:18:09.085: [iter 5 : loss : 0.5515 = 0.2848 + 0.2649 + 0.0005 + 0.0013, time: 12.293442]
2023-11-02 10:18:09.733: epoch 5:	0.01201447  	0.04638652  	0.03135425  
2023-11-02 10:18:09.733: Find a better model.
2023-11-02 10:18:21.693: [iter 6 : loss : 0.5242 = 0.2649 + 0.2574 + 0.0006 + 0.0013, time: 11.948267]
2023-11-02 10:18:22.318: epoch 6:	0.01250010  	0.04799489  	0.03255877  
2023-11-02 10:18:22.318: Find a better model.
2023-11-02 10:18:34.576: [iter 7 : loss : 0.5014 = 0.2487 + 0.2507 + 0.0007 + 0.0013, time: 12.243649]
2023-11-02 10:18:35.172: epoch 7:	0.01293528  	0.04986967  	0.03416892  
2023-11-02 10:18:35.172: Find a better model.
2023-11-02 10:18:47.604: [iter 8 : loss : 0.4827 = 0.2356 + 0.2450 + 0.0008 + 0.0012, time: 12.416949]
2023-11-02 10:18:48.269: epoch 8:	0.01341462  	0.05188536  	0.03555161  
2023-11-02 10:18:48.269: Find a better model.
2023-11-02 10:19:00.475: [iter 9 : loss : 0.4645 = 0.2226 + 0.2398 + 0.0009 + 0.0012, time: 12.193284]
2023-11-02 10:19:01.137: epoch 9:	0.01359752  	0.05249491  	0.03631933  
2023-11-02 10:19:01.137: Find a better model.
2023-11-02 10:19:13.618: [iter 10 : loss : 0.4502 = 0.2132 + 0.2349 + 0.0009 + 0.0012, time: 12.460154]
2023-11-02 10:19:14.280: epoch 10:	0.01400747  	0.05420446  	0.03756462  
2023-11-02 10:19:14.280: Find a better model.
2023-11-02 10:19:26.732: [iter 11 : loss : 0.4367 = 0.2042 + 0.2304 + 0.0010 + 0.0012, time: 12.436708]
2023-11-02 10:19:27.400: epoch 11:	0.01433543  	0.05528244  	0.03832515  
2023-11-02 10:19:27.401: Find a better model.
2023-11-02 10:19:39.758: [iter 12 : loss : 0.4245 = 0.1961 + 0.2262 + 0.0011 + 0.0011, time: 12.342742]
2023-11-02 10:19:40.407: epoch 12:	0.01465708  	0.05652406  	0.03895221  
2023-11-02 10:19:40.408: Find a better model.
2023-11-02 10:19:52.655: [iter 13 : loss : 0.4146 = 0.1899 + 0.2223 + 0.0012 + 0.0011, time: 12.233361]
2023-11-02 10:19:53.291: epoch 13:	0.01494720  	0.05777459  	0.03973475  
2023-11-02 10:19:53.292: Find a better model.
2023-11-02 10:20:05.489: [iter 14 : loss : 0.4036 = 0.1827 + 0.2185 + 0.0013 + 0.0011, time: 12.182132]
2023-11-02 10:20:06.138: epoch 14:	0.01527516  	0.05935439  	0.04085783  
2023-11-02 10:20:06.139: Find a better model.
2023-11-02 10:20:18.377: [iter 15 : loss : 0.3921 = 0.1749 + 0.2148 + 0.0013 + 0.0011, time: 12.222890]
2023-11-02 10:20:19.018: epoch 15:	0.01554636  	0.06054477  	0.04166575  
2023-11-02 10:20:19.018: Find a better model.
2023-11-02 10:20:31.494: [iter 16 : loss : 0.3842 = 0.1705 + 0.2112 + 0.0014 + 0.0011, time: 12.461110]
2023-11-02 10:20:32.123: epoch 16:	0.01584280  	0.06176882  	0.04236972  
2023-11-02 10:20:32.123: Find a better model.
2023-11-02 10:20:44.456: [iter 17 : loss : 0.3761 = 0.1659 + 0.2077 + 0.0015 + 0.0010, time: 12.320004]
2023-11-02 10:20:45.086: epoch 17:	0.01610769  	0.06308695  	0.04337208  
2023-11-02 10:20:45.086: Find a better model.
2023-11-02 10:20:57.391: [iter 18 : loss : 0.3688 = 0.1618 + 0.2044 + 0.0016 + 0.0010, time: 12.286980]
2023-11-02 10:20:58.025: epoch 18:	0.01653657  	0.06479271  	0.04439506  
2023-11-02 10:20:58.026: Find a better model.
2023-11-02 10:21:10.567: [iter 19 : loss : 0.3605 = 0.1566 + 0.2012 + 0.0017 + 0.0010, time: 12.524135]
2023-11-02 10:21:11.194: epoch 19:	0.01687084  	0.06637120  	0.04531491  
2023-11-02 10:21:11.195: Find a better model.
2023-11-02 10:21:23.795: [iter 20 : loss : 0.3529 = 0.1521 + 0.1980 + 0.0017 + 0.0010, time: 12.587147]
2023-11-02 10:21:24.459: epoch 20:	0.01719250  	0.06792405  	0.04630375  
2023-11-02 10:21:24.459: Find a better model.
2023-11-02 10:21:36.945: [iter 21 : loss : 0.3459 = 0.1482 + 0.1949 + 0.0018 + 0.0010, time: 12.469850]
2023-11-02 10:21:37.616: epoch 21:	0.01743217  	0.06870190  	0.04682877  
2023-11-02 10:21:37.616: Find a better model.
2023-11-02 10:21:50.268: [iter 22 : loss : 0.3395 = 0.1449 + 0.1917 + 0.0019 + 0.0010, time: 12.637607]
2023-11-02 10:21:50.946: epoch 22:	0.01765922  	0.06973389  	0.04764574  
2023-11-02 10:21:50.946: Find a better model.
2023-11-02 10:22:03.381: [iter 23 : loss : 0.3338 = 0.1419 + 0.1890 + 0.0020 + 0.0009, time: 12.411139]
2023-11-02 10:22:04.027: epoch 23:	0.01788628  	0.07045444  	0.04835634  
2023-11-02 10:22:04.028: Find a better model.
2023-11-02 10:22:16.418: [iter 24 : loss : 0.3283 = 0.1392 + 0.1861 + 0.0021 + 0.0009, time: 12.373905]
2023-11-02 10:22:17.089: epoch 24:	0.01814487  	0.07166805  	0.04921985  
2023-11-02 10:22:17.089: Find a better model.
2023-11-02 10:22:29.614: [iter 25 : loss : 0.3213 = 0.1349 + 0.1833 + 0.0021 + 0.0009, time: 12.507253]
2023-11-02 10:22:30.286: epoch 25:	0.01842869  	0.07294645  	0.05008707  
2023-11-02 10:22:30.287: Find a better model.
2023-11-02 10:22:42.740: [iter 26 : loss : 0.3151 = 0.1316 + 0.1804 + 0.0022 + 0.0009, time: 12.438550]
2023-11-02 10:22:43.387: epoch 26:	0.01878187  	0.07446516  	0.05085822  
2023-11-02 10:22:43.387: Find a better model.
2023-11-02 10:22:55.691: [iter 27 : loss : 0.3106 = 0.1297 + 0.1777 + 0.0023 + 0.0009, time: 12.291732]
2023-11-02 10:22:56.339: epoch 27:	0.01888909  	0.07478333  	0.05124120  
2023-11-02 10:22:56.339: Find a better model.
2023-11-02 10:23:08.683: [iter 28 : loss : 0.3047 = 0.1266 + 0.1748 + 0.0024 + 0.0009, time: 12.329623]
2023-11-02 10:23:09.332: epoch 28:	0.01913506  	0.07591177  	0.05183566  
2023-11-02 10:23:09.333: Find a better model.
2023-11-02 10:23:21.643: [iter 29 : loss : 0.2998 = 0.1244 + 0.1721 + 0.0025 + 0.0009, time: 12.297480]
2023-11-02 10:23:22.302: epoch 29:	0.01940626  	0.07705936  	0.05259159  
2023-11-02 10:23:22.302: Find a better model.
2023-11-02 10:23:34.681: [iter 30 : loss : 0.2960 = 0.1232 + 0.1695 + 0.0026 + 0.0008, time: 12.362651]
2023-11-02 10:23:35.315: epoch 30:	0.01949456  	0.07747661  	0.05286939  
2023-11-02 10:23:35.315: Find a better model.
2023-11-02 10:23:47.736: [iter 31 : loss : 0.2899 = 0.1194 + 0.1670 + 0.0026 + 0.0008, time: 12.403544]
2023-11-02 10:23:48.377: epoch 31:	0.01976576  	0.07849512  	0.05353088  
2023-11-02 10:23:48.377: Find a better model.
2023-11-02 10:24:00.820: [iter 32 : loss : 0.2876 = 0.1197 + 0.1643 + 0.0027 + 0.0008, time: 12.428738]
2023-11-02 10:24:01.455: epoch 32:	0.01994867  	0.07923669  	0.05407830  
2023-11-02 10:24:01.456: Find a better model.
2023-11-02 10:24:13.979: [iter 33 : loss : 0.2807 = 0.1153 + 0.1618 + 0.0028 + 0.0008, time: 12.509219]
2023-11-02 10:24:14.626: epoch 33:	0.02013157  	0.07982714  	0.05453359  
2023-11-02 10:24:14.626: Find a better model.
2023-11-02 10:24:27.188: [iter 34 : loss : 0.2785 = 0.1157 + 0.1592 + 0.0029 + 0.0008, time: 12.547698]
2023-11-02 10:24:27.858: epoch 34:	0.02030816  	0.08031038  	0.05501448  
2023-11-02 10:24:27.858: Find a better model.
2023-11-02 10:24:40.088: [iter 35 : loss : 0.2728 = 0.1122 + 0.1568 + 0.0030 + 0.0008, time: 12.217588]
2023-11-02 10:24:40.724: epoch 35:	0.02055413  	0.08153289  	0.05573449  
2023-11-02 10:24:40.724: Find a better model.
2023-11-02 10:24:52.968: [iter 36 : loss : 0.2690 = 0.1107 + 0.1545 + 0.0031 + 0.0008, time: 12.229793]
2023-11-02 10:24:53.612: epoch 36:	0.02074335  	0.08237105  	0.05628463  
2023-11-02 10:24:53.612: Find a better model.
2023-11-02 10:25:06.021: [iter 37 : loss : 0.2650 = 0.1090 + 0.1521 + 0.0032 + 0.0008, time: 12.394953]
2023-11-02 10:25:06.619: epoch 37:	0.02087578  	0.08296456  	0.05664534  
2023-11-02 10:25:06.619: Find a better model.
2023-11-02 10:25:18.853: [iter 38 : loss : 0.2618 = 0.1082 + 0.1497 + 0.0032 + 0.0007, time: 12.218718]
2023-11-02 10:25:19.520: epoch 38:	0.02103346  	0.08355477  	0.05706292  
2023-11-02 10:25:19.520: Find a better model.
2023-11-02 10:25:32.105: [iter 39 : loss : 0.2570 = 0.1057 + 0.1472 + 0.0033 + 0.0007, time: 12.568516]
2023-11-02 10:25:32.743: epoch 39:	0.02129206  	0.08490357  	0.05771245  
2023-11-02 10:25:32.744: Find a better model.
2023-11-02 10:25:45.379: [iter 40 : loss : 0.2545 = 0.1057 + 0.1447 + 0.0034 + 0.0007, time: 12.619391]
2023-11-02 10:25:46.049: epoch 40:	0.02136775  	0.08506469  	0.05799561  
2023-11-02 10:25:46.049: Find a better model.
2023-11-02 10:25:58.715: [iter 41 : loss : 0.2499 = 0.1033 + 0.1424 + 0.0035 + 0.0007, time: 12.653103]
2023-11-02 10:25:59.384: epoch 41:	0.02157588  	0.08594140  	0.05846700  
2023-11-02 10:25:59.384: Find a better model.
2023-11-02 10:26:12.027: [iter 42 : loss : 0.2466 = 0.1020 + 0.1403 + 0.0036 + 0.0007, time: 12.628403]
2023-11-02 10:26:12.641: epoch 42:	0.02164524  	0.08614980  	0.05862701  
2023-11-02 10:26:12.641: Find a better model.
2023-11-02 10:26:24.815: [iter 43 : loss : 0.2433 = 0.1012 + 0.1377 + 0.0037 + 0.0007, time: 12.155538]
2023-11-02 10:26:25.476: epoch 43:	0.02182184  	0.08682186  	0.05913802  
2023-11-02 10:26:25.476: Find a better model.
2023-11-02 10:26:37.596: [iter 44 : loss : 0.2402 = 0.1003 + 0.1355 + 0.0038 + 0.0007, time: 12.107325]
2023-11-02 10:26:38.263: epoch 44:	0.02195428  	0.08727455  	0.05945320  
2023-11-02 10:26:38.263: Find a better model.
2023-11-02 10:26:50.526: [iter 45 : loss : 0.2360 = 0.0982 + 0.1333 + 0.0039 + 0.0007, time: 12.249603]
2023-11-02 10:26:51.159: epoch 45:	0.02211826  	0.08783594  	0.05969781  
2023-11-02 10:26:51.159: Find a better model.
2023-11-02 10:27:03.835: [iter 46 : loss : 0.2332 = 0.0977 + 0.1309 + 0.0039 + 0.0006, time: 12.662789]
2023-11-02 10:27:04.447: epoch 46:	0.02228856  	0.08862724  	0.06020818  
2023-11-02 10:27:04.447: Find a better model.
2023-11-02 10:27:16.722: [iter 47 : loss : 0.2307 = 0.0973 + 0.1287 + 0.0040 + 0.0006, time: 12.254690]
2023-11-02 10:27:17.356: epoch 47:	0.02242731  	0.08922783  	0.06060994  
2023-11-02 10:27:17.356: Find a better model.
2023-11-02 10:27:30.004: [iter 48 : loss : 0.2269 = 0.0956 + 0.1266 + 0.0041 + 0.0006, time: 12.631902]
2023-11-02 10:27:30.637: epoch 48:	0.02259759  	0.08996215  	0.06097350  
2023-11-02 10:27:30.637: Find a better model.
2023-11-02 10:27:43.191: [iter 49 : loss : 0.2230 = 0.0937 + 0.1245 + 0.0042 + 0.0006, time: 12.541086]
2023-11-02 10:27:43.843: epoch 49:	0.02276788  	0.09062751  	0.06152609  
2023-11-02 10:27:43.843: Find a better model.
2023-11-02 10:27:56.401: [iter 50 : loss : 0.2194 = 0.0925 + 0.1220 + 0.0043 + 0.0006, time: 12.541728]
2023-11-02 10:27:57.073: epoch 50:	0.02281834  	0.09076200  	0.06169649  
2023-11-02 10:27:57.073: Find a better model.
2023-11-02 10:28:09.783: [iter 51 : loss : 0.2178 = 0.0929 + 0.1200 + 0.0044 + 0.0006, time: 12.692256]
2023-11-02 10:28:10.467: epoch 51:	0.02294448  	0.09110140  	0.06205647  
2023-11-02 10:28:10.467: Find a better model.
2023-11-02 10:28:22.977: [iter 52 : loss : 0.2144 = 0.0915 + 0.1178 + 0.0045 + 0.0006, time: 12.492004]
2023-11-02 10:28:23.635: epoch 52:	0.02308322  	0.09195619  	0.06261086  
2023-11-02 10:28:23.635: Find a better model.
2023-11-02 10:28:35.854: [iter 53 : loss : 0.2118 = 0.0910 + 0.1157 + 0.0046 + 0.0006, time: 12.201286]
2023-11-02 10:28:36.508: epoch 53:	0.02324091  	0.09247585  	0.06285897  
2023-11-02 10:28:36.508: Find a better model.
2023-11-02 10:28:48.895: [iter 54 : loss : 0.2086 = 0.0900 + 0.1134 + 0.0047 + 0.0006, time: 12.372065]
2023-11-02 10:28:49.537: epoch 54:	0.02341749  	0.09299740  	0.06332211  
2023-11-02 10:28:49.537: Find a better model.
2023-11-02 10:29:02.031: [iter 55 : loss : 0.2049 = 0.0882 + 0.1113 + 0.0048 + 0.0005, time: 12.476941]
2023-11-02 10:29:02.698: epoch 55:	0.02362561  	0.09397468  	0.06378800  
2023-11-02 10:29:02.698: Find a better model.
2023-11-02 10:29:15.246: [iter 56 : loss : 0.2028 = 0.0883 + 0.1092 + 0.0049 + 0.0005, time: 12.534161]
2023-11-02 10:29:15.901: epoch 56:	0.02373283  	0.09465602  	0.06421112  
2023-11-02 10:29:15.901: Find a better model.
2023-11-02 10:29:28.397: [iter 57 : loss : 0.2002 = 0.0877 + 0.1071 + 0.0050 + 0.0005, time: 12.476462]
2023-11-02 10:29:29.061: epoch 57:	0.02382113  	0.09491812  	0.06461718  
2023-11-02 10:29:29.061: Find a better model.
2023-11-02 10:29:41.510: [iter 58 : loss : 0.1958 = 0.0855 + 0.1047 + 0.0051 + 0.0005, time: 12.433504]
2023-11-02 10:29:42.191: epoch 58:	0.02389050  	0.09521550  	0.06477392  
2023-11-02 10:29:42.192: Find a better model.
2023-11-02 10:29:54.955: [iter 59 : loss : 0.1939 = 0.0856 + 0.1026 + 0.0051 + 0.0005, time: 12.748005]
2023-11-02 10:29:55.616: epoch 59:	0.02404187  	0.09592543  	0.06516007  
2023-11-02 10:29:55.616: Find a better model.
2023-11-02 10:30:08.334: [iter 60 : loss : 0.1929 = 0.0865 + 0.1006 + 0.0052 + 0.0005, time: 12.701580]
2023-11-02 10:30:09.045: epoch 60:	0.02416170  	0.09659299  	0.06555639  
2023-11-02 10:30:09.045: Find a better model.
2023-11-02 10:30:21.636: [iter 61 : loss : 0.1879 = 0.0837 + 0.0983 + 0.0053 + 0.0005, time: 12.569600]
2023-11-02 10:30:22.330: epoch 61:	0.02423740  	0.09653737  	0.06576996  
2023-11-02 10:30:34.922: [iter 62 : loss : 0.1855 = 0.0833 + 0.0963 + 0.0054 + 0.0005, time: 12.573466]
2023-11-02 10:30:35.582: epoch 62:	0.02446445  	0.09742554  	0.06624753  
2023-11-02 10:30:35.582: Find a better model.
2023-11-02 10:30:48.045: [iter 63 : loss : 0.1842 = 0.0840 + 0.0942 + 0.0055 + 0.0005, time: 12.449461]
2023-11-02 10:30:48.645: epoch 63:	0.02465996  	0.09834846  	0.06678822  
2023-11-02 10:30:48.645: Find a better model.
2023-11-02 10:31:01.040: [iter 64 : loss : 0.1801 = 0.0819 + 0.0921 + 0.0056 + 0.0004, time: 12.380717]
2023-11-02 10:31:01.688: epoch 64:	0.02479241  	0.09873063  	0.06713148  
2023-11-02 10:31:01.688: Find a better model.
2023-11-02 10:31:14.310: [iter 65 : loss : 0.1765 = 0.0803 + 0.0901 + 0.0057 + 0.0004, time: 12.602435]
2023-11-02 10:31:14.982: epoch 65:	0.02491225  	0.09928941  	0.06742924  
2023-11-02 10:31:14.982: Find a better model.
2023-11-02 10:31:27.478: [iter 66 : loss : 0.1744 = 0.0801 + 0.0880 + 0.0058 + 0.0004, time: 12.476597]
2023-11-02 10:31:28.169: epoch 66:	0.02500685  	0.09957382  	0.06782697  
2023-11-02 10:31:28.170: Find a better model.
2023-11-02 10:31:40.746: [iter 67 : loss : 0.1736 = 0.0813 + 0.0859 + 0.0059 + 0.0004, time: 12.557889]
2023-11-02 10:31:41.380: epoch 67:	0.02505100  	0.09991989  	0.06826992  
2023-11-02 10:31:41.380: Find a better model.
2023-11-02 10:31:53.942: [iter 68 : loss : 0.1715 = 0.0813 + 0.0837 + 0.0060 + 0.0004, time: 12.542497]
2023-11-02 10:31:54.588: epoch 68:	0.02530328  	0.10086867  	0.06881857  
2023-11-02 10:31:54.594: Find a better model.
2023-11-02 10:32:06.999: [iter 69 : loss : 0.1685 = 0.0799 + 0.0820 + 0.0061 + 0.0004, time: 12.387753]
2023-11-02 10:32:07.655: epoch 69:	0.02533482  	0.10095022  	0.06908746  
2023-11-02 10:32:07.656: Find a better model.
2023-11-02 10:32:20.055: [iter 70 : loss : 0.1671 = 0.0807 + 0.0798 + 0.0062 + 0.0004, time: 12.384506]
2023-11-02 10:32:20.727: epoch 70:	0.02555557  	0.10202034  	0.06975793  
2023-11-02 10:32:20.727: Find a better model.
2023-11-02 10:32:33.420: [iter 71 : loss : 0.1628 = 0.0783 + 0.0778 + 0.0063 + 0.0004, time: 12.674878]
2023-11-02 10:32:34.067: epoch 71:	0.02556188  	0.10228506  	0.07001787  
2023-11-02 10:32:34.067: Find a better model.
2023-11-02 10:32:46.676: [iter 72 : loss : 0.1613 = 0.0788 + 0.0757 + 0.0064 + 0.0004, time: 12.592948]
2023-11-02 10:32:47.341: epoch 72:	0.02570693  	0.10271087  	0.07016232  
2023-11-02 10:32:47.341: Find a better model.
2023-11-02 10:32:59.846: [iter 73 : loss : 0.1580 = 0.0772 + 0.0739 + 0.0065 + 0.0004, time: 12.486995]
2023-11-02 10:33:00.520: epoch 73:	0.02589614  	0.10344825  	0.07069355  
2023-11-02 10:33:00.520: Find a better model.
2023-11-02 10:33:13.226: [iter 74 : loss : 0.1558 = 0.0770 + 0.0719 + 0.0066 + 0.0003, time: 12.686943]
2023-11-02 10:33:13.884: epoch 74:	0.02599075  	0.10423506  	0.07102601  
2023-11-02 10:33:13.884: Find a better model.
2023-11-02 10:33:26.353: [iter 75 : loss : 0.1528 = 0.0760 + 0.0697 + 0.0068 + 0.0003, time: 12.452040]
2023-11-02 10:33:26.992: epoch 75:	0.02619258  	0.10471354  	0.07139714  
2023-11-02 10:33:26.998: Find a better model.
2023-11-02 10:33:39.487: [iter 76 : loss : 0.1534 = 0.0785 + 0.0676 + 0.0069 + 0.0003, time: 12.468622]
2023-11-02 10:33:40.161: epoch 76:	0.02623673  	0.10515225  	0.07174311  
2023-11-02 10:33:40.161: Find a better model.
2023-11-02 10:33:52.635: [iter 77 : loss : 0.1490 = 0.0759 + 0.0658 + 0.0070 + 0.0003, time: 12.457233]
2023-11-02 10:33:53.288: epoch 77:	0.02636918  	0.10599456  	0.07217366  
2023-11-02 10:33:53.288: Find a better model.
2023-11-02 10:34:05.894: [iter 78 : loss : 0.1462 = 0.0750 + 0.0639 + 0.0071 + 0.0003, time: 12.587063]
2023-11-02 10:34:06.545: epoch 78:	0.02647009  	0.10618877  	0.07231022  
2023-11-02 10:34:06.545: Find a better model.
2023-11-02 10:34:19.094: [iter 79 : loss : 0.1441 = 0.0749 + 0.0617 + 0.0072 + 0.0003, time: 12.531039]
2023-11-02 10:34:19.772: epoch 79:	0.02652685  	0.10660969  	0.07261332  
2023-11-02 10:34:19.772: Find a better model.
2023-11-02 10:34:32.491: [iter 80 : loss : 0.1417 = 0.0744 + 0.0598 + 0.0073 + 0.0003, time: 12.703451]
2023-11-02 10:34:33.155: epoch 80:	0.02660254  	0.10703108  	0.07285754  
2023-11-02 10:34:33.155: Find a better model.
2023-11-02 10:34:45.691: [iter 81 : loss : 0.1406 = 0.0752 + 0.0577 + 0.0074 + 0.0003, time: 12.521089]
2023-11-02 10:34:46.344: epoch 81:	0.02670976  	0.10743725  	0.07320818  
2023-11-02 10:34:46.345: Find a better model.
2023-11-02 10:34:58.874: [iter 82 : loss : 0.1387 = 0.0752 + 0.0558 + 0.0075 + 0.0003, time: 12.514281]
2023-11-02 10:34:59.556: epoch 82:	0.02675391  	0.10768507  	0.07347767  
2023-11-02 10:34:59.556: Find a better model.
2023-11-02 10:35:12.285: [iter 83 : loss : 0.1347 = 0.0728 + 0.0540 + 0.0076 + 0.0003, time: 12.710442]
2023-11-02 10:35:12.960: epoch 83:	0.02686743  	0.10821873  	0.07376700  
2023-11-02 10:35:12.960: Find a better model.
2023-11-02 10:35:25.646: [iter 84 : loss : 0.1322 = 0.0725 + 0.0518 + 0.0077 + 0.0002, time: 12.670404]
2023-11-02 10:35:26.311: epoch 84:	0.02698096  	0.10864551  	0.07417179  
2023-11-02 10:35:26.311: Find a better model.
2023-11-02 10:35:38.876: [iter 85 : loss : 0.1302 = 0.0722 + 0.0499 + 0.0078 + 0.0002, time: 12.549075]
2023-11-02 10:35:39.507: epoch 85:	0.02705033  	0.10902894  	0.07432505  
2023-11-02 10:35:39.507: Find a better model.
2023-11-02 10:35:52.198: [iter 86 : loss : 0.1291 = 0.0731 + 0.0478 + 0.0079 + 0.0002, time: 12.675741]
2023-11-02 10:35:52.877: epoch 86:	0.02718908  	0.10942172  	0.07465111  
2023-11-02 10:35:52.878: Find a better model.
2023-11-02 10:36:05.454: [iter 87 : loss : 0.1274 = 0.0734 + 0.0458 + 0.0080 + 0.0002, time: 12.555925]
2023-11-02 10:36:06.127: epoch 87:	0.02730261  	0.10996459  	0.07488132  
2023-11-02 10:36:06.127: Find a better model.
2023-11-02 10:36:18.859: [iter 88 : loss : 0.1254 = 0.0732 + 0.0439 + 0.0082 + 0.0002, time: 12.717778]
2023-11-02 10:36:19.511: epoch 88:	0.02729629  	0.10987578  	0.07500139  
2023-11-02 10:36:32.201: [iter 89 : loss : 0.1228 = 0.0722 + 0.0421 + 0.0083 + 0.0002, time: 12.673016]
2023-11-02 10:36:32.874: epoch 89:	0.02756120  	0.11091252  	0.07551076  
2023-11-02 10:36:32.874: Find a better model.
2023-11-02 10:36:45.426: [iter 90 : loss : 0.1207 = 0.0719 + 0.0402 + 0.0084 + 0.0002, time: 12.535946]
2023-11-02 10:36:46.109: epoch 90:	0.02752966  	0.11094293  	0.07558978  
2023-11-02 10:36:46.109: Find a better model.
2023-11-02 10:36:58.680: [iter 91 : loss : 0.1177 = 0.0708 + 0.0382 + 0.0085 + 0.0002, time: 12.554143]
2023-11-02 10:36:59.335: epoch 91:	0.02753597  	0.11081221  	0.07575624  
2023-11-02 10:37:11.845: [iter 92 : loss : 0.1172 = 0.0724 + 0.0360 + 0.0086 + 0.0002, time: 12.493138]
2023-11-02 10:37:12.532: epoch 92:	0.02760535  	0.11126054  	0.07588999  
2023-11-02 10:37:12.533: Find a better model.
2023-11-02 10:37:25.149: [iter 93 : loss : 0.1140 = 0.0706 + 0.0346 + 0.0087 + 0.0002, time: 12.599441]
2023-11-02 10:37:25.797: epoch 93:	0.02771257  	0.11166894  	0.07613003  
2023-11-02 10:37:25.797: Find a better model.
2023-11-02 10:37:38.519: [iter 94 : loss : 0.1128 = 0.0713 + 0.0326 + 0.0088 + 0.0001, time: 12.696962]
2023-11-02 10:37:39.168: epoch 94:	0.02783870  	0.11226127  	0.07642525  
2023-11-02 10:37:39.169: Find a better model.
2023-11-02 10:37:51.519: [iter 95 : loss : 0.1113 = 0.0716 + 0.0306 + 0.0089 + 0.0001, time: 12.333395]
2023-11-02 10:37:52.192: epoch 95:	0.02786393  	0.11240271  	0.07669574  
2023-11-02 10:37:52.192: Find a better model.
2023-11-02 10:38:04.711: [iter 96 : loss : 0.1090 = 0.0711 + 0.0288 + 0.0091 + 0.0001, time: 12.505602]
2023-11-02 10:38:05.376: epoch 96:	0.02790808  	0.11240081  	0.07672407  
2023-11-02 10:38:18.058: [iter 97 : loss : 0.1043 = 0.0681 + 0.0270 + 0.0092 + 0.0001, time: 12.664165]
2023-11-02 10:38:18.680: epoch 97:	0.02813513  	0.11345758  	0.07721243  
2023-11-02 10:38:18.681: Find a better model.
2023-11-02 10:38:31.093: [iter 98 : loss : 0.1046 = 0.0705 + 0.0247 + 0.0093 + 0.0001, time: 12.396879]
2023-11-02 10:38:31.753: epoch 98:	0.02816035  	0.11345971  	0.07729793  
2023-11-02 10:38:31.753: Find a better model.
2023-11-02 10:38:44.206: [iter 99 : loss : 0.1011 = 0.0686 + 0.0230 + 0.0094 + 0.0001, time: 12.437967]
2023-11-02 10:38:44.878: epoch 99:	0.02816666  	0.11342990  	0.07744617  
2023-11-02 10:38:57.430: [iter 100 : loss : 0.1003 = 0.0695 + 0.0212 + 0.0095 + 0.0001, time: 12.534919]
2023-11-02 10:38:58.073: epoch 100:	0.02831803  	0.11413058  	0.07784103  
2023-11-02 10:38:58.074: Find a better model.
2023-11-02 10:39:10.639: [iter 101 : loss : 0.1006 = 0.0717 + 0.0192 + 0.0096 + 0.0001, time: 12.550071]
2023-11-02 10:39:11.237: epoch 101:	0.02842524  	0.11459470  	0.07808822  
2023-11-02 10:39:11.237: Find a better model.
2023-11-02 10:39:23.853: [iter 102 : loss : 0.0989 = 0.0717 + 0.0174 + 0.0098 + 0.0001, time: 12.602056]
2023-11-02 10:39:24.476: epoch 102:	0.02857031  	0.11530512  	0.07843670  
2023-11-02 10:39:24.476: Find a better model.
2023-11-02 10:39:37.090: [iter 103 : loss : 0.0955 = 0.0700 + 0.0156 + 0.0099 + 0.0001, time: 12.596331]
2023-11-02 10:39:37.748: epoch 103:	0.02860815  	0.11536798  	0.07867482  
2023-11-02 10:39:37.748: Find a better model.
2023-11-02 10:39:50.034: [iter 104 : loss : 0.0928 = 0.0690 + 0.0138 + 0.0100 + 0.0000, time: 12.266047]
2023-11-02 10:39:50.703: epoch 104:	0.02869646  	0.11568905  	0.07893542  
2023-11-02 10:39:50.703: Find a better model.
2023-11-02 10:40:03.168: [iter 105 : loss : 0.0898 = 0.0676 + 0.0120 + 0.0101 + 0.0000, time: 12.445084]
2023-11-02 10:40:03.795: epoch 105:	0.02886675  	0.11633956  	0.07920471  
2023-11-02 10:40:03.796: Find a better model.
2023-11-02 10:40:16.459: [iter 106 : loss : 0.0907 = 0.0704 + 0.0101 + 0.0102 + 0.0000, time: 12.651573]
2023-11-02 10:40:17.140: epoch 106:	0.02874692  	0.11595020  	0.07909708  
2023-11-02 10:40:29.744: [iter 107 : loss : 0.0868 = 0.0681 + 0.0084 + 0.0103 + 0.0000, time: 12.587522]
2023-11-02 10:40:30.432: epoch 107:	0.02882891  	0.11641316  	0.07938307  
2023-11-02 10:40:30.432: Find a better model.
2023-11-02 10:40:43.038: [iter 108 : loss : 0.0867 = 0.0697 + 0.0065 + 0.0105 + 0.0000, time: 12.585556]
2023-11-02 10:40:43.677: epoch 108:	0.02897396  	0.11687790  	0.07971986  
2023-11-02 10:40:43.677: Find a better model.
2023-11-02 10:40:56.180: [iter 109 : loss : 0.0825 = 0.0673 + 0.0047 + 0.0106 + 0.0000, time: 12.487573]
2023-11-02 10:40:56.828: epoch 109:	0.02887305  	0.11668759  	0.07965986  
2023-11-02 10:41:09.438: [iter 110 : loss : 0.0823 = 0.0688 + 0.0029 + 0.0107 + -0.0000, time: 12.588202]
2023-11-02 10:41:10.082: epoch 110:	0.02897396  	0.11707995  	0.07995533  
2023-11-02 10:41:10.082: Find a better model.
2023-11-02 10:41:22.619: [iter 111 : loss : 0.0776 = 0.0660 + 0.0009 + 0.0108 + -0.0000, time: 12.520057]
2023-11-02 10:41:23.246: epoch 111:	0.02907487  	0.11752379  	0.08032029  
2023-11-02 10:41:23.247: Find a better model.
2023-11-02 10:41:35.782: [iter 112 : loss : 0.0793 = 0.0691 + -0.0007 + 0.0109 + -0.0000, time: 12.519719]
2023-11-02 10:41:36.453: epoch 112:	0.02918840  	0.11801487  	0.08061235  
2023-11-02 10:41:36.453: Find a better model.
2023-11-02 10:41:48.954: [iter 113 : loss : 0.0744 = 0.0656 + -0.0023 + 0.0111 + -0.0000, time: 12.480508]
2023-11-02 10:41:49.592: epoch 113:	0.02927040  	0.11833671  	0.08082519  
2023-11-02 10:41:49.592: Find a better model.
2023-11-02 10:42:02.036: [iter 114 : loss : 0.0737 = 0.0670 + -0.0045 + 0.0112 + -0.0000, time: 12.429368]
2023-11-02 10:42:02.708: epoch 114:	0.02935869  	0.11856590  	0.08082350  
2023-11-02 10:42:02.709: Find a better model.
2023-11-02 10:42:15.346: [iter 115 : loss : 0.0736 = 0.0686 + -0.0063 + 0.0113 + -0.0001, time: 12.623723]
2023-11-02 10:42:16.037: epoch 115:	0.02931454  	0.11831030  	0.08085860  
2023-11-02 10:42:28.737: [iter 116 : loss : 0.0712 = 0.0680 + -0.0081 + 0.0114 + -0.0001, time: 12.678686]
2023-11-02 10:42:29.392: epoch 116:	0.02927038  	0.11819816  	0.08099875  
2023-11-02 10:42:42.050: [iter 117 : loss : 0.0689 = 0.0671 + -0.0097 + 0.0115 + -0.0001, time: 12.639400]
2023-11-02 10:42:42.688: epoch 117:	0.02934607  	0.11838754  	0.08121753  
2023-11-02 10:42:55.164: [iter 118 : loss : 0.0661 = 0.0659 + -0.0114 + 0.0117 + -0.0001, time: 12.459903]
2023-11-02 10:42:55.808: epoch 118:	0.02939022  	0.11846753  	0.08130699  
2023-11-02 10:43:08.424: [iter 119 : loss : 0.0666 = 0.0681 + -0.0132 + 0.0118 + -0.0001, time: 12.593740]
2023-11-02 10:43:09.056: epoch 119:	0.02954159  	0.11911298  	0.08162140  
2023-11-02 10:43:09.056: Find a better model.
2023-11-02 10:43:21.697: [iter 120 : loss : 0.0638 = 0.0668 + -0.0148 + 0.0119 + -0.0001, time: 12.626383]
2023-11-02 10:43:22.349: epoch 120:	0.02951006  	0.11913113  	0.08165511  
2023-11-02 10:43:22.349: Find a better model.
2023-11-02 10:43:34.953: [iter 121 : loss : 0.0636 = 0.0685 + -0.0169 + 0.0120 + -0.0001, time: 12.586912]
2023-11-02 10:43:35.606: epoch 121:	0.02953529  	0.11937260  	0.08193979  
2023-11-02 10:43:35.606: Find a better model.
2023-11-02 10:43:48.201: [iter 122 : loss : 0.0609 = 0.0672 + -0.0184 + 0.0121 + -0.0001, time: 12.576499]
2023-11-02 10:43:48.847: epoch 122:	0.02946590  	0.11906987  	0.08187679  
2023-11-02 10:44:01.464: [iter 123 : loss : 0.0587 = 0.0668 + -0.0203 + 0.0123 + -0.0001, time: 12.599182]
2023-11-02 10:44:02.116: epoch 123:	0.02954790  	0.11959611  	0.08208451  
2023-11-02 10:44:02.117: Find a better model.
2023-11-02 10:44:14.548: [iter 124 : loss : 0.0568 = 0.0665 + -0.0219 + 0.0124 + -0.0001, time: 12.412626]
2023-11-02 10:44:15.222: epoch 124:	0.02968035  	0.12012435  	0.08230009  
2023-11-02 10:44:15.222: Find a better model.
2023-11-02 10:44:27.716: [iter 125 : loss : 0.0574 = 0.0687 + -0.0237 + 0.0125 + -0.0001, time: 12.478723]
2023-11-02 10:44:28.360: epoch 125:	0.02962359  	0.11979455  	0.08234789  
2023-11-02 10:44:41.025: [iter 126 : loss : 0.0537 = 0.0666 + -0.0253 + 0.0126 + -0.0001, time: 12.649165]
2023-11-02 10:44:41.695: epoch 126:	0.02974973  	0.12043338  	0.08258215  
2023-11-02 10:44:41.695: Find a better model.
2023-11-02 10:44:54.286: [iter 127 : loss : 0.0508 = 0.0653 + -0.0271 + 0.0128 + -0.0002, time: 12.575904]
2023-11-02 10:44:54.944: epoch 127:	0.02981279  	0.12056361  	0.08273482  
2023-11-02 10:44:54.944: Find a better model.
2023-11-02 10:45:07.475: [iter 128 : loss : 0.0516 = 0.0675 + -0.0286 + 0.0129 + -0.0002, time: 12.515302]
2023-11-02 10:45:08.137: epoch 128:	0.02981279  	0.12042131  	0.08279317  
2023-11-02 10:45:20.579: [iter 129 : loss : 0.0498 = 0.0675 + -0.0305 + 0.0130 + -0.0002, time: 12.427249]
2023-11-02 10:45:21.229: epoch 129:	0.02986955  	0.12054569  	0.08289022  
2023-11-02 10:45:33.863: [iter 130 : loss : 0.0482 = 0.0674 + -0.0321 + 0.0131 + -0.0002, time: 12.617636]
2023-11-02 10:45:34.537: epoch 130:	0.02992631  	0.12073153  	0.08301129  
2023-11-02 10:45:34.537: Find a better model.
2023-11-02 10:45:47.030: [iter 131 : loss : 0.0442 = 0.0650 + -0.0339 + 0.0133 + -0.0002, time: 12.478810]
2023-11-02 10:45:47.663: epoch 131:	0.02989478  	0.12039559  	0.08284895  
2023-11-02 10:46:00.279: [iter 132 : loss : 0.0469 = 0.0691 + -0.0353 + 0.0134 + -0.0002, time: 12.595539]
2023-11-02 10:46:00.946: epoch 132:	0.03009660  	0.12148819  	0.08345018  
2023-11-02 10:46:00.946: Find a better model.
2023-11-02 10:46:13.411: [iter 133 : loss : 0.0439 = 0.0676 + -0.0370 + 0.0135 + -0.0002, time: 12.450185]
2023-11-02 10:46:14.087: epoch 133:	0.03009660  	0.12162374  	0.08352159  
2023-11-02 10:46:14.088: Find a better model.
2023-11-02 10:46:26.559: [iter 134 : loss : 0.0426 = 0.0679 + -0.0387 + 0.0136 + -0.0002, time: 12.452402]
2023-11-02 10:46:27.233: epoch 134:	0.03018490  	0.12178959  	0.08368164  
2023-11-02 10:46:27.233: Find a better model.
2023-11-02 10:46:39.827: [iter 135 : loss : 0.0398 = 0.0665 + -0.0403 + 0.0138 + -0.0002, time: 12.577384]
2023-11-02 10:46:40.515: epoch 135:	0.03023534  	0.12209558  	0.08391620  
2023-11-02 10:46:40.515: Find a better model.
2023-11-02 10:46:53.131: [iter 136 : loss : 0.0359 = 0.0644 + -0.0421 + 0.0139 + -0.0002, time: 12.598952]
2023-11-02 10:46:53.807: epoch 136:	0.03031734  	0.12258294  	0.08429526  
2023-11-02 10:46:53.807: Find a better model.
2023-11-02 10:47:06.195: [iter 137 : loss : 0.0368 = 0.0668 + -0.0438 + 0.0140 + -0.0002, time: 12.370585]
2023-11-02 10:47:06.851: epoch 137:	0.03041194  	0.12301540  	0.08446001  
2023-11-02 10:47:06.852: Find a better model.
2023-11-02 10:47:19.561: [iter 138 : loss : 0.0354 = 0.0666 + -0.0450 + 0.0141 + -0.0002, time: 12.693118]
2023-11-02 10:47:20.234: epoch 138:	0.03046240  	0.12312320  	0.08463831  
2023-11-02 10:47:20.234: Find a better model.
2023-11-02 10:47:32.689: [iter 139 : loss : 0.0340 = 0.0671 + -0.0472 + 0.0143 + -0.0003, time: 12.437075]
2023-11-02 10:47:33.363: epoch 139:	0.03047502  	0.12318864  	0.08463396  
2023-11-02 10:47:33.363: Find a better model.
2023-11-02 10:47:45.880: [iter 140 : loss : 0.0335 = 0.0681 + -0.0487 + 0.0144 + -0.0003, time: 12.500706]
2023-11-02 10:47:46.538: epoch 140:	0.03048762  	0.12330315  	0.08466823  
2023-11-02 10:47:46.538: Find a better model.
2023-11-02 10:47:59.141: [iter 141 : loss : 0.0312 = 0.0671 + -0.0502 + 0.0145 + -0.0003, time: 12.582463]
2023-11-02 10:47:59.732: epoch 141:	0.03050024  	0.12318411  	0.08481593  
2023-11-02 10:48:12.391: [iter 142 : loss : 0.0305 = 0.0677 + -0.0516 + 0.0146 + -0.0003, time: 12.639590]
2023-11-02 10:48:13.060: epoch 142:	0.03053808  	0.12337767  	0.08521620  
2023-11-02 10:48:13.060: Find a better model.
2023-11-02 10:48:25.704: [iter 143 : loss : 0.0301 = 0.0690 + -0.0533 + 0.0148 + -0.0003, time: 12.627485]
2023-11-02 10:48:26.364: epoch 143:	0.03061376  	0.12374104  	0.08525598  
2023-11-02 10:48:26.364: Find a better model.
2023-11-02 10:48:38.811: [iter 144 : loss : 0.0262 = 0.0664 + -0.0548 + 0.0149 + -0.0003, time: 12.429813]
2023-11-02 10:48:39.484: epoch 144:	0.03070206  	0.12403530  	0.08542392  
2023-11-02 10:48:39.485: Find a better model.
2023-11-02 10:48:52.061: [iter 145 : loss : 0.0236 = 0.0652 + -0.0564 + 0.0150 + -0.0003, time: 12.555599]
2023-11-02 10:48:52.743: epoch 145:	0.03077145  	0.12448202  	0.08560852  
2023-11-02 10:48:52.743: Find a better model.
2023-11-02 10:49:05.251: [iter 146 : loss : 0.0250 = 0.0681 + -0.0579 + 0.0151 + -0.0003, time: 12.491344]
2023-11-02 10:49:05.916: epoch 146:	0.03079667  	0.12442378  	0.08565640  
2023-11-02 10:49:18.554: [iter 147 : loss : 0.0235 = 0.0680 + -0.0594 + 0.0153 + -0.0003, time: 12.620366]
2023-11-02 10:49:19.218: epoch 147:	0.03086605  	0.12493101  	0.08592396  
2023-11-02 10:49:19.219: Find a better model.
2023-11-02 10:49:31.653: [iter 148 : loss : 0.0218 = 0.0677 + -0.0610 + 0.0154 + -0.0003, time: 12.416007]
2023-11-02 10:49:32.334: epoch 148:	0.03085974  	0.12478796  	0.08599953  
2023-11-02 10:49:45.012: [iter 149 : loss : 0.0195 = 0.0669 + -0.0626 + 0.0155 + -0.0003, time: 12.661640]
2023-11-02 10:49:45.700: epoch 149:	0.03084713  	0.12463444  	0.08596940  
2023-11-02 10:49:58.298: [iter 150 : loss : 0.0202 = 0.0691 + -0.0642 + 0.0157 + -0.0003, time: 12.581283]
2023-11-02 10:49:58.982: epoch 150:	0.03092281  	0.12497855  	0.08625586  
2023-11-02 10:49:58.982: Find a better model.
2023-11-02 10:50:11.517: [iter 151 : loss : 0.0164 = 0.0666 + -0.0657 + 0.0158 + -0.0004, time: 12.516652]
2023-11-02 10:50:12.191: epoch 151:	0.03094173  	0.12506460  	0.08630618  
2023-11-02 10:50:12.191: Find a better model.
2023-11-02 10:50:24.818: [iter 152 : loss : 0.0161 = 0.0677 + -0.0671 + 0.0159 + -0.0004, time: 12.610125]
2023-11-02 10:50:25.486: epoch 152:	0.03095435  	0.12520173  	0.08635691  
2023-11-02 10:50:25.486: Find a better model.
2023-11-02 10:50:38.107: [iter 153 : loss : 0.0132 = 0.0662 + -0.0687 + 0.0160 + -0.0004, time: 12.604041]
2023-11-02 10:50:38.779: epoch 153:	0.03097327  	0.12509546  	0.08639693  
2023-11-02 10:50:51.174: [iter 154 : loss : 0.0144 = 0.0688 + -0.0702 + 0.0161 + -0.0004, time: 12.377550]
2023-11-02 10:50:51.805: epoch 154:	0.03095435  	0.12516324  	0.08651704  
2023-11-02 10:51:04.385: [iter 155 : loss : 0.0091 = 0.0649 + -0.0717 + 0.0163 + -0.0004, time: 12.561147]
2023-11-02 10:51:05.039: epoch 155:	0.03096067  	0.12519841  	0.08646502  
2023-11-02 10:51:17.459: [iter 156 : loss : 0.0085 = 0.0656 + -0.0731 + 0.0164 + -0.0004, time: 12.404331]
2023-11-02 10:51:18.129: epoch 156:	0.03109310  	0.12553085  	0.08681618  
2023-11-02 10:51:18.129: Find a better model.
2023-11-02 10:51:30.741: [iter 157 : loss : 0.0072 = 0.0658 + -0.0747 + 0.0165 + -0.0004, time: 12.596818]
2023-11-02 10:51:31.384: epoch 157:	0.03111833  	0.12587620  	0.08686261  
2023-11-02 10:51:31.384: Find a better model.
2023-11-02 10:51:43.853: [iter 158 : loss : 0.0082 = 0.0679 + -0.0760 + 0.0167 + -0.0004, time: 12.450338]
2023-11-02 10:51:44.528: epoch 158:	0.03118140  	0.12618794  	0.08705655  
2023-11-02 10:51:44.528: Find a better model.
2023-11-02 10:51:57.150: [iter 159 : loss : 0.0057 = 0.0670 + -0.0777 + 0.0168 + -0.0004, time: 12.605784]
2023-11-02 10:51:57.786: epoch 159:	0.03110572  	0.12568934  	0.08701240  
2023-11-02 10:52:10.427: [iter 160 : loss : 0.0032 = 0.0659 + -0.0792 + 0.0169 + -0.0004, time: 12.624024]
2023-11-02 10:52:11.080: epoch 160:	0.03122554  	0.12612434  	0.08727200  
2023-11-02 10:52:23.668: [iter 161 : loss : 0.0030 = 0.0670 + -0.0806 + 0.0170 + -0.0004, time: 12.570340]
2023-11-02 10:52:24.352: epoch 161:	0.03129491  	0.12636971  	0.08728240  
2023-11-02 10:52:24.352: Find a better model.
2023-11-02 10:52:36.836: [iter 162 : loss : 0.0013 = 0.0668 + -0.0822 + 0.0172 + -0.0004, time: 12.467667]
2023-11-02 10:52:37.504: epoch 162:	0.03130122  	0.12653023  	0.08732167  
2023-11-02 10:52:37.504: Find a better model.
2023-11-02 10:52:50.072: [iter 163 : loss : 0.0002 = 0.0668 + -0.0835 + 0.0173 + -0.0004, time: 12.552791]
2023-11-02 10:52:50.740: epoch 163:	0.03138321  	0.12663552  	0.08758023  
2023-11-02 10:52:50.741: Find a better model.
2023-11-02 10:53:03.436: [iter 164 : loss : -0.0007 = 0.0673 + -0.0850 + 0.0174 + -0.0005, time: 12.677623]
2023-11-02 10:53:04.139: epoch 164:	0.03138952  	0.12676665  	0.08756819  
2023-11-02 10:53:04.140: Find a better model.
2023-11-02 10:53:16.718: [iter 165 : loss : -0.0018 = 0.0677 + -0.0866 + 0.0176 + -0.0005, time: 12.555865]
2023-11-02 10:53:17.357: epoch 165:	0.03150304  	0.12711711  	0.08788211  
2023-11-02 10:53:17.357: Find a better model.
2023-11-02 10:53:29.761: [iter 166 : loss : -0.0038 = 0.0670 + -0.0880 + 0.0177 + -0.0005, time: 12.386488]
2023-11-02 10:53:30.431: epoch 166:	0.03151566  	0.12723055  	0.08797981  
2023-11-02 10:53:30.432: Find a better model.
2023-11-02 10:53:43.066: [iter 167 : loss : -0.0062 = 0.0659 + -0.0894 + 0.0178 + -0.0005, time: 12.616958]
2023-11-02 10:53:43.752: epoch 167:	0.03150935  	0.12729941  	0.08791981  
2023-11-02 10:53:43.753: Find a better model.
2023-11-02 10:53:56.383: [iter 168 : loss : -0.0069 = 0.0666 + -0.0910 + 0.0179 + -0.0005, time: 12.609699]
2023-11-02 10:53:57.042: epoch 168:	0.03152827  	0.12721032  	0.08795264  
2023-11-02 10:54:09.494: [iter 169 : loss : -0.0052 = 0.0693 + -0.0921 + 0.0181 + -0.0005, time: 12.431754]
2023-11-02 10:54:10.189: epoch 169:	0.03143366  	0.12691724  	0.08790126  
2023-11-02 10:54:22.850: [iter 170 : loss : -0.0092 = 0.0666 + -0.0935 + 0.0182 + -0.0005, time: 12.639311]
2023-11-02 10:54:23.502: epoch 170:	0.03149043  	0.12721050  	0.08817060  
2023-11-02 10:54:35.957: [iter 171 : loss : -0.0112 = 0.0661 + -0.0951 + 0.0183 + -0.0005, time: 12.438044]
2023-11-02 10:54:36.635: epoch 171:	0.03162288  	0.12766284  	0.08852766  
2023-11-02 10:54:36.635: Find a better model.
2023-11-02 10:54:49.072: [iter 172 : loss : -0.0145 = 0.0642 + -0.0966 + 0.0185 + -0.0005, time: 12.420129]
2023-11-02 10:54:49.742: epoch 172:	0.03161026  	0.12767084  	0.08869401  
2023-11-02 10:54:49.742: Find a better model.
2023-11-02 10:55:02.350: [iter 173 : loss : -0.0122 = 0.0676 + -0.0979 + 0.0186 + -0.0005, time: 12.590660]
2023-11-02 10:55:03.011: epoch 173:	0.03175532  	0.12814115  	0.08902366  
2023-11-02 10:55:03.011: Find a better model.
2023-11-02 10:55:15.464: [iter 174 : loss : -0.0143 = 0.0669 + -0.0994 + 0.0187 + -0.0005, time: 12.438649]
2023-11-02 10:55:16.101: epoch 174:	0.03174271  	0.12816796  	0.08914810  
2023-11-02 10:55:16.102: Find a better model.
2023-11-02 10:55:28.657: [iter 175 : loss : -0.0147 = 0.0676 + -0.1006 + 0.0188 + -0.0005, time: 12.537712]
2023-11-02 10:55:29.295: epoch 175:	0.03186254  	0.12845208  	0.08916797  
2023-11-02 10:55:29.295: Find a better model.
2023-11-02 10:55:41.795: [iter 176 : loss : -0.0175 = 0.0660 + -0.1019 + 0.0190 + -0.0005, time: 12.484095]
2023-11-02 10:55:42.464: epoch 176:	0.03183731  	0.12826234  	0.08924881  
2023-11-02 10:55:54.953: [iter 177 : loss : -0.0170 = 0.0681 + -0.1036 + 0.0191 + -0.0005, time: 12.473237]
2023-11-02 10:55:55.624: epoch 177:	0.03196345  	0.12896749  	0.08951817  
2023-11-02 10:55:55.624: Find a better model.
2023-11-02 10:56:08.289: [iter 178 : loss : -0.0191 = 0.0673 + -0.1050 + 0.0192 + -0.0006, time: 12.648318]
2023-11-02 10:56:08.930: epoch 178:	0.03201391  	0.12927182  	0.08972476  
2023-11-02 10:56:08.930: Find a better model.
2023-11-02 10:56:21.433: [iter 179 : loss : -0.0205 = 0.0672 + -0.1064 + 0.0194 + -0.0006, time: 12.482755]
2023-11-02 10:56:22.111: epoch 179:	0.03204544  	0.12936537  	0.08972239  
2023-11-02 10:56:22.111: Find a better model.
2023-11-02 10:56:34.489: [iter 180 : loss : -0.0197 = 0.0687 + -0.1074 + 0.0195 + -0.0006, time: 12.363108]
2023-11-02 10:56:35.149: epoch 180:	0.03214005  	0.12980564  	0.09001031  
2023-11-02 10:56:35.149: Find a better model.
2023-11-02 10:56:47.550: [iter 181 : loss : -0.0194 = 0.0708 + -0.1092 + 0.0196 + -0.0006, time: 12.381096]
2023-11-02 10:56:48.202: epoch 181:	0.03212111  	0.12964725  	0.09012549  
2023-11-02 10:57:00.738: [iter 182 : loss : -0.0243 = 0.0669 + -0.1104 + 0.0197 + -0.0006, time: 12.522308]
2023-11-02 10:57:01.425: epoch 182:	0.03232294  	0.13052256  	0.09037239  
2023-11-02 10:57:01.425: Find a better model.
2023-11-02 10:57:13.816: [iter 183 : loss : -0.0262 = 0.0661 + -0.1115 + 0.0199 + -0.0006, time: 12.367050]
2023-11-02 10:57:14.484: epoch 183:	0.03225987  	0.13019462  	0.09024728  
2023-11-02 10:57:26.940: [iter 184 : loss : -0.0262 = 0.0673 + -0.1129 + 0.0200 + -0.0006, time: 12.440029]
2023-11-02 10:57:27.606: epoch 184:	0.03229140  	0.13031612  	0.09035193  
2023-11-02 10:57:40.079: [iter 185 : loss : -0.0285 = 0.0661 + -0.1141 + 0.0201 + -0.0006, time: 12.460310]
2023-11-02 10:57:40.759: epoch 185:	0.03232926  	0.13076009  	0.09044454  
2023-11-02 10:57:40.759: Find a better model.
2023-11-02 10:57:53.225: [iter 186 : loss : -0.0279 = 0.0680 + -0.1156 + 0.0202 + -0.0006, time: 12.442174]
2023-11-02 10:57:53.916: epoch 186:	0.03236710  	0.13091888  	0.09058629  
2023-11-02 10:57:53.917: Find a better model.
2023-11-02 10:58:06.582: [iter 187 : loss : -0.0298 = 0.0675 + -0.1171 + 0.0204 + -0.0006, time: 12.647609]
2023-11-02 10:58:07.229: epoch 187:	0.03246800  	0.13109200  	0.09056343  
2023-11-02 10:58:07.229: Find a better model.
2023-11-02 10:58:19.701: [iter 188 : loss : -0.0292 = 0.0689 + -0.1180 + 0.0205 + -0.0006, time: 12.452209]
2023-11-02 10:58:20.364: epoch 188:	0.03245538  	0.13122140  	0.09069376  
2023-11-02 10:58:20.364: Find a better model.
2023-11-02 10:58:32.861: [iter 189 : loss : -0.0325 = 0.0671 + -0.1196 + 0.0206 + -0.0006, time: 12.479275]
2023-11-02 10:58:33.538: epoch 189:	0.03246798  	0.13111964  	0.09070963  
2023-11-02 10:58:46.132: [iter 190 : loss : -0.0312 = 0.0693 + -0.1207 + 0.0207 + -0.0006, time: 12.576415]
2023-11-02 10:58:46.805: epoch 190:	0.03249953  	0.13126315  	0.09074946  
2023-11-02 10:58:46.805: Find a better model.
2023-11-02 10:58:59.437: [iter 191 : loss : -0.0345 = 0.0675 + -0.1222 + 0.0209 + -0.0006, time: 12.614454]
2023-11-02 10:59:00.067: epoch 191:	0.03257520  	0.13153048  	0.09095345  
2023-11-02 10:59:00.067: Find a better model.
2023-11-02 10:59:12.448: [iter 192 : loss : -0.0353 = 0.0679 + -0.1236 + 0.0210 + -0.0006, time: 12.362859]
2023-11-02 10:59:13.112: epoch 192:	0.03250583  	0.13124649  	0.09086762  
2023-11-02 10:59:25.763: [iter 193 : loss : -0.0353 = 0.0690 + -0.1248 + 0.0211 + -0.0007, time: 12.634687]
2023-11-02 10:59:26.427: epoch 193:	0.03259413  	0.13155676  	0.09104047  
2023-11-02 10:59:26.428: Find a better model.
2023-11-02 10:59:38.975: [iter 194 : loss : -0.0387 = 0.0667 + -0.1260 + 0.0212 + -0.0007, time: 12.528396]
2023-11-02 10:59:39.657: epoch 194:	0.03263826  	0.13174182  	0.09118718  
2023-11-02 10:59:39.657: Find a better model.
2023-11-02 10:59:52.040: [iter 195 : loss : -0.0401 = 0.0663 + -0.1271 + 0.0214 + -0.0007, time: 12.361910]
2023-11-02 10:59:52.717: epoch 195:	0.03263827  	0.13194373  	0.09137028  
2023-11-02 10:59:52.717: Find a better model.
2023-11-02 11:00:05.195: [iter 196 : loss : -0.0388 = 0.0690 + -0.1286 + 0.0215 + -0.0007, time: 12.460152]
2023-11-02 11:00:05.834: epoch 196:	0.03258152  	0.13173646  	0.09128655  
2023-11-02 11:00:18.249: [iter 197 : loss : -0.0408 = 0.0682 + -0.1300 + 0.0216 + -0.0007, time: 12.399297]
2023-11-02 11:00:18.929: epoch 197:	0.03259413  	0.13165456  	0.09128334  
2023-11-02 11:00:31.404: [iter 198 : loss : -0.0435 = 0.0667 + -0.1313 + 0.0218 + -0.0007, time: 12.455927]
2023-11-02 11:00:32.056: epoch 198:	0.03261304  	0.13163890  	0.09132146  
2023-11-02 11:00:44.655: [iter 199 : loss : -0.0453 = 0.0659 + -0.1324 + 0.0219 + -0.0007, time: 12.582940]
2023-11-02 11:00:45.346: epoch 199:	0.03267610  	0.13179563  	0.09136788  
2023-11-02 11:00:57.704: [iter 200 : loss : -0.0424 = 0.0700 + -0.1337 + 0.0220 + -0.0007, time: 12.335251]
2023-11-02 11:00:58.346: epoch 200:	0.03276440  	0.13210957  	0.09156234  
2023-11-02 11:00:58.346: Find a better model.
2023-11-02 11:00:58.346: best_result@epoch 200:

2023-11-02 11:00:58.346: 		0.0328      	0.1321      	0.0916      

2023-04-30 12:42:28.725: my pid: 36875
2023-04-30 12:42:28.725: model: model.general_recommender.GNNEC
2023-04-30 12:42:28.725: Dataset statistics:
Name: amazon-book
The number of users: 7928
The number of items: 29346
The number of ratings: 460224
Average actions of users: 58.05
Average actions of items: 15.68
The sparsity of the dataset: 99.802186%

The number of training: 417417
The number of validation: 0
The number of testing: 42807
2023-04-30 12:42:28.725: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=amazon-book
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=amazon-book
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
mf_reg=1e-4
svd_q=5
2023-04-30 12:42:34.635: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-04-30 12:43:28.316: [iter 1 : loss : 0.9283 = 0.5913 + 0.3353 + 0.0000 + 0.0017, time: 53.680206]
2023-04-30 12:43:29.136: epoch 1:	0.01102426  	0.04279512  	0.02920666  
2023-04-30 12:43:29.141: Find a better model.
2023-04-30 12:44:56.452: [iter 2 : loss : 0.6331 = 0.3327 + 0.2987 + 0.0002 + 0.0015, time: 87.287955]
2023-04-30 12:44:57.433: epoch 2:	0.01369213  	0.05402970  	0.03757772  
2023-04-30 12:44:57.433: Find a better model.
2023-04-30 12:46:27.215: [iter 3 : loss : 0.5048 = 0.2284 + 0.2746 + 0.0004 + 0.0014, time: 89.764987]
2023-04-30 12:46:28.227: epoch 3:	0.01583649  	0.06302314  	0.04212074  
2023-04-30 12:46:28.227: Find a better model.
2023-04-30 12:47:58.637: [iter 4 : loss : 0.4378 = 0.1811 + 0.2548 + 0.0006 + 0.0013, time: 90.389777]
2023-04-30 12:47:59.628: epoch 4:	0.01714835  	0.06852921  	0.04620473  
2023-04-30 12:47:59.628: Find a better model.
2023-04-30 12:49:29.955: [iter 5 : loss : 0.3899 = 0.1520 + 0.2360 + 0.0007 + 0.0012, time: 90.307804]
2023-04-30 12:49:30.978: epoch 5:	0.01836560  	0.07297205  	0.04927181  
2023-04-30 12:49:30.978: Find a better model.
2023-04-30 12:51:01.170: [iter 6 : loss : 0.3534 = 0.1322 + 0.2192 + 0.0008 + 0.0011, time: 90.177496]
2023-04-30 12:51:02.204: epoch 6:	0.01998650  	0.07971180  	0.05389489  
2023-04-30 12:51:02.204: Find a better model.
2023-04-30 12:52:31.921: [iter 7 : loss : 0.3222 = 0.1169 + 0.2033 + 0.0009 + 0.0011, time: 89.697353]
2023-04-30 12:52:32.930: epoch 7:	0.02123529  	0.08401228  	0.05656105  
2023-04-30 12:52:32.930: Find a better model.
2023-04-30 12:54:02.590: [iter 8 : loss : 0.2959 = 0.1050 + 0.1889 + 0.0011 + 0.0010, time: 89.642392]
2023-04-30 12:54:03.600: epoch 8:	0.02242732  	0.08865817  	0.05966976  
2023-04-30 12:54:03.600: Find a better model.
2023-04-30 12:55:33.152: [iter 9 : loss : 0.2711 = 0.0947 + 0.1743 + 0.0012 + 0.0009, time: 89.528615]
2023-04-30 12:55:34.178: epoch 9:	0.02302646  	0.09139243  	0.06159742  
2023-04-30 12:55:34.179: Find a better model.
2023-04-30 12:57:03.632: [iter 10 : loss : 0.2491 = 0.0864 + 0.1605 + 0.0013 + 0.0009, time: 89.437827]
2023-04-30 12:57:04.624: epoch 10:	0.02407973  	0.09517032  	0.06460464  
2023-04-30 12:57:04.624: Find a better model.
2023-04-30 12:58:34.300: [iter 11 : loss : 0.2295 = 0.0793 + 0.1480 + 0.0014 + 0.0008, time: 89.659362]
2023-04-30 12:58:35.318: epoch 11:	0.02487440  	0.09884576  	0.06721893  
2023-04-30 12:58:35.318: Find a better model.
2023-04-30 13:00:05.091: [iter 12 : loss : 0.2110 = 0.0729 + 0.1358 + 0.0016 + 0.0007, time: 89.757089]
2023-04-30 13:00:06.081: epoch 12:	0.02570692  	0.10235751  	0.06969664  
2023-04-30 13:00:06.082: Find a better model.
2023-04-30 13:01:35.850: [iter 13 : loss : 0.1943 = 0.0672 + 0.1247 + 0.0017 + 0.0007, time: 89.753864]
2023-04-30 13:01:36.856: epoch 13:	0.02641962  	0.10553496  	0.07161463  
2023-04-30 13:01:36.857: Find a better model.
2023-04-30 13:03:06.585: [iter 14 : loss : 0.1800 = 0.0626 + 0.1150 + 0.0018 + 0.0006, time: 89.711959]
2023-04-30 13:03:07.594: epoch 14:	0.02715753  	0.10835764  	0.07370617  
2023-04-30 13:03:07.594: Find a better model.
2023-04-30 13:04:37.082: [iter 15 : loss : 0.1658 = 0.0581 + 0.1052 + 0.0020 + 0.0006, time: 89.472650]
2023-04-30 13:04:38.061: epoch 15:	0.02770622  	0.11036050  	0.07478255  
2023-04-30 13:04:38.061: Find a better model.
2023-04-30 13:06:07.773: [iter 16 : loss : 0.1533 = 0.0544 + 0.0963 + 0.0021 + 0.0005, time: 89.696468]
2023-04-30 13:06:08.779: epoch 16:	0.02807204  	0.11212315  	0.07640911  
2023-04-30 13:06:08.779: Find a better model.
2023-04-30 13:07:38.414: [iter 17 : loss : 0.1420 = 0.0509 + 0.0884 + 0.0022 + 0.0005, time: 89.621473]
2023-04-30 13:07:39.430: epoch 17:	0.02845677  	0.11385225  	0.07783888  
2023-04-30 13:07:39.430: Find a better model.
2023-04-30 13:09:08.900: [iter 18 : loss : 0.1321 = 0.0483 + 0.0810 + 0.0023 + 0.0004, time: 89.454962]
2023-04-30 13:09:09.925: epoch 18:	0.02859553  	0.11442078  	0.07818550  
2023-04-30 13:09:09.926: Find a better model.
2023-04-30 13:10:39.473: [iter 19 : loss : 0.1218 = 0.0449 + 0.0740 + 0.0025 + 0.0004, time: 89.526623]
2023-04-30 13:10:40.480: epoch 19:	0.02913161  	0.11690358  	0.07937441  
2023-04-30 13:10:40.480: Find a better model.
2023-04-30 13:12:10.242: [iter 20 : loss : 0.1138 = 0.0422 + 0.0686 + 0.0026 + 0.0004, time: 89.744256]
2023-04-30 13:12:11.301: epoch 20:	0.02925145  	0.11718612  	0.07991719  
2023-04-30 13:12:11.301: Find a better model.
2023-04-30 13:13:40.894: [iter 21 : loss : 0.1066 = 0.0403 + 0.0632 + 0.0027 + 0.0003, time: 89.576027]
2023-04-30 13:13:41.938: epoch 21:	0.02915685  	0.11686911  	0.07973059  
2023-04-30 13:15:11.612: [iter 22 : loss : 0.0999 = 0.0382 + 0.0586 + 0.0028 + 0.0003, time: 89.655482]
2023-04-30 13:15:12.627: epoch 22:	0.02945958  	0.11809097  	0.08014275  
2023-04-30 13:15:12.627: Find a better model.
2023-04-30 13:16:42.396: [iter 23 : loss : 0.0939 = 0.0363 + 0.0544 + 0.0030 + 0.0003, time: 89.749172]
2023-04-30 13:16:43.399: epoch 23:	0.02947850  	0.11804165  	0.08056394  
2023-04-30 13:18:13.026: [iter 24 : loss : 0.0885 = 0.0344 + 0.0508 + 0.0031 + 0.0003, time: 89.607032]
2023-04-30 13:18:14.044: epoch 24:	0.02953527  	0.11848412  	0.08116735  
2023-04-30 13:18:14.045: Find a better model.
2023-04-30 13:19:43.570: [iter 25 : loss : 0.0829 = 0.0322 + 0.0472 + 0.0032 + 0.0003, time: 89.507744]
2023-04-30 13:19:44.560: epoch 25:	0.02958572  	0.11860557  	0.08150085  
2023-04-30 13:19:44.560: Find a better model.
2023-04-30 13:21:14.419: [iter 26 : loss : 0.0783 = 0.0307 + 0.0441 + 0.0033 + 0.0002, time: 89.842427]
2023-04-30 13:21:15.432: epoch 26:	0.02973078  	0.11920714  	0.08206956  
2023-04-30 13:21:15.432: Find a better model.
2023-04-30 13:22:45.253: [iter 27 : loss : 0.0749 = 0.0297 + 0.0416 + 0.0034 + 0.0002, time: 89.801091]
2023-04-30 13:22:46.307: epoch 27:	0.03001460  	0.12056577  	0.08256980  
2023-04-30 13:22:46.307: Find a better model.
2023-04-30 13:24:14.919: [iter 28 : loss : 0.0705 = 0.0281 + 0.0387 + 0.0035 + 0.0002, time: 88.586659]
2023-04-30 13:24:15.964: epoch 28:	0.03015967  	0.12128466  	0.08274715  
2023-04-30 13:24:15.964: Find a better model.
2023-04-30 13:25:45.470: [iter 29 : loss : 0.0673 = 0.0273 + 0.0362 + 0.0036 + 0.0002, time: 89.490381]
2023-04-30 13:25:46.508: epoch 29:	0.03016596  	0.12142657  	0.08263600  
2023-04-30 13:25:46.508: Find a better model.
2023-04-30 13:27:16.053: [iter 30 : loss : 0.0638 = 0.0259 + 0.0340 + 0.0037 + 0.0002, time: 89.525161]
2023-04-30 13:27:17.058: epoch 30:	0.03019118  	0.12154604  	0.08308322  
2023-04-30 13:27:17.058: Find a better model.
2023-04-30 13:28:46.352: [iter 31 : loss : 0.0604 = 0.0245 + 0.0320 + 0.0038 + 0.0002, time: 89.275455]
2023-04-30 13:28:47.365: epoch 31:	0.02987585  	0.12009762  	0.08257625  
2023-04-30 13:30:16.937: [iter 32 : loss : 0.0583 = 0.0243 + 0.0300 + 0.0039 + 0.0002, time: 89.550325]
2023-04-30 13:30:17.920: epoch 32:	0.03002091  	0.12098826  	0.08283041  
2023-04-30 13:31:47.470: [iter 33 : loss : 0.0549 = 0.0228 + 0.0281 + 0.0040 + 0.0001, time: 89.528887]
2023-04-30 13:31:48.497: epoch 33:	0.02998937  	0.12070286  	0.08279656  
2023-04-30 13:33:18.253: [iter 34 : loss : 0.0527 = 0.0221 + 0.0263 + 0.0041 + 0.0001, time: 89.738391]
2023-04-30 13:33:19.280: epoch 34:	0.02992629  	0.12037923  	0.08252227  
2023-04-30 13:34:46.469: [iter 35 : loss : 0.0505 = 0.0213 + 0.0250 + 0.0042 + 0.0001, time: 87.171800]
2023-04-30 13:34:47.467: epoch 35:	0.02997045  	0.12022763  	0.08253425  
2023-04-30 13:36:17.019: [iter 36 : loss : 0.0484 = 0.0207 + 0.0234 + 0.0043 + 0.0001, time: 89.530269]
2023-04-30 13:36:18.035: epoch 36:	0.02985061  	0.11989290  	0.08234028  
2023-04-30 13:37:47.414: [iter 37 : loss : 0.0461 = 0.0198 + 0.0219 + 0.0043 + 0.0001, time: 89.363657]
2023-04-30 13:37:48.453: epoch 37:	0.02984431  	0.12023915  	0.08245779  
2023-04-30 13:39:18.214: [iter 38 : loss : 0.0443 = 0.0192 + 0.0206 + 0.0044 + 0.0001, time: 89.734428]
2023-04-30 13:39:19.221: epoch 38:	0.02986322  	0.12036350  	0.08236642  
2023-04-30 13:40:48.912: [iter 39 : loss : 0.0424 = 0.0184 + 0.0194 + 0.0045 + 0.0001, time: 89.665787]
2023-04-30 13:40:49.942: epoch 39:	0.02978123  	0.12033445  	0.08242915  
2023-04-30 13:42:19.831: [iter 40 : loss : 0.0410 = 0.0181 + 0.0182 + 0.0046 + 0.0001, time: 89.868488]
2023-04-30 13:42:20.849: epoch 40:	0.02976232  	0.11980742  	0.08216759  
2023-04-30 13:42:20.849: Early stopping is trigger at epoch: 40
2023-04-30 13:42:20.849: best_result@epoch 30:

2023-04-30 13:42:20.849: 		0.0302      	0.1215      	0.0831      

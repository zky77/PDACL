2023-11-02 09:51:58.245: my pid: 3846
2023-11-02 09:51:58.245: model: model.general_recommender.GNNEC
2023-11-02 09:51:58.245: Dataset statistics:
Name: amazon-book
The number of users: 7928
The number of items: 29346
The number of ratings: 460224
Average actions of users: 58.05
Average actions of items: 15.68
The sparsity of the dataset: 99.802186%

The number of training: 417417
The number of validation: 0
The number of testing: 42807
2023-11-02 09:51:58.246: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=amazon-book
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.1
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=amazon-book
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.1
mf_reg=1e-4
svd_q=5
2023-11-02 09:52:02.625: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-11-02 09:52:15.886: [iter 1 : loss : 0.7824 = 0.6219 + 0.1598 + 0.0000 + 0.0008, time: 13.260125]
2023-11-02 09:52:16.587: epoch 1:	0.01347768  	0.05311122  	0.03573683  
2023-11-02 09:52:16.587: Find a better model.
2023-11-02 09:52:28.969: [iter 2 : loss : 0.2765 = 0.4176 + -0.1405 + 0.0002 + -0.0009, time: 12.361727]
2023-11-02 09:52:29.688: epoch 2:	0.01706003  	0.06853951  	0.04637631  
2023-11-02 09:52:29.688: Find a better model.
2023-11-02 09:52:42.045: [iter 3 : loss : -0.0241 = 0.3122 + -0.3349 + 0.0004 + -0.0019, time: 12.338125]
2023-11-02 09:52:42.712: epoch 3:	0.01883863  	0.07511010  	0.05099970  
2023-11-02 09:52:42.712: Find a better model.
2023-11-02 09:52:55.179: [iter 4 : loss : -0.2163 = 0.2613 + -0.4756 + 0.0006 + -0.0026, time: 12.452970]
2023-11-02 09:52:55.906: epoch 4:	0.02022616  	0.08105100  	0.05531130  
2023-11-02 09:52:55.906: Find a better model.
2023-11-02 09:53:08.423: [iter 5 : loss : -0.3697 = 0.2302 + -0.5975 + 0.0009 + -0.0032, time: 12.499590]
2023-11-02 09:53:09.109: epoch 5:	0.02130467  	0.08551752  	0.05818324  
2023-11-02 09:53:09.109: Find a better model.
2023-11-02 09:53:21.396: [iter 6 : loss : -0.4933 = 0.2114 + -0.7021 + 0.0011 + -0.0038, time: 12.270350]
2023-11-02 09:53:22.109: epoch 6:	0.02247145  	0.09034393  	0.06153163  
2023-11-02 09:53:22.109: Find a better model.
2023-11-02 09:53:34.432: [iter 7 : loss : -0.5998 = 0.1994 + -0.7962 + 0.0014 + -0.0043, time: 12.309527]
2023-11-02 09:53:35.126: epoch 7:	0.02276789  	0.09114753  	0.06264348  
2023-11-02 09:53:35.126: Find a better model.
2023-11-02 09:53:47.507: [iter 8 : loss : -0.6905 = 0.1918 + -0.8792 + 0.0016 + -0.0047, time: 12.367770]
2023-11-02 09:53:48.207: epoch 8:	0.02308324  	0.09259783  	0.06350984  
2023-11-02 09:53:48.208: Find a better model.
2023-11-02 09:54:00.416: [iter 9 : loss : nan = nan + nan + nan + nan, time: 12.194996]
2023-11-02 09:54:01.079: epoch 9:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:54:13.413: [iter 10 : loss : nan = nan + nan + nan + nan, time: 12.320373]
2023-11-02 09:54:14.051: epoch 10:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:54:26.485: [iter 11 : loss : nan = nan + nan + nan + nan, time: 12.418915]
2023-11-02 09:54:27.128: epoch 11:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:54:39.259: [iter 12 : loss : nan = nan + nan + nan + nan, time: 12.114785]
2023-11-02 09:54:39.891: epoch 12:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:54:52.378: [iter 13 : loss : nan = nan + nan + nan + nan, time: 12.469433]
2023-11-02 09:54:53.049: epoch 13:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:55:05.358: [iter 14 : loss : nan = nan + nan + nan + nan, time: 12.292429]
2023-11-02 09:55:06.002: epoch 14:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:55:18.204: [iter 15 : loss : nan = nan + nan + nan + nan, time: 12.186340]
2023-11-02 09:55:18.843: epoch 15:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:55:31.275: [iter 16 : loss : nan = nan + nan + nan + nan, time: 12.416209]
2023-11-02 09:55:31.934: epoch 16:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:55:44.222: [iter 17 : loss : nan = nan + nan + nan + nan, time: 12.273582]
2023-11-02 09:55:44.874: epoch 17:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:55:57.077: [iter 18 : loss : nan = nan + nan + nan + nan, time: 12.188793]
2023-11-02 09:55:57.712: epoch 18:	0.00026488  	0.00082033  	0.00038939  
2023-11-02 09:55:57.712: Early stopping is trigger at epoch: 18
2023-11-02 09:55:57.712: best_result@epoch 8:

2023-11-02 09:55:57.712: 		0.0231      	0.0926      	0.0635      

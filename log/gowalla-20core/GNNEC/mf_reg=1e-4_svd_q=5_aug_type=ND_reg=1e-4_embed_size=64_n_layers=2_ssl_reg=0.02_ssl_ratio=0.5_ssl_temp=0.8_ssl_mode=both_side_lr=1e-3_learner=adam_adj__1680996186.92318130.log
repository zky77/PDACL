2023-04-09 07:23:06.923: my pid: 11437
2023-04-09 07:23:06.923: model: model.general_recommender.GNNEC
2023-04-09 07:23:06.923: Dataset statistics:
Name: gowalla-20core
The number of users: 11113
The number of items: 18074
The number of ratings: 523315
Average actions of users: 47.09
Average actions of items: 28.95
The sparsity of the dataset: 99.739458%

The number of training: 475362
The number of validation: 0
The number of testing: 47953
2023-04-09 07:23:06.924: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=gowalla-20core
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.8
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=gowalla-20core
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.8
mf_reg=1e-4
svd_q=5
2023-04-09 07:23:13.006: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-04-09 07:23:39.135: [iter 1 : loss : 0.8855 = 0.5263 + 0.3573 + 0.0001 + 0.0018, time: 26.127976]
2023-04-09 07:23:39.777: epoch 1:	0.01841142  	0.09752527  	0.06579208  
2023-04-09 07:23:39.777: Find a better model.
2023-04-09 07:24:05.711: [iter 2 : loss : 0.5686 = 0.2381 + 0.3284 + 0.0004 + 0.0017, time: 25.920084]
2023-04-09 07:24:06.297: epoch 2:	0.01967127  	0.10396356  	0.07046359  
2023-04-09 07:24:06.297: Find a better model.
2023-04-09 07:24:32.582: [iter 3 : loss : 0.4912 = 0.1717 + 0.3173 + 0.0006 + 0.0016, time: 26.268846]
2023-04-09 07:24:33.208: epoch 3:	0.02124156  	0.11278030  	0.07628719  
2023-04-09 07:24:33.208: Find a better model.
2023-04-09 07:24:59.390: [iter 4 : loss : 0.4559 = 0.1436 + 0.3101 + 0.0007 + 0.0016, time: 26.167578]
2023-04-09 07:25:00.015: epoch 4:	0.02252389  	0.11946476  	0.08143311  
2023-04-09 07:25:00.015: Find a better model.
2023-04-09 07:25:26.318: [iter 5 : loss : 0.4331 = 0.1262 + 0.3046 + 0.0008 + 0.0016, time: 26.289015]
2023-04-09 07:25:26.964: epoch 5:	0.02314028  	0.12315454  	0.08499328  
2023-04-09 07:25:26.964: Find a better model.
2023-04-09 07:25:52.890: [iter 6 : loss : 0.4184 = 0.1150 + 0.3009 + 0.0009 + 0.0015, time: 25.913131]
2023-04-09 07:25:53.529: epoch 6:	0.02383305  	0.12653582  	0.08726950  
2023-04-09 07:25:53.529: Find a better model.
2023-04-09 07:26:19.548: [iter 7 : loss : 0.4049 = 0.1055 + 0.2969 + 0.0010 + 0.0015, time: 26.000586]
2023-04-09 07:26:20.152: epoch 7:	0.02414794  	0.12790133  	0.08852232  
2023-04-09 07:26:20.152: Find a better model.
2023-04-09 07:26:46.152: [iter 8 : loss : 0.3961 = 0.0999 + 0.2936 + 0.0011 + 0.0015, time: 25.986353]
2023-04-09 07:26:46.758: epoch 8:	0.02444486  	0.12975000  	0.09018492  
2023-04-09 07:26:46.758: Find a better model.
2023-04-09 07:27:12.804: [iter 9 : loss : 0.3875 = 0.0944 + 0.2905 + 0.0011 + 0.0015, time: 26.031595]
2023-04-09 07:27:13.420: epoch 9:	0.02490374  	0.13236375  	0.09191202  
2023-04-09 07:27:13.420: Find a better model.
2023-04-09 07:27:39.576: [iter 10 : loss : 0.3816 = 0.0907 + 0.2882 + 0.0012 + 0.0015, time: 26.140864]
2023-04-09 07:27:40.189: epoch 10:	0.02534458  	0.13484216  	0.09323002  
2023-04-09 07:27:40.189: Find a better model.
2023-04-09 07:28:06.262: [iter 11 : loss : 0.3753 = 0.0866 + 0.2860 + 0.0013 + 0.0015, time: 26.056990]
2023-04-09 07:28:06.871: epoch 11:	0.02571345  	0.13679668  	0.09442265  
2023-04-09 07:28:06.872: Find a better model.
2023-04-09 07:28:32.777: [iter 12 : loss : 0.3689 = 0.0826 + 0.2835 + 0.0013 + 0.0015, time: 25.890324]
2023-04-09 07:28:33.392: epoch 12:	0.02610483  	0.13871443  	0.09554275  
2023-04-09 07:28:33.392: Find a better model.
2023-04-09 07:28:59.420: [iter 13 : loss : 0.3644 = 0.0799 + 0.2816 + 0.0014 + 0.0014, time: 26.014743]
2023-04-09 07:29:00.022: epoch 13:	0.02650969  	0.14081024  	0.09666489  
2023-04-09 07:29:00.022: Find a better model.
2023-04-09 07:29:25.991: [iter 14 : loss : 0.3595 = 0.0769 + 0.2796 + 0.0015 + 0.0014, time: 25.955667]
2023-04-09 07:29:26.599: epoch 14:	0.02680211  	0.14249583  	0.09777797  
2023-04-09 07:29:26.599: Find a better model.
2023-04-09 07:29:52.760: [iter 15 : loss : 0.3562 = 0.0755 + 0.2777 + 0.0015 + 0.0014, time: 26.147758]
2023-04-09 07:29:53.372: epoch 15:	0.02715749  	0.14454702  	0.09913839  
2023-04-09 07:29:53.372: Find a better model.
2023-04-09 07:30:19.620: [iter 16 : loss : 0.3522 = 0.0732 + 0.2759 + 0.0016 + 0.0014, time: 26.232246]
2023-04-09 07:30:20.208: epoch 16:	0.02753534  	0.14643551  	0.10015373  
2023-04-09 07:30:20.208: Find a better model.
2023-04-09 07:30:46.310: [iter 17 : loss : 0.3474 = 0.0702 + 0.2742 + 0.0017 + 0.0014, time: 26.086719]
2023-04-09 07:30:46.925: epoch 17:	0.02769277  	0.14723222  	0.10100907  
2023-04-09 07:30:46.925: Find a better model.
2023-04-09 07:31:13.007: [iter 18 : loss : 0.3450 = 0.0694 + 0.2725 + 0.0017 + 0.0014, time: 26.067518]
2023-04-09 07:31:13.644: epoch 18:	0.02793121  	0.14808924  	0.10186090  
2023-04-09 07:31:13.644: Find a better model.
2023-04-09 07:31:39.611: [iter 19 : loss : 0.3414 = 0.0672 + 0.2710 + 0.0018 + 0.0014, time: 25.953129]
2023-04-09 07:31:40.225: epoch 19:	0.02819212  	0.14927432  	0.10282936  
2023-04-09 07:31:40.225: Find a better model.
2023-04-09 07:32:06.307: [iter 20 : loss : 0.3388 = 0.0663 + 0.2693 + 0.0018 + 0.0014, time: 26.068747]
2023-04-09 07:32:06.945: epoch 20:	0.02842155  	0.15087116  	0.10363989  
2023-04-09 07:32:06.945: Find a better model.
2023-04-09 07:32:32.897: [iter 21 : loss : 0.3356 = 0.0646 + 0.2677 + 0.0019 + 0.0014, time: 25.937591]
2023-04-09 07:32:33.508: epoch 21:	0.02861050  	0.15180522  	0.10449529  
2023-04-09 07:32:33.508: Find a better model.
2023-04-09 07:32:59.541: [iter 22 : loss : 0.3321 = 0.0625 + 0.2662 + 0.0020 + 0.0014, time: 26.020394]
2023-04-09 07:33:00.166: epoch 22:	0.02888042  	0.15290965  	0.10539190  
2023-04-09 07:33:00.167: Find a better model.
2023-04-09 07:33:26.408: [iter 23 : loss : 0.3292 = 0.0612 + 0.2646 + 0.0020 + 0.0014, time: 26.224077]
2023-04-09 07:33:26.996: epoch 23:	0.02893893  	0.15343116  	0.10603774  
2023-04-09 07:33:26.996: Find a better model.
2023-04-09 07:33:53.077: [iter 24 : loss : 0.3264 = 0.0599 + 0.2631 + 0.0021 + 0.0014, time: 26.065333]
2023-04-09 07:33:53.683: epoch 24:	0.02926283  	0.15497106  	0.10703563  
2023-04-09 07:33:53.683: Find a better model.
2023-04-09 07:34:19.649: [iter 25 : loss : 0.3242 = 0.0586 + 0.2620 + 0.0022 + 0.0013, time: 25.950979]
2023-04-09 07:34:20.273: epoch 25:	0.02945176  	0.15569042  	0.10785485  
2023-04-09 07:34:20.273: Find a better model.
2023-04-09 07:34:46.121: [iter 26 : loss : 0.3212 = 0.0573 + 0.2603 + 0.0022 + 0.0013, time: 25.833169]
2023-04-09 07:34:46.739: epoch 26:	0.02963173  	0.15738100  	0.10860018  
2023-04-09 07:34:46.740: Find a better model.
2023-04-09 07:35:12.749: [iter 27 : loss : 0.3186 = 0.0562 + 0.2588 + 0.0023 + 0.0013, time: 25.995094]
2023-04-09 07:35:13.352: epoch 27:	0.02984315  	0.15874311  	0.10961787  
2023-04-09 07:35:13.352: Find a better model.
2023-04-09 07:35:39.740: [iter 28 : loss : 0.3168 = 0.0558 + 0.2573 + 0.0024 + 0.0013, time: 26.376034]
2023-04-09 07:35:40.349: epoch 28:	0.03006357  	0.15982264  	0.11027269  
2023-04-09 07:35:40.350: Find a better model.
2023-04-09 07:36:06.438: [iter 29 : loss : 0.3143 = 0.0547 + 0.2559 + 0.0024 + 0.0013, time: 26.074871]
2023-04-09 07:36:07.065: epoch 29:	0.03029303  	0.16054371  	0.11086626  
2023-04-09 07:36:07.065: Find a better model.
2023-04-09 07:36:33.375: [iter 30 : loss : 0.3109 = 0.0523 + 0.2548 + 0.0025 + 0.0013, time: 26.294705]
2023-04-09 07:36:33.970: epoch 30:	0.03038300  	0.16087015  	0.11171731  
2023-04-09 07:36:33.970: Find a better model.
2023-04-09 07:37:00.182: [iter 31 : loss : 0.3098 = 0.0526 + 0.2534 + 0.0025 + 0.0013, time: 26.195002]
2023-04-09 07:37:00.802: epoch 31:	0.03060345  	0.16259813  	0.11278293  
2023-04-09 07:37:00.802: Find a better model.
2023-04-09 07:37:27.059: [iter 32 : loss : 0.3074 = 0.0512 + 0.2523 + 0.0026 + 0.0013, time: 26.239054]
2023-04-09 07:37:27.675: epoch 32:	0.03089586  	0.16420536  	0.11358517  
2023-04-09 07:37:27.675: Find a better model.
2023-04-09 07:37:53.836: [iter 33 : loss : 0.3049 = 0.0502 + 0.2508 + 0.0027 + 0.0013, time: 26.146063]
2023-04-09 07:37:54.450: epoch 33:	0.03089586  	0.16387896  	0.11379904  
2023-04-09 07:38:20.883: [iter 34 : loss : 0.3032 = 0.0500 + 0.2492 + 0.0027 + 0.0013, time: 26.418556]
2023-04-09 07:38:21.514: epoch 34:	0.03098584  	0.16467033  	0.11433975  
2023-04-09 07:38:21.514: Find a better model.
2023-04-09 07:38:47.435: [iter 35 : loss : 0.3013 = 0.0494 + 0.2478 + 0.0028 + 0.0013, time: 25.905188]
2023-04-09 07:38:48.054: epoch 35:	0.03127826  	0.16603528  	0.11504196  
2023-04-09 07:38:48.054: Find a better model.
2023-04-09 07:39:13.947: [iter 36 : loss : 0.2985 = 0.0477 + 0.2466 + 0.0029 + 0.0013, time: 25.871030]
2023-04-09 07:39:14.562: epoch 36:	0.03132774  	0.16631274  	0.11544500  
2023-04-09 07:39:14.563: Find a better model.
2023-04-09 07:39:40.448: [iter 37 : loss : 0.2962 = 0.0466 + 0.2454 + 0.0029 + 0.0013, time: 25.873140]
2023-04-09 07:39:41.060: epoch 37:	0.03160668  	0.16752394  	0.11621351  
2023-04-09 07:39:41.060: Find a better model.
2023-04-09 07:40:06.819: [iter 38 : loss : 0.2949 = 0.0465 + 0.2441 + 0.0030 + 0.0013, time: 25.744572]
2023-04-09 07:40:07.447: epoch 38:	0.03169667  	0.16827606  	0.11693736  
2023-04-09 07:40:07.448: Find a better model.
2023-04-09 07:40:33.378: [iter 39 : loss : 0.2928 = 0.0457 + 0.2427 + 0.0031 + 0.0013, time: 25.914488]
2023-04-09 07:40:33.999: epoch 39:	0.03186763  	0.16895883  	0.11745075  
2023-04-09 07:40:33.999: Find a better model.
2023-04-09 07:40:59.783: [iter 40 : loss : 0.2913 = 0.0456 + 0.2413 + 0.0032 + 0.0012, time: 25.771907]
2023-04-09 07:41:00.406: epoch 40:	0.03209254  	0.16988635  	0.11815632  
2023-04-09 07:41:00.406: Find a better model.
2023-04-09 07:41:26.372: [iter 41 : loss : 0.2890 = 0.0443 + 0.2403 + 0.0032 + 0.0012, time: 25.953436]
2023-04-09 07:41:26.969: epoch 41:	0.03224100  	0.17063893  	0.11868919  
2023-04-09 07:41:26.969: Find a better model.
2023-04-09 07:41:52.805: [iter 42 : loss : 0.2880 = 0.0444 + 0.2390 + 0.0033 + 0.0012, time: 25.824605]
2023-04-09 07:41:53.386: epoch 42:	0.03235348  	0.17114697  	0.11927769  
2023-04-09 07:41:53.386: Find a better model.
2023-04-09 07:42:19.357: [iter 43 : loss : 0.2863 = 0.0440 + 0.2378 + 0.0034 + 0.0012, time: 25.957505]
2023-04-09 07:42:19.939: epoch 43:	0.03255591  	0.17222084  	0.11974232  
2023-04-09 07:42:19.940: Find a better model.
2023-04-09 07:42:45.859: [iter 44 : loss : 0.2837 = 0.0425 + 0.2366 + 0.0034 + 0.0012, time: 25.907480]
2023-04-09 07:42:46.480: epoch 44:	0.03281231  	0.17345113  	0.12038249  
2023-04-09 07:42:46.480: Find a better model.
2023-04-09 07:43:12.170: [iter 45 : loss : 0.2832 = 0.0429 + 0.2355 + 0.0035 + 0.0012, time: 25.676075]
2023-04-09 07:43:12.770: epoch 45:	0.03289330  	0.17403032  	0.12076973  
2023-04-09 07:43:12.770: Find a better model.
2023-04-09 07:43:38.502: [iter 46 : loss : 0.2811 = 0.0419 + 0.2343 + 0.0036 + 0.0012, time: 25.720370]
2023-04-09 07:43:39.097: epoch 46:	0.03301926  	0.17463997  	0.12111323  
2023-04-09 07:43:39.097: Find a better model.
2023-04-09 07:44:04.830: [iter 47 : loss : 0.2788 = 0.0410 + 0.2330 + 0.0037 + 0.0012, time: 25.720706]
2023-04-09 07:44:05.441: epoch 47:	0.03308224  	0.17516434  	0.12164519  
2023-04-09 07:44:05.441: Find a better model.
2023-04-09 07:44:30.482: [iter 48 : loss : 0.2788 = 0.0420 + 0.2320 + 0.0037 + 0.0012, time: 25.024484]
2023-04-09 07:44:31.036: epoch 48:	0.03320821  	0.17604677  	0.12230784  
2023-04-09 07:44:31.036: Find a better model.
2023-04-09 07:44:55.995: [iter 49 : loss : 0.2764 = 0.0407 + 0.2307 + 0.0038 + 0.0012, time: 24.946966]
2023-04-09 07:44:56.527: epoch 49:	0.03333869  	0.17676063  	0.12275498  
2023-04-09 07:44:56.528: Find a better model.
2023-04-09 07:45:21.518: [iter 50 : loss : 0.2740 = 0.0394 + 0.2295 + 0.0039 + 0.0012, time: 24.979776]
2023-04-09 07:45:22.116: epoch 50:	0.03349616  	0.17746541  	0.12310284  
2023-04-09 07:45:22.116: Find a better model.
2023-04-09 07:45:47.991: [iter 51 : loss : 0.2728 = 0.0393 + 0.2283 + 0.0040 + 0.0012, time: 25.861632]
2023-04-09 07:45:48.590: epoch 51:	0.03369861  	0.17843421  	0.12366645  
2023-04-09 07:45:48.590: Find a better model.
2023-04-09 07:46:14.510: [iter 52 : loss : 0.2718 = 0.0395 + 0.2271 + 0.0040 + 0.0012, time: 25.906358]
2023-04-09 07:46:15.123: epoch 52:	0.03372558  	0.17874014  	0.12409659  
2023-04-09 07:46:15.123: Find a better model.
2023-04-09 07:46:40.972: [iter 53 : loss : 0.2696 = 0.0384 + 0.2259 + 0.0041 + 0.0012, time: 25.835131]
2023-04-09 07:46:41.596: epoch 53:	0.03383803  	0.17926538  	0.12463951  
2023-04-09 07:46:41.597: Find a better model.
2023-04-09 07:47:07.391: [iter 54 : loss : 0.2684 = 0.0379 + 0.2251 + 0.0042 + 0.0012, time: 25.779418]
2023-04-09 07:47:08.012: epoch 54:	0.03397749  	0.18009958  	0.12519455  
2023-04-09 07:47:08.012: Find a better model.
2023-04-09 07:47:33.842: [iter 55 : loss : 0.2671 = 0.0381 + 0.2236 + 0.0043 + 0.0012, time: 25.814008]
2023-04-09 07:47:34.458: epoch 55:	0.03419343  	0.18100658  	0.12569019  
2023-04-09 07:47:34.458: Find a better model.
2023-04-09 07:48:00.307: [iter 56 : loss : 0.2664 = 0.0382 + 0.2226 + 0.0043 + 0.0011, time: 25.833496]
2023-04-09 07:48:00.913: epoch 56:	0.03430592  	0.18190548  	0.12610964  
2023-04-09 07:48:00.913: Find a better model.
2023-04-09 07:48:26.751: [iter 57 : loss : 0.2642 = 0.0371 + 0.2216 + 0.0044 + 0.0011, time: 25.825096]
2023-04-09 07:48:27.341: epoch 57:	0.03450834  	0.18246457  	0.12677263  
2023-04-09 07:48:27.341: Find a better model.
2023-04-09 07:48:53.160: [iter 58 : loss : 0.2628 = 0.0367 + 0.2205 + 0.0045 + 0.0011, time: 25.807649]
2023-04-09 07:48:53.730: epoch 58:	0.03456231  	0.18306555  	0.12723602  
2023-04-09 07:48:53.730: Find a better model.
2023-04-09 07:49:18.706: [iter 59 : loss : 0.2621 = 0.0372 + 0.2193 + 0.0046 + 0.0011, time: 24.964624]
2023-04-09 07:49:19.289: epoch 59:	0.03471977  	0.18392037  	0.12781075  
2023-04-09 07:49:19.289: Find a better model.
2023-04-09 07:49:45.182: [iter 60 : loss : 0.2597 = 0.0358 + 0.2182 + 0.0046 + 0.0011, time: 25.881540]
2023-04-09 07:49:45.794: epoch 60:	0.03477376  	0.18380646  	0.12796202  
2023-04-09 07:50:11.591: [iter 61 : loss : 0.2578 = 0.0348 + 0.2171 + 0.0047 + 0.0011, time: 25.783071]
2023-04-09 07:50:12.190: epoch 61:	0.03491321  	0.18460476  	0.12852648  
2023-04-09 07:50:12.190: Find a better model.
2023-04-09 07:50:38.096: [iter 62 : loss : 0.2568 = 0.0348 + 0.2161 + 0.0048 + 0.0011, time: 25.894367]
2023-04-09 07:50:38.738: epoch 62:	0.03499417  	0.18485261  	0.12879235  
2023-04-09 07:50:38.738: Find a better model.
2023-04-09 07:51:04.442: [iter 63 : loss : 0.2556 = 0.0346 + 0.2150 + 0.0049 + 0.0011, time: 25.687310]
2023-04-09 07:51:05.056: epoch 63:	0.03514263  	0.18559478  	0.12919044  
2023-04-09 07:51:05.056: Find a better model.
2023-04-09 07:51:30.842: [iter 64 : loss : 0.2541 = 0.0343 + 0.2138 + 0.0050 + 0.0011, time: 25.774018]
2023-04-09 07:51:31.469: epoch 64:	0.03512014  	0.18542637  	0.12935343  
2023-04-09 07:51:57.359: [iter 65 : loss : 0.2530 = 0.0341 + 0.2128 + 0.0051 + 0.0011, time: 25.876045]
2023-04-09 07:51:57.994: epoch 65:	0.03518762  	0.18587713  	0.12980920  
2023-04-09 07:51:57.994: Find a better model.
2023-04-09 07:52:23.791: [iter 66 : loss : 0.2515 = 0.0337 + 0.2116 + 0.0051 + 0.0011, time: 25.784378]
2023-04-09 07:52:24.399: epoch 66:	0.03530007  	0.18671525  	0.13021894  
2023-04-09 07:52:24.399: Find a better model.
2023-04-09 07:52:50.256: [iter 67 : loss : 0.2506 = 0.0339 + 0.2105 + 0.0052 + 0.0011, time: 25.843135]
2023-04-09 07:52:50.876: epoch 67:	0.03530009  	0.18662181  	0.13020237  
2023-04-09 07:53:16.928: [iter 68 : loss : 0.2490 = 0.0332 + 0.2094 + 0.0053 + 0.0011, time: 26.036552]
2023-04-09 07:53:17.502: epoch 68:	0.03548903  	0.18764716  	0.13081688  
2023-04-09 07:53:17.502: Find a better model.
2023-04-09 07:53:43.461: [iter 69 : loss : 0.2482 = 0.0334 + 0.2084 + 0.0054 + 0.0011, time: 25.943692]
2023-04-09 07:53:44.058: epoch 69:	0.03541705  	0.18737502  	0.13078387  
2023-04-09 07:54:09.893: [iter 70 : loss : 0.2470 = 0.0331 + 0.2073 + 0.0055 + 0.0011, time: 25.823138]
2023-04-09 07:54:10.475: epoch 70:	0.03567347  	0.18859126  	0.13154322  
2023-04-09 07:54:10.475: Find a better model.
2023-04-09 07:54:36.576: [iter 71 : loss : 0.2454 = 0.0326 + 0.2062 + 0.0056 + 0.0011, time: 26.086313]
2023-04-09 07:54:37.197: epoch 71:	0.03571397  	0.18888885  	0.13172267  
2023-04-09 07:54:37.197: Find a better model.
2023-04-09 07:55:03.145: [iter 72 : loss : 0.2446 = 0.0326 + 0.2053 + 0.0056 + 0.0011, time: 25.930755]
2023-04-09 07:55:03.733: epoch 72:	0.03571399  	0.18865244  	0.13181035  
2023-04-09 07:55:29.757: [iter 73 : loss : 0.2431 = 0.0323 + 0.2040 + 0.0057 + 0.0011, time: 26.008780]
2023-04-09 07:55:30.338: epoch 73:	0.03585793  	0.18925126  	0.13223776  
2023-04-09 07:55:30.338: Find a better model.
2023-04-09 07:55:56.219: [iter 74 : loss : 0.2426 = 0.0326 + 0.2031 + 0.0058 + 0.0010, time: 25.867963]
2023-04-09 07:55:56.814: epoch 74:	0.03593444  	0.18995422  	0.13268726  
2023-04-09 07:55:56.814: Find a better model.
2023-04-09 07:56:22.897: [iter 75 : loss : 0.2408 = 0.0317 + 0.2021 + 0.0059 + 0.0010, time: 26.068950]
2023-04-09 07:56:23.513: epoch 75:	0.03607841  	0.19075036  	0.13318174  
2023-04-09 07:56:23.513: Find a better model.
2023-04-09 07:56:49.616: [iter 76 : loss : 0.2395 = 0.0316 + 0.2009 + 0.0060 + 0.0010, time: 26.088242]
2023-04-09 07:56:50.232: epoch 76:	0.03615488  	0.19086877  	0.13329428  
2023-04-09 07:56:50.233: Find a better model.
2023-04-09 07:57:16.441: [iter 77 : loss : 0.2385 = 0.0312 + 0.2001 + 0.0061 + 0.0010, time: 26.195733]
2023-04-09 07:57:17.064: epoch 77:	0.03623587  	0.19156708  	0.13387291  
2023-04-09 07:57:17.064: Find a better model.
2023-04-09 07:57:43.271: [iter 78 : loss : 0.2373 = 0.0312 + 0.1990 + 0.0062 + 0.0010, time: 26.192938]
2023-04-09 07:57:43.889: epoch 78:	0.03634832  	0.19183755  	0.13425271  
2023-04-09 07:57:43.890: Find a better model.
2023-04-09 07:58:10.112: [iter 79 : loss : 0.2366 = 0.0315 + 0.1979 + 0.0063 + 0.0010, time: 26.210021]
2023-04-09 07:58:10.718: epoch 79:	0.03643379  	0.19199425  	0.13436976  
2023-04-09 07:58:10.718: Find a better model.
2023-04-09 07:58:36.786: [iter 80 : loss : 0.2340 = 0.0297 + 0.1969 + 0.0064 + 0.0010, time: 26.052890]
2023-04-09 07:58:37.413: epoch 80:	0.03648778  	0.19236609  	0.13437083  
2023-04-09 07:58:37.413: Find a better model.
2023-04-09 07:59:03.485: [iter 81 : loss : 0.2343 = 0.0310 + 0.1958 + 0.0064 + 0.0010, time: 26.058681]
2023-04-09 07:59:04.110: epoch 81:	0.03660475  	0.19264850  	0.13474923  
2023-04-09 07:59:04.110: Find a better model.
2023-04-09 07:59:30.185: [iter 82 : loss : 0.2316 = 0.0291 + 0.1949 + 0.0065 + 0.0010, time: 26.060883]
2023-04-09 07:59:30.774: epoch 82:	0.03675321  	0.19358289  	0.13527036  
2023-04-09 07:59:30.775: Find a better model.
2023-04-09 07:59:56.780: [iter 83 : loss : 0.2315 = 0.0300 + 0.1939 + 0.0066 + 0.0010, time: 25.992592]
2023-04-09 07:59:57.388: epoch 83:	0.03679819  	0.19393314  	0.13561283  
2023-04-09 07:59:57.389: Find a better model.
2023-04-09 08:00:23.472: [iter 84 : loss : 0.2299 = 0.0294 + 0.1928 + 0.0067 + 0.0010, time: 26.068634]
2023-04-09 08:00:24.088: epoch 84:	0.03696913  	0.19495450  	0.13597701  
2023-04-09 08:00:24.088: Find a better model.
2023-04-09 08:00:50.296: [iter 85 : loss : 0.2291 = 0.0296 + 0.1917 + 0.0068 + 0.0010, time: 26.189269]
2023-04-09 08:00:50.900: epoch 85:	0.03698263  	0.19514567  	0.13618740  
2023-04-09 08:00:50.900: Find a better model.
2023-04-09 08:01:17.141: [iter 86 : loss : 0.2283 = 0.0296 + 0.1908 + 0.0069 + 0.0010, time: 26.229387]
2023-04-09 08:01:17.769: epoch 86:	0.03695564  	0.19498707  	0.13638777  
2023-04-09 08:01:43.937: [iter 87 : loss : 0.2271 = 0.0293 + 0.1898 + 0.0070 + 0.0010, time: 26.153455]
2023-04-09 08:01:44.550: epoch 87:	0.03715359  	0.19604185  	0.13708414  
2023-04-09 08:01:44.550: Find a better model.
2023-04-09 08:02:10.731: [iter 88 : loss : 0.2261 = 0.0292 + 0.1888 + 0.0071 + 0.0010, time: 26.169206]
2023-04-09 08:02:11.335: epoch 88:	0.03717608  	0.19648324  	0.13741811  
2023-04-09 08:02:11.335: Find a better model.
2023-04-09 08:02:37.376: [iter 89 : loss : 0.2241 = 0.0281 + 0.1878 + 0.0072 + 0.0010, time: 26.024146]
2023-04-09 08:02:38.003: epoch 89:	0.03717608  	0.19646229  	0.13751595  
2023-04-09 08:03:04.224: [iter 90 : loss : 0.2236 = 0.0285 + 0.1868 + 0.0073 + 0.0010, time: 26.208748]
2023-04-09 08:03:04.846: epoch 90:	0.03734703  	0.19719009  	0.13798773  
2023-04-09 08:03:04.846: Find a better model.
2023-04-09 08:03:30.766: [iter 91 : loss : 0.2225 = 0.0284 + 0.1858 + 0.0074 + 0.0010, time: 25.898124]
2023-04-09 08:03:31.376: epoch 91:	0.03743253  	0.19738370  	0.13817197  
2023-04-09 08:03:31.376: Find a better model.
2023-04-09 08:03:57.570: [iter 92 : loss : 0.2212 = 0.0281 + 0.1847 + 0.0075 + 0.0010, time: 26.176393]
2023-04-09 08:03:58.183: epoch 92:	0.03753150  	0.19764122  	0.13852637  
2023-04-09 08:03:58.183: Find a better model.
2023-04-09 08:04:24.390: [iter 93 : loss : 0.2196 = 0.0274 + 0.1837 + 0.0076 + 0.0009, time: 26.191855]
2023-04-09 08:04:24.978: epoch 93:	0.03758099  	0.19771147  	0.13865091  
2023-04-09 08:04:24.978: Find a better model.
2023-04-09 08:04:51.264: [iter 94 : loss : 0.2191 = 0.0278 + 0.1827 + 0.0077 + 0.0009, time: 26.273107]
2023-04-09 08:04:51.885: epoch 94:	0.03764847  	0.19842476  	0.13913588  
2023-04-09 08:04:51.886: Find a better model.
2023-04-09 08:05:18.122: [iter 95 : loss : 0.2178 = 0.0272 + 0.1818 + 0.0078 + 0.0009, time: 26.221347]
2023-04-09 08:05:18.705: epoch 95:	0.03765297  	0.19842902  	0.13932499  
2023-04-09 08:05:18.705: Find a better model.
2023-04-09 08:05:45.083: [iter 96 : loss : 0.2163 = 0.0268 + 0.1806 + 0.0079 + 0.0009, time: 26.366012]
2023-04-09 08:05:45.713: epoch 96:	0.03778344  	0.19917132  	0.13962150  
2023-04-09 08:05:45.713: Find a better model.
2023-04-09 08:06:11.769: [iter 97 : loss : 0.2147 = 0.0259 + 0.1799 + 0.0080 + 0.0009, time: 26.040126]
2023-04-09 08:06:12.392: epoch 97:	0.03780141  	0.19934465  	0.13970350  
2023-04-09 08:06:12.392: Find a better model.
2023-04-09 08:06:38.356: [iter 98 : loss : 0.2149 = 0.0270 + 0.1789 + 0.0081 + 0.0009, time: 25.949415]
2023-04-09 08:06:38.953: epoch 98:	0.03791388  	0.19967747  	0.13995828  
2023-04-09 08:06:38.954: Find a better model.
2023-04-09 08:07:05.014: [iter 99 : loss : 0.2135 = 0.0266 + 0.1778 + 0.0082 + 0.0009, time: 26.048843]
2023-04-09 08:07:05.622: epoch 99:	0.03805335  	0.20030782  	0.14032292  
2023-04-09 08:07:05.622: Find a better model.
2023-04-09 08:07:31.987: [iter 100 : loss : 0.2127 = 0.0267 + 0.1769 + 0.0083 + 0.0009, time: 26.352683]
2023-04-09 08:07:32.585: epoch 100:	0.03807585  	0.20040424  	0.14061709  
2023-04-09 08:07:32.585: Find a better model.
2023-04-09 08:07:58.846: [iter 101 : loss : 0.2126 = 0.0274 + 0.1759 + 0.0084 + 0.0009, time: 26.244978]
2023-04-09 08:07:59.425: epoch 101:	0.03821084  	0.20094988  	0.14083976  
2023-04-09 08:07:59.425: Find a better model.
2023-04-09 08:08:25.528: [iter 102 : loss : 0.2116 = 0.0273 + 0.1749 + 0.0085 + 0.0009, time: 26.088462]
2023-04-09 08:08:26.129: epoch 102:	0.03820183  	0.20100799  	0.14109668  
2023-04-09 08:08:26.129: Find a better model.
2023-04-09 08:08:52.408: [iter 103 : loss : 0.2101 = 0.0267 + 0.1739 + 0.0086 + 0.0009, time: 26.265121]
2023-04-09 08:08:53.029: epoch 103:	0.03825581  	0.20119698  	0.14124224  
2023-04-09 08:08:53.030: Find a better model.
2023-04-09 08:09:19.322: [iter 104 : loss : 0.2082 = 0.0257 + 0.1730 + 0.0087 + 0.0009, time: 26.278119]
2023-04-09 08:09:19.944: epoch 104:	0.03830079  	0.20130832  	0.14134853  
2023-04-09 08:09:19.944: Find a better model.
2023-04-09 08:09:46.042: [iter 105 : loss : 0.2070 = 0.0252 + 0.1721 + 0.0088 + 0.0009, time: 26.082457]
2023-04-09 08:09:46.634: epoch 105:	0.03839978  	0.20180815  	0.14171250  
2023-04-09 08:09:46.634: Find a better model.
2023-04-09 08:10:12.945: [iter 106 : loss : 0.2060 = 0.0251 + 0.1711 + 0.0089 + 0.0009, time: 26.295994]
2023-04-09 08:10:13.568: epoch 106:	0.03839526  	0.20184150  	0.14174110  
2023-04-09 08:10:13.568: Find a better model.
2023-04-09 08:10:39.684: [iter 107 : loss : 0.2055 = 0.0255 + 0.1701 + 0.0090 + 0.0009, time: 26.100552]
2023-04-09 08:10:40.302: epoch 107:	0.03845825  	0.20211241  	0.14190285  
2023-04-09 08:10:40.302: Find a better model.
2023-04-09 08:11:06.603: [iter 108 : loss : 0.2051 = 0.0260 + 0.1691 + 0.0091 + 0.0009, time: 26.281901]
2023-04-09 08:11:07.218: epoch 108:	0.03840878  	0.20187932  	0.14168717  
2023-04-09 08:11:33.326: [iter 109 : loss : 0.2037 = 0.0253 + 0.1683 + 0.0092 + 0.0009, time: 26.093211]
2023-04-09 08:11:33.992: epoch 109:	0.03852575  	0.20266497  	0.14201163  
2023-04-09 08:11:33.992: Find a better model.
2023-04-09 08:12:00.107: [iter 110 : loss : 0.2034 = 0.0259 + 0.1673 + 0.0093 + 0.0009, time: 26.101897]
2023-04-09 08:12:00.726: epoch 110:	0.03851227  	0.20262977  	0.14208589  
2023-04-09 08:12:26.959: [iter 111 : loss : 0.2021 = 0.0253 + 0.1665 + 0.0094 + 0.0009, time: 26.218862]
2023-04-09 08:12:27.583: epoch 111:	0.03850777  	0.20255718  	0.14235233  
2023-04-09 08:12:53.672: [iter 112 : loss : 0.2006 = 0.0246 + 0.1656 + 0.0095 + 0.0009, time: 26.076477]
2023-04-09 08:12:54.316: epoch 112:	0.03852574  	0.20228405  	0.14220951  
2023-04-09 08:13:20.235: [iter 113 : loss : 0.1995 = 0.0246 + 0.1645 + 0.0096 + 0.0008, time: 25.904646]
2023-04-09 08:13:20.854: epoch 113:	0.03856624  	0.20280218  	0.14245598  
2023-04-09 08:13:20.854: Find a better model.
2023-04-09 08:13:46.926: [iter 114 : loss : 0.1989 = 0.0248 + 0.1636 + 0.0097 + 0.0008, time: 26.059372]
2023-04-09 08:13:47.557: epoch 114:	0.03859324  	0.20282853  	0.14259028  
2023-04-09 08:13:47.557: Find a better model.
2023-04-09 08:14:13.605: [iter 115 : loss : 0.1981 = 0.0248 + 0.1626 + 0.0098 + 0.0008, time: 26.032628]
2023-04-09 08:14:14.217: epoch 115:	0.03859323  	0.20290060  	0.14275049  
2023-04-09 08:14:14.218: Find a better model.
2023-04-09 08:14:40.371: [iter 116 : loss : 0.1968 = 0.0242 + 0.1618 + 0.0099 + 0.0008, time: 26.139882]
2023-04-09 08:14:40.985: epoch 116:	0.03876418  	0.20378207  	0.14306998  
2023-04-09 08:14:40.986: Find a better model.
2023-04-09 08:15:06.984: [iter 117 : loss : 0.1969 = 0.0250 + 0.1611 + 0.0100 + 0.0008, time: 25.985781]
2023-04-09 08:15:07.611: epoch 117:	0.03880018  	0.20405623  	0.14327320  
2023-04-09 08:15:07.611: Find a better model.
2023-04-09 08:15:33.892: [iter 118 : loss : 0.1947 = 0.0236 + 0.1601 + 0.0101 + 0.0008, time: 26.267503]
2023-04-09 08:15:34.515: epoch 118:	0.03889915  	0.20444505  	0.14349595  
2023-04-09 08:15:34.515: Find a better model.
2023-04-09 08:16:00.651: [iter 119 : loss : 0.1946 = 0.0244 + 0.1591 + 0.0103 + 0.0008, time: 26.121768]
2023-04-09 08:16:01.268: epoch 119:	0.03890365  	0.20465171  	0.14365441  
2023-04-09 08:16:01.269: Find a better model.
2023-04-09 08:16:27.450: [iter 120 : loss : 0.1935 = 0.0241 + 0.1583 + 0.0104 + 0.0008, time: 26.166511]
2023-04-09 08:16:28.023: epoch 120:	0.03892616  	0.20445682  	0.14364891  
2023-04-09 08:16:54.000: [iter 121 : loss : 0.1930 = 0.0243 + 0.1574 + 0.0105 + 0.0008, time: 25.962924]
2023-04-09 08:16:54.582: epoch 121:	0.03898915  	0.20470262  	0.14376839  
2023-04-09 08:16:54.582: Find a better model.
2023-04-09 08:17:20.999: [iter 122 : loss : 0.1922 = 0.0242 + 0.1566 + 0.0106 + 0.0008, time: 26.400728]
2023-04-09 08:17:21.608: epoch 122:	0.03905215  	0.20486061  	0.14387068  
2023-04-09 08:17:21.608: Find a better model.
2023-04-09 08:17:47.478: [iter 123 : loss : 0.1906 = 0.0235 + 0.1556 + 0.0107 + 0.0008, time: 25.855231]
2023-04-09 08:17:48.133: epoch 123:	0.03905666  	0.20492832  	0.14395460  
2023-04-09 08:17:48.133: Find a better model.
2023-04-09 08:18:14.157: [iter 124 : loss : 0.1899 = 0.0236 + 0.1547 + 0.0108 + 0.0008, time: 26.009585]
2023-04-09 08:18:14.804: epoch 124:	0.03904315  	0.20476371  	0.14397529  
2023-04-09 08:18:40.868: [iter 125 : loss : 0.1889 = 0.0235 + 0.1537 + 0.0109 + 0.0008, time: 26.050273]
2023-04-09 08:18:41.484: epoch 125:	0.03915562  	0.20502870  	0.14414929  
2023-04-09 08:18:41.484: Find a better model.
2023-04-09 08:19:07.521: [iter 126 : loss : 0.1878 = 0.0229 + 0.1530 + 0.0110 + 0.0008, time: 26.022327]
2023-04-09 08:19:08.156: epoch 126:	0.03905663  	0.20469446  	0.14395498  
2023-04-09 08:19:34.451: [iter 127 : loss : 0.1874 = 0.0233 + 0.1522 + 0.0111 + 0.0008, time: 26.282349]
2023-04-09 08:19:35.051: epoch 127:	0.03921858  	0.20556989  	0.14438759  
2023-04-09 08:19:35.051: Find a better model.
2023-04-09 08:20:01.107: [iter 128 : loss : 0.1863 = 0.0231 + 0.1512 + 0.0112 + 0.0008, time: 26.042817]
2023-04-09 08:20:01.732: epoch 128:	0.03934004  	0.20599808  	0.14443475  
2023-04-09 08:20:01.733: Find a better model.
2023-04-09 08:20:27.972: [iter 129 : loss : 0.1857 = 0.0234 + 0.1502 + 0.0114 + 0.0008, time: 26.223011]
2023-04-09 08:20:28.561: epoch 129:	0.03942556  	0.20641652  	0.14479451  
2023-04-09 08:20:28.561: Find a better model.
2023-04-09 08:20:54.951: [iter 130 : loss : 0.1851 = 0.0236 + 0.1494 + 0.0115 + 0.0008, time: 26.377145]
2023-04-09 08:20:55.562: epoch 130:	0.03951103  	0.20669642  	0.14491270  
2023-04-09 08:20:55.562: Find a better model.
2023-04-09 08:21:21.669: [iter 131 : loss : 0.1840 = 0.0232 + 0.1484 + 0.0116 + 0.0008, time: 26.093129]
2023-04-09 08:21:22.279: epoch 131:	0.03939855  	0.20636822  	0.14483123  
2023-04-09 08:21:48.490: [iter 132 : loss : 0.1837 = 0.0236 + 0.1477 + 0.0117 + 0.0008, time: 26.195510]
2023-04-09 08:21:49.103: epoch 132:	0.03938055  	0.20614243  	0.14483501  
2023-04-09 08:22:15.446: [iter 133 : loss : 0.1822 = 0.0228 + 0.1469 + 0.0118 + 0.0008, time: 26.327815]
2023-04-09 08:22:16.061: epoch 133:	0.03940306  	0.20633505  	0.14499250  
2023-04-09 08:22:42.089: [iter 134 : loss : 0.1819 = 0.0230 + 0.1463 + 0.0119 + 0.0008, time: 26.013013]
2023-04-09 08:22:42.708: epoch 134:	0.03952452  	0.20692481  	0.14552075  
2023-04-09 08:22:42.708: Find a better model.
2023-04-09 08:23:08.765: [iter 135 : loss : 0.1809 = 0.0229 + 0.1452 + 0.0120 + 0.0007, time: 26.043643]
2023-04-09 08:23:09.390: epoch 135:	0.03950652  	0.20688353  	0.14539638  
2023-04-09 08:23:35.424: [iter 136 : loss : 0.1799 = 0.0227 + 0.1444 + 0.0121 + 0.0007, time: 26.017939]
2023-04-09 08:23:35.986: epoch 136:	0.03945704  	0.20655482  	0.14541431  
2023-04-09 08:24:02.011: [iter 137 : loss : 0.1783 = 0.0218 + 0.1435 + 0.0122 + 0.0007, time: 26.012283]
2023-04-09 08:24:02.645: epoch 137:	0.03942554  	0.20632747  	0.14541735  
2023-04-09 08:24:28.756: [iter 138 : loss : 0.1786 = 0.0229 + 0.1427 + 0.0124 + 0.0007, time: 26.096288]
2023-04-09 08:24:29.368: epoch 138:	0.03952450  	0.20685112  	0.14563046  
2023-04-09 08:24:55.740: [iter 139 : loss : 0.1787 = 0.0236 + 0.1419 + 0.0125 + 0.0007, time: 26.357580]
2023-04-09 08:24:56.319: epoch 139:	0.03960998  	0.20706493  	0.14555027  
2023-04-09 08:24:56.319: Find a better model.
2023-04-09 08:25:22.331: [iter 140 : loss : 0.1773 = 0.0229 + 0.1411 + 0.0126 + 0.0007, time: 25.998778]
2023-04-09 08:25:22.936: epoch 140:	0.03967747  	0.20784034  	0.14576451  
2023-04-09 08:25:22.936: Find a better model.
2023-04-09 08:25:48.957: [iter 141 : loss : 0.1765 = 0.0228 + 0.1403 + 0.0127 + 0.0007, time: 26.002992]
2023-04-09 08:25:49.542: epoch 141:	0.03974494  	0.20819113  	0.14580905  
2023-04-09 08:25:49.542: Find a better model.
2023-04-09 08:26:15.785: [iter 142 : loss : 0.1749 = 0.0218 + 0.1396 + 0.0128 + 0.0007, time: 26.228486]
2023-04-09 08:26:16.387: epoch 142:	0.03983494  	0.20843089  	0.14618957  
2023-04-09 08:26:16.387: Find a better model.
2023-04-09 08:26:42.608: [iter 143 : loss : 0.1746 = 0.0222 + 0.1388 + 0.0129 + 0.0007, time: 26.208865]
2023-04-09 08:26:43.176: epoch 143:	0.03988893  	0.20831977  	0.14615270  
2023-04-09 08:27:09.080: [iter 144 : loss : 0.1737 = 0.0221 + 0.1379 + 0.0130 + 0.0007, time: 25.890791]
2023-04-09 08:27:09.682: epoch 144:	0.03983943  	0.20826931  	0.14625399  
2023-04-09 08:27:35.762: [iter 145 : loss : 0.1727 = 0.0218 + 0.1371 + 0.0131 + 0.0007, time: 26.067217]
2023-04-09 08:27:36.392: epoch 145:	0.03984842  	0.20831615  	0.14618167  
2023-04-09 08:28:02.351: [iter 146 : loss : 0.1713 = 0.0211 + 0.1363 + 0.0133 + 0.0007, time: 25.940493]
2023-04-09 08:28:02.962: epoch 146:	0.03995191  	0.20874010  	0.14653142  
2023-04-09 08:28:02.963: Find a better model.
2023-04-09 08:28:29.198: [iter 147 : loss : 0.1714 = 0.0218 + 0.1355 + 0.0134 + 0.0007, time: 26.221524]
2023-04-09 08:28:29.808: epoch 147:	0.03996541  	0.20863912  	0.14646204  
2023-04-09 08:28:55.622: [iter 148 : loss : 0.1709 = 0.0219 + 0.1348 + 0.0135 + 0.0007, time: 25.799016]
2023-04-09 08:28:56.241: epoch 148:	0.03992042  	0.20863619  	0.14636517  
2023-04-09 08:29:22.105: [iter 149 : loss : 0.1700 = 0.0218 + 0.1339 + 0.0136 + 0.0007, time: 25.849342]
2023-04-09 08:29:22.672: epoch 149:	0.03995642  	0.20881456  	0.14637628  
2023-04-09 08:29:22.673: Find a better model.
2023-04-09 08:29:48.617: [iter 150 : loss : 0.1692 = 0.0217 + 0.1332 + 0.0137 + 0.0007, time: 25.931204]
2023-04-09 08:29:49.209: epoch 150:	0.03996540  	0.20887361  	0.14642075  
2023-04-09 08:29:49.209: Find a better model.
2023-04-09 08:30:15.088: [iter 151 : loss : 0.1687 = 0.0217 + 0.1325 + 0.0138 + 0.0007, time: 25.866262]
2023-04-09 08:30:15.712: epoch 151:	0.03999691  	0.20877497  	0.14646855  
2023-04-09 08:30:41.575: [iter 152 : loss : 0.1678 = 0.0216 + 0.1316 + 0.0139 + 0.0007, time: 25.846954]
2023-04-09 08:30:42.183: epoch 152:	0.03996992  	0.20857368  	0.14637895  
2023-04-09 08:31:08.234: [iter 153 : loss : 0.1665 = 0.0209 + 0.1309 + 0.0140 + 0.0007, time: 26.035314]
2023-04-09 08:31:08.853: epoch 153:	0.03998340  	0.20871042  	0.14647369  
2023-04-09 08:31:34.722: [iter 154 : loss : 0.1659 = 0.0209 + 0.1301 + 0.0142 + 0.0007, time: 25.853478]
2023-04-09 08:31:35.344: epoch 154:	0.04007339  	0.20922983  	0.14662911  
2023-04-09 08:31:35.344: Find a better model.
2023-04-09 08:32:01.126: [iter 155 : loss : 0.1657 = 0.0214 + 0.1294 + 0.0143 + 0.0007, time: 25.769904]
2023-04-09 08:32:01.740: epoch 155:	0.04004190  	0.20905787  	0.14666948  
2023-04-09 08:32:27.538: [iter 156 : loss : 0.1647 = 0.0210 + 0.1287 + 0.0144 + 0.0007, time: 25.784686]
2023-04-09 08:32:28.114: epoch 156:	0.04002392  	0.20908970  	0.14663409  
2023-04-09 08:32:54.010: [iter 157 : loss : 0.1653 = 0.0222 + 0.1280 + 0.0145 + 0.0007, time: 25.884526]
2023-04-09 08:32:54.637: epoch 157:	0.04007790  	0.20938888  	0.14670402  
2023-04-09 08:32:54.637: Find a better model.
2023-04-09 08:33:20.494: [iter 158 : loss : 0.1628 = 0.0206 + 0.1270 + 0.0146 + 0.0007, time: 25.841954]
2023-04-09 08:33:21.099: epoch 158:	0.04009140  	0.20935468  	0.14679146  
2023-04-09 08:33:47.027: [iter 159 : loss : 0.1640 = 0.0223 + 0.1264 + 0.0147 + 0.0006, time: 25.914119]
2023-04-09 08:33:47.625: epoch 159:	0.04007791  	0.20954786  	0.14673643  
2023-04-09 08:33:47.625: Find a better model.
2023-04-09 08:34:13.471: [iter 160 : loss : 0.1623 = 0.0212 + 0.1257 + 0.0148 + 0.0006, time: 25.833721]
2023-04-09 08:34:14.120: epoch 160:	0.04009591  	0.20930305  	0.14664416  
2023-04-09 08:34:39.999: [iter 161 : loss : 0.1609 = 0.0205 + 0.1248 + 0.0149 + 0.0006, time: 25.864464]
2023-04-09 08:34:40.610: epoch 161:	0.04011390  	0.20939410  	0.14647590  
2023-04-09 08:35:06.389: [iter 162 : loss : 0.1618 = 0.0218 + 0.1243 + 0.0150 + 0.0006, time: 25.765143]
2023-04-09 08:35:07.022: epoch 162:	0.04005993  	0.20900433  	0.14647661  
2023-04-09 08:35:32.968: [iter 163 : loss : 0.1599 = 0.0207 + 0.1234 + 0.0152 + 0.0006, time: 25.931444]
2023-04-09 08:35:33.576: epoch 163:	0.04001043  	0.20873657  	0.14642063  
2023-04-09 08:35:59.481: [iter 164 : loss : 0.1593 = 0.0207 + 0.1227 + 0.0153 + 0.0006, time: 25.892468]
2023-04-09 08:36:00.097: epoch 164:	0.04008691  	0.20935889  	0.14675257  
2023-04-09 08:36:26.034: [iter 165 : loss : 0.1592 = 0.0213 + 0.1220 + 0.0154 + 0.0006, time: 25.922096]
2023-04-09 08:36:26.652: epoch 165:	0.04027138  	0.21010128  	0.14699946  
2023-04-09 08:36:26.653: Find a better model.
2023-04-09 08:36:52.513: [iter 166 : loss : 0.1585 = 0.0210 + 0.1214 + 0.0155 + 0.0006, time: 25.844118]
2023-04-09 08:36:53.129: epoch 166:	0.04026687  	0.20983624  	0.14698544  
2023-04-09 08:37:19.099: [iter 167 : loss : 0.1576 = 0.0208 + 0.1206 + 0.0156 + 0.0006, time: 25.951471]
2023-04-09 08:37:19.701: epoch 167:	0.04026690  	0.20967016  	0.14690033  
2023-04-09 08:37:45.519: [iter 168 : loss : 0.1574 = 0.0212 + 0.1199 + 0.0157 + 0.0006, time: 25.803295]
2023-04-09 08:37:46.101: epoch 168:	0.04027588  	0.20985427  	0.14699334  
2023-04-09 08:38:11.876: [iter 169 : loss : 0.1566 = 0.0208 + 0.1194 + 0.0158 + 0.0006, time: 25.761179]
2023-04-09 08:38:12.492: epoch 169:	0.04034786  	0.21042058  	0.14734127  
2023-04-09 08:38:12.492: Find a better model.
2023-04-09 08:38:38.388: [iter 170 : loss : 0.1556 = 0.0205 + 0.1185 + 0.0159 + 0.0006, time: 25.879503]
2023-04-09 08:38:39.007: epoch 170:	0.04033438  	0.21021226  	0.14742033  
2023-04-09 08:39:04.817: [iter 171 : loss : 0.1547 = 0.0201 + 0.1179 + 0.0161 + 0.0006, time: 25.795266]
2023-04-09 08:39:05.426: epoch 171:	0.04037487  	0.21028692  	0.14736666  
2023-04-09 08:39:31.221: [iter 172 : loss : 0.1544 = 0.0205 + 0.1171 + 0.0162 + 0.0006, time: 25.779058]
2023-04-09 08:39:31.807: epoch 172:	0.04032987  	0.21031527  	0.14719419  
2023-04-09 08:39:57.769: [iter 173 : loss : 0.1542 = 0.0209 + 0.1165 + 0.0163 + 0.0006, time: 25.946086]
2023-04-09 08:39:58.389: epoch 173:	0.04041085  	0.21062572  	0.14739640  
2023-04-09 08:39:58.389: Find a better model.
2023-04-09 08:40:24.263: [iter 174 : loss : 0.1531 = 0.0202 + 0.1160 + 0.0164 + 0.0006, time: 25.859597]
2023-04-09 08:40:24.875: epoch 174:	0.04049184  	0.21106824  	0.14766492  
2023-04-09 08:40:24.876: Find a better model.
2023-04-09 08:40:50.725: [iter 175 : loss : 0.1530 = 0.0208 + 0.1152 + 0.0165 + 0.0006, time: 25.834678]
2023-04-09 08:40:51.356: epoch 175:	0.04049634  	0.21111009  	0.14777146  
2023-04-09 08:40:51.356: Find a better model.
2023-04-09 08:41:17.194: [iter 176 : loss : 0.1520 = 0.0201 + 0.1146 + 0.0166 + 0.0006, time: 25.817025]
2023-04-09 08:41:17.837: epoch 176:	0.04041085  	0.21082050  	0.14766866  
2023-04-09 08:41:43.686: [iter 177 : loss : 0.1517 = 0.0206 + 0.1138 + 0.0167 + 0.0006, time: 25.832997]
2023-04-09 08:41:44.294: epoch 177:	0.04046036  	0.21115756  	0.14752711  
2023-04-09 08:41:44.295: Find a better model.
2023-04-09 08:42:10.118: [iter 178 : loss : 0.1514 = 0.0207 + 0.1133 + 0.0168 + 0.0006, time: 25.808947]
2023-04-09 08:42:10.720: epoch 178:	0.04049181  	0.21117516  	0.14747480  
2023-04-09 08:42:10.720: Find a better model.
2023-04-09 08:42:36.559: [iter 179 : loss : 0.1505 = 0.0203 + 0.1126 + 0.0169 + 0.0006, time: 25.823689]
2023-04-09 08:42:37.165: epoch 179:	0.04051881  	0.21138944  	0.14754583  
2023-04-09 08:42:37.165: Find a better model.
2023-04-09 08:43:02.995: [iter 180 : loss : 0.1491 = 0.0196 + 0.1118 + 0.0171 + 0.0006, time: 25.817445]
2023-04-09 08:43:03.601: epoch 180:	0.04045131  	0.21122070  	0.14745434  
2023-04-09 08:43:29.510: [iter 181 : loss : 0.1491 = 0.0200 + 0.1114 + 0.0172 + 0.0006, time: 25.897880]
2023-04-09 08:43:30.127: epoch 181:	0.04048282  	0.21109489  	0.14743137  
2023-04-09 08:43:55.992: [iter 182 : loss : 0.1485 = 0.0199 + 0.1108 + 0.0173 + 0.0006, time: 25.850181]
2023-04-09 08:43:56.593: epoch 182:	0.04058180  	0.21184608  	0.14762470  
2023-04-09 08:43:56.593: Find a better model.
2023-04-09 08:44:22.446: [iter 183 : loss : 0.1473 = 0.0193 + 0.1100 + 0.0174 + 0.0006, time: 25.836506]
2023-04-09 08:44:23.052: epoch 183:	0.04054580  	0.21143310  	0.14764233  
2023-04-09 08:44:48.979: [iter 184 : loss : 0.1463 = 0.0189 + 0.1094 + 0.0175 + 0.0006, time: 25.914624]
2023-04-09 08:44:49.575: epoch 184:	0.04056381  	0.21149856  	0.14761354  
2023-04-09 08:45:15.576: [iter 185 : loss : 0.1467 = 0.0196 + 0.1089 + 0.0176 + 0.0006, time: 25.985926]
2023-04-09 08:45:16.155: epoch 185:	0.04065829  	0.21199517  	0.14794146  
2023-04-09 08:45:16.156: Find a better model.
2023-04-09 08:45:42.048: [iter 186 : loss : 0.1460 = 0.0197 + 0.1080 + 0.0177 + 0.0006, time: 25.881397]
2023-04-09 08:45:42.661: epoch 186:	0.04064479  	0.21174802  	0.14779018  
2023-04-09 08:46:08.788: [iter 187 : loss : 0.1458 = 0.0200 + 0.1074 + 0.0178 + 0.0006, time: 26.113724]
2023-04-09 08:46:09.378: epoch 187:	0.04062230  	0.21183464  	0.14762412  
2023-04-09 08:46:35.258: [iter 188 : loss : 0.1445 = 0.0192 + 0.1068 + 0.0180 + 0.0005, time: 25.867275]
2023-04-09 08:46:35.859: epoch 188:	0.04074825  	0.21259059  	0.14796326  
2023-04-09 08:46:35.859: Find a better model.
2023-04-09 08:47:02.052: [iter 189 : loss : 0.1452 = 0.0202 + 0.1065 + 0.0181 + 0.0005, time: 26.178925]
2023-04-09 08:47:02.667: epoch 189:	0.04078873  	0.21269779  	0.14789779  
2023-04-09 08:47:02.667: Find a better model.
2023-04-09 08:47:29.042: [iter 190 : loss : 0.1431 = 0.0188 + 0.1056 + 0.0182 + 0.0005, time: 26.360930]
2023-04-09 08:47:29.634: epoch 190:	0.04091021  	0.21309409  	0.14811672  
2023-04-09 08:47:29.634: Find a better model.
2023-04-09 08:47:55.701: [iter 191 : loss : 0.1440 = 0.0200 + 0.1052 + 0.0183 + 0.0005, time: 26.052586]
2023-04-09 08:47:56.310: epoch 191:	0.04078874  	0.21222952  	0.14775105  
2023-04-09 08:48:22.516: [iter 192 : loss : 0.1429 = 0.0195 + 0.1045 + 0.0184 + 0.0005, time: 26.192184]
2023-04-09 08:48:23.127: epoch 192:	0.04081573  	0.21246533  	0.14786436  
2023-04-09 08:48:49.113: [iter 193 : loss : 0.1425 = 0.0196 + 0.1039 + 0.0185 + 0.0005, time: 25.973777]
2023-04-09 08:48:49.731: epoch 193:	0.04081574  	0.21285212  	0.14799455  
2023-04-09 08:49:15.713: [iter 194 : loss : 0.1422 = 0.0197 + 0.1033 + 0.0186 + 0.0005, time: 25.966985]
2023-04-09 08:49:16.320: epoch 194:	0.04083373  	0.21278462  	0.14811727  
2023-04-09 08:49:42.478: [iter 195 : loss : 0.1417 = 0.0198 + 0.1027 + 0.0187 + 0.0005, time: 26.145116]
2023-04-09 08:49:43.092: epoch 195:	0.04079774  	0.21278252  	0.14817165  
2023-04-09 08:50:09.189: [iter 196 : loss : 0.1409 = 0.0193 + 0.1023 + 0.0188 + 0.0005, time: 26.082856]
2023-04-09 08:50:09.803: epoch 196:	0.04082473  	0.21276525  	0.14821230  
2023-04-09 08:50:35.808: [iter 197 : loss : 0.1405 = 0.0194 + 0.1016 + 0.0189 + 0.0005, time: 25.991264]
2023-04-09 08:50:36.422: epoch 197:	0.04083374  	0.21260692  	0.14823715  
2023-04-09 08:51:02.493: [iter 198 : loss : 0.1400 = 0.0194 + 0.1011 + 0.0190 + 0.0005, time: 26.055638]
2023-04-09 08:51:03.110: epoch 198:	0.04081124  	0.21271947  	0.14831232  
2023-04-09 08:51:29.134: [iter 199 : loss : 0.1393 = 0.0192 + 0.1005 + 0.0192 + 0.0005, time: 26.011656]
2023-04-09 08:51:29.712: epoch 199:	0.04088321  	0.21288548  	0.14831653  
2023-04-09 08:51:56.089: [iter 200 : loss : 0.1379 = 0.0184 + 0.0997 + 0.0193 + 0.0005, time: 26.363779]
2023-04-09 08:51:56.694: epoch 200:	0.04092370  	0.21301806  	0.14844792  
2023-04-09 08:51:56.694: Early stopping is trigger at epoch: 200
2023-04-09 08:51:56.694: best_result@epoch 190:

2023-04-09 08:51:56.694: 		0.0409      	0.2131      	0.1481      

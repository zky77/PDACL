2023-04-30 15:22:00.382: my pid: 6532
2023-04-30 15:22:00.382: model: model.general_recommender.GNNEC
2023-04-30 15:22:00.382: Dataset statistics:
Name: gowalla-20core
The number of users: 11113
The number of items: 18074
The number of ratings: 523315
Average actions of users: 47.09
Average actions of items: 28.95
The sparsity of the dataset: 99.739458%

The number of training: 475362
The number of validation: 0
The number of testing: 47953
2023-04-30 15:22:00.382: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=gowalla-20core
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=gowalla-20core
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.5
mf_reg=1e-4
svd_q=5
2023-04-30 15:22:09.542: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-04-30 15:23:17.312: [iter 1 : loss : 0.8776 = 0.5292 + 0.3466 + 0.0001 + 0.0018, time: 67.761938]
2023-04-30 15:23:18.424: epoch 1:	0.01920333  	0.10178646  	0.06866714  
2023-04-30 15:23:18.425: Find a better model.
2023-04-30 15:24:25.655: [iter 2 : loss : 0.5523 = 0.2378 + 0.3126 + 0.0004 + 0.0016, time: 67.210927]
2023-04-30 15:24:26.769: epoch 2:	0.02123707  	0.11292046  	0.07718906  
2023-04-30 15:24:26.770: Find a better model.
2023-04-30 15:25:35.524: [iter 3 : loss : 0.4699 = 0.1676 + 0.3002 + 0.0006 + 0.0015, time: 68.731903]
2023-04-30 15:25:36.636: epoch 3:	0.02300983  	0.12230248  	0.08465926  
2023-04-30 15:25:36.636: Find a better model.
2023-04-30 15:26:45.818: [iter 4 : loss : 0.4301 = 0.1380 + 0.2899 + 0.0007 + 0.0015, time: 69.159277]
2023-04-30 15:26:46.928: epoch 4:	0.02407598  	0.12801479  	0.08896177  
2023-04-30 15:26:46.929: Find a better model.
2023-04-30 15:27:55.687: [iter 5 : loss : 0.4061 = 0.1204 + 0.2834 + 0.0008 + 0.0014, time: 68.730765]
2023-04-30 15:27:56.742: epoch 5:	0.02472378  	0.13122174  	0.09170719  
2023-04-30 15:27:56.742: Find a better model.
2023-04-30 15:29:07.307: [iter 6 : loss : 0.3903 = 0.1092 + 0.2788 + 0.0009 + 0.0014, time: 70.547517]
2023-04-30 15:29:08.441: epoch 6:	0.02542104  	0.13524352  	0.09404354  
2023-04-30 15:29:08.441: Find a better model.
2023-04-30 15:30:11.776: [iter 7 : loss : 0.3761 = 0.0998 + 0.2739 + 0.0010 + 0.0014, time: 63.314699]
2023-04-30 15:30:12.807: epoch 7:	0.02598786  	0.13864319  	0.09582239  
2023-04-30 15:30:12.808: Find a better model.
2023-04-30 15:31:14.171: [iter 8 : loss : 0.3657 = 0.0938 + 0.2694 + 0.0011 + 0.0014, time: 61.341685]
2023-04-30 15:31:15.152: epoch 8:	0.02642872  	0.14085813  	0.09731536  
2023-04-30 15:31:15.152: Find a better model.
2023-04-30 15:32:16.064: [iter 9 : loss : 0.3539 = 0.0880 + 0.2634 + 0.0012 + 0.0014, time: 60.890646]
2023-04-30 15:32:17.035: epoch 9:	0.02697304  	0.14387973  	0.09936658  
2023-04-30 15:32:17.035: Find a better model.
2023-04-30 15:33:17.696: [iter 10 : loss : 0.3470 = 0.0840 + 0.2604 + 0.0012 + 0.0013, time: 60.640934]
2023-04-30 15:33:18.673: epoch 10:	0.02757134  	0.14662001  	0.10099980  
2023-04-30 15:33:18.674: Find a better model.
2023-04-30 15:34:19.408: [iter 11 : loss : 0.3399 = 0.0797 + 0.2575 + 0.0013 + 0.0013, time: 60.715086]
2023-04-30 15:34:20.436: epoch 11:	0.02802119  	0.14901149  	0.10206097  
2023-04-30 15:34:20.436: Find a better model.
2023-04-30 15:35:21.246: [iter 12 : loss : 0.3316 = 0.0754 + 0.2535 + 0.0014 + 0.0013, time: 60.791026]
2023-04-30 15:35:22.181: epoch 12:	0.02848905  	0.15131812  	0.10396869  
2023-04-30 15:35:22.181: Find a better model.
2023-04-30 15:36:22.624: [iter 13 : loss : 0.3255 = 0.0723 + 0.2504 + 0.0015 + 0.0013, time: 60.426277]
2023-04-30 15:36:23.576: epoch 13:	0.02891192  	0.15328041  	0.10498781  
2023-04-30 15:36:23.576: Find a better model.
2023-04-30 15:37:24.448: [iter 14 : loss : 0.3183 = 0.0690 + 0.2464 + 0.0015 + 0.0013, time: 60.854250]
2023-04-30 15:37:25.427: epoch 14:	0.02924482  	0.15526752  	0.10642780  
2023-04-30 15:37:25.427: Find a better model.
2023-04-30 15:38:26.089: [iter 15 : loss : 0.3137 = 0.0671 + 0.2437 + 0.0016 + 0.0013, time: 60.645183]
2023-04-30 15:38:27.088: epoch 15:	0.02959573  	0.15649216  	0.10788679  
2023-04-30 15:38:27.088: Find a better model.
2023-04-30 15:39:27.562: [iter 16 : loss : 0.3075 = 0.0644 + 0.2402 + 0.0017 + 0.0012, time: 60.453712]
2023-04-30 15:39:28.543: epoch 16:	0.02995560  	0.15853889  	0.10903542  
2023-04-30 15:39:28.543: Find a better model.
2023-04-30 15:40:29.393: [iter 17 : loss : 0.3013 = 0.0612 + 0.2370 + 0.0018 + 0.0012, time: 60.831107]
2023-04-30 15:40:30.380: epoch 17:	0.03034249  	0.16055858  	0.11028840  
2023-04-30 15:40:30.381: Find a better model.
2023-04-30 15:41:31.275: [iter 18 : loss : 0.2958 = 0.0600 + 0.2327 + 0.0018 + 0.0012, time: 60.874917]
2023-04-30 15:41:32.261: epoch 18:	0.03069338  	0.16293083  	0.11163636  
2023-04-30 15:41:32.261: Find a better model.
2023-04-30 15:42:33.066: [iter 19 : loss : 0.2915 = 0.0576 + 0.2308 + 0.0019 + 0.0012, time: 60.785060]
2023-04-30 15:42:34.042: epoch 19:	0.03103978  	0.16498166  	0.11280172  
2023-04-30 15:42:34.042: Find a better model.
2023-04-30 15:43:34.671: [iter 20 : loss : 0.2864 = 0.0563 + 0.2270 + 0.0020 + 0.0012, time: 60.610650]
2023-04-30 15:43:35.637: epoch 20:	0.03125121  	0.16603957  	0.11407785  
2023-04-30 15:43:35.637: Find a better model.
2023-04-30 15:44:36.457: [iter 21 : loss : 0.2812 = 0.0542 + 0.2238 + 0.0021 + 0.0012, time: 60.802009]
2023-04-30 15:44:37.431: epoch 21:	0.03142668  	0.16733605  	0.11518558  
2023-04-30 15:44:37.431: Find a better model.
2023-04-30 15:45:38.070: [iter 22 : loss : 0.2773 = 0.0525 + 0.2215 + 0.0022 + 0.0012, time: 60.613324]
2023-04-30 15:45:39.072: epoch 22:	0.03168761  	0.16838364  	0.11561879  
2023-04-30 15:45:39.072: Find a better model.
2023-04-30 15:46:37.313: [iter 23 : loss : 0.2717 = 0.0507 + 0.2176 + 0.0023 + 0.0011, time: 58.220309]
2023-04-30 15:46:38.296: epoch 23:	0.03195753  	0.17008463  	0.11675705  
2023-04-30 15:46:38.296: Find a better model.
2023-04-30 15:47:39.109: [iter 24 : loss : 0.2673 = 0.0492 + 0.2146 + 0.0024 + 0.0011, time: 60.796050]
2023-04-30 15:47:40.079: epoch 24:	0.03224996  	0.17162612  	0.11787122  
2023-04-30 15:47:40.079: Find a better model.
2023-04-30 15:48:40.792: [iter 25 : loss : 0.2635 = 0.0481 + 0.2119 + 0.0025 + 0.0011, time: 60.690701]
2023-04-30 15:48:41.761: epoch 25:	0.03254688  	0.17294022  	0.11915223  
2023-04-30 15:48:41.761: Find a better model.
2023-04-30 15:49:41.058: [iter 26 : loss : 0.2586 = 0.0463 + 0.2086 + 0.0026 + 0.0011, time: 59.279020]
2023-04-30 15:49:42.040: epoch 26:	0.03274933  	0.17409919  	0.11941517  
2023-04-30 15:49:42.041: Find a better model.
2023-04-30 15:50:43.018: [iter 27 : loss : 0.2543 = 0.0451 + 0.2055 + 0.0026 + 0.0011, time: 60.959075]
2023-04-30 15:50:43.980: epoch 27:	0.03301023  	0.17535584  	0.12085089  
2023-04-30 15:50:43.980: Find a better model.
2023-04-30 15:51:44.723: [iter 28 : loss : 0.2511 = 0.0447 + 0.2027 + 0.0027 + 0.0011, time: 60.721689]
2023-04-30 15:51:45.677: epoch 28:	0.03321719  	0.17691819  	0.12166711  
2023-04-30 15:51:45.677: Find a better model.
2023-04-30 15:52:30.207: [iter 29 : loss : 0.2468 = 0.0435 + 0.1994 + 0.0028 + 0.0010, time: 44.505181]
2023-04-30 15:52:30.867: epoch 29:	0.03338366  	0.17718805  	0.12196225  
2023-04-30 15:52:30.868: Find a better model.
2023-04-30 15:53:07.188: [iter 30 : loss : 0.2422 = 0.0412 + 0.1970 + 0.0029 + 0.0010, time: 36.306107]
2023-04-30 15:53:07.867: epoch 30:	0.03355011  	0.17817982  	0.12299891  
2023-04-30 15:53:07.868: Find a better model.
2023-04-30 15:53:44.192: [iter 31 : loss : 0.2392 = 0.0412 + 0.1940 + 0.0030 + 0.0010, time: 36.303622]
2023-04-30 15:53:44.849: epoch 31:	0.03381557  	0.17931166  	0.12404192  
2023-04-30 15:53:44.849: Find a better model.
2023-04-30 15:54:21.152: [iter 32 : loss : 0.2353 = 0.0396 + 0.1915 + 0.0032 + 0.0010, time: 36.289166]
2023-04-30 15:54:21.843: epoch 32:	0.03413048  	0.18024483  	0.12505326  
2023-04-30 15:54:21.843: Find a better model.
2023-04-30 15:54:58.165: [iter 33 : loss : 0.2317 = 0.0389 + 0.1885 + 0.0033 + 0.0010, time: 36.309658]
2023-04-30 15:54:58.825: epoch 33:	0.03434644  	0.18130368  	0.12596391  
2023-04-30 15:54:58.826: Find a better model.
2023-04-30 15:55:35.243: [iter 34 : loss : 0.2281 = 0.0382 + 0.1856 + 0.0034 + 0.0010, time: 36.403125]
2023-04-30 15:55:35.916: epoch 34:	0.03445889  	0.18161285  	0.12651172  
2023-04-30 15:55:35.916: Find a better model.
2023-04-30 15:56:12.352: [iter 35 : loss : 0.2244 = 0.0377 + 0.1823 + 0.0035 + 0.0010, time: 36.422228]
2023-04-30 15:56:13.018: epoch 35:	0.03456687  	0.18202308  	0.12689865  
2023-04-30 15:56:13.018: Find a better model.
2023-04-30 15:56:49.424: [iter 36 : loss : 0.2202 = 0.0359 + 0.1797 + 0.0036 + 0.0009, time: 36.392317]
2023-04-30 15:56:50.088: epoch 36:	0.03471981  	0.18287590  	0.12740275  
2023-04-30 15:56:50.088: Find a better model.
2023-04-30 15:57:26.585: [iter 37 : loss : 0.2165 = 0.0350 + 0.1769 + 0.0037 + 0.0009, time: 36.482066]
2023-04-30 15:57:27.245: epoch 37:	0.03497174  	0.18424176  	0.12816551  
2023-04-30 15:57:27.246: Find a better model.
2023-04-30 15:58:03.108: [iter 38 : loss : 0.2138 = 0.0346 + 0.1745 + 0.0038 + 0.0009, time: 35.849406]
2023-04-30 15:58:03.740: epoch 38:	0.03518768  	0.18530104  	0.12924507  
2023-04-30 15:58:03.740: Find a better model.
2023-04-30 15:58:37.843: [iter 39 : loss : 0.2101 = 0.0336 + 0.1717 + 0.0039 + 0.0009, time: 34.087484]
2023-04-30 15:58:38.512: epoch 39:	0.03525067  	0.18560879  	0.12932009  
2023-04-30 15:58:38.513: Find a better model.
2023-04-30 15:59:14.929: [iter 40 : loss : 0.2070 = 0.0333 + 0.1687 + 0.0041 + 0.0009, time: 36.399502]
2023-04-30 15:59:15.582: epoch 40:	0.03555659  	0.18709287  	0.13002078  
2023-04-30 15:59:15.582: Find a better model.
2023-04-30 15:59:52.104: [iter 41 : loss : 0.2031 = 0.0322 + 0.1658 + 0.0042 + 0.0009, time: 36.508303]
2023-04-30 15:59:52.762: epoch 41:	0.03562405  	0.18744498  	0.13040195  
2023-04-30 15:59:52.763: Find a better model.
2023-04-30 16:00:29.147: [iter 42 : loss : 0.2002 = 0.0320 + 0.1631 + 0.0043 + 0.0009, time: 36.371597]
2023-04-30 16:00:29.826: epoch 42:	0.03583549  	0.18862714  	0.13135310  
2023-04-30 16:00:29.826: Find a better model.
2023-04-30 16:01:06.288: [iter 43 : loss : 0.1977 = 0.0316 + 0.1609 + 0.0044 + 0.0008, time: 36.448664]
2023-04-30 16:01:06.943: epoch 43:	0.03603344  	0.18956822  	0.13225222  
2023-04-30 16:01:06.943: Find a better model.
2023-04-30 16:01:43.269: [iter 44 : loss : 0.1939 = 0.0302 + 0.1584 + 0.0045 + 0.0008, time: 36.308465]
2023-04-30 16:01:43.907: epoch 44:	0.03627637  	0.19105539  	0.13294050  
2023-04-30 16:01:43.907: Find a better model.
2023-04-30 16:02:20.358: [iter 45 : loss : 0.1919 = 0.0306 + 0.1558 + 0.0047 + 0.0008, time: 36.436548]
2023-04-30 16:02:21.038: epoch 45:	0.03641133  	0.19172016  	0.13348286  
2023-04-30 16:02:21.038: Find a better model.
2023-04-30 16:02:57.547: [iter 46 : loss : 0.1881 = 0.0294 + 0.1531 + 0.0048 + 0.0008, time: 36.495660]
2023-04-30 16:02:58.208: epoch 46:	0.03654630  	0.19204214  	0.13357808  
2023-04-30 16:02:58.208: Find a better model.
2023-04-30 16:03:34.630: [iter 47 : loss : 0.1849 = 0.0289 + 0.1504 + 0.0049 + 0.0008, time: 36.407276]
2023-04-30 16:03:35.285: epoch 47:	0.03661379  	0.19230749  	0.13376306  
2023-04-30 16:03:35.286: Find a better model.
2023-04-30 16:04:11.933: [iter 48 : loss : 0.1831 = 0.0290 + 0.1483 + 0.0050 + 0.0008, time: 36.631234]
2023-04-30 16:04:12.602: epoch 48:	0.03681174  	0.19305025  	0.13442621  
2023-04-30 16:04:12.602: Find a better model.
2023-04-30 16:04:47.845: [iter 49 : loss : 0.1798 = 0.0281 + 0.1457 + 0.0052 + 0.0008, time: 35.225271]
2023-04-30 16:04:48.488: epoch 49:	0.03691969  	0.19391815  	0.13485076  
2023-04-30 16:04:48.488: Find a better model.
2023-04-30 16:05:23.156: [iter 50 : loss : 0.1761 = 0.0269 + 0.1432 + 0.0053 + 0.0007, time: 34.655211]
2023-04-30 16:05:23.820: epoch 50:	0.03683871  	0.19352084  	0.13495283  
2023-04-30 16:06:00.277: [iter 51 : loss : 0.1737 = 0.0269 + 0.1406 + 0.0054 + 0.0007, time: 36.444479]
2023-04-30 16:06:00.938: epoch 51:	0.03689720  	0.19341886  	0.13493536  
2023-04-30 16:06:37.505: [iter 52 : loss : 0.1711 = 0.0267 + 0.1381 + 0.0056 + 0.0007, time: 36.550162]
2023-04-30 16:06:38.174: epoch 52:	0.03699167  	0.19407240  	0.13504846  
2023-04-30 16:06:38.175: Find a better model.
2023-04-30 16:07:14.489: [iter 53 : loss : 0.1683 = 0.0260 + 0.1359 + 0.0057 + 0.0007, time: 36.298495]
2023-04-30 16:07:15.153: epoch 53:	0.03695119  	0.19390509  	0.13501622  
2023-04-30 16:07:51.526: [iter 54 : loss : 0.1657 = 0.0254 + 0.1337 + 0.0058 + 0.0007, time: 36.353099]
2023-04-30 16:07:52.170: epoch 54:	0.03713562  	0.19471353  	0.13595952  
2023-04-30 16:07:52.171: Find a better model.
2023-04-30 16:08:25.636: [iter 55 : loss : 0.1631 = 0.0253 + 0.1311 + 0.0060 + 0.0007, time: 33.453252]
2023-04-30 16:08:26.306: epoch 55:	0.03727060  	0.19536030  	0.13641362  
2023-04-30 16:08:26.307: Find a better model.
2023-04-30 16:09:02.381: [iter 56 : loss : 0.1612 = 0.0255 + 0.1289 + 0.0061 + 0.0007, time: 36.058496]
2023-04-30 16:09:03.204: epoch 56:	0.03729311  	0.19546738  	0.13639538  
2023-04-30 16:09:03.205: Find a better model.
2023-04-30 16:09:39.503: [iter 57 : loss : 0.1580 = 0.0244 + 0.1267 + 0.0062 + 0.0007, time: 36.282402]
2023-04-30 16:09:40.264: epoch 57:	0.03746409  	0.19631775  	0.13666156  
2023-04-30 16:09:40.264: Find a better model.
2023-04-30 16:10:16.374: [iter 58 : loss : 0.1557 = 0.0241 + 0.1246 + 0.0064 + 0.0006, time: 36.088948]
2023-04-30 16:10:17.058: epoch 58:	0.03755857  	0.19718790  	0.13711235  
2023-04-30 16:10:17.058: Find a better model.
2023-04-30 16:10:49.338: [iter 59 : loss : 0.1539 = 0.0245 + 0.1222 + 0.0065 + 0.0006, time: 32.255107]
2023-04-30 16:10:50.025: epoch 59:	0.03760352  	0.19723050  	0.13730095  
2023-04-30 16:10:50.026: Find a better model.
2023-04-30 16:11:24.580: [iter 60 : loss : 0.1508 = 0.0234 + 0.1201 + 0.0067 + 0.0006, time: 34.536933]
2023-04-30 16:11:25.230: epoch 60:	0.03769803  	0.19801457  	0.13749310  
2023-04-30 16:11:25.230: Find a better model.
2023-04-30 16:12:01.652: [iter 61 : loss : 0.1481 = 0.0225 + 0.1182 + 0.0068 + 0.0006, time: 36.406526]
2023-04-30 16:12:02.328: epoch 61:	0.03773852  	0.19817628  	0.13760993  
2023-04-30 16:12:02.329: Find a better model.
2023-04-30 16:12:38.854: [iter 62 : loss : 0.1463 = 0.0227 + 0.1161 + 0.0069 + 0.0006, time: 36.508821]
2023-04-30 16:12:39.513: epoch 62:	0.03774302  	0.19799100  	0.13746169  
2023-04-30 16:13:15.988: [iter 63 : loss : 0.1437 = 0.0221 + 0.1140 + 0.0071 + 0.0006, time: 36.459001]
2023-04-30 16:13:16.658: epoch 63:	0.03795449  	0.19931147  	0.13802335  
2023-04-30 16:13:16.658: Find a better model.
2023-04-30 16:13:53.044: [iter 64 : loss : 0.1415 = 0.0218 + 0.1120 + 0.0072 + 0.0006, time: 36.369472]
2023-04-30 16:13:53.721: epoch 64:	0.03794547  	0.19881064  	0.13822374  
2023-04-30 16:14:29.808: [iter 65 : loss : 0.1396 = 0.0215 + 0.1101 + 0.0073 + 0.0006, time: 36.069826]
2023-04-30 16:14:30.477: epoch 65:	0.03811193  	0.19990097  	0.13871789  
2023-04-30 16:14:30.477: Find a better model.
2023-04-30 16:15:06.840: [iter 66 : loss : 0.1372 = 0.0211 + 0.1080 + 0.0075 + 0.0006, time: 36.341831]
2023-04-30 16:15:07.497: epoch 66:	0.03811194  	0.19994584  	0.13860689  
2023-04-30 16:15:07.497: Find a better model.
2023-04-30 16:15:39.339: [iter 67 : loss : 0.1357 = 0.0214 + 0.1061 + 0.0076 + 0.0006, time: 31.828409]
2023-04-30 16:15:40.009: epoch 67:	0.03817491  	0.20011643  	0.13857469  
2023-04-30 16:15:40.009: Find a better model.
2023-04-30 16:16:16.336: [iter 68 : loss : 0.1334 = 0.0209 + 0.1042 + 0.0078 + 0.0005, time: 36.309534]
2023-04-30 16:16:16.981: epoch 68:	0.03821540  	0.20010749  	0.13840786  
2023-04-30 16:16:53.308: [iter 69 : loss : 0.1320 = 0.0211 + 0.1024 + 0.0079 + 0.0005, time: 36.309911]
2023-04-30 16:16:53.968: epoch 69:	0.03821992  	0.20022075  	0.13862330  
2023-04-30 16:16:53.968: Find a better model.
2023-04-30 16:17:30.395: [iter 70 : loss : 0.1301 = 0.0209 + 0.1006 + 0.0080 + 0.0005, time: 36.407707]
2023-04-30 16:17:31.058: epoch 70:	0.03821094  	0.20001258  	0.13860694  
2023-04-30 16:18:07.354: [iter 71 : loss : 0.1276 = 0.0201 + 0.0988 + 0.0082 + 0.0005, time: 36.279840]
2023-04-30 16:18:08.041: epoch 71:	0.03826043  	0.20042276  	0.13862133  
2023-04-30 16:18:08.041: Find a better model.
2023-04-30 16:18:44.407: [iter 72 : loss : 0.1264 = 0.0203 + 0.0972 + 0.0083 + 0.0005, time: 36.346190]
2023-04-30 16:18:45.067: epoch 72:	0.03839090  	0.20074505  	0.13874815  
2023-04-30 16:18:45.067: Find a better model.
2023-04-30 16:19:21.367: [iter 73 : loss : 0.1242 = 0.0200 + 0.0952 + 0.0085 + 0.0005, time: 36.284524]
2023-04-30 16:19:22.014: epoch 73:	0.03840891  	0.20049590  	0.13857499  
2023-04-30 16:19:58.313: [iter 74 : loss : 0.1229 = 0.0200 + 0.0938 + 0.0086 + 0.0005, time: 36.285038]
2023-04-30 16:19:58.976: epoch 74:	0.03853038  	0.20133756  	0.13894810  
2023-04-30 16:19:58.976: Find a better model.
2023-04-30 16:20:35.386: [iter 75 : loss : 0.1211 = 0.0198 + 0.0921 + 0.0087 + 0.0005, time: 36.387808]
2023-04-30 16:20:36.049: epoch 75:	0.03853936  	0.20092213  	0.13906652  
2023-04-30 16:21:12.372: [iter 76 : loss : 0.1192 = 0.0195 + 0.0904 + 0.0089 + 0.0005, time: 36.306653]
2023-04-30 16:21:13.024: epoch 76:	0.03852585  	0.20079131  	0.13886259  
2023-04-30 16:21:49.465: [iter 77 : loss : 0.1177 = 0.0192 + 0.0890 + 0.0090 + 0.0005, time: 36.426413]
2023-04-30 16:21:50.144: epoch 77:	0.03851686  	0.20043093  	0.13869974  
2023-04-30 16:22:26.518: [iter 78 : loss : 0.1158 = 0.0189 + 0.0873 + 0.0091 + 0.0005, time: 36.352914]
2023-04-30 16:22:27.173: epoch 78:	0.03848537  	0.20003298  	0.13859767  
2023-04-30 16:23:03.462: [iter 79 : loss : 0.1144 = 0.0190 + 0.0857 + 0.0093 + 0.0004, time: 36.273932]
2023-04-30 16:23:04.118: epoch 79:	0.03844038  	0.19971278  	0.13858931  
2023-04-30 16:23:40.620: [iter 80 : loss : 0.1121 = 0.0180 + 0.0842 + 0.0094 + 0.0004, time: 36.488665]
2023-04-30 16:23:41.269: epoch 80:	0.03836389  	0.19968352  	0.13827667  
2023-04-30 16:24:17.664: [iter 81 : loss : 0.1117 = 0.0190 + 0.0827 + 0.0095 + 0.0004, time: 36.382876]
2023-04-30 16:24:18.316: epoch 81:	0.03840888  	0.20002384  	0.13832743  
2023-04-30 16:24:54.296: [iter 82 : loss : 0.1092 = 0.0177 + 0.0814 + 0.0097 + 0.0004, time: 35.964240]
2023-04-30 16:24:54.950: epoch 82:	0.03842688  	0.19956627  	0.13818105  
2023-04-30 16:25:31.231: [iter 83 : loss : 0.1082 = 0.0180 + 0.0800 + 0.0098 + 0.0004, time: 36.266501]
2023-04-30 16:25:31.884: epoch 83:	0.03839087  	0.19964918  	0.13810262  
2023-04-30 16:26:08.281: [iter 84 : loss : 0.1064 = 0.0175 + 0.0786 + 0.0099 + 0.0004, time: 36.380640]
2023-04-30 16:26:08.931: epoch 84:	0.03847638  	0.19980222  	0.13813120  
2023-04-30 16:26:08.932: Early stopping is trigger at epoch: 84
2023-04-30 16:26:08.932: best_result@epoch 74:

2023-04-30 16:26:08.932: 		0.0385      	0.2013      	0.1389      

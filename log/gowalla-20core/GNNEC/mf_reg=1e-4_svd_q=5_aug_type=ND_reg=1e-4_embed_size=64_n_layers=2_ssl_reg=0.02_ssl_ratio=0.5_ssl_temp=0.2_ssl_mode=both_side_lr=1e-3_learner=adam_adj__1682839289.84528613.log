2023-04-30 15:21:29.845: my pid: 6432
2023-04-30 15:21:29.845: model: model.general_recommender.GNNEC
2023-04-30 15:21:29.845: Dataset statistics:
Name: gowalla-20core
The number of users: 11113
The number of items: 18074
The number of ratings: 523315
Average actions of users: 47.09
Average actions of items: 28.95
The sparsity of the dataset: 99.739458%

The number of training: 475362
The number of validation: 0
The number of testing: 47953
2023-04-30 15:21:29.846: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=gowalla-20core
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=gowalla-20core
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
mf_reg=1e-4
svd_q=5
2023-04-30 15:21:36.273: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-04-30 15:22:21.222: [iter 1 : loss : 0.8816 = 0.5583 + 0.3216 + 0.0001 + 0.0016, time: 44.945425]
2023-04-30 15:22:22.272: epoch 1:	0.02359015  	0.12487593  	0.08753356  
2023-04-30 15:22:22.273: Find a better model.
2023-04-30 15:23:29.639: [iter 2 : loss : 0.5693 = 0.2783 + 0.2893 + 0.0003 + 0.0014, time: 67.346638]
2023-04-30 15:23:30.670: epoch 2:	0.02607334  	0.13801026  	0.09653022  
2023-04-30 15:23:30.670: Find a better model.
2023-04-30 15:24:37.970: [iter 3 : loss : 0.4607 = 0.1862 + 0.2728 + 0.0005 + 0.0013, time: 67.276978]
2023-04-30 15:24:39.079: epoch 3:	0.02757136  	0.14664841  	0.10270993  
2023-04-30 15:24:39.080: Find a better model.
2023-04-30 15:25:47.669: [iter 4 : loss : 0.4025 = 0.1468 + 0.2537 + 0.0007 + 0.0013, time: 68.567089]
2023-04-30 15:25:48.740: epoch 4:	0.02873647  	0.15340021  	0.10639497  
2023-04-30 15:25:48.740: Find a better model.
2023-04-30 15:26:57.598: [iter 5 : loss : 0.3671 = 0.1243 + 0.2408 + 0.0008 + 0.0012, time: 68.836468]
2023-04-30 15:26:58.634: epoch 5:	0.02984314  	0.15881909  	0.11017453  
2023-04-30 15:26:58.635: Find a better model.
2023-04-30 15:28:07.599: [iter 6 : loss : 0.3406 = 0.1094 + 0.2291 + 0.0009 + 0.0012, time: 68.943984]
2023-04-30 15:28:08.723: epoch 6:	0.03058993  	0.16284700  	0.11338803  
2023-04-30 15:28:08.723: Find a better model.
2023-04-30 15:29:19.764: [iter 7 : loss : 0.3137 = 0.0978 + 0.2137 + 0.0011 + 0.0011, time: 71.020416]
2023-04-30 15:29:20.833: epoch 7:	0.03112978  	0.16567117  	0.11572597  
2023-04-30 15:29:20.833: Find a better model.
2023-04-30 15:30:22.073: [iter 8 : loss : 0.2906 = 0.0893 + 0.1991 + 0.0012 + 0.0010, time: 61.217681]
2023-04-30 15:30:23.055: epoch 8:	0.03188557  	0.16947526  	0.11733609  
2023-04-30 15:30:23.056: Find a better model.
2023-04-30 15:31:24.299: [iter 9 : loss : 0.2682 = 0.0818 + 0.1841 + 0.0013 + 0.0010, time: 61.222193]
2023-04-30 15:31:25.332: epoch 9:	0.03245242  	0.17190447  	0.11913361  
2023-04-30 15:31:25.333: Find a better model.
2023-04-30 15:32:26.418: [iter 10 : loss : 0.2504 = 0.0760 + 0.1720 + 0.0015 + 0.0009, time: 61.062682]
2023-04-30 15:32:27.453: epoch 10:	0.03292029  	0.17442670  	0.12070883  
2023-04-30 15:32:27.453: Find a better model.
2023-04-30 15:33:29.084: [iter 11 : loss : 0.2318 = 0.0708 + 0.1584 + 0.0016 + 0.0009, time: 61.609959]
2023-04-30 15:33:30.143: epoch 11:	0.03312274  	0.17574362  	0.12204241  
2023-04-30 15:33:30.143: Find a better model.
2023-04-30 15:34:31.500: [iter 12 : loss : 0.2114 = 0.0655 + 0.1434 + 0.0017 + 0.0008, time: 61.334743]
2023-04-30 15:34:32.535: epoch 12:	0.03348264  	0.17709136  	0.12273045  
2023-04-30 15:34:32.536: Find a better model.
2023-04-30 15:35:34.101: [iter 13 : loss : 0.1956 = 0.0612 + 0.1318 + 0.0019 + 0.0007, time: 61.546505]
2023-04-30 15:35:35.194: epoch 13:	0.03378408  	0.17864949  	0.12368459  
2023-04-30 15:35:35.195: Find a better model.
2023-04-30 15:36:36.325: [iter 14 : loss : 0.1791 = 0.0574 + 0.1190 + 0.0020 + 0.0007, time: 61.104108]
2023-04-30 15:36:37.377: epoch 14:	0.03393253  	0.18017209  	0.12429977  
2023-04-30 15:36:37.377: Find a better model.
2023-04-30 15:37:38.569: [iter 15 : loss : 0.1645 = 0.0541 + 0.1076 + 0.0022 + 0.0006, time: 61.168392]
2023-04-30 15:37:39.574: epoch 15:	0.03428788  	0.18180488  	0.12513991  
2023-04-30 15:37:39.575: Find a better model.
2023-04-30 15:38:41.042: [iter 16 : loss : 0.1502 = 0.0506 + 0.0967 + 0.0024 + 0.0005, time: 61.445889]
2023-04-30 15:38:42.074: epoch 16:	0.03428790  	0.18202746  	0.12497091  
2023-04-30 15:38:42.074: Find a better model.
2023-04-30 15:39:43.363: [iter 17 : loss : 0.1370 = 0.0474 + 0.0866 + 0.0025 + 0.0005, time: 61.270172]
2023-04-30 15:39:44.378: epoch 17:	0.03439141  	0.18202278  	0.12512630  
2023-04-30 15:40:45.410: [iter 18 : loss : 0.1253 = 0.0453 + 0.0769 + 0.0027 + 0.0004, time: 61.014932]
2023-04-30 15:40:46.455: epoch 18:	0.03432397  	0.18167582  	0.12414331  
2023-04-30 15:41:47.487: [iter 19 : loss : 0.1151 = 0.0426 + 0.0692 + 0.0028 + 0.0004, time: 61.007926]
2023-04-30 15:41:48.526: epoch 19:	0.03457588  	0.18269262  	0.12436378  
2023-04-30 15:41:48.526: Find a better model.
2023-04-30 15:42:49.502: [iter 20 : loss : 0.1059 = 0.0406 + 0.0619 + 0.0030 + 0.0004, time: 60.958801]
2023-04-30 15:42:50.552: epoch 20:	0.03445441  	0.18205847  	0.12449773  
2023-04-30 15:43:51.848: [iter 21 : loss : 0.0969 = 0.0382 + 0.0552 + 0.0031 + 0.0003, time: 61.274137]
2023-04-30 15:43:52.886: epoch 21:	0.03436896  	0.18188474  	0.12371707  
2023-04-30 15:44:53.883: [iter 22 : loss : 0.0898 = 0.0365 + 0.0497 + 0.0033 + 0.0003, time: 60.968928]
2023-04-30 15:44:54.886: epoch 22:	0.03422952  	0.18110234  	0.12275815  
2023-04-30 15:45:56.211: [iter 23 : loss : 0.0827 = 0.0344 + 0.0446 + 0.0034 + 0.0003, time: 61.304410]
2023-04-30 15:45:57.241: epoch 23:	0.03416656  	0.18101312  	0.12258168  
2023-04-30 15:46:56.344: [iter 24 : loss : 0.0765 = 0.0328 + 0.0400 + 0.0036 + 0.0002, time: 59.083382]
2023-04-30 15:46:57.397: epoch 24:	0.03420254  	0.18139909  	0.12237003  
2023-04-30 15:47:58.686: [iter 25 : loss : 0.0719 = 0.0317 + 0.0363 + 0.0037 + 0.0002, time: 61.269103]
2023-04-30 15:47:59.723: epoch 25:	0.03422504  	0.18141226  	0.12256573  
2023-04-30 15:48:59.869: [iter 26 : loss : 0.0665 = 0.0299 + 0.0326 + 0.0038 + 0.0002, time: 60.121686]
2023-04-30 15:49:00.915: epoch 26:	0.03411256  	0.18041359  	0.12141856  
2023-04-30 15:50:02.143: [iter 27 : loss : 0.0623 = 0.0287 + 0.0295 + 0.0040 + 0.0002, time: 61.208435]
2023-04-30 15:50:03.135: epoch 27:	0.03423402  	0.18134890  	0.12213919  
2023-04-30 15:51:04.002: [iter 28 : loss : 0.0590 = 0.0278 + 0.0270 + 0.0041 + 0.0001, time: 60.847840]
2023-04-30 15:51:05.004: epoch 28:	0.03409007  	0.18060838  	0.12169690  
2023-04-30 15:52:06.143: [iter 29 : loss : 0.0556 = 0.0269 + 0.0244 + 0.0042 + 0.0001, time: 61.117538]
2023-04-30 15:52:07.156: epoch 29:	0.03394609  	0.17999455  	0.12103439  
2023-04-30 15:52:07.156: Early stopping is trigger at epoch: 29
2023-04-30 15:52:07.156: best_result@epoch 19:

2023-04-30 15:52:07.156: 		0.0346      	0.1827      	0.1244      

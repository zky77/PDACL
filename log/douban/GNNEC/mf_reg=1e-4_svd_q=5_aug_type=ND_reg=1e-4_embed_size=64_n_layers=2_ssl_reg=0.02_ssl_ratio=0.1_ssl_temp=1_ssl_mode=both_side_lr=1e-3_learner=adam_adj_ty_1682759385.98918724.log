2023-04-29 17:09:45.989: my pid: 12980
2023-04-29 17:09:45.989: model: model.general_recommender.GNNEC
2023-04-29 17:09:45.990: Dataset statistics:
Name: douban
The number of users: 2765
The number of items: 26926
The number of ratings: 882145
Average actions of users: 319.04
Average actions of items: 32.76
The sparsity of the dataset: 98.815124%

The number of training: 795166
The number of validation: 0
The number of testing: 86979
2023-04-29 17:09:45.990: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=douban
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=1
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=100
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=douban
epochs=100
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=1
mf_reg=1e-4
svd_q=5
2023-04-29 17:09:52.906: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-04-29 17:11:58.424: [iter 1 : loss : 0.7529 = 0.4026 + 0.3483 + 0.0002 + 0.0018, time: 125.514292]
2023-04-29 17:11:58.859: epoch 1:	0.08115818  	0.05980886  	0.10525309  
2023-04-29 17:11:58.859: Find a better model.
2023-04-29 17:14:20.225: [iter 2 : loss : 0.5585 = 0.2170 + 0.3392 + 0.0006 + 0.0018, time: 141.323338]
2023-04-29 17:14:20.637: epoch 2:	0.07934183  	0.05844683  	0.10359100  
2023-04-29 17:16:39.899: [iter 3 : loss : 0.5404 = 0.2022 + 0.3357 + 0.0007 + 0.0018, time: 139.212665]
2023-04-29 17:16:40.339: epoch 3:	0.07792468  	0.05794659  	0.10199980  
2023-04-29 17:18:58.434: [iter 4 : loss : 0.5303 = 0.1942 + 0.3336 + 0.0008 + 0.0017, time: 138.048070]
2023-04-29 17:18:58.862: epoch 4:	0.07762519  	0.05788973  	0.10194089  
2023-04-29 17:21:17.993: [iter 5 : loss : 0.5223 = 0.1878 + 0.3319 + 0.0009 + 0.0017, time: 139.089832]
2023-04-29 17:21:18.406: epoch 5:	0.07782482  	0.05765366  	0.10209013  
2023-04-29 17:23:34.612: [iter 6 : loss : 0.5151 = 0.1821 + 0.3303 + 0.0010 + 0.0017, time: 136.170997]
2023-04-29 17:23:35.022: epoch 6:	0.07858334  	0.05850353  	0.10291336  
2023-04-29 17:25:56.147: [iter 7 : loss : 0.5077 = 0.1767 + 0.3282 + 0.0011 + 0.0017, time: 141.077662]
2023-04-29 17:25:56.567: epoch 7:	0.07930192  	0.05874966  	0.10351113  
2023-04-29 17:28:13.467: [iter 8 : loss : 0.4979 = 0.1693 + 0.3258 + 0.0012 + 0.0017, time: 136.851196]
2023-04-29 17:28:13.918: epoch 8:	0.08147753  	0.06040150  	0.10625011  
2023-04-29 17:28:13.919: Find a better model.
2023-04-29 17:30:34.562: [iter 9 : loss : 0.4859 = 0.1599 + 0.3230 + 0.0013 + 0.0017, time: 140.581033]
2023-04-29 17:30:34.998: epoch 9:	0.08379293  	0.06141570  	0.10861552  
2023-04-29 17:30:34.998: Find a better model.
2023-04-29 17:32:54.903: [iter 10 : loss : 0.4760 = 0.1532 + 0.3197 + 0.0014 + 0.0017, time: 139.861162]
2023-04-29 17:32:55.329: epoch 10:	0.08658731  	0.06274518  	0.11135131  
2023-04-29 17:32:55.330: Find a better model.
2023-04-29 17:35:16.438: [iter 11 : loss : 0.4650 = 0.1455 + 0.3163 + 0.0015 + 0.0017, time: 141.055327]
2023-04-29 17:35:16.911: epoch 11:	0.08982083  	0.06444673  	0.11516812  
2023-04-29 17:35:16.912: Find a better model.
2023-04-29 17:37:36.339: [iter 12 : loss : 0.4529 = 0.1370 + 0.3125 + 0.0017 + 0.0016, time: 139.388798]
2023-04-29 17:37:36.761: epoch 12:	0.09313425  	0.06727841  	0.11920276  
2023-04-29 17:37:36.761: Find a better model.
2023-04-29 17:39:55.975: [iter 13 : loss : 0.4430 = 0.1307 + 0.3088 + 0.0019 + 0.0016, time: 139.168417]
2023-04-29 17:39:56.405: epoch 13:	0.09750554  	0.07100300  	0.12452298  
2023-04-29 17:39:56.405: Find a better model.
2023-04-29 17:42:16.032: [iter 14 : loss : 0.4333 = 0.1247 + 0.3049 + 0.0021 + 0.0016, time: 139.588325]
2023-04-29 17:42:16.451: epoch 14:	0.10147764  	0.07416527  	0.12951992  
2023-04-29 17:42:16.451: Find a better model.
2023-04-29 17:44:32.513: [iter 15 : loss : 0.4246 = 0.1197 + 0.3010 + 0.0023 + 0.0016, time: 136.020706]
2023-04-29 17:44:32.906: epoch 15:	0.10592847  	0.07797974  	0.13452518  
2023-04-29 17:44:32.911: Find a better model.
2023-04-29 17:46:53.617: [iter 16 : loss : 0.4144 = 0.1130 + 0.2973 + 0.0025 + 0.0016, time: 140.678113]
2023-04-29 17:46:54.055: epoch 16:	0.10922184  	0.07999028  	0.13876095  
2023-04-29 17:46:54.055: Find a better model.
2023-04-29 17:49:13.007: [iter 17 : loss : 0.4072 = 0.1094 + 0.2936 + 0.0027 + 0.0015, time: 138.913703]
2023-04-29 17:49:13.413: epoch 17:	0.11081853  	0.08108015  	0.14134665  
2023-04-29 17:49:13.413: Find a better model.
2023-04-29 17:51:33.733: [iter 18 : loss : 0.3992 = 0.1046 + 0.2901 + 0.0029 + 0.0015, time: 140.282155]
2023-04-29 17:51:34.126: epoch 18:	0.11275467  	0.08396780  	0.14361823  
2023-04-29 17:51:34.126: Find a better model.
2023-04-29 17:53:52.843: [iter 19 : loss : 0.3920 = 0.1007 + 0.2866 + 0.0032 + 0.0015, time: 138.672791]
2023-04-29 17:53:53.248: epoch 19:	0.11471064  	0.08533424  	0.14581829  
2023-04-29 17:53:53.248: Find a better model.
2023-04-29 17:56:12.421: [iter 20 : loss : 0.3853 = 0.0971 + 0.2833 + 0.0034 + 0.0015, time: 139.125309]
2023-04-29 17:56:12.827: epoch 20:	0.11526957  	0.08541337  	0.14723305  
2023-04-29 17:56:12.827: Find a better model.
2023-04-29 17:58:30.731: [iter 21 : loss : 0.3786 = 0.0935 + 0.2800 + 0.0036 + 0.0015, time: 137.873841]
2023-04-29 17:58:31.129: epoch 21:	0.11726558  	0.08783697  	0.14971271  
2023-04-29 17:58:31.129: Find a better model.
2023-04-29 18:00:47.076: [iter 22 : loss : 0.3739 = 0.0917 + 0.2768 + 0.0039 + 0.0015, time: 135.909209]
2023-04-29 18:00:47.496: epoch 22:	0.11814371  	0.08821151  	0.15080896  
2023-04-29 18:00:47.496: Find a better model.
2023-04-29 18:03:07.875: [iter 23 : loss : 0.3672 = 0.0878 + 0.2738 + 0.0041 + 0.0014, time: 140.340269]
2023-04-29 18:03:08.254: epoch 23:	0.11920160  	0.08861745  	0.15241635  
2023-04-29 18:03:08.255: Find a better model.
2023-04-29 18:05:26.812: [iter 24 : loss : 0.3620 = 0.0854 + 0.2708 + 0.0044 + 0.0014, time: 138.524938]
2023-04-29 18:05:27.211: epoch 24:	0.12063874  	0.08953144  	0.15384212  
2023-04-29 18:05:27.211: Find a better model.
2023-04-29 18:07:47.970: [iter 25 : loss : 0.3569 = 0.0831 + 0.2677 + 0.0047 + 0.0014, time: 140.716523]
2023-04-29 18:07:48.381: epoch 25:	0.12167664  	0.09023599  	0.15495588  
2023-04-29 18:07:48.381: Find a better model.
2023-04-29 18:10:05.448: [iter 26 : loss : 0.3517 = 0.0806 + 0.2647 + 0.0050 + 0.0014, time: 137.027690]
2023-04-29 18:10:05.874: epoch 26:	0.12215570  	0.09032156  	0.15600610  
2023-04-29 18:10:05.874: Find a better model.
2023-04-29 18:12:22.802: [iter 27 : loss : 0.3471 = 0.0785 + 0.2620 + 0.0052 + 0.0014, time: 136.894831]
2023-04-29 18:12:23.215: epoch 27:	0.12267460  	0.09064260  	0.15715067  
2023-04-29 18:12:23.215: Find a better model.
2023-04-29 18:14:40.035: [iter 28 : loss : 0.3426 = 0.0765 + 0.2593 + 0.0055 + 0.0014, time: 136.772744]
2023-04-29 18:14:40.463: epoch 28:	0.12315363  	0.09076530  	0.15761891  
2023-04-29 18:14:40.463: Find a better model.
2023-04-29 18:16:58.373: [iter 29 : loss : 0.3384 = 0.0748 + 0.2564 + 0.0058 + 0.0013, time: 137.868648]
2023-04-29 18:16:58.760: epoch 29:	0.12355288  	0.09167725  	0.15844035  
2023-04-29 18:16:58.761: Find a better model.
2023-04-29 18:19:16.571: [iter 30 : loss : 0.3335 = 0.0722 + 0.2538 + 0.0061 + 0.0013, time: 137.764221]
2023-04-29 18:19:16.968: epoch 30:	0.12441117  	0.09165122  	0.15962964  
2023-04-29 18:21:21.291: [iter 31 : loss : 0.3301 = 0.0711 + 0.2513 + 0.0064 + 0.0013, time: 124.280292]
2023-04-29 18:21:21.725: epoch 31:	0.12534927  	0.09271374  	0.16068256  
2023-04-29 18:21:21.725: Find a better model.
2023-04-29 18:23:28.344: [iter 32 : loss : 0.3255 = 0.0688 + 0.2487 + 0.0067 + 0.0013, time: 126.572091]
2023-04-29 18:23:28.743: epoch 32:	0.12612768  	0.09335218  	0.16127016  
2023-04-29 18:23:28.744: Find a better model.
2023-04-29 18:25:45.499: [iter 33 : loss : 0.3226 = 0.0680 + 0.2462 + 0.0070 + 0.0013, time: 136.715248]
2023-04-29 18:25:45.901: epoch 33:	0.12636727  	0.09340189  	0.16176276  
2023-04-29 18:25:45.902: Find a better model.
2023-04-29 18:28:01.561: [iter 34 : loss : 0.3188 = 0.0664 + 0.2438 + 0.0073 + 0.0013, time: 135.625715]
2023-04-29 18:28:01.996: epoch 34:	0.12736531  	0.09425153  	0.16271560  
2023-04-29 18:28:01.996: Find a better model.
2023-04-29 18:30:21.905: [iter 35 : loss : 0.3162 = 0.0658 + 0.2415 + 0.0076 + 0.0013, time: 139.867795]
2023-04-29 18:30:22.331: epoch 35:	0.12666662  	0.09288430  	0.16214299  
2023-04-29 18:32:36.027: [iter 36 : loss : 0.3130 = 0.0645 + 0.2393 + 0.0080 + 0.0013, time: 133.629135]
2023-04-29 18:32:36.435: epoch 36:	0.12744504  	0.09336787  	0.16265398  
2023-04-29 18:34:56.863: [iter 37 : loss : 0.3090 = 0.0625 + 0.2370 + 0.0083 + 0.0013, time: 140.391293]
2023-04-29 18:34:57.271: epoch 37:	0.12732531  	0.09421876  	0.16283345  
2023-04-29 18:37:14.562: [iter 38 : loss : 0.3069 = 0.0622 + 0.2349 + 0.0086 + 0.0012, time: 137.254039]
2023-04-29 18:37:15.017: epoch 38:	0.12760471  	0.09373215  	0.16296397  
2023-04-29 18:39:35.844: [iter 39 : loss : 0.3022 = 0.0593 + 0.2328 + 0.0089 + 0.0012, time: 140.784467]
2023-04-29 18:39:36.249: epoch 39:	0.12790419  	0.09451839  	0.16318147  
2023-04-29 18:39:36.249: Find a better model.
2023-04-29 18:41:52.570: [iter 40 : loss : 0.3006 = 0.0595 + 0.2307 + 0.0092 + 0.0012, time: 136.282672]
2023-04-29 18:41:52.995: epoch 40:	0.12794401  	0.09506612  	0.16372152  
2023-04-29 18:41:52.995: Find a better model.
2023-04-29 18:44:13.402: [iter 41 : loss : 0.2982 = 0.0588 + 0.2287 + 0.0095 + 0.0012, time: 140.367876]
2023-04-29 18:44:13.817: epoch 41:	0.12758474  	0.09490364  	0.16338906  
2023-04-29 18:46:34.826: [iter 42 : loss : 0.2954 = 0.0577 + 0.2268 + 0.0098 + 0.0012, time: 140.963950]
2023-04-29 18:46:35.219: epoch 42:	0.12786406  	0.09540758  	0.16304953  
2023-04-29 18:46:35.219: Find a better model.
2023-04-29 18:48:50.000: [iter 43 : loss : 0.2930 = 0.0569 + 0.2248 + 0.0101 + 0.0012, time: 134.741193]
2023-04-29 18:48:50.390: epoch 43:	0.12842292  	0.09539095  	0.16361970  
2023-04-29 18:51:11.137: [iter 44 : loss : 0.2905 = 0.0559 + 0.2231 + 0.0104 + 0.0012, time: 140.700586]
2023-04-29 18:51:11.573: epoch 44:	0.12880215  	0.09637285  	0.16395828  
2023-04-29 18:51:11.573: Find a better model.
2023-04-29 18:53:30.055: [iter 45 : loss : 0.2879 = 0.0548 + 0.2212 + 0.0107 + 0.0012, time: 138.442107]
2023-04-29 18:53:30.469: epoch 45:	0.12836303  	0.09583490  	0.16410965  
2023-04-29 18:55:51.283: [iter 46 : loss : 0.2861 = 0.0545 + 0.2195 + 0.0110 + 0.0012, time: 140.767128]
2023-04-29 18:55:51.725: epoch 46:	0.12828335  	0.09547338  	0.16367878  
2023-04-29 18:58:09.573: [iter 47 : loss : 0.2837 = 0.0535 + 0.2178 + 0.0112 + 0.0012, time: 137.801568]
2023-04-29 18:58:09.981: epoch 47:	0.12860261  	0.09487575  	0.16359212  
2023-04-29 19:00:28.708: [iter 48 : loss : 0.2817 = 0.0529 + 0.2161 + 0.0115 + 0.0011, time: 138.684276]
2023-04-29 19:00:29.129: epoch 48:	0.12874231  	0.09531348  	0.16378711  
2023-04-29 19:02:49.412: [iter 49 : loss : 0.2796 = 0.0522 + 0.2145 + 0.0118 + 0.0011, time: 140.235687]
2023-04-29 19:02:49.806: epoch 49:	0.12886213  	0.09599137  	0.16379248  
2023-04-29 19:05:07.360: [iter 50 : loss : 0.2774 = 0.0513 + 0.2129 + 0.0121 + 0.0011, time: 137.512188]
2023-04-29 19:05:07.721: epoch 50:	0.12892205  	0.09499319  	0.16370799  
2023-04-29 19:07:23.566: [iter 51 : loss : 0.2757 = 0.0509 + 0.2113 + 0.0123 + 0.0011, time: 135.802706]
2023-04-29 19:07:23.963: epoch 51:	0.12850291  	0.09509234  	0.16316268  
2023-04-29 19:09:42.848: [iter 52 : loss : 0.2735 = 0.0500 + 0.2098 + 0.0126 + 0.0011, time: 138.841774]
2023-04-29 19:09:43.280: epoch 52:	0.12830333  	0.09488538  	0.16342530  
2023-04-29 19:12:03.576: [iter 53 : loss : 0.2717 = 0.0496 + 0.2082 + 0.0129 + 0.0011, time: 140.246377]
2023-04-29 19:12:03.988: epoch 53:	0.12854278  	0.09517107  	0.16342737  
2023-04-29 19:14:22.667: [iter 54 : loss : 0.2696 = 0.0486 + 0.2068 + 0.0131 + 0.0011, time: 138.637453]
2023-04-29 19:14:23.127: epoch 54:	0.12884220  	0.09463624  	0.16340661  
2023-04-29 19:14:23.127: Early stopping is trigger at epoch: 54
2023-04-29 19:14:23.127: best_result@epoch 44:

2023-04-29 19:14:23.127: 		0.1288      	0.0964      	0.1640      

2023-09-01 12:12:37.292: my pid: 31778
2023-09-01 12:12:37.292: model: model.general_recommender.GNNEC
2023-09-01 12:12:37.292: Dataset statistics:
Name: douban
The number of users: 2765
The number of items: 26926
The number of ratings: 882145
Average actions of users: 319.04
Average actions of items: 32.76
The sparsity of the dataset: 98.815124%

The number of training: 795166
The number of validation: 0
The number of testing: 86979
2023-09-01 12:12:37.292: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=douban
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=douban
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
mf_reg=0.02
svd_q=5
2023-09-01 12:12:49.647: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 12:13:26.334: [iter 1 : loss : 1.1674 = 0.5000 + 0.3343 + 0.0002 + 0.3330, time: 36.685598]
2023-09-01 12:13:26.618: epoch 1:	0.08151744  	0.06036506  	0.10623460  
2023-09-01 12:13:26.619: Find a better model.
2023-09-01 12:14:03.187: [iter 2 : loss : 0.9290 = 0.3037 + 0.3137 + 0.0006 + 0.3111, time: 36.532652]
2023-09-01 12:14:03.470: epoch 2:	0.08570904  	0.06495298  	0.11172735  
2023-09-01 12:14:03.470: Find a better model.
2023-09-01 12:14:39.962: [iter 3 : loss : 0.8396 = 0.2490 + 0.2964 + 0.0009 + 0.2933, time: 36.442168]
2023-09-01 12:14:40.222: epoch 3:	0.09227599  	0.06914196  	0.11988629  
2023-09-01 12:14:40.222: Find a better model.
2023-09-01 12:15:16.326: [iter 4 : loss : 0.7698 = 0.2123 + 0.2797 + 0.0012 + 0.2766, time: 36.069403]
2023-09-01 12:15:16.585: epoch 4:	0.09982096  	0.07614420  	0.12877961  
2023-09-01 12:15:16.585: Find a better model.
2023-09-01 12:15:52.955: [iter 5 : loss : 0.7126 = 0.1854 + 0.2646 + 0.0016 + 0.2610, time: 36.339597]
2023-09-01 12:15:53.213: epoch 5:	0.10590860  	0.07995812  	0.13562110  
2023-09-01 12:15:53.213: Find a better model.
2023-09-01 12:16:29.250: [iter 6 : loss : 0.6654 = 0.1671 + 0.2501 + 0.0021 + 0.2462, time: 36.002962]
2023-09-01 12:16:29.507: epoch 6:	0.11033960  	0.08236080  	0.14015326  
2023-09-01 12:16:29.508: Find a better model.
2023-09-01 12:17:05.881: [iter 7 : loss : 0.6230 = 0.1525 + 0.2360 + 0.0025 + 0.2320, time: 36.345902]
2023-09-01 12:17:06.152: epoch 7:	0.11413193  	0.08507254  	0.14550821  
2023-09-01 12:17:06.153: Find a better model.
2023-09-01 12:17:42.628: [iter 8 : loss : 0.5849 = 0.1412 + 0.2225 + 0.0030 + 0.2183, time: 36.447645]
2023-09-01 12:17:42.915: epoch 8:	0.11728557  	0.08801142  	0.14962713  
2023-09-01 12:17:42.915: Find a better model.
2023-09-01 12:18:19.396: [iter 9 : loss : 0.5481 = 0.1297 + 0.2096 + 0.0035 + 0.2052, time: 36.447675]
2023-09-01 12:18:19.678: epoch 9:	0.12015975  	0.08975321  	0.15300074  
2023-09-01 12:18:19.678: Find a better model.
2023-09-01 12:18:56.155: [iter 10 : loss : 0.5161 = 0.1220 + 0.1973 + 0.0041 + 0.1927, time: 36.441544]
2023-09-01 12:18:56.422: epoch 10:	0.12199617  	0.09056874  	0.15460995  
2023-09-01 12:18:56.422: Find a better model.
2023-09-01 12:19:32.603: [iter 11 : loss : 0.4874 = 0.1158 + 0.1857 + 0.0047 + 0.1812, time: 36.153503]
2023-09-01 12:19:32.877: epoch 11:	0.12307394  	0.09107778  	0.15527962  
2023-09-01 12:19:32.878: Find a better model.
2023-09-01 12:20:27.914: [iter 12 : loss : 0.4592 = 0.1083 + 0.1752 + 0.0053 + 0.1704, time: 55.012401]
2023-09-01 12:20:28.167: epoch 12:	0.12411191  	0.09141197  	0.15601423  
2023-09-01 12:20:28.167: Find a better model.
2023-09-01 12:21:27.099: [iter 13 : loss : 0.4363 = 0.1044 + 0.1653 + 0.0059 + 0.1607, time: 58.901170]
2023-09-01 12:21:27.365: epoch 13:	0.12435140  	0.09324417  	0.15619710  
2023-09-01 12:21:27.366: Find a better model.
2023-09-01 12:22:26.778: [iter 14 : loss : 0.4138 = 0.0993 + 0.1563 + 0.0065 + 0.1517, time: 59.390473]
2023-09-01 12:22:27.042: epoch 14:	0.12518972  	0.09331553  	0.15635960  
2023-09-01 12:22:27.042: Find a better model.
2023-09-01 12:23:26.430: [iter 15 : loss : 0.3961 = 0.0970 + 0.1483 + 0.0070 + 0.1438, time: 59.363865]
2023-09-01 12:23:26.681: epoch 15:	0.12481039  	0.09263966  	0.15589724  
2023-09-01 12:24:25.753: [iter 16 : loss : 0.3780 = 0.0926 + 0.1412 + 0.0076 + 0.1367, time: 59.043622]
2023-09-01 12:24:26.014: epoch 16:	0.12467065  	0.09131265  	0.15508963  
2023-09-01 12:25:24.668: [iter 17 : loss : 0.3636 = 0.0904 + 0.1348 + 0.0081 + 0.1304, time: 58.631099]
2023-09-01 12:25:24.925: epoch 17:	0.12463088  	0.09109716  	0.15494339  
2023-09-01 12:26:23.957: [iter 18 : loss : 0.3495 = 0.0869 + 0.1291 + 0.0087 + 0.1249, time: 59.013211]
2023-09-01 12:26:24.217: epoch 18:	0.12443129  	0.09164862  	0.15454373  
2023-09-01 12:27:23.649: [iter 19 : loss : 0.3385 = 0.0855 + 0.1240 + 0.0091 + 0.1199, time: 59.410607]
2023-09-01 12:27:23.920: epoch 19:	0.12365288  	0.09082023  	0.15349144  
2023-09-01 12:28:23.893: [iter 20 : loss : 0.3279 = 0.0835 + 0.1193 + 0.0096 + 0.1155, time: 59.941499]
2023-09-01 12:28:24.139: epoch 20:	0.12323368  	0.08993779  	0.15276711  
2023-09-01 12:29:23.561: [iter 21 : loss : 0.3184 = 0.0814 + 0.1154 + 0.0100 + 0.1116, time: 59.399319]
2023-09-01 12:29:23.769: epoch 21:	0.12299422  	0.08957715  	0.15261127  
2023-09-01 12:30:22.462: [iter 22 : loss : 0.3118 = 0.0814 + 0.1118 + 0.0105 + 0.1082, time: 58.671974]
2023-09-01 12:30:22.709: epoch 22:	0.12197624  	0.08872022  	0.15164028  
2023-09-01 12:31:21.780: [iter 23 : loss : 0.3030 = 0.0786 + 0.1085 + 0.0109 + 0.1050, time: 59.044800]
2023-09-01 12:31:22.039: epoch 23:	0.12109799  	0.08741248  	0.15079488  
2023-09-01 12:32:21.175: [iter 24 : loss : 0.2965 = 0.0778 + 0.1054 + 0.0112 + 0.1021, time: 59.110103]
2023-09-01 12:32:21.416: epoch 24:	0.12073874  	0.08757462  	0.15042125  
2023-09-01 12:32:21.417: Early stopping is trigger at epoch: 24
2023-09-01 12:32:21.417: best_result@epoch 14:

2023-09-01 12:32:21.417: 		0.1252      	0.0933      	0.1564      

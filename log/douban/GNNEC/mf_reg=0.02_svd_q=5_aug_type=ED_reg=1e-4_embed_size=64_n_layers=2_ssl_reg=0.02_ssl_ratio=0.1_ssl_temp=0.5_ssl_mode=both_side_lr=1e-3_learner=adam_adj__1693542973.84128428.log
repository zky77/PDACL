2023-09-01 12:36:13.841: my pid: 38432
2023-09-01 12:36:13.841: model: model.general_recommender.GNNEC
2023-09-01 12:36:13.841: Dataset statistics:
Name: douban
The number of users: 2765
The number of items: 26926
The number of ratings: 882145
Average actions of users: 319.04
Average actions of items: 32.76
The sparsity of the dataset: 98.815124%

The number of training: 795166
The number of validation: 0
The number of testing: 86979
2023-09-01 12:36:13.841: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=douban
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ED
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=douban
epochs=200
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ED
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
mf_reg=0.02
svd_q=5
2023-09-01 12:36:28.874: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 12:37:28.946: [iter 1 : loss : 1.1692 = 0.5029 + 0.3339 + 0.0002 + 0.3322, time: 60.071327]
2023-09-01 12:37:29.213: epoch 1:	0.08301441  	0.06168383  	0.10823145  
2023-09-01 12:37:29.213: Find a better model.
2023-09-01 12:38:29.135: [iter 2 : loss : 0.9204 = 0.3011 + 0.3109 + 0.0006 + 0.3077, time: 59.896308]
2023-09-01 12:38:29.395: epoch 2:	0.08748550  	0.06387544  	0.11445778  
2023-09-01 12:38:29.395: Find a better model.
2023-09-01 12:39:29.653: [iter 3 : loss : 0.8284 = 0.2454 + 0.2928 + 0.0009 + 0.2893, time: 60.238748]
2023-09-01 12:39:29.927: epoch 3:	0.09628797  	0.07237709  	0.12497551  
2023-09-01 12:39:29.927: Find a better model.
2023-09-01 12:40:30.420: [iter 4 : loss : 0.7605 = 0.2100 + 0.2765 + 0.0013 + 0.2728, time: 60.475075]
2023-09-01 12:40:30.661: epoch 4:	0.10261529  	0.07713457  	0.13142762  
2023-09-01 12:40:30.661: Find a better model.
2023-09-01 12:41:30.940: [iter 5 : loss : 0.7055 = 0.1846 + 0.2615 + 0.0017 + 0.2577, time: 60.257591]
2023-09-01 12:41:31.191: epoch 5:	0.10758517  	0.08134978  	0.13636911  
2023-09-01 12:41:31.191: Find a better model.
2023-09-01 12:42:32.531: [iter 6 : loss : 0.6592 = 0.1660 + 0.2475 + 0.0021 + 0.2436, time: 61.320524]
2023-09-01 12:42:32.789: epoch 6:	0.11143736  	0.08297997  	0.14099677  
2023-09-01 12:42:32.790: Find a better model.
2023-09-01 12:43:33.560: [iter 7 : loss : 0.6181 = 0.1515 + 0.2340 + 0.0026 + 0.2300, time: 60.746288]
2023-09-01 12:43:33.818: epoch 7:	0.11471072  	0.08569064  	0.14515276  
2023-09-01 12:43:33.818: Find a better model.
2023-09-01 12:44:34.102: [iter 8 : loss : 0.5814 = 0.1405 + 0.2210 + 0.0031 + 0.2169, time: 60.255643]
2023-09-01 12:44:34.364: epoch 8:	0.11780447  	0.08902643  	0.14861979  
2023-09-01 12:44:34.364: Find a better model.
2023-09-01 12:45:34.620: [iter 9 : loss : 0.5469 = 0.1305 + 0.2085 + 0.0036 + 0.2043, time: 60.228190]
2023-09-01 12:45:34.854: epoch 9:	0.11966075  	0.09136251  	0.15086031  
2023-09-01 12:45:34.854: Find a better model.
2023-09-01 12:46:35.451: [iter 10 : loss : 0.5161 = 0.1231 + 0.1966 + 0.0041 + 0.1923, time: 60.575304]
2023-09-01 12:46:35.705: epoch 10:	0.12095819  	0.09327646  	0.15275586  
2023-09-01 12:46:35.705: Find a better model.
2023-09-01 12:47:36.116: [iter 11 : loss : 0.4864 = 0.1154 + 0.1854 + 0.0047 + 0.1809, time: 60.388047]
2023-09-01 12:47:36.371: epoch 11:	0.12175650  	0.09302588  	0.15378293  
2023-09-01 12:48:37.935: [iter 12 : loss : 0.4593 = 0.1090 + 0.1748 + 0.0053 + 0.1703, time: 61.539057]
2023-09-01 12:48:38.199: epoch 12:	0.12225551  	0.09275009  	0.15410446  
2023-09-01 12:49:39.468: [iter 13 : loss : 0.4360 = 0.1045 + 0.1651 + 0.0059 + 0.1606, time: 61.244226]
2023-09-01 12:49:39.664: epoch 13:	0.12195617  	0.09213296  	0.15372962  
2023-09-01 12:50:40.082: [iter 14 : loss : 0.4142 = 0.0998 + 0.1562 + 0.0064 + 0.1517, time: 60.391406]
2023-09-01 12:50:40.338: epoch 14:	0.12251507  	0.09198742  	0.15375645  
2023-09-01 12:51:40.925: [iter 15 : loss : 0.3952 = 0.0963 + 0.1481 + 0.0070 + 0.1437, time: 60.567373]
2023-09-01 12:51:41.183: epoch 15:	0.12253504  	0.09120290  	0.15281564  
2023-09-01 12:52:42.786: [iter 16 : loss : 0.3780 = 0.0927 + 0.1410 + 0.0076 + 0.1367, time: 61.575010]
2023-09-01 12:52:43.045: epoch 16:	0.12195617  	0.09092200  	0.15212946  
2023-09-01 12:53:44.213: [iter 17 : loss : 0.3639 = 0.0908 + 0.1345 + 0.0081 + 0.1304, time: 61.141847]
2023-09-01 12:53:44.455: epoch 17:	0.12163687  	0.09026527  	0.15145919  
2023-09-01 12:54:45.491: [iter 18 : loss : 0.3498 = 0.0877 + 0.1287 + 0.0086 + 0.1247, time: 61.013353]
2023-09-01 12:54:45.745: epoch 18:	0.12133755  	0.08941021  	0.15122297  
2023-09-01 12:55:46.883: [iter 19 : loss : 0.3384 = 0.0859 + 0.1236 + 0.0091 + 0.1197, time: 61.114151]
2023-09-01 12:55:47.140: epoch 19:	0.12051921  	0.08910462  	0.15010379  
2023-09-01 12:56:48.865: [iter 20 : loss : 0.3272 = 0.0830 + 0.1191 + 0.0096 + 0.1155, time: 61.690874]
2023-09-01 12:56:49.134: epoch 20:	0.11996024  	0.08807090  	0.14926939  
2023-09-01 12:56:49.134: Early stopping is trigger at epoch: 20
2023-09-01 12:56:49.134: best_result@epoch 10:

2023-09-01 12:56:49.134: 		0.1210      	0.0933      	0.1528      

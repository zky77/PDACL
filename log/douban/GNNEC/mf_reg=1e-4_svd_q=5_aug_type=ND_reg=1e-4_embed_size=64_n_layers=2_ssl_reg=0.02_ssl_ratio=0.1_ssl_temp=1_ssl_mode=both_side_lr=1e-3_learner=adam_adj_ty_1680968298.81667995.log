2023-04-08 23:38:18.817: my pid: 34142
2023-04-08 23:38:18.817: model: model.general_recommender.GNNEC
2023-04-08 23:38:18.817: Dataset statistics:
Name: douban
The number of users: 2765
The number of items: 26926
The number of ratings: 882145
Average actions of users: 319.04
Average actions of items: 32.76
The sparsity of the dataset: 98.815124%

The number of training: 795166
The number of validation: 0
The number of testing: 86979
2023-04-08 23:38:18.817: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=douban
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=1e-4
svd_q=5
aug_type=ND
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=1
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=100
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=douban
epochs=100
n_layers=2
embed_size=64
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=1
mf_reg=1e-4
svd_q=5
2023-04-08 23:38:24.967: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-04-08 23:40:17.622: [iter 1 : loss : 0.7529 = 0.4026 + 0.3483 + 0.0002 + 0.0018, time: 112.653843]
2023-04-08 23:40:17.926: epoch 1:	0.08115818  	0.05980886  	0.10525309  
2023-04-08 23:40:17.926: Find a better model.
2023-04-08 23:42:10.564: [iter 2 : loss : 0.5585 = 0.2170 + 0.3392 + 0.0006 + 0.0018, time: 112.610752]
2023-04-08 23:42:10.857: epoch 2:	0.07934183  	0.05844683  	0.10359100  
2023-04-08 23:43:35.638: [iter 3 : loss : 0.5404 = 0.2022 + 0.3357 + 0.0007 + 0.0018, time: 84.756493]
2023-04-08 23:43:35.923: epoch 3:	0.07792468  	0.05794659  	0.10199980  
2023-04-08 23:45:10.131: [iter 4 : loss : 0.5303 = 0.1942 + 0.3336 + 0.0008 + 0.0017, time: 94.174452]
2023-04-08 23:45:10.424: epoch 4:	0.07762519  	0.05788973  	0.10194089  
2023-04-08 23:47:03.388: [iter 5 : loss : 0.5223 = 0.1878 + 0.3319 + 0.0009 + 0.0017, time: 112.937633]
2023-04-08 23:47:03.680: epoch 5:	0.07782482  	0.05765366  	0.10209013  
2023-04-08 23:48:45.265: [iter 6 : loss : 0.5151 = 0.1821 + 0.3303 + 0.0010 + 0.0017, time: 101.559844]
2023-04-08 23:48:45.537: epoch 6:	0.07858334  	0.05850353  	0.10291336  
2023-04-08 23:50:04.709: [iter 7 : loss : 0.5077 = 0.1767 + 0.3282 + 0.0011 + 0.0017, time: 79.141606]
2023-04-08 23:50:05.001: epoch 7:	0.07930192  	0.05874966  	0.10351113  
2023-04-08 23:51:57.521: [iter 8 : loss : 0.4979 = 0.1693 + 0.3258 + 0.0012 + 0.0017, time: 112.495260]
2023-04-08 23:51:57.840: epoch 8:	0.08147753  	0.06040150  	0.10625011  
2023-04-08 23:51:57.840: Find a better model.
2023-04-08 23:53:50.191: [iter 9 : loss : 0.4859 = 0.1599 + 0.3230 + 0.0013 + 0.0017, time: 112.324758]
2023-04-08 23:53:50.488: epoch 9:	0.08379293  	0.06141570  	0.10861552  
2023-04-08 23:53:50.488: Find a better model.
2023-04-08 23:55:17.712: [iter 10 : loss : 0.4760 = 0.1532 + 0.3197 + 0.0014 + 0.0017, time: 87.198477]
2023-04-08 23:55:17.991: epoch 10:	0.08658731  	0.06274518  	0.11135131  
2023-04-08 23:55:17.991: Find a better model.
2023-04-08 23:56:52.884: [iter 11 : loss : 0.4650 = 0.1455 + 0.3163 + 0.0015 + 0.0017, time: 94.864765]
2023-04-08 23:56:53.179: epoch 11:	0.08982083  	0.06444673  	0.11516812  
2023-04-08 23:56:53.179: Find a better model.
2023-04-08 23:58:45.599: [iter 12 : loss : 0.4529 = 0.1370 + 0.3125 + 0.0017 + 0.0016, time: 112.395483]
2023-04-08 23:58:45.885: epoch 12:	0.09313425  	0.06727841  	0.11920276  
2023-04-08 23:58:45.885: Find a better model.
2023-04-09 00:00:27.958: [iter 13 : loss : 0.4430 = 0.1307 + 0.3088 + 0.0019 + 0.0016, time: 102.045951]
2023-04-09 00:00:28.221: epoch 13:	0.09750554  	0.07100300  	0.12452298  
2023-04-09 00:00:28.221: Find a better model.
2023-04-09 00:01:49.064: [iter 14 : loss : 0.4333 = 0.1247 + 0.3049 + 0.0021 + 0.0016, time: 80.816101]
2023-04-09 00:01:49.357: epoch 14:	0.10147764  	0.07416527  	0.12951992  
2023-04-09 00:01:49.357: Find a better model.
2023-04-09 00:03:42.115: [iter 15 : loss : 0.4246 = 0.1197 + 0.3010 + 0.0023 + 0.0016, time: 112.731930]
2023-04-09 00:03:42.408: epoch 15:	0.10592847  	0.07797974  	0.13452518  
2023-04-09 00:03:42.408: Find a better model.
2023-04-09 00:05:35.077: [iter 16 : loss : 0.4144 = 0.1130 + 0.2973 + 0.0025 + 0.0016, time: 112.641783]
2023-04-09 00:05:35.370: epoch 16:	0.10920189  	0.07998818  	0.13874803  
2023-04-09 00:05:35.370: Find a better model.
2023-04-09 00:07:01.776: [iter 17 : loss : 0.4072 = 0.1094 + 0.2936 + 0.0027 + 0.0015, time: 86.369417]
2023-04-09 00:07:02.051: epoch 17:	0.11081853  	0.08108015  	0.14134665  
2023-04-09 00:07:02.051: Find a better model.
2023-04-09 00:08:38.697: [iter 18 : loss : 0.3992 = 0.1046 + 0.2901 + 0.0029 + 0.0015, time: 96.617868]
2023-04-09 00:08:39.011: epoch 18:	0.11275467  	0.08396780  	0.14361823  
2023-04-09 00:08:39.011: Find a better model.
2023-04-09 00:10:31.577: [iter 19 : loss : 0.3920 = 0.1007 + 0.2866 + 0.0032 + 0.0015, time: 112.535111]
2023-04-09 00:10:31.868: epoch 19:	0.11471064  	0.08533424  	0.14581829  
2023-04-09 00:10:31.868: Find a better model.
2023-04-09 00:12:12.448: [iter 20 : loss : 0.3853 = 0.0971 + 0.2833 + 0.0034 + 0.0015, time: 100.555091]
2023-04-09 00:12:12.724: epoch 20:	0.11526957  	0.08541337  	0.14723305  
2023-04-09 00:12:12.724: Find a better model.
2023-04-09 00:13:33.581: [iter 21 : loss : 0.3786 = 0.0935 + 0.2800 + 0.0036 + 0.0015, time: 80.828310]
2023-04-09 00:13:33.885: epoch 21:	0.11726558  	0.08783697  	0.14971271  
2023-04-09 00:13:33.885: Find a better model.
2023-04-09 00:15:26.184: [iter 22 : loss : 0.3739 = 0.0917 + 0.2768 + 0.0039 + 0.0015, time: 112.273517]
2023-04-09 00:15:26.466: epoch 22:	0.11814371  	0.08821151  	0.15080896  
2023-04-09 00:15:26.467: Find a better model.
2023-04-09 00:17:19.065: [iter 23 : loss : 0.3672 = 0.0878 + 0.2738 + 0.0041 + 0.0014, time: 112.572491]
2023-04-09 00:17:19.367: epoch 23:	0.11920160  	0.08861745  	0.15241635  
2023-04-09 00:17:19.367: Find a better model.
2023-04-09 00:18:44.619: [iter 24 : loss : 0.3620 = 0.0854 + 0.2708 + 0.0044 + 0.0014, time: 85.225819]
2023-04-09 00:18:44.925: epoch 24:	0.12063874  	0.08953144  	0.15384212  
2023-04-09 00:18:44.926: Find a better model.
2023-04-09 00:20:18.295: [iter 25 : loss : 0.3569 = 0.0831 + 0.2677 + 0.0047 + 0.0014, time: 93.327204]
2023-04-09 00:20:18.589: epoch 25:	0.12167664  	0.09023599  	0.15495588  
2023-04-09 00:20:18.589: Find a better model.
2023-04-09 00:22:11.197: [iter 26 : loss : 0.3517 = 0.0806 + 0.2647 + 0.0050 + 0.0014, time: 112.583201]
2023-04-09 00:22:11.493: epoch 26:	0.12215570  	0.09032156  	0.15600610  
2023-04-09 00:22:11.494: Find a better model.
2023-04-09 00:23:52.556: [iter 27 : loss : 0.3471 = 0.0785 + 0.2620 + 0.0052 + 0.0014, time: 101.035467]
2023-04-09 00:23:52.833: epoch 27:	0.12267460  	0.09064260  	0.15715067  
2023-04-09 00:23:52.833: Find a better model.
2023-04-09 00:25:11.610: [iter 28 : loss : 0.3426 = 0.0765 + 0.2593 + 0.0055 + 0.0014, time: 78.748504]
2023-04-09 00:25:11.816: epoch 28:	0.12315363  	0.09076530  	0.15761891  
2023-04-09 00:25:11.816: Find a better model.
2023-04-09 00:27:00.676: [iter 29 : loss : 0.3384 = 0.0748 + 0.2564 + 0.0058 + 0.0013, time: 108.836347]
2023-04-09 00:27:00.970: epoch 29:	0.12355288  	0.09167725  	0.15844035  
2023-04-09 00:27:00.970: Find a better model.
2023-04-09 00:28:53.693: [iter 30 : loss : 0.3335 = 0.0722 + 0.2538 + 0.0061 + 0.0013, time: 112.700347]
2023-04-09 00:28:53.983: epoch 30:	0.12441117  	0.09165122  	0.15962964  
2023-04-09 00:30:23.103: [iter 31 : loss : 0.3301 = 0.0711 + 0.2513 + 0.0064 + 0.0013, time: 89.097342]
2023-04-09 00:30:23.385: epoch 31:	0.12534927  	0.09271374  	0.16068256  
2023-04-09 00:30:23.385: Find a better model.
2023-04-09 00:31:48.439: [iter 32 : loss : 0.3255 = 0.0688 + 0.2487 + 0.0067 + 0.0013, time: 85.024262]
2023-04-09 00:31:48.735: epoch 32:	0.12612768  	0.09335218  	0.16127016  
2023-04-09 00:31:48.735: Find a better model.
2023-04-09 00:33:41.082: [iter 33 : loss : 0.3226 = 0.0680 + 0.2462 + 0.0070 + 0.0013, time: 112.321428]
2023-04-09 00:33:41.357: epoch 33:	0.12636727  	0.09340189  	0.16176276  
2023-04-09 00:33:41.357: Find a better model.
2023-04-09 00:35:30.721: [iter 34 : loss : 0.3188 = 0.0664 + 0.2438 + 0.0073 + 0.0013, time: 109.340021]
2023-04-09 00:35:31.000: epoch 34:	0.12736531  	0.09425153  	0.16271560  
2023-04-09 00:35:31.000: Find a better model.
2023-04-09 00:36:55.578: [iter 35 : loss : 0.3162 = 0.0658 + 0.2415 + 0.0076 + 0.0013, time: 84.549647]
2023-04-09 00:36:55.849: epoch 35:	0.12666662  	0.09288430  	0.16214299  
2023-04-09 00:38:35.066: [iter 36 : loss : 0.3130 = 0.0645 + 0.2393 + 0.0080 + 0.0013, time: 99.187717]
2023-04-09 00:38:35.361: epoch 36:	0.12744504  	0.09336787  	0.16265398  
2023-04-09 00:40:28.214: [iter 37 : loss : 0.3090 = 0.0625 + 0.2370 + 0.0083 + 0.0013, time: 112.826569]
2023-04-09 00:40:28.512: epoch 37:	0.12732531  	0.09421876  	0.16283345  
2023-04-09 00:42:04.202: [iter 38 : loss : 0.3069 = 0.0622 + 0.2349 + 0.0086 + 0.0012, time: 95.663141]
2023-04-09 00:42:04.439: epoch 38:	0.12760471  	0.09373215  	0.16296397  
2023-04-09 00:43:28.696: [iter 39 : loss : 0.3022 = 0.0593 + 0.2328 + 0.0089 + 0.0012, time: 84.229766]
2023-04-09 00:43:28.988: epoch 39:	0.12790419  	0.09451839  	0.16318147  
2023-04-09 00:43:28.988: Find a better model.
2023-04-09 00:45:21.466: [iter 40 : loss : 0.3006 = 0.0595 + 0.2307 + 0.0092 + 0.0012, time: 112.456942]
2023-04-09 00:45:21.764: epoch 40:	0.12794401  	0.09506612  	0.16372152  
2023-04-09 00:45:21.764: Find a better model.
2023-04-09 00:47:12.606: [iter 41 : loss : 0.2982 = 0.0588 + 0.2287 + 0.0095 + 0.0012, time: 110.817202]
2023-04-09 00:47:12.878: epoch 41:	0.12758474  	0.09490364  	0.16338906  
2023-04-09 00:48:39.107: [iter 42 : loss : 0.2954 = 0.0577 + 0.2268 + 0.0098 + 0.0012, time: 86.204998]
2023-04-09 00:48:39.383: epoch 42:	0.12786406  	0.09540758  	0.16304953  
2023-04-09 00:48:39.383: Find a better model.
2023-04-09 00:50:16.564: [iter 43 : loss : 0.2930 = 0.0569 + 0.2248 + 0.0101 + 0.0012, time: 97.152607]
2023-04-09 00:50:16.856: epoch 43:	0.12842292  	0.09539095  	0.16361970  
2023-04-09 00:52:09.200: [iter 44 : loss : 0.2905 = 0.0559 + 0.2231 + 0.0104 + 0.0012, time: 112.318403]
2023-04-09 00:52:09.490: epoch 44:	0.12880215  	0.09637285  	0.16395828  
2023-04-09 00:52:09.491: Find a better model.
2023-04-09 00:53:47.108: [iter 45 : loss : 0.2879 = 0.0548 + 0.2212 + 0.0107 + 0.0012, time: 97.590583]
2023-04-09 00:53:47.385: epoch 45:	0.12836303  	0.09583490  	0.16410965  
2023-04-09 00:55:10.947: [iter 46 : loss : 0.2861 = 0.0545 + 0.2195 + 0.0110 + 0.0012, time: 83.530891]
2023-04-09 00:55:11.244: epoch 46:	0.12828335  	0.09547338  	0.16367878  
2023-04-09 00:57:03.815: [iter 47 : loss : 0.2837 = 0.0535 + 0.2178 + 0.0112 + 0.0012, time: 112.546147]
2023-04-09 00:57:04.107: epoch 47:	0.12860261  	0.09487575  	0.16359212  
2023-04-09 00:58:55.693: [iter 48 : loss : 0.2817 = 0.0529 + 0.2161 + 0.0115 + 0.0011, time: 111.560058]
2023-04-09 00:58:55.972: epoch 48:	0.12874231  	0.09531348  	0.16378711  
2023-04-09 01:00:22.358: [iter 49 : loss : 0.2796 = 0.0522 + 0.2145 + 0.0118 + 0.0011, time: 86.356579]
2023-04-09 01:00:22.616: epoch 49:	0.12886213  	0.09599137  	0.16379248  
2023-04-09 01:02:01.314: [iter 50 : loss : 0.2774 = 0.0513 + 0.2129 + 0.0121 + 0.0011, time: 98.672008]
2023-04-09 01:02:01.611: epoch 50:	0.12892205  	0.09499319  	0.16370799  
2023-04-09 01:03:53.826: [iter 51 : loss : 0.2757 = 0.0509 + 0.2113 + 0.0123 + 0.0011, time: 112.190364]
2023-04-09 01:03:54.119: epoch 51:	0.12850291  	0.09509234  	0.16316268  
2023-04-09 01:05:31.955: [iter 52 : loss : 0.2735 = 0.0500 + 0.2098 + 0.0126 + 0.0011, time: 97.810256]
2023-04-09 01:05:32.202: epoch 52:	0.12830333  	0.09488538  	0.16342530  
2023-04-09 01:06:55.216: [iter 53 : loss : 0.2717 = 0.0496 + 0.2082 + 0.0129 + 0.0011, time: 82.984313]
2023-04-09 01:06:55.514: epoch 53:	0.12854278  	0.09517107  	0.16342737  
2023-04-09 01:08:48.623: [iter 54 : loss : 0.2696 = 0.0486 + 0.2068 + 0.0131 + 0.0011, time: 113.081585]
2023-04-09 01:08:48.916: epoch 54:	0.12884220  	0.09463624  	0.16340661  
2023-04-09 01:08:48.917: Early stopping is trigger at epoch: 54
2023-04-09 01:08:48.917: best_result@epoch 44:

2023-04-09 01:08:48.917: 		0.1288      	0.0964      	0.1640      

2023-09-01 11:18:05.300: my pid: 24648
2023-09-01 11:18:05.300: model: model.general_recommender.GNNEC
2023-09-01 11:18:05.300: Dataset statistics:
Name: douban
The number of users: 2765
The number of items: 26926
The number of ratings: 882145
Average actions of users: 319.04
Average actions of items: 32.76
The sparsity of the dataset: 98.815124%

The number of training: 795166
The number of validation: 0
The number of testing: 86979
2023-09-01 11:18:05.300: NeuRec:[NeuRec]:
recommender=GNNEC
dataset=douban
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

GNNEC:[hyperparameters]:
mf_reg=0.02
svd_q=5
aug_type=ND
reg=1e-4
embed_size=32
n_layers=2
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
ssl_mode=both_side
lr=1e-3
learner=adam
adj_type=pre
epochs=200
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0

Command line:
recommender=GNNEC
dataset=douban
epochs=200
n_layers=2
embed_size=32
batch_size=2048
lr=1e-3
aug_type=ND
reg=1e-4
ssl_reg=0.02
ssl_ratio=0.1
ssl_temp=0.5
mf_reg=0.02
svd_q=5
2023-09-01 11:18:17.431: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-09-01 11:18:48.213: [iter 1 : loss : 1.2225 = 0.5455 + 0.3391 + 0.0001 + 0.3378, time: 30.782128]
2023-09-01 11:18:48.492: epoch 1:	0.08105834  	0.06061111  	0.10514743  
2023-09-01 11:18:48.493: Find a better model.
2023-09-01 11:19:18.846: [iter 2 : loss : 0.9872 = 0.3412 + 0.3236 + 0.0004 + 0.3219, time: 30.320132]
2023-09-01 11:19:19.107: epoch 2:	0.08089869  	0.05994977  	0.10472769  
2023-09-01 11:19:49.491: [iter 3 : loss : 0.9160 = 0.2896 + 0.3138 + 0.0006 + 0.3119, time: 30.347658]
2023-09-01 11:19:49.752: epoch 3:	0.08173700  	0.06128508  	0.10713030  
2023-09-01 11:19:49.752: Find a better model.
2023-09-01 11:20:20.012: [iter 4 : loss : 0.8613 = 0.2556 + 0.3034 + 0.0008 + 0.3015, time: 30.225593]
2023-09-01 11:20:20.282: epoch 4:	0.08487077  	0.06343334  	0.11146184  
2023-09-01 11:20:20.282: Find a better model.
2023-09-01 11:20:50.610: [iter 5 : loss : 0.8128 = 0.2280 + 0.2931 + 0.0010 + 0.2907, time: 30.304878]
2023-09-01 11:20:50.861: epoch 5:	0.08948162  	0.06643476  	0.11591522  
2023-09-01 11:20:50.861: Find a better model.
2023-09-01 11:21:21.211: [iter 6 : loss : 0.7721 = 0.2082 + 0.2827 + 0.0013 + 0.2800, time: 30.316046]
2023-09-01 11:21:21.475: epoch 6:	0.09339380  	0.06935579  	0.12073664  
2023-09-01 11:21:21.475: Find a better model.
2023-09-01 11:21:52.113: [iter 7 : loss : 0.7341 = 0.1911 + 0.2721 + 0.0015 + 0.2693, time: 30.615261]
2023-09-01 11:21:52.384: epoch 7:	0.09790470  	0.07177155  	0.12569164  
2023-09-01 11:21:52.384: Find a better model.
2023-09-01 11:22:22.702: [iter 8 : loss : 0.7000 = 0.1775 + 0.2619 + 0.0018 + 0.2589, time: 30.290756]
2023-09-01 11:22:22.985: epoch 8:	0.10183691  	0.07507392  	0.13076758  
2023-09-01 11:22:22.985: Find a better model.
2023-09-01 11:22:53.519: [iter 9 : loss : 0.6669 = 0.1640 + 0.2520 + 0.0021 + 0.2487, time: 30.498590]
2023-09-01 11:22:53.799: epoch 9:	0.10582875  	0.07843937  	0.13628034  
2023-09-01 11:22:53.799: Find a better model.
2023-09-01 11:23:24.091: [iter 10 : loss : 0.6383 = 0.1546 + 0.2424 + 0.0025 + 0.2389, time: 30.261484]
2023-09-01 11:23:24.341: epoch 10:	0.10990045  	0.08005719  	0.14068179  
2023-09-01 11:23:24.341: Find a better model.
2023-09-01 11:23:54.509: [iter 11 : loss : 0.6119 = 0.1465 + 0.2331 + 0.0028 + 0.2295, time: 30.144533]
2023-09-01 11:23:54.783: epoch 11:	0.11283450  	0.08214327  	0.14368246  
2023-09-01 11:23:54.783: Find a better model.
2023-09-01 11:24:24.893: [iter 12 : loss : 0.5865 = 0.1384 + 0.2243 + 0.0031 + 0.2206, time: 30.080292]
2023-09-01 11:24:25.179: epoch 12:	0.11520979  	0.08407724  	0.14673169  
2023-09-01 11:24:25.179: Find a better model.
2023-09-01 11:24:55.368: [iter 13 : loss : 0.5652 = 0.1336 + 0.2159 + 0.0035 + 0.2122, time: 30.165263]
2023-09-01 11:24:55.652: epoch 13:	0.11628758  	0.08528735  	0.14823146  
2023-09-01 11:24:55.652: Find a better model.
2023-09-01 11:25:25.844: [iter 14 : loss : 0.5435 = 0.1276 + 0.2079 + 0.0039 + 0.2042, time: 30.163136]
2023-09-01 11:25:26.095: epoch 14:	0.11782444  	0.08682191  	0.14995840  
2023-09-01 11:25:26.095: Find a better model.
2023-09-01 11:25:56.197: [iter 15 : loss : 0.5259 = 0.1248 + 0.2003 + 0.0042 + 0.1966, time: 30.070100]
2023-09-01 11:25:56.447: epoch 15:	0.11840337  	0.08805815  	0.15095417  
2023-09-01 11:25:56.448: Find a better model.
2023-09-01 11:26:26.850: [iter 16 : loss : 0.5075 = 0.1201 + 0.1932 + 0.0046 + 0.1895, time: 30.379186]
2023-09-01 11:26:27.114: epoch 16:	0.11914189  	0.08834119  	0.15117377  
2023-09-01 11:26:27.114: Find a better model.
2023-09-01 11:26:57.296: [iter 17 : loss : 0.4918 = 0.1174 + 0.1866 + 0.0050 + 0.1828, time: 30.150286]
2023-09-01 11:26:57.579: epoch 17:	0.11976066  	0.08886116  	0.15149315  
2023-09-01 11:26:57.579: Find a better model.
2023-09-01 11:27:27.914: [iter 18 : loss : 0.4753 = 0.1131 + 0.1803 + 0.0054 + 0.1765, time: 30.302650]
2023-09-01 11:27:28.190: epoch 18:	0.11988032  	0.08957298  	0.15114993  
2023-09-01 11:27:28.190: Find a better model.
2023-09-01 11:27:58.191: [iter 19 : loss : 0.4624 = 0.1117 + 0.1744 + 0.0057 + 0.1706, time: 29.977103]
2023-09-01 11:27:58.461: epoch 19:	0.11988028  	0.08925031  	0.15105848  
2023-09-01 11:28:28.717: [iter 20 : loss : 0.4482 = 0.1084 + 0.1687 + 0.0061 + 0.1650, time: 30.218104]
2023-09-01 11:28:28.975: epoch 20:	0.11994018  	0.08919372  	0.15102132  
2023-09-01 11:28:59.280: [iter 21 : loss : 0.4360 = 0.1062 + 0.1635 + 0.0065 + 0.1599, time: 30.273487]
2023-09-01 11:28:59.532: epoch 21:	0.11992017  	0.08855035  	0.15048085  
2023-09-01 11:29:29.852: [iter 22 : loss : 0.4268 = 0.1062 + 0.1587 + 0.0068 + 0.1550, time: 30.293322]
2023-09-01 11:29:30.114: epoch 22:	0.12007999  	0.08866178  	0.15066157  
2023-09-01 11:30:00.359: [iter 23 : loss : 0.4148 = 0.1029 + 0.1542 + 0.0072 + 0.1505, time: 30.218659]
2023-09-01 11:30:00.602: epoch 23:	0.11966074  	0.08796734  	0.14990477  
2023-09-01 11:30:30.840: [iter 24 : loss : 0.4058 = 0.1022 + 0.1498 + 0.0075 + 0.1462, time: 30.218769]
2023-09-01 11:30:31.109: epoch 24:	0.11930156  	0.08781762  	0.14933865  
2023-09-01 11:31:01.579: [iter 25 : loss : 0.3963 = 0.1005 + 0.1457 + 0.0079 + 0.1422, time: 30.437685]
2023-09-01 11:31:01.839: epoch 25:	0.11852306  	0.08736414  	0.14799657  
2023-09-01 11:31:32.061: [iter 26 : loss : 0.3882 = 0.0995 + 0.1420 + 0.0082 + 0.1386, time: 30.196509]
2023-09-01 11:31:32.323: epoch 26:	0.11848316  	0.08674573  	0.14745849  
2023-09-01 11:32:02.954: [iter 27 : loss : 0.3802 = 0.0980 + 0.1386 + 0.0085 + 0.1351, time: 30.595312]
2023-09-01 11:32:03.243: epoch 27:	0.11840331  	0.08610883  	0.14691491  
2023-09-01 11:32:33.236: [iter 28 : loss : 0.3728 = 0.0968 + 0.1353 + 0.0088 + 0.1319, time: 29.967411]
2023-09-01 11:32:33.483: epoch 28:	0.11832350  	0.08557507  	0.14639306  
2023-09-01 11:32:33.483: Early stopping is trigger at epoch: 28
2023-09-01 11:32:33.483: best_result@epoch 18:

2023-09-01 11:32:33.484: 		0.1199      	0.0896      	0.1511      
